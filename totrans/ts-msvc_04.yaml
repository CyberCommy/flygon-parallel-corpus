- en: Beginning Your Microservice Journey
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices are one of the most tangible solutions in an enterprise to make
    quick, effective, and scalable applications. However, if they are not properly
    designed or understood, incorrect implementations and interpretations can lead
    to disastrous or irrecoverable failures. This chapter will begin our microservices
    journey by getting our hands dirty and diving deep into practical implementations.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter will start with a description of shopping microservices, which we
    are going to develop throughout our journey. We will learn how to slice and dice
    a system into a connected set of microservices. We will design the overall architecture
    of our shopping cart microservices, define separation layers, add cache levels,
    and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of shopping cart microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecture design of shopping cart microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation plan for shopping cart microservices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schema design and database selection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservice predevelopment aspects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing some microservices for the shopping cart
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservice design best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of shopping cart microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most important aspect while working on a new system is its design. A poor
    initial design is always a leading cause of more challenges ahead. Rather than
    moaning later, solving errors, or applying patches to cover up a poor design,
    it is always wise not to rush through the design process, spend enough time, and
    have a flexible fool-proof design. This can only be achieved by understanding
    the requirements clearly. In this section, we will give a brief overview of shopping
    cart microservices; the problem we need to solve via microservices; and an overview
    of the business process, functional view, and deployment and design views.
  prefs: []
  type: TYPE_NORMAL
- en: Business process overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The use case for our scenario is pretty straightforward. The following process
    diagram shows the end-to-end shopping process that we need to convert to microservices.
    The user adds an item to the cart, the inventory is updated, the user pays for
    the item, and then is able to check out. There are several validations involved,
    based on business rules. For example, if the user''s payment fails, then they
    should not be able to check out; if the inventory is not available, then the item
    should not be added to the cart and so on. Take a look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72153c1f-f798-4aa4-b08b-7663f60d4e55.png)'
  prefs: []
  type: TYPE_IMG
- en: Business process overview
  prefs: []
  type: TYPE_NORMAL
- en: Functional view
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Each business capability and its sub-capabilities are shown in a row, which
    essentially constitutes the shopping cart microservices. Some sub-capabilities
    are involved in more than one business capability and hence we need to manage
    some cross-cutting concerns. For example, an inventory service is used both as
    a separate process and when a person checks out a product. The following diagram
    shows the functional view of the shopping cart microservices:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/193b2e4a-8d72-423a-8488-704770f5a066.png)'
  prefs: []
  type: TYPE_IMG
- en: Functional view
  prefs: []
  type: TYPE_NORMAL
- en: The diagram combines the business capabilities into one picture. For example,
    the inventory service states there are two sub-functions—add product details and
    add product quantity and inventory items. That summarizes the inventory service's
    objectives. Creating a functional view for our system gives us a clear understanding
    of all the business processes and related things involved in them.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment view
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The requirement for deployment is pretty straightforward. Based on demand,
    we need to add new services to support various business capabilities on the fly.
    Say, for example, right now the payment medium is **PayPal**, but it may happen
    in the future that we also need to support some local payment options, such as
    bank wallets. At that time, we should easily be able to add new microservices
    without disrupting the entire ecosystem. The following diagram shows the deployment
    view. Right now, there are two nodes (one master and one slave), but based on
    demand, the number of nodes may increase or decrease based on the business capabilities,
    a spike in traffic, and other requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/35bb0ad2-fda8-42fe-b101-a7b43af015f7.png)'
  prefs: []
  type: TYPE_IMG
- en: Deployment view
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we got a brief overview of our shopping cart microservice system.
    We understood its functional, business process, and deployment views. In the next
    section, we will see the architecture design of the shopping cart microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Architecture design of our system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will look at the architectural aspects involved in distributed
    microservices. We will look at our overall architecture diagram, which we are
    going to make throughout the book, and look at aspects such as separating concerns,
    how to apply reactive patterns, and the microservice efficiency model. So, let's
    get started.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we know our business requirements, let''s design our architecture.
    Based on our knowledge of microservices and other concepts from [Chapter 1](2eeeb09d-ecd0-403b-8a64-ac754090cebe.xhtml), *Debunking
    Microservices*, we have the final overall diagram, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/71920699-b87a-49d8-a2ca-fd95f8fa8931.png)'
  prefs: []
  type: TYPE_IMG
- en: Microservice architecture
  prefs: []
  type: TYPE_NORMAL
- en: We will study components such as API Gateway, service registry, and discovery
    in much more detail in later chapters. Here, they are just mentioned as part of
    the overall view.
  prefs: []
  type: TYPE_NORMAL
- en: Let's understand the key components in the preceding diagram to get a better
    idea of our architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Different microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If we understood our business requirements correctly, we will come up with
    the following business capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: Product catalog
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Price catalog
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discounts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Invoice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Payment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inventory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on our business capabilities and single responsibility, we divided our
    microservices briefly into various smaller applications. In our design, we ensured
    that each business capability is implemented by a single microservice and we don't
    overload a microservice with more than one microservice. We briefly divided our
    entire system into various microservices, such as a shopping cart microservice,
    products microservice, payment microservice, consumer microservice, cache microservice,
    price calculations and suggestions microservice, and so on. The overall granular
    flow can be seen in the preceding diagram. Another important thing to notice is
    that each microservice has its separate data store. Different business capabilities
    have different needs. For example, when a person checks out a product, if the
    transaction failed, then all transactions such as adding a product to a customer's
    purchase item, deducting quantity from a product inventory, and so on should be
    rolled back. In this case, we need relational databases that can handle transactions,
    whereas in the case of products, our metadata constantly changes. Some products
    may have more features than other products. In such cases, having a fixed relational
    schema is not wise and we can go for NoSQL data stores.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing this book, MongoDB 4.0 had not yet been introduced. It
    provides the following transactional plus NoSQL benefits in one.
  prefs: []
  type: TYPE_NORMAL
- en: Cache microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next component that we are going to see is centralized cache storage. This
    microservice directly interacts with all microservices and we may use this service
    to cache our responses when needed. Often it may happen that a service goes down,
    and we may still preserve the application by showing cached data (things such
    as product information and metadata rarely change; we may cache them for a certain
    interval of time, thus preventing an extra database hop). Having a cache increases
    the performance and availability of the system, which ultimately leads to cost
    optimization. It provides a blazing fast user experience. As microservices are
    constantly moving, often they may not be reached. In such cases, it is always
    advantageous to have a cached response when reaching out to availability zones
    fails.
  prefs: []
  type: TYPE_NORMAL
- en: Service registry and discovery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the start of the diagram, we included the service registry. This is a dynamic
    database maintained on the startup and shutdown events of all microservices. Services
    subscribe to the registry and listen for updates to know whether the service has
    gone down or not. The entire process is done through the service registry and
    discovery. The registrator updates the registry whenever a service goes down or
    goes up. This registry is cached on all clients who subscribe to the registry,
    so whenever a service needs to be interacted with, an address is fetched from
    this registry. We will look in detail at this process in [Chapter 6](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml),
    *Service Registry and Discovery*.
  prefs: []
  type: TYPE_NORMAL
- en: Registrator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next component that we are going to look at, which is available alongside
    the cache, is the **Registrator** ([http://gliderlabs.github.io/registrator/latest/](http://gliderlabs.github.io/registrator/latest/)).
    The Registrator is a third-party service registration tool that basically watches
    for startup and shutdown events of microservices and, based on the output of those
    events, dynamically updates the centralized service registry. Different services
    can then directly communicate with the registry to get updated locations of services.
    The Registrator ensures that registration and deregistration code is not duplicated
    across systems. We will look at this in more detail in [Chapter 6](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml),
    *Service Registry and Discovery*, where we integrate the Registrator with the
    consul.
  prefs: []
  type: TYPE_NORMAL
- en: Logger
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the important aspects of any application is the logs. Analyzing any problem
    becomes very easy when appropriate logs are used. Hence, here we have a centralized
    logger microservice that is based on the famous Elastic framework. Logstash watches
    for log files and transforms them into appropriate JSON before pushing to Elasticsearch.
    We can visualize the logs through the Kibana dashboard. Each microservice will
    have its unique UUID or some log pattern configured. We will look at this in much
    more detail in [Chapter 9](90996850-1ced-4678-a297-3e1fee118eb9.xhtml), *Deployment,
    Logging, and Monitoring*.
  prefs: []
  type: TYPE_NORMAL
- en: Gateway
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the most important part and the starting point of our microservices.
    It is the central point where we will handle cross-cutting concerns, such as authentication,
    authorization, transformation, and so on. While creating different microservices
    on various servers, we usually abstract the information of hosts and ports from
    the client. The client just makes a request to the gateway and the gateway takes
    care of the rest by interacting with the service registry and load balancer and
    redirecting the request to the appropriate service. This is the most important
    part in a microservice and it should be made highly available.
  prefs: []
  type: TYPE_NORMAL
- en: After going through the architecture diagram, now let's understand some aspects
    related to the architecture that we will use later.
  prefs: []
  type: TYPE_NORMAL
- en: Design aspects involved
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before actually coding, we need to understand the *how* and *why*. Let''s say
    if I have to cut down a tree (PS: I am a nature lover and I don''t support this),
    instead of directly chopping it down, I would rather first sharpen the axe. We
    are going to do the same, sharpen our axe first. In this section, we are going
    to look at various aspects involved in designing microservices. We will look at
    what models of communication to go through, what is included in microservices,
    and what areas to take care of in order to achieve efficient microservice development.'
  prefs: []
  type: TYPE_NORMAL
- en: Microservice efficiency model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Based on the various needs and requirements, we have defined a microservice
    efficiency model. Any proper implementation of microservices must adhere to it
    and provide a standard set of functionalities, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Communication over HTTP and HTTP listeners
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Message or socket listeners
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storage capabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Proper business/technical capabilities definitions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service endpoint definitions and communication protocols
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service contacts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service documentation through tools such as Swagger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following diagram, we have summarized our microservice efficiency model:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/45ff4392-2534-40b5-9a86-b3c583c80c30.png)'
  prefs: []
  type: TYPE_IMG
- en: Microservice efficiency model
  prefs: []
  type: TYPE_NORMAL
- en: Let's now look at each of the four sections of the preceding diagram.
  prefs: []
  type: TYPE_NORMAL
- en: Core functionalities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Core functionalities are part of the microservice itself. They include the
    following functionalities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Technical capabilities**: Any technical functionalities needed, such as interacting
    with the service registry, sending out events to an event queue, processing events,
    and so on, are involved here.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Business capabilities**: Microservices written to achieve a business capability
    or fulfill a business requirement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HTTP listeners**: A part of the technical capability; here we define APIs
    for external consumers. While starting the server, an HTTP listener is started,
    eliminating any other needs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Message listeners**: A part of event-based communication where the sender
    doesn''t worry whether the message listeners are implemented.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API Gateway**: One point of communication for the end client. The API Gateway
    is the single place for handling any core concerns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Document storage or data storage**: Our data layer for the application. Based
    on our needs, we may use any of the available data stores.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supporting efficiencies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'These are solutions to help in achieving core microservice implementation.
    They include the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load balancer**: Anapplication load balancer to redirect based on changes
    in the server topology. It handles dynamic services going up or down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service registry**: A runtime environment for services if they go up or down
    to publish to. It maintains the active log of all services along with the available
    instances.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Central logs**: A core centralized logging solution to observe logs all places,
    rather than individually opening containers and seeking logs there.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Security**: Checking authentic client requests through common available mechanisms,
    such as OAuth, token-based, IP-based, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Testing**: Testing out the microservices and essentials, such as inter-microservice
    communication, scalability, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure role
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the infrastructure expectations needed for efficient microservice
    implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Server layer**: An efficient mechanism to choose for deploying our microservice.
    Well-known options include Amazon EC2 instance, Red Hat OpenShift, or serverless.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Container**: Dockerizing the application, so it can run easily on any OS
    without much fuss about installation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CI/CD**: A process to maintain easy deployment cycles.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clustering**: Server load balancers to handle the load or spike in applications
    as required.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Governance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Processes and reference information to ease up our overall life cycle in application
    development include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Contract testing**: Testing out microservice expectations and actual outputs
    to make sure frequent changes don''t break anything'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalablity**: Spawning new instances and removing those instances on demand
    to handle spikes in load'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Documentation**: Generating documentation to easily understand what someone
    is actually doing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will carve out an implementation plan for our microservice
    development.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation plan for shopping cart microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the key challenges in microservice development is fixing the scope of
    a microservice:'
  prefs: []
  type: TYPE_NORMAL
- en: If a microservice is too big, you end up in monolithic hell and get stuck in
    a huge turnaround time, with difficulty adding new features and implementing bug
    fixes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a microservice is too small, either we end up with tight coupling among services
    or too much code duplication and resource consumption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a microservice size is right, but the bounded context isn't fixed, such as
    services sharing a database, it leads to higher coupling and dependencies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we are going to devise an implementation plan for our shopping
    cart microservices. We will formulate a general workflow or plan and design our
    system according to the plan. We will also see what to do when our scope is not
    clear, and how to proceed in such cases to ultimately reach our microservices
    goal. We will look at how to potentially avoid the aforementioned loop holes.
  prefs: []
  type: TYPE_NORMAL
- en: What to do when the scope is not clear
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Until now, we have designed our architectural plan based on scoping microservices,
    but that was when our requirements were pretty clear. We knew exactly what we
    had to make. But in most cases, you won''t have a similar scenario. You will either
    be migrating from a monolithic system to microservices or you will be engulfed
    in constantly changing requirements or business capabilities that are still evolving,
    or it may be that the complexities of technical capabilities could not be estimated
    at the primer stage, making it difficult for you to scope the microservices. The
    following section is for such scenarios where you can perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dream big and start big**: Deciding the scope of microservices is always
    a huge task, as it defines the overall bounded context. If that is not decided
    clearly, we ultimately get stuck in monolithic hell. However, if the scope is
    narrowed down too much, it has its disadvantages too. You will suffer difficulties,
    as you will end up with data duplication between two microservices, unclear responsibility,
    and difficulty deploying services independently. Carving out microservices from
    existing microservices is much easier than managing too narrowly carved microservices.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Separate out microservices from existing microservices**: Once you feel that
    a microservice is too big, you will need to start separating out the service.
    First of all, the scope needs to be decided for both the existing and new microservice
    based on business and technical capabilities. Anything pertaining to a new microservice
    goes into its own module. Then any communication between the existing modules
    is moved to common interfaces, such as HTTP API/event-based communication, and
    so on. Microservices can be planned for later development too; when in doubt,
    always create a separate module, so we can easily move it out.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Identify technical capabilities**: A technical capability is anything that
    supports other microservices, such as listening to events emitted by event queues,
    registering to the service registry, and so on. Keeping the technical capability
    inside the same microservice can be a huge risk as it will soon lead to tight
    coupling and the same technical capability might be implemented by lots of other
    services too.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Adherence standards for microservices based on business and technical capabilities**: Microservices
    adhere to fixed standards—self-sufficiency, resiliency, transparency, automation,
    and distribution. Each of the points can briefly be stated as:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A microservice serves a single business capability (modularity is the key thing).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A microservice can be easily deployed individually. Each service would have
    its own build script and CI/CD pipeline. The common point would be the API Gateway
    and service registry.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can easily find out the owners of microservices. They would be distributed
    and each team can own one microservice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A microservice can be replaced without much hassle. We will have common registration
    options via the service registry and discovery. Each of our services can be accessed
    via HTTP.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By following these steps, you will ultimately reach the microservice level,
    where each service will be serving a single business capability.
  prefs: []
  type: TYPE_NORMAL
- en: Schema design and database selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The main part of any application is its database selection. In this section,
    we will look at how to design our database for microservices, whether to keep
    it separate, to keep it shared, and which database to go to—SQL or NoSQL? We will
    look at how to categorize data stores based on data types and business capabilities.
    There are lots of options available. Microservices support polyglot persistence.
    The approach of selecting a particular data store based on business capabilities
    and needs is termed polyglot persistence. The following points discuss which database
    to refer to based on use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: We can leverage Apache Cassandra to support tabular data, such as inventory
    data. It has options such as distributed consistency and lightweight transactions
    to support ACID transactions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can leverage Redis to support cache data where the data model is simply a
    key-value pair. Read operations in Redis are super fast.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can leverage MongoDB to support product data stored in unstructured form
    with the ability to index on any particular field. A document-oriented database
    such as MongoDB has powerful options, such as an index in specific attributes
    to search faster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can leverage GraphQL to support complex relationships. GraphQL is extremely
    useful for many-to-many relationships, for example, our shopping cart recommendation
    system. Facebook uses GraphQL.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use relational databases to support legacy systems or systems that require
    maintaining structured relational data. We use relational data where data doesn't
    change frequently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we will look into these points in detail and understand things
    such as how should the data layer be in a microservice. Then, we will look into
    types of databases and understand their advantages, disadvantages, and use cases.
    So, let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: How to segregate data between microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The hardest thing about microservices is our data. Each microservice should
    maintain data by owning their individual database. Data must not be shared via
    a database. This rule helps us to eliminate a common case that leads to tight
    coupling between different microservices. If two microservices share the same
    database layer, and if the second service doesn't know about the first service
    changing the database schema, it will fail. Due to this, service owners need to
    be constantly in touch and this differs from our microservice path.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the questions that may come to our mind are how will the database stay
    in the microservice world? Will the services be sharing databases? If yes, then
    what would be the repercussions of shared data? Let''s answer these questions.
    We all know the phrase, *with ownership comes responsibility*. Similarly, if a
    service owns a data store, then it is solely responsible for keeping it up to
    date. Also, for optimal performance, the data that a microservice needs should
    be nearby or local, preferably within the microservice container itself, as microservices
    need to often interact with it. So far, we have learned about two principles for
    how to segregate data:'
  prefs: []
  type: TYPE_NORMAL
- en: Data should be divided so that each microservice (fulfilling a certain business
    capability) should easily ensure that the database is up to date and not allow
    any other services direct access.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data relevant to that microservice should be in a nearby vicinity. Keeping it
    far away increases database costs plus network costs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the general processes for segregating data is to build up a domain model
    comprising entities, objects, and aggregates. Let's say we have the following
    use cases—allowing a customer to search for a product, allowing a customer to
    buy a particular type of product, and allowing a customer to buy the product. 
    We have three functionalities—search, buy, and inventory. Each functionality has
    its own needs and so the product database is stored in the product catalog service,
    the inventory is stored differently, and the search service queries the product
    catalog service, and these results are cached.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will look at these rules in detail with an example, which
    will help us to decide where to keep a data layer and how it should be divided
    to give us maximum advantage.
  prefs: []
  type: TYPE_NORMAL
- en: Postulate 1 – data ownership should be regulated via business capabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the major ideas for deciding where data belongs in a microservice system
    is deciding on the basis of business capabilities. A microservice is just a service
    fulfilling a business capability that cannot be possible without having a data
    store. A business capability defines the contained region of the microservice.
    Everything that belongs to handling that capability should reside inside the microservice.
    For example, only one microservice should have a customer's personal details,
    comprising a delivery address, and email address. Another microservice can have
    a customer's purchase history and a third microservice can have customer preferences.
    The microservice responsible for the business capability is responsible for storing
    the data and keeping it up to date.
  prefs: []
  type: TYPE_NORMAL
- en: Postulate 2 – replicate the database for speed and robustness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The second factor at play when selecting where a piece of data should be stored
    in a microservice system is decided based on the scope or locality. There's a
    big change if the data store is in the vicinity of a microservice or far off,
    even though we are talking about the same data. A microservice can query its own
    database for data or a microservice can query another microservice for that same
    data. The latter, of course, will come with cons and tight dependencies. Looking
    in the local neighborhood is much faster than looking at different cities. Once
    you have decided on the scope of the data, you will realize that microservices
    need to talk to one another very often.
  prefs: []
  type: TYPE_NORMAL
- en: 'This kind of microservice often creates a very tight dependency, meaning we
    are stuck to the same old monolithic stuff. To loosen this, coupling a caching
    database or maintaining a cache store often comes in handy. You can cache responses
    as they are, or you can add a read model to expire cache after a certain time
    interval. The microservice that owns the local data should be in the best position
    to decide when a particular piece of code becomes invalid based on the business
    capability. HTTP cache headers should be used to control caching. Managing a cache
    is simply controlling the cache-control header. For example, the line `cache-control:
    private, max-age:3600` caches the response for 3,600 seconds.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next section, we will look into how to select the best database based
    on the following criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: How is my data? Is it a bunch of tables, a document, a key-value pair, or a
    graph?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much is my data write and read frequency? Do my write requests come randomly
    or are they evenly distributed in time? Is there a read-all-at-once scenario?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there more write operations or are there more read operations?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to choose a data store for your microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most fundamental questions that pop up while designing microservices
    is *how does one choose the correct data store?* We will be talking about this
    in much more detail in the *Service* *state* section in [Chapter 7](162a0f25-2890-4a58-aa41-e9c9b5fc6c2d.xhtml),
    *Service State and Interservice Communication*, but here, let's get our fundamentals
    right.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first and foremost step in selecting any ideal data store is to find out
    the nature of our microservice data. Based on the nature of the data, we can briefly
    define the following categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ephemeral or short-lived data**: A cache server is a classic example of short-lived
    data. It is a temporary store whose objective is to enhance the user experience
    by serving information in real time, thus avoiding frequent database calls. This
    is especially important where most of the operations are read intensive. Also,
    this store has no extra durability or security concerns as it does not have a
    master copy of the data. However, that being said, this should not be treated
    lightly as it has to be highly available. Failures can cause poor user experience
    and subsequently crash the main database as it won''t be able to handle such frequent
    calls. Examples of such data stores include Redis, Elasticsearch, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transient or momentary data**: Data such as logs and messages usually come
    in bulk volume and frequency. Ingestion services process this information before
    passing it to the appropriate destinations. Such data stores need high frequency
    writes. Features such as time series data or JSON format are added advantages.
    The support requirements for transient data are higher as it is mostly used in
    event-based communications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operational or functional data**: Operational data focuses on any information
    that is gathered from user sessions, such as user profiles, user shopping cart,
    wish lists, and so on. Being the primary data store, this kind of microservice
    provides better user experience with real-time feedback. For business continuity,
    this kinds of data must be retained. Here the durability, consistency, and availability
    requirements are very high. We can have any kind of data store as per our needs,
    providing any of the following structures—JSON, graph, key-value, relational,
    and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transactional data**: Data gathered from a series of processes or transactions,
    such as payment processing, order management, must be stored in a database that
    supports ACID controls to avoid disasters (we will mostly use relational databases
    for transactional data). At the time of writing of this book, MongoDB 4.0, supporting
    transactional data, was still not available. Once generally available NoSQL data
    stores can be used even for transaction management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design of product microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Based on our requirements, we can categorize data into the following various
    segments:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Microservice** | **Data store type** |'
  prefs: []
  type: TYPE_TB
- en: '| Caching | Ephemeral (example: ELK) |'
  prefs: []
  type: TYPE_TB
- en: '| User comments, ratings, feedback, and product top sellers | Transient |'
  prefs: []
  type: TYPE_TB
- en: '| Product catalog | Operational |'
  prefs: []
  type: TYPE_TB
- en: '| Product search engine | Operational |'
  prefs: []
  type: TYPE_TB
- en: '| Order processing | Transactional |'
  prefs: []
  type: TYPE_TB
- en: '| Order fulfillment | Transactional |'
  prefs: []
  type: TYPE_TB
- en: For our product catalog database, we will proceed with the following design.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the current chapter, we are going to go with the product catalog service,
    which requires us to use an operational data store. We will go with MongoDB. A
    product will have at least the following items—variant, price, hierarchy, vendor,
    feedback email, configurations, description, and so on. Instead of getting everything
    in a single document, we will use the following schema design:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Some of the advantages of this schema design are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It is easy to have a faceted search which returns results in quick milliseconds
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each index will end with `_id`, making it useful for pagination
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficient sorting can be done on various attributes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservice predevelopment aspects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we are going to look at some common development aspects that
    we will follow throughout the book. We will understand some common aspects, such
    as which HTTP message code to use, how to set up logging, which kinds of logging
    to keep, how to use PM2 options, and how to trace a request or attach a unique
    identifier to a microservice. So, let's get started.
  prefs: []
  type: TYPE_NORMAL
- en: HTTP code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**HTTP code** dominates standard API communication and are one of the general
    standards across any general-purpose API. It resolves common issues for any request
    that is made to the server, whether it is successful, whether it is producing
    a server error, and so on. HTTP resolves every single request with HTTP code with
    ranges that indicate the nature of the code. HTTP codes are standards ([http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html](http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html))
    based on various code and response actions are taken accordingly, so the concept
    of not reinventing the wheel essentially applies here. In this section, we will
    look at some of the standard code ranges along with their meanings.'
  prefs: []
  type: TYPE_NORMAL
- en: 1xx – informational
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **1xx** code provides primitive functionalities, such as operations happening
    in the background, switching protocols, or the state of the initial request. For
    example, `100 Continue` indicates that the server has received request headers
    and is now awaiting the request body, `101 Switching Protocols` indicates that
    the client has requested a protocol change from the server and the request has
    been approved, and `102` indicates that the operation is happening in the background
    and will take time to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 2xx – success
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is to indicate that a certain level of success has been achieved with information
    success code used in HTTP requests. It packages several responses into specific
    code. For example, `200 Ok` means that nothing went wrong and a GET or POST request
    was successful. `201 Created` means that a GET or POST request has been fulfilled
    and a new resource has been created for the client. `202 Accepted` means that
    a request has been accepted and is now being processed. `204 No Content` means
    that there is no content coming back from the server (very similar to `200`).
    `206 Partial Content` is usually used for paginated responses indicating there
    is more data to follow.
  prefs: []
  type: TYPE_NORMAL
- en: 3xx – redirections
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **3xx** range is all about the status of the resource or the endpoint. It
    indicates what additional actions must be taken to complete that request as the
    server is still accepting communication, but the endpoint contacted is not the
    correct point of entry in the system. The most common codes used are `301 Moved
    Permanently`, which indicates that future requests must be handled by different
    URIs, `302 Found`, which indicates a temporary redirect is needed for some reason,
    `303 See other`, which tells browsers to see another page, and `308 Permanent
    Redirect`, which indicates a permanent redirection for that resource (this is
    the same as `301`, but does not allow the HTTP method to change).
  prefs: []
  type: TYPE_NORMAL
- en: 4xx – client errors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This range of codes is the most well known due to the traditional `404 Not found`
    error, which is a well-known placeholder for URLs that are not properly formed.
    This range of codes indicates that there is something wrong with the request.
    Other well-known codes include `400 Bad Request` (a request that is syntactically
    incorrect), `401 Unauthorized` (lack of authentication from the client), and `403
    Forbidden` (the user does not have privileges). Another common code is `429 Too
    Many Requests`, which is used for rate-limiting requests to indicate that traffic
    from the particular client is rejected.
  prefs: []
  type: TYPE_NORMAL
- en: 5xx – server errors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This range of codes indicates that there has been a processing error on the
    server or there is something wrong in the server. Whenever a **5xx** code is issued,
    it states that there is some sort of problem in the server that cannot be fixed
    by the client and has to be handled accordingly. Some of the widely used codes
    are `500 Internal Server Error` (this indicates that an error has occurred in
    the server's software and no information is disclosed), `501 Not Implemented` (this
    indicates an endpoint that is not yet implemented, but is still being requested
    for), and `503 Service Unavailable` (this states that the server is down for some
    reason and is not able to process any more requests). On receiving `503`, appropriate
    actions must be taken to start the server again.
  prefs: []
  type: TYPE_NORMAL
- en: Why HTTP code is vital in microservices?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices are fully distributed and constantly moving. Therefore, without
    any standard means of communication, we won't be able to trigger the corresponding
    fail-safe measure. For instance, if we implement the circuit breaker pattern,
    the circuit should know that whenever it receives the **5xx** series of code,
    it should keep the circuit open as the server is unavailable. Similarly, if it
    received `429`, then it should block the request from that particular client.
    The complete microservice ecosystem includes proxies, caches, RPCs, and other
    services for which HTTP is the common language. Based on the aforementioned code,
    they can take appropriate action accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn about logging aspects and how to handle logging
    in microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Auditing via logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Until now, we have heard that microservices are distributed and services are
    constantly in flux. We need to keep track of all the services and the output that
    they throw. Using `console.log()` is a very bad practice as we won''t be able
    to keep track of all the services because `console.log()` doesn''t have a fixed
    format. Also, we need a stack trace whenever there is an error to debug the possible
    problem. To have distributed logging, we will use the `winston` module ([https://github.com/winstonjs/winston](https://github.com/winstonjs/winston)).
    It has various options, such as log levels, log formats, and so on. For each microservice,
    we will be passing a unique microservice ID, which will identify it when we aggregate
    the logs. For aggregation, we will use the famous ELK Stack, described in [Chapter
    9](90996850-1ced-4678-a297-3e1fee118eb9.xhtml), *Deployment, Logging, and Monitoring*.
    The following are various kinds of log, sorted in priority order, which are generally
    used:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Fatal/emergency (0)**: This is the most catastrophic level, used when the
    system won''t be able to recover or function normally. This forces things like
    shutdown or some other heinous errors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alert (1)**: Upon receiving this severe log, actions must be taken immediately
    to prevent system shutdowns. The critical difference here is that the system is
    still usable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Critical(2)**: Here, action needs not be taken immediately. This level includes 
    situations such as failure to connect to a socket, failure to get the latest chat
    message, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Error(3)**: This is a problem that should be investigated. The Sys Admin
    has to be notified about it, but we don''t need to drag him out of bed as this
    is not an emergency. It is generally used to track overall quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Warning(4)**: This level is used when there might be an error or there might
    not be an error. Warning conditions are close to errors but they are not errors.
    They indicate potentially harmful situations or events that might possibly lead
    to an error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Notice(5)**: This level is a normal log, but with some significant conditions.
    As an example, you may get messages such as Caught SIGBUS attempting to dump core
    in ....'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Info(6)**: This level is used for unnoticeable information, such as the server
    has been running for *x* hours and interesting runtime events. These logs are
    immediately visible on the console, as the purpose of these logs is to be conservative.
    These logs should be kept to the minimum.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Debug(7)**: This is used for detailed information on the flow through the
    system. It includes messages used for the sake of debugging, for example, something
    like Opening file... or Getting products for productId 47.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logs need to be enabled. If you enable fatal logs, then all logs will be seen.
    If you enable info logs, then only info and debug logs will be seen. Logs for
    all levels have their custom method in Winston and we can add our own format.
  prefs: []
  type: TYPE_NORMAL
- en: PM2 process manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Node.js is single threaded, meaning any use of a JavaScript `throw` statement
    will raise an exception that must be handled using the `try...catch` statements.
    Otherwise, the Node.js process will exit immediately, making it unavailable to
    process any further requests. As Node.js runs on single process uncaught exceptions,
    it needs to be handled carefully. If not, it will crash and bring down the whole
    application. So, the golden rule in Node.js is *if any exception bubbles out to
    the top without being handled, our application dies*.
  prefs: []
  type: TYPE_NORMAL
- en: '**PM2** is a process manager designed to keep our service alive forever. It
    is a production process manager with a built-in load balancer and is the perfect
    candidate for microservices. PM2 comes in quite handy as it allows us to declare
    the behavior of each microservice with a simple JSON format. PM2 is an advanced
    task runner with built-in monitoring and zero downtime utilities. Scaling a PM2
    command is just a matter of typing the number of instances we want to spawn up
    or down. Starting a new process with PM2 will initiate a fork mode of the process
    and let the load balancer handle the rest. PM2 acts as a round robin between the
    main process and the process workers so that we can cope with the extra load at
    the same time. Some of the standard deployment features provided by PM2 are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `pm2 start <process_name>` | Starts a process in fork mode with auto-restart
    when the server goes down |'
  prefs: []
  type: TYPE_TB
- en: '| `pm2 stop <process_name>` | Stops the PM2 process |'
  prefs: []
  type: TYPE_TB
- en: '| `pm2 restart <process_name>` | Restarts a process with updated code |'
  prefs: []
  type: TYPE_TB
- en: '| `pm2 reload <process_name>` | Reloads PM2 process with zero downtime |'
  prefs: []
  type: TYPE_TB
- en: '| `pm2 start <process_name> -i max` | Starts a PM2 process in the max number
    of fork modes; that is, it will spawn the max number of instances based on the
    number of CPUs available |'
  prefs: []
  type: TYPE_TB
- en: '| `pm2 monit` | Monitors a PM2 process |'
  prefs: []
  type: TYPE_TB
- en: '| `pm2 start ecosystem.config.js --env staging` | Starts a process, taking
    configurations from `ecosystem.config.js` |'
  prefs: []
  type: TYPE_TB
- en: 'PM2 can also be used as a deployment tool or an advanced means for CI/CD. All
    you need to do is define your deployment script in the `ecosystem.config.js` file,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, all we have to do is hit the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This command acts as a local deployment tool. Adding things such as path, PEM
    file key, and so on are steps where we can connect to the server. Once connected
    to the server using the specified user, the PM2 process starts and we can run
    our application. The latest Git repository will be cloned and then PM2 will start
    the `dist/Index.js` file in the forever option.
  prefs: []
  type: TYPE_NORMAL
- en: Tracing requests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Tracing request** origins is very important, as sometimes we need to reconstruct
    the entire journey of the customer in our system. It provides useful information
    on the system, such as sources of latency. It also enables developers to observe
    how an individual request is being handled by searching across all aggregated
    logs with some unique microservice ID, or to find out the overall journey of the
    user by passing in a time frame. The following is a sample log generated through
    Winston:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'All important data can be seen from the log. We will be using the ELK Stack
    for our log. ELK has huge advantages, as it combines the power of the following
    three tools—**Logstash** (configured to read logs or register events from a myriad
    of sources and send log events to multiple sources), **Kibana** (a configurable
    web dashboard that is used to query Elasticsearch for log information and present
    it to the user), and **Elasticsearch** (a search server based on Lucene, used
    to collect logs, parse them, and store them for later purposes, providing a RESTful
    service and schema-free JSON documents). It has the following advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Each instance of **Winston** is configured with ELK. Thus, our log service is
    externalized and the storing of our logs is centralized. Hence, there is a single
    data source where requests can be traced.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to the auto-schema definition and proper format of Winston, we have log-structured
    data. For example, if I want to query all the logs from `4:40` to `4.43`, I am
    just an Elasticsearch query away as I know that all my logs have a time component
    at a fixed level in JSON.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Winston log formats take care of creating and passing a correlational identifier
    across all the requests. Therefore, server-specific logs, if required, can be
    traced easily by querying that specific parameter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our logs are searchable through Elasticsearch. Elasticsearch provides Kibana
    as well as REST APIs, which can be called upon to look at any point in time through
    all the data in the data source. A lucene-based implementation helps to fetch
    results faster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The logging level can be changed on the fly in Winston. We can have various
    log levels and based on the priority of logs, the lower level of logs may or may
    not be seen. This is pretty helpful in solving production-level issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we looked at logging and how it solves such problems as understanding
    customer behavior (how much time a customer spends on the page, how much time
    an action on each page took, what are some of the possible problems, and so on).
    In the next section, we will start developing shopping cart microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Developing some microservices for a shopping cart
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will develop some microservices for a shopping cart, uniquely
    identified by their business capabilities. So, let''s get a quick overview of
    our current problems before getting our hands dirty. The shopping cart monolithic
    was going well, but with the advent of digitalization, there was a huge increase
    in transaction volumes—300-500 times compared the original estimates. The end
    to end architecture was reviewed and it had the following limitations, based on
    which the microservice architecture was introduced:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Firmness and sturdiness**: The firmness of the system was greatly impacted
    due to errors and stuck threads, which forced the Node.js application server to
    not accept any new transactions and do a forceful restart. Memory allocation issues
    and database lock threads were major problems. Certain resource-intensive operations
    were impacting the entire application and the resource allocation pool was always
    consumed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment outages**: Due to adding more and more capabilities, the server
    outage window increased largely because of the server startup time. The large
    size of `node_modules` turned out to be the primary culprit. Since the entire
    application was packaged as a monolith, the entire application demanded to install
    the `node` modules again and again and then start our node-HTTP server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sharpness**: The complexity of code increased exponentially over time and
    so did the distribution of work. A tight coupling dependency was created among
    the teams. As a result, changes were harder to implement and deploy. Impact analysis
    became too complex to perform. As a result, it was like *fix one bug, 13 others
    come up*. Such complexity rose to a situation where the `node_modules` size was
    over 1 GB. Such complications eventually stopped **continuous integration** (**CI**)
    and unit test casing. Eventually, the quality of the product deteriorated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Such situations and problems demanded an evolutionary approach. Such situations
    demanded a microservices development approach. In this section, we will look at
    the microservice setup approach, which will give us various advantages, such as
    selective service scaling, technological independence (easy migration to new technologies),
    containing faults, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Itinerary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s quickly go through the itinerary that we are going to perform in this
    exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Development setup and prerequisite modules**: In this section, we will summarize
    the development tools and `npm` modules that we will use in the project. We will
    look at such prerequisites as application properties, custom middleware, dependency
    injection, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application directory configurations**: We will analyze the structure that
    we will use in other microservices and understand all the files that we will need
    and where to write the logic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configuration files**: We will have a look at all the configuration files
    through which we can specify various settings, such as database hostname, port
    URL, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Processing data**: We will briefly summarize code patterns and how they can
    support optimal developer output and make the developer''s life easier.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ready to serve**: We will analyze `package.json` and Docker files and see
    how we can use these two files to make our microservice ready to serve any service
    requests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, let's get started with our itinerary.
  prefs: []
  type: TYPE_NORMAL
- en: Development setup and prerequisite modules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will look at several aspects that we need to take care of
    while developing and creating our **Development Sandbox.** We will get an overview
    of all the node modules that we will use and the core aspects that each `node`
    module will satisfy. So, it's time to get our hands dirty.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note: We saw how to write custom types in [Chapter 2](c1987454-3c62-4e25-abf5-28a9abf833e8.xhtml), *Gearing
    up for the Journey*, for any node module that is not written in ES6\. We will
    leverage this for any module whose types are not available in the `DefinitelyTyped`
    repository.'
  prefs: []
  type: TYPE_NORMAL
- en: Repository pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will understand the repository pattern, which gives us the
    power to have our code in a single place. TypeScript introduced generics (just
    like the feature in Java), which we are going to utilize to the full extent in
    our microservices. The repository pattern is one of the most widely used patterns
    to create an enterprise-level application. It enables us to directly work with
    data in the application by creating a new layer for database operations and business
    logic.
  prefs: []
  type: TYPE_NORMAL
- en: Combining generics and the repository pattern opens up countless advantages.
    Working with the JavaScript application, we need to deal with problems such as
    code sharing between applications and going modular. The generic repository pattern
    solves this by giving us the power to write an abstraction of data when we have
    one abstract class with generics (or many depending on the business capability)
    and reuse the implementation layer independent of the data model, passing only
    the types to someone's classes. When we talk about the repository pattern, it
    is a repository where we can keep all the operations of the database (CRUD) in
    one locality for any generic business entity. When you need to do the operation
    in the database, your application calls the repository methods, thus enabling
    transparency for whoever calls. Combining this with generics leads to one abstraction,
    one base class that has all the common methods. Our `EntityRepository` only extends
    the base class with all the implementations of the database operations.
  prefs: []
  type: TYPE_NORMAL
- en: This pattern follows the open/closed principle, where the base class is open
    for extension but closed for modification.
  prefs: []
  type: TYPE_NORMAL
- en: 'It has various advantages, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It can be used as an extensibility measure where you just need to write one
    class for all common operations, such as CRUDs, when all other entities should
    have similar operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Business logic can be unit tested without touching the data access logic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The database layer can be reused
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Database access code is centrally managed in order to implement any database
    access policies and, like caching, it is a walk in the park
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring application properties
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As per the twelve-factor standards (recall the, *Twelve-factor app of microservices*, section
    in [Chapter 1](2eeeb09d-ecd0-403b-8a64-ac754090cebe.xhtml), *Debunking Microservices*),
    one code base should suffice for multiple environments, such as QA, dev, production,
    and so on. Ensure that we have the application properties file in our application,
    where we can specify the environment name and environment-related stuff. Config
    ([https://www.npmjs.com/package/config](https://www.npmjs.com/package/config))
    is one such module, which helps you in organizing all configurations. This module
    just reads configurations files in the `./config` directory (it should be at the
    same level as `package.json`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Salient features of config are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It can support formats such as YAML, YML, JSON, CSV, XML.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It can create one directory config parallel to `package.json` and inside it
    create one file, `default.ext` (here, `.ext` can be any of the aforementioned
    formats).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To read from config files, just use the following lines of code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: It has support for various config files, where a hierarchy is maintained for
    supporting various environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It even has support for multiple node instances; the perfect fit for microservices.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom health module
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, adding new modules to the application causes the application to go
    out of order. We need custom health modules to actually keep watch on the service
    and alert us that the service is out of order (service discovery does exactly
    this, which we will look at in [Chapter 6](0c5e001e-6dca-4805-866c-7be793a91c70.xhtml),
    *Service Registry and Discovery*). We will be using `express-ping` ([https://www.npmjs.com/package/express-ping](https://www.npmjs.com/package/express-ping))
    to find out the health of our node. By introducing this module in our middleware,
    we can expose a simple API that will tell us about its internal health to both
    operators and other applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Salient features of `express-ping` are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It is a zero configuration module, where just injecting this in the middleware
    will expose a health endpoint.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To use this module, simply use the following lines of code:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding just the previous LOCs will expose a `<url>/health` endpoint that we
    can use for health check purposes.We can add authorized access or even use middleware
    for our exposed `/ping` API, which is just plain old express:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This endpoint can be used anywhere just to check the health of the application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dependency injection and inversion of control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will see how to use basic principles such as dependency
    injection and inversion of control. Coming from a Java background, I tend to use
    these principles in any application in order to make my development process smoother.
    Luckily, we have the exact modules matching our requirements. We will use `inversify`
    ([https://www.npmjs.com/package/inversify](https://www.npmjs.com/package/inversify))
    as the inversion of control container and `typedi` ([https://www.npmjs.com/package/typedi](https://www.npmjs.com/package/typedi))
    for dependency injection.
  prefs: []
  type: TYPE_NORMAL
- en: Inversify
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Inversion of control** (**IOC**) is about getting freedom, more flexibility,
    and less dependency on others. Say you are using a desktop computer, you are enslaved
    (or let''s say controlled). You have to sit before a screen and look at it, using
    the keyboard to type and mouse to navigate. Badly written software can enslave
    you similarly. If you replace your desktop with a laptop, then you have inverted
    control. You can easily take it and move around. So, now you can control where
    you are with your computer rather than the computer controlling it. IOC in software
    is very similar. Traditionally speaking, IOC is a design principle in which custom-written
    portions of the computer program receive the flow of control from a generic framework.We
    have `inversifyJS` available as an `npm` module. As per their official docs:'
  prefs: []
  type: TYPE_NORMAL
- en: <q>*InversifyJS is a lightweight inversion of control container for TypeScript
    and JavaScript applications. An IOC container will use a class constructor to
    identify and inject its dependencies. It has a friendly API and encourages the
    usage of best OOP and IoC practices adhering to SOLID principles.*</q>
  prefs: []
  type: TYPE_NORMAL
- en: Typedi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dependency injection is a means by which classes, components, and services specify
    which libraries they depend on. By simply injecting dependencies into a microservice,
    the service is empowered with the ability to reference dependencies directly,
    rather than looking them up in a service registry or using a service locator.
    The power to encapsulate any service, discover it, and distribute load is an extremely
    valuable addition to microservices. **Typedi** is a dependency injection tool
    for JavaScript and TypeScript. Using Typedi is very easy. All you do is create
    a container and start using dependency injection principles on that container.
    Typedi provides various annotations, such as `@Service`, `@Inject`, and more.
    You can even create your own custom decorators.
  prefs: []
  type: TYPE_NORMAL
- en: TypeORM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Inspired by frameworks such as hibernate and doctrine, the Entity Framework **TypeORM**
    ([https://www.npmjs.com/package/typeorm](https://www.npmjs.com/package/typeorm))
    is an ORM framework supporting active record and data mapper patterns, unlike
    all other JavaScript ORMs. This enables us to write high quality, loosely coupled,
    scalable, and maintainable applications in the most productive way ever. It has
    the following advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Uses multiple database connections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Works with multiple database types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Query caching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hooks, such as subscribers and listeners
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Written in TypeScript
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports both the Data Mapper and Active Record patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connection pooling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streaming raw results (reactive programming)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eager and lazy relations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports SQL as well as NoSQL databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application directory configurations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The directory structure of this application focuses on our architectural approach
    based on separation of concerns. Each folder structure will have files specifically
    pertaining to the name of the folder. In the following screenshot, you can see
    the overall structure and detailed structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2795b24c-b3ae-493a-811d-b583cab39c49.png)'
  prefs: []
  type: TYPE_IMG
- en: Configuration structure
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, you can see two folder structures. The first one
    is the high-level and overall folder structure highlighting important folders,
    whereas the second one is a detailed expanded view of the `src` folder. The folder
    structure follows the *separation of concerns* approach to eliminate code duplication
    and share singleton services between controllers.
  prefs: []
  type: TYPE_NORMAL
- en: In computer science, **separation of concerns** (**SoC**) is a design principle
    for dividing a computer program into distinct sections or capabilities so that
    each section addresses a separate concern and is independent of the other. A concern
    is a set of information that affects the code of any application.
  prefs: []
  type: TYPE_NORMAL
- en: Let's understand our folder structure and the files it contains, and what concern
    the folder actually addresses.
  prefs: []
  type: TYPE_NORMAL
- en: src/data-layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This folder is responsible for the overall organization of the data, its storage,
    and accessibility methods. Model definitions and iridium files can be found here.
    It has the following folders:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Adapters**: This implements the setup of MongoDB connection methods for connecting
    to the MongoDB database and adding events on connected, error, open, disconnected,
    reconnected, and forced exit methods'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data-abstracts**: This has both the schemas representing the structure of
    each MongoDB collection and the documents representing each set of data in the
    collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data-agents**: This has the query transactions against the data store for
    each MongoDB collection'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Model**: This has a TypeScript class representation of the data portrayed
    by the MongoDB document'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: src/business-layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This folder has the implementation of business logic and other resources that
    are needed by the service layer or the middleware layer, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Security**: If we want some security or tokens at a particular microservice
    level, this is where we will add our authentication logic (generally, we don''t
    write the authentication layer at the individual service level). Rather, we write
    it at the API Gateway level, which we will see in [Chapter 5](720d1d4e-1795-457c-903e-65c5a5fb5433.xhtml), *Understanding
    API Gateway*. Here, we will write code for the service registration/deregistration,
    verification, internal security, microservices communicating with the service
    registry, the API Gateway, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Validators**: This will have schema and processing logic for validating data
    sent with API requests. We will write our class-validator ([https://www.npmjs.com/package/class-validator](https://www.npmjs.com/package/class-validator))
    schema here, together with some custom validation functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: src/service-layer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This folder includes the processes for establishing API endpoints in the form
    of routes, which will handle all responses to data requests. It has the following
    folders:'
  prefs: []
  type: TYPE_NORMAL
- en: '`controllers`: This serves as a primer for processing any data requests associated
    with routes. The custom `controllers` are featured by `npm` module `routing-controllers`
    ([https://www.npmjs.com/package/routing-controllers](https://www.npmjs.com/package/routing-controllers))
    using in-built decorators, such as `@Get`, `@Put`, `@Delete`, `@Param`, and so
    on. These functions implement basic GET, POST, DELETE, and PUT methods for transacting
    with the database via the RESTful API. We can even have socket initialization
    code and more. We will use dependency injection to inject some services which
    will be used here.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`request`: This has TypeScript interfaces defining and showing the attributes
    that constitute each of the different kinds of request in the controller.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`response`: This has TypeScript interfaces defining and showing the attributes
    that constitute each of the different kinds of response in the controller.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: src/middleware
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This contains resources that have any server configuration, as well as a certain
    place to store any utility processes that can be shared across any application.
    We can have centralized configurations, such `aslogger`, `cache`, `elk`, and so
    on:'
  prefs: []
  type: TYPE_NORMAL
- en: '`common`: This has an instantiation of the logger module, which can be shared
    across the entire application. This module is based on `winston` ([https://www.npmjs.com/package/winston](https://www.npmjs.com/package/winston)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config`: This has vendor-specific implementations. We will have express configuration
    and express middleware defined here, as well as all the important configurations
    for organizing the REST API endpoints.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`custom-middleware`: This folder will have all our custom-written middleware,
    which we can utilize in any controller class or any particular method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will look at some of the configuration files that configure
    and define the application and determine how it will run. For example, the port
    on which it will run, the  port the database is connected to, the modules installed,
    the transpilation configuration, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Configuration files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at some of the configuration files that we will use throughout
    the project, and use them to govern the project in different environments or as
    per the use case:'
  prefs: []
  type: TYPE_NORMAL
- en: '**`default.json`**: Node.js has an excellent module, `node-config`. You can
    find the `config` file in the `config` folder parallel to `package.json`. Here,
    you can have multiple configuration files that can be picked up based on environments.
    For example, `default.json` would be loaded first, followed by `{deployment}.json`,
    and so on. Here is a sample file:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**`src/Index.ts`**:This initializes our application, by making a new object
    of the application defined in the `middleware`/`config`/`application`. It imports
    reflected metadata that initializes our dependency injection container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**`package.json`**: This serves as the manifest file in all of the Node.js
    application. It delineates the external libraries required for building the application
    in two sections, `dependencies` and `devDependencies`.  This provides a `scripts` tag
    that has external commands for building, running, and packaging the module.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tsconfig.json`: This provides options for TypeScript when it performs the
    task of transpiling to JavaScript. For example, if we have `sourceMaps:true`,
    we will be able to debug TypeScript code via generated sourcemaps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`src/data-layer/adapters/MongoAccess.ts`: This will have a connection to the
    MongoDB database and various event handlers attached to various events of MongoDB,
    such as `open`, `connected`, `error`, `disconnected`, `reconnected`, and so on:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '`src/middleware/config/Express.ts`:This is where our express middleware resides.
    We will attach standard configurations, such as `helmet`, `bodyparser`, `cookieparser`,
    `cors origin`, and so on, and set up our `controllers` folder with the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Processing data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As with most web servers that accept and process requests from clients, we
    have a very similar thing here. We just have granularized things at a macro level.
    The overall flow of the process is shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3cece010-b02d-4e55-916e-51149307de81.png)Processing data'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s understand the process by taking any of the sample endpoints through
    each of the sections in the preceding diagram. You can find the whole sample in
    `chapter-4/products-catalog service`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'An API request to put a specific product based on the attributes of the product
    is sent to the server, `http://localhost:8081/products/add-update-product`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The registered controllers with the `/products` path capture the request based
    on the `URI /products/`.  If a middleware is registered in `Express.ts`, it will
    get triggered first; otherwise, the controller method gets called. Registering
    a middleware is simple. Create a middleware class with the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: To use this middleware in any controller, just make use of the `@UseBefore`
    and `@UseAfter` decorators on top of any method/controller.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since we want to execute some core logic (such as picking the response from
    the cache or logging), the `middleware` function gets executed first. This resides
    in `middleware/custom-middleware/MyMiddleWare.ts`. Using the `async` capabilities
    of Node.js, the method will do what is necessary and then proceed on to the next
    request with `next()`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the custom middleware, we can have various checks; for example, we may want
    to expose the APIs only if there is a valid `ownerId` or only to authorized sellers.
    If the request does not have a valid `ownerId`, the request will no longer progress
    through the rest of the application, and we can throw an error indicating authenticity
    or an invalid `productId`. However, if the `ownerId` is valid, then the request
    will continue to progress through the routes. This is the role of `MyMiddleWare.ts`.
    The next part will go through the controllers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The next part is the `@JsonControllers` defined by the decorators provided
    by routing controllers. We define our routing controller and post API for adding
    and updating a product:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This will create a PUT request for `API <host:url>/products/add-update-product`.
    The `@Body` annotation will convert a cast of the request body to `IProductCreateRequest
    (src/service-layer/request/IProductRequest.ts`) in the variable request (as seen
    in the argument of the `addIpdateProduct` method), which will be available throughout
    the method. The `request` and `responses` folder contains the transformation of
    a various `request` and `response` objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first part of the controller is to validate the request. The validation
    and security logic will be inside the `src/business-layer` folder. Inside the
    `validator` folder, we will have `ProductValidationSchema.ts` and `ProductValidatorProcessor.ts`.
    Inside `ProductValidationSchema.ts`, add the validation schema rules (various
    validation messages through which we want to identify whether a request is correct
    or has junk data) using the `class-validator` ([https://www.npmjs.com/package/class-validator](https://www.npmjs.com/package/class-validator))
    inbuilt decorators, (`@MinLength,` `@MaxLength`, `@IsEmail`, and so on):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will use these messages to validate our request object. In `ProductValidationProcessor.ts`,
    create a validator method that returns a consolidated array of messages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In `ProductsController.ts`, call the method. If there are errors in the request,
    the request will stop there and won''t propagate to the rest of the API. If the
    response is valid, then it will pass through the data agent to push the data to
    MongoDB:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'When the request is valid, the controller, `ProductController.ts`, calls the
    `ProductDataAgent.ts` method, `createNewProduct(..)`, in the data layer in order
    to put the data into MongoDB. Further more, based on the Mongoose schema definition,
    it will automatically maintain a duplication check entry:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Controllers in the service layer not only provide access to the data layer through
    data agents used for negotiating queries against the data store, but they also
    provide an entry point of access to the business layer to process other business
    rules, such as validating product input. The `ProductDataAgent.ts` method returns
    the object returned by MongoDB. It also has other methods, such as `deleteProduct`,
    `findAllProducts`, `findProductByCategory`, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'After completing the transaction with the data store in `ProductDataAgent.ts`,
    a promise in the form of a vanilla object is returned to `ProductController.ts`,
    indicating a failure or success. When a successful product is added to a database,
    the object inserted along with MongoDB''s `ObjectID()` is returned. The data associated
    with the product is constructed as `ProductModel` and will be resolved as an `IProductResponse`
    to `ProductController.ts`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: If some mishap occurs in the processing of the query in `ProductDataAgent.ts`,
    such as a broken connection to the data store, a result in the form of an error
    message will be returned. A similar error response will be thrown if an object
    with the same name already exists.
  prefs: []
  type: TYPE_NORMAL
- en: This completes the example of how data flows through the application. Based
    on many backend applications and cross-cutting factors, this is designed in order
    to have a smooth flow and eliminate redundant code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, this project will have other APIs, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: GET request to get all products
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GET request to get products by ID
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GET request to get products by product type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DELETE request to delete a single product
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ready to serve (package.json and Docker)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will look at how to write scripts in `package.json` and
    then automate the whole thing using Docker.
  prefs: []
  type: TYPE_NORMAL
- en: package.json
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we know how data flows, let''s understand how to make it ready to
    serve. Install TypeScript and `rimraf` as dependencies and add the following inside
    the `scripts` tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'To run the entire process, execute the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This will first delete the `dist` folder if it exists, and then, based on the
    `src` folder, it will transpile the folder and generate the `dist` folder. Once
    the `dist` is generated, we can run our server with `node ./dist/Index.js` and
    `npm run start` in combination.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a later chapter, we will do more things here, including test coverage and
    generating the swagger documentation. Our build script should cover the following
    things:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate documentation via `swagger-gen`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Invoke `Express.ts`, which will have all routes configured along with middleware
    and dependency injection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `tsc` command will transpile the TypeScript files into JavaScript files
    using the `"outputDirectory":"./dist"` attribute in `tsconfig.json` to identify
    where the JavaScript files should be placed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SwaggerUI will generate the documentation, which will be available on the web
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, to test the API, create a product JSON of the following order and hit
    a POST request with the following payload:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see a successful response with ResponseCode: 200 and MongoDB''s ObjectId.
    It will look something like this: "id": "5acac73b8bd4f146bcff9667".'
  prefs: []
  type: TYPE_NORMAL
- en: This is the general approach to how we are going to write our microservice.
    It shows us more behavior on separation of control, how it can be achieved using
    TypeScript, and some enterprise design patterns. Thin controllers that lie in
    the service layer rely on references to the business layer and data layer for
    implementing the process with which we can eliminate redundant code and enable
    the sharing of services between controllers. Similarly, you can write countless
    services based on the same approach. Say you want to write a payment microservice,
    you can use the `typeorm` module for SQL operations and have the same code structure.
  prefs: []
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that our application is up and running, let's containerize it, so we can
    push our image to anyone. Containers such as Docker help us to package an entire
    application including the libraries, dependencies, environment, and anything else
    needed by the application to run. Containers are helpful as they isolate the application
    from the infrastructure so we can easily run it on different platforms without
    the need to worry about the system on which we are running.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our objectives are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Spin up a working version of our product catalog microservice, Mongo microservice,
    just by running `docker-compose up`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Docker workflow should be what we are using the Node.js workflow that includes
    transpiling, and serving the `dist` folder
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use data containers for initializing MongoDB
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'So, let''s get started. We will create our `container` file and write starting
    scripts inside it by performing the following steps. You can find the source in
    the `Chapter 4/products-catalog -with-docker` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create the `.dockerignore` file to ignore things that we don''t want
    in our built container:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will write our `Dockerfile`. An image is made up of a set of layers
    and instructions that we define in our `Dockerfile`. We will initialize our Node.js
    application code here:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We are done with the Node.js part. Now, we need to configure our MongoDB. We
    will use `docker compose`, a tool for running multiple container applications,
    which will spin up our application and run it. Let''s add a `docker-compose.yml`
    file for adding our MongoDB:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Running multiple containers inside a single container is not possible as such.
    We would be leveraging the Docker Compose up tool ([https://docs.docker.com/compose/overview/](https://docs.docker.com/compose/overview/)) ,which
    can be downloaded by running `sudo curl -L https://github.com/docker/compose/releases/download/1.21.0/docker-compose-$(uname
    -s)-$(uname -m) -o/usr/local/bin/docker-compose`. We will look at `docker compose`
    in [Chapter 9](90996850-1ced-4678-a297-3e1fee118eb9.xhtml), *Deployment, Logging,
    and Monitoring*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Breaking up this file shows us the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We have a service called `app`, which adds a container for the product-catalog
    service.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We instruct Docker to restart the container automatically if it fails.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To build the app service (our TypeScript Node.js application), we need to tell
    the location of our `Dockerfile` where it can find build instructions. The `build
    ./` command tells Docker that the `Dockerfile` is at the same level as `docker-compose.yml`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We map the host and the container port (here we have kept both the same).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have added another service, Mongo, which pulls the standard Mongo image from
    the Docker Hub registry.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we define a data directory by mounting `/data/db` and the local data directory
    `/data`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This will have an advantage similar to when we start a new container. Docker
    compose will use the volume of previous containers and thus ensure there is no
    data loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we link the app container to the Mongo container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Port `3000:8081` is basically telling us that the Node.js service exposed to
    the outside container world can be accessed at port `3000`, whereas internally
    the application runs on port `8081`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, just open up a terminal at the parent level and hit the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: This will spin up two containers and aggregate the logs of both containers.
    We have now successfully Dockerized our application.
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Running `docker-compose up` will give you an error that it can''t connect
    to MongoDB. What could we have done wrong? We are running multiple containers
    via the `docker-compose` option. Mongo runs inside its own container; hence, it
    is not accessible via `localhost:27017`. We need to change our connection URL
    to point it to the Docker service rather than the localhost. Change the following
    line in `default.json` from:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 6\. Now, run `docker-compose` up and you will be able to successfully get the
    service up and running.
  prefs: []
  type: TYPE_NORMAL
- en: By dockerizing our microservice, we have completed the development and build
    cycle. In the next section, we will quickly recap what we have done so far, before
    moving on to the next topic, *Microservice best practices*.
  prefs: []
  type: TYPE_NORMAL
- en: Synopsis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will have a quick look at some of the modules that we used
    and describe their purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `routing-controllers` | Has various options and is based on ES6\. It has
    lots of decorators, such as `@GET`, `@POST`, and `@PUT`, which help us to design
    configuration-free services. |'
  prefs: []
  type: TYPE_TB
- en: '| `config` | Config module from which we can write various files based on different
    environments, thus helping us to adhere to the twelve-factor app. |'
  prefs: []
  type: TYPE_TB
- en: '| `typedi` | Used as a dependency injection container. We can then use it to
    inject services (`@Service`) into any controller. |'
  prefs: []
  type: TYPE_TB
- en: '| `winston` | Used for the logging module. |'
  prefs: []
  type: TYPE_TB
- en: '| `typeORM` | Module written in TypeScript for dealing with relational databases.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `mongoose` | Popular Mongoose ORM module for dealing with MongoDB. |'
  prefs: []
  type: TYPE_TB
- en: '| `cors` | To enable CORS support for our microservices. |'
  prefs: []
  type: TYPE_TB
- en: '| `class-validator` | Used to validate any input requests based on our configured
    rules. |'
  prefs: []
  type: TYPE_TB
- en: Similarly, based on this folder structure and modules, we can create any number
    of microservices supporting any databases. Now that we have a clear understanding
    of how to design a microservice, in the next section we will look at some microservice
    design best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Microservice design best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have developed some microservices, it's time to learn about some
    patterns and some design decisions involved around them. To get a broader perspective,
    we will look at what a microservice should handle and what it shouldn't. A number
    of factors need to be considered while designing microservices, keeping best practices
    in mind. Microservices are solely designed on the principle of single responsibility.
    We need to define boundaries and contain our microservices. The following sections
    cover all the factors and design principles that need to be considered for efficiently
    developing microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up proper microservice scope
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the most important decisions relating to designing microservices is
    the microservice size. Size and scope can have a huge impact on microservice design.
    While comparing to traditional approaches, we can say there should be one REST
    endpoint per any container or any component that performs a single responsibility.
    Our microservices should be domain-driven, where each service is bound to the
    specific context in that domain and will be dealing with a specific business capability.
    A business capability can be defined as something or anything that is being done
    to contribute to achieving business goals. In our shopping cart microservice system,
    payment, adding to the cart, recommending a product, and dispatching a product
    are different business capabilities. Each different business capability should
    be implemented by a separate microservice. If we go with this model, we will end
    up in our microservices list with a product catalog service, price catalog service,
    invoice service, payment service, and so on. Each of the technical capabilities,
    if any, should be bundled as separate microservices. Technical capabilities don''t
    directly contribute to achieving business goals, but rather serve as a simplification
    to support other services. An example includes the integration service. The main
    points that we should adhere to can be summarized as:'
  prefs: []
  type: TYPE_NORMAL
- en: Microservices should be responsible for a single capability (be it technical
    or business)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices should be individually deployable and scalable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices should be easily maintainable by a small team and should be replaceable
    at any point in time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Self-governing functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another important factor while scoping microservices is deciding when to pull
    out the function. If the function is self-sustaining, that is, it has very few
    dependencies on external functions, it processes a given output and gives out
    some output. It can then be taken as a microservice boundary and kept as a separate
    microservice. Common examples are caching, encryption, authorization, authentication,
    and so on. Our shopping cart has numerous such examples. For example, it can be
    a central log service, or a price calculation microservice that takes in various
    inputs, such as product name, customer discounts, and so on, and then calculates
    the price of the product after applying promotional discounts, if any.
  prefs: []
  type: TYPE_NORMAL
- en: Polyglot architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the key requirements that gave birth to microservices is support for
    a polyglot architecture. Various business capabilities need different treatment.
    The principle of "one rule applies everywhere" doesn't work anymore. Different
    technologies, architectures, and approaches are needed to handle all business
    and technological capabilities. When we are scoping microservices, this is another
    key factor to take care of. For example, in our shopping microservice system,
    a product search microservice doesn't need relational databases, but adding to
    the cart and the payment service need ACID compliance, as handling transactions
    there is a very niche requirement.
  prefs: []
  type: TYPE_NORMAL
- en: Size of independent deployable component
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A distributed microservice ecosystem will take full advantage of currently increasing
    CI/CD processes for automation. Automating various steps, such as integration,
    delivery, deployment, unit testing, scaling, and code coverage and then creating
    a deployable unit makes life easier. If we include too many things in a single
    microservices container, it will pose some huge challenge, as there are a lot
    of processes involved, such as installing dependencies, automatic file copying
    or downloading the source from Git, building, deploying, and then starting up.
    With increasing complexity in the microservice, the size of the microservice will
    increase, which soon increases the trouble in managing it. A well-designed microservice
    makes sure that deployment units remain manageable.
  prefs: []
  type: TYPE_NORMAL
- en: Distributing and scaling services whenever required
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While designing microservices, it is important to breakup microservices based
    on various parameters, such as in-depth analysis of which business capabilities
    are most sought after, a division of services based on ownership, loosely coupled
    architecture, and so on. Microservices designed with this division are effective
    in the long run as we can easily scale out any service on demand and isolate our
    failure points. In our product microservices, approximately 60% of the requests
    would be search based. In this case, our search microservice container has to
    run separately so it can scale separately when needed. Elasticsearch or Redis
    can be introduced on top of this microservice, which would give better response
    times. This will have various advantages, such as cost reduction, effective use
    of resources, business benefits, cost optimizations, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Being Agile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With dynamically changing requirements, the Agile methodology of development
    has been adopted everywhere. One of the important considerations in scoping out
    microservices is developing in such a way that each team can develop different
    parts of the pie. Each of the team builds different microservices and then we
    construct the full pie. For example, in our shopping cart microservices, we can
    have one recommendation service that specifically targets an audience based on
    their preferences and history. This can be developed keeping users' tracking history,
    browser history, and more in mind, which can result in a complex algorithm. This
    is why it will be developed as a separate microservice, which can be handled by
    separate teams.
  prefs: []
  type: TYPE_NORMAL
- en: Single business capability handler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Drifting away a bit from the traditional single responsibility principle, a
    single microservice should handle a single business capability or technical capability.
    One microservice should not perform multiple responsibilities. Based on the pattern
    of design, a business capability can be divided into more than one microservice.
    For example, in our shopping cart microservices in inventory management, we may
    introduce a CQRS pattern to achieve some quality attributes, where our reads and
    writes would be spread across different service containers. When each service
    is mapped to a bounded context, handling a single business capability, it is much
    easier to manage them. Each service may exist as separate products, targeting
    a specific community. They should be reusable, easily deployable, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Adapting to shifting needs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices should be designed so that they can be easily detached from the
    system with the minimum amount of rewrites. This enables us to easily add experimental
    features. For example, in our shopping cart microservices, we may add a product
    ranking service based on the feedback received. If the service doesn't work out
    or the business capability is not achieved, this service can be thrown out or
    easily replaced with another service. Scoping microservices here plays an important
    role, as a minimum viable product can be made and then, on top of it, features
    can be added or removed as per the requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Handling dependencies and coupling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another important factor in scoping out services is dependencies and the coupling
    a service introduces. Dependencies in microservices have to be evaluated to make
    sure that tight coupling is not introduced in the system. To avoid a high-coupled
    system, decompose the system into business/technical/functional capabilities and
    create a functional dependency tree. Having too many request-response calls, cyclical
    dependencies, and so on are some of the factors that may break a microservice.
    Another important aspect in designing robust microservices is to have event-driven
    architecture; that is, instead of waiting for a response, a microservice should
    react upon receiving an event.
  prefs: []
  type: TYPE_NORMAL
- en: Deciding the number of endpoints in a microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While this may seem an important point in consideration for designing microservices,
    it is not at all a design consideration. A microservice container may host one
    or many endpoints. A more important consideration is bounding the microservice.
    Based on the business or technical capabilities, there may be only one endpoint,
    whereas in many cases there could be more than one endpoint in a microservice.
    For example, going back to our shopping cart services for our inventory management
    where we introduced a CQRS pattern, we have separate read and write services,
    each containing single endpoints. Another example can be a polyglot architecture,
    where we have multiple endpoints in order to have communication between various
    microservices. We usually break services into containers based on our deployment
    and scaling needs. For our checkout service, all services are connected and use
    the same relational database. In this case, there is no need to separate out these
    into different microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Communication styles between microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another important factor to be considered while designing microservices is the
    communication style between microservices. There can be a synchronous mode (sending
    requests, receiving responses) or an asynchronous mode of communication (fire
    and forget). Both modes have their own pros and cons and have their specific use
    cases where they can be used. In order to have a scalable microservice, a combination
    of both approaches is needed. Apart from this, nowadays "being real-time" is the
    new trend. Socket-based communication promotes real-time communication. Yet another
    way of dividing communication styles is based on the number of receivers. For
    a single receiver, we have a command-based pattern (CQRS, as seen in earlier chapters).
    For more than one receiver, we have an event-driven architecture that is based
    on the principle of the publish and subscribe pattern, where in-service buses
    are used.
  prefs: []
  type: TYPE_NORMAL
- en: Specifying and testing the microservices contract
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A contract can be defined as a set of agreements (protocol, request body, address,
    and so on) between the consumer and the provider, which helps to smooth the interactions
    that take place between them. Microservices should be designed so that they can
    be independently deployed, without any dependencies on one another. To achieve
    this complete independence, each microservice should have well written, versioned,
    and defined contracts, which all its clients (other microservices) must adhere
    to. Introducing breaking changes at any time might be a problem as clients may
    require previous versions of the contract. Only after appropriate communication
    should a contract be put out of service or turned down. Some best practices include
    deploying new versions side by side and including versioning in your API. For
    example, `/product-service/v1`, then `/product-service/v2`. Using **consumer-driven
    contracts** (**CDCs**) is one of the modern ways to test microservices, as compared
    to integration tests. Further, in this book, we will be using Pact JS to test
    our contracts ([Chapter 8](a7273aa2-2981-4013-8d5f-dbee87462d35.xhtml), *Testing,
    Debugging, and Documenting*).
  prefs: []
  type: TYPE_NORMAL
- en: Number of microservices in a container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Containerizing your microservice is one of the most recommended ways for deploying
    microservices. Containers provide agility in your system and it streamlines the
    development and testing experience. Containers are portable across any infrastructure
    and can be easily deployed on AWS too. Deciding on the number of microservices
    that a container can contain is vital and is dependent upon various factors such
    as container capacity, memory, selective scaling, resource requirements, traffic
    volume per service, and so on. Based on these facts, we can decide whether deployments
    can be brought together or not. Even if services are brought together, it has
    to be ensured that these services are run independently and they are not sharing
    anything. Selective scaling is also one of the crucial factors in deciding on
    the number of microservices in a container. It should be such that deployments
    are self-managed, an example being AWS Lambda. The following are the available patterns
    and the limitations of each of the patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Service instance per virtual machine**:Here, you package each service as
    a virtual machine image (traditional approach), such as an Amazon EC2 EMI. Here,
    each service is a separate VM that is launched in a separate VM image:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Limitations**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Less efficient resource utilization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You pay for entire VM; therefore, if you are not utilizing the entire VM, you
    are paying charges for nothing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a new version on a service is very slow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing multiple VMs soon becomes a huge pain and a time-consuming activity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service instance per container**:Here, each service runs on its own container.
    Containers are one portable virtualization technique. They have their own root
    filesystem and portable namespaces. You can limit their CPU resources and memory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Limitations**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A container is not as mature as a VM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling spikes in the load is an extra added task
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring the VM infrastructure and container infrastructure is again an added
    task
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Serverless**:One of the latest "worry free trends" is the serverless architecture,
    where you package a microservice, package it as a ZIP, and deploy it to serverless
    platforms, such as AWS Lambda. You are just billed for each request based on the
    time taken and memory consumed. For example, a Lambda function is stateless.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Limitations:**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This approach is not feasible for long-term running services. An example can
    be where a service is dependent on another service or a third-party broker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requests must complete in less than 300 seconds.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Services must be stateless, as each separate instance is run for each request.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Services must start quickly or else they will be timed out.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Services must be run in one of the supported languages. For example, AWS Lambda
    supports Java, Node.js, and Python.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data sources and rule engine among microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another important factor is applying a rules engine and deciding upon data sources
    in our distributed system. Rules are an essential part of any system as they help
    us to govern the entire system. Many organizations use a centralized rules engine
    or workflow processes following the BPMN standards example, Drools. An embedded
    rule engine can either be placed within the service or can be external to the
    service based on usage. If there are complex rules, a central authoring repository
    with an embedded engine would be the best choice. Since it is centrally distributed,
    there can be technology dependencies, rules running rules within some application
    server boundaries, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '**Business Process Modeling Notations** (**BPMN**) are standardized notations
    with the objective of creating visual models of any business or any organizational
    process. Often in business capabilities, we need a definitive workflow that may
    change as per requirements. We never hardcode any processes or write our own engine
    and leverage BPMN tools for it.'
  prefs: []
  type: TYPE_NORMAL
- en: Just like the rules engine, deciding on data stores among microservices is also
    crucial. Transactional boundaries should be set up within our defined business
    capabilities. For example, in our shopping cart microservices, at the checkout
    we need to maintain transactions and we can go with RDBMS as a data source to
    ensure integrity and follow ACID principles. However, product catalog databases
    don't have any transactions and we can use NoSQL databases for them.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we began designing our microservices for the shopping cart
    services. We analyzed our requirements based on technical, functional, and business
    capabilities, which are the primary drivers in scoping microservices. We designed
    our schema, analyzed our microservice structure, and ran it on Docker. Finally,
    we looked at some of the best practices for microservice design and learned how
    to scope microservices based on our business capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to learn how to introduce a gateway to our
    microservices and understand the problem a gateway solves. We are going to see
    how API Gateway solves centralized concerns in distributed systems. We will get
    acquainted with some API Gateway design patterns and design our gateway for the
    shopping cart microservices.
  prefs: []
  type: TYPE_NORMAL
