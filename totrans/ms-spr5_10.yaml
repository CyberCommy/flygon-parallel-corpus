- en: Spring Cloud Data Flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring Data Flow brings the microservices architecture into typical data flow
    and event flow scenarios. We will discuss more about these scenarios later in
    this chapter. Building on top of other Spring Projects, such as Spring Cloud Stream,
    Spring Integration, and Spring Boot, Spring Data Flow makes it easy to define
    and scale use cases involving data and event flows using message-based integration.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need asynchronous communication?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is Spring Cloud Stream? How does it build on top of Spring Integration?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why do we need Spring Data Flow?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the important concepts in Spring Data Flow you would need to understand?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the use cases where Spring Data Flow is useful?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will also implement a simple event flow scenario with three microservices
    acting as the source (application generating the events), processor, and sink
    (application consuming events). We will implement the microservices using Spring
    Cloud Stream and establish connections between them over the message broker using
    Spring Cloud Data Flow.
  prefs: []
  type: TYPE_NORMAL
- en: Message-based asynchronous communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two options when integrating applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Synchronous**: Service consumer invokes the service provider and waits for
    a response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Asynchronous**: Service consumer invokes the service provider by putting
    the message on the message broker but does not wait for the response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The services that we built with Spring Boot in *Chapter 5, Building Microservices
    with Spring Boot,* (`random` service, `add` service) are examples of synchronous
    integration. These are typical web services that are exposed over HTTP. The service
    consumer calls the service and waits for a response. The next call is made only
    on the completion of the previous service call.
  prefs: []
  type: TYPE_NORMAL
- en: One important disadvantage of this approach is the expectation that the service
    provider is always available. The service consumer will need to re-execute the
    service again if the service provider is down or, for some reason, the service
    fails in execution.
  prefs: []
  type: TYPE_NORMAL
- en: An alternate approach is to use message-based asynchronous communications. Service
    consumer puts a message on the message broker. The service provider listens on
    the message broker and as soon as a message is available, it processes it.
  prefs: []
  type: TYPE_NORMAL
- en: An advantage here is that even if the service provider is down for a while,
    it can process the messages on the message broker whenever it comes back up. The
    service provider does not need to be available all the time. While there is a
    possibility of a lag, data would eventually be consistent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows an example of asynchronous message-based communication:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4e968de-1d77-43b1-bd60-0ce412b12ac0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'There are two kinds of scenarios where asynchronous communication improves
    reliability:'
  prefs: []
  type: TYPE_NORMAL
- en: If the service provider is down, then the messages will be queued in the message
    broker. When service provider is back up, it will process these messages. So,
    the messages will not be lost even if service provider is down.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there is an error in processing the message, the service provider will put
    the message in an error channel. When the error is analyzed and fixed, the message
    can be moved from the error channel to the input channel and queued for reprocessing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The important thing to note is that in both the preceding scenarios, service
    consumer does not need to worry if the service provider is down or message processing
    has failed. Service consumer sends a message and forgets about it. The messaging
    architecture ensures that the message is eventually processed successfully.
  prefs: []
  type: TYPE_NORMAL
- en: 'Message-based asynchronous communication is typically used in event flows and
    data flows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Event flows**: This involve processing logic based on an event. For example,
    a new customer event or a stock price change event or a currency change event.
    Downstream applications will be listening on the message broker for events and
    will react to them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data flows**: This involve data that is enhanced through multiple applications
    and finally stored down to a data store.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functionally, the content of the message exchanged between data flow architectures
    is different from that of event flow architectures. However, technically, it is
    a just another message that is sent from one system to another. In this chapter,
    we will not differentiate between event and data flows. Spring Cloud Data Flow
    can handle all these flows--in spite of having only data flow in the name. We
    use event flow, data flow, or message flow interchangeably to indicate a flow
    of messages between different applications.
  prefs: []
  type: TYPE_NORMAL
- en: Complexities of asynchronous communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the preceding example is a simple communication between two applications,
    typical flows in real-world applications can be much more complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows an example scenario involving the message flow across
    three different applications. The source application generates the event. The
    processor application processes the event and generates another message that will
    be processed by the sink application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1ef4605f-eba9-4a16-b50c-6be64bf87b15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Another example scenario involves an event that is consumed by multiple applications.
    For example, when a customer is registered, we would want to send them an e-mail,
    a welcome kit, and a mail. A simple messaging architecture for this scenario is
    shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d1fa3516-aa1e-4224-a9eb-2d92f5b566c8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To implement the preceding scenarios, a number of different steps are involved:'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the message broker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating different channels on the message broker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Writing application code to connect to a specific channel on the message broker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Installing necessary binders in the applications to connect to the message brokers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Setting up the connection between the applications and the message broker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Building and deploying the applications.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Consider a scenario where some of these applications in the flow have to process
    a huge load of messages. We would need to create multiple instances of such applications
    based on the load. The implementation complexity becomes multifold. These are
    the challenges that Spring Cloud Data Flow and Spring Cloud Stream aim to solve.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at how different Spring projects--Spring Cloud
    Stream (built on top of Spring Integration) and Spring Cloud Data Flow enable
    us to do message-based integrations with little configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Spring projects for asynchronous messages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will look at different projects provided by Spring to enable
    message-based communication between applications. We will start with Spring Integration
    and then move on to projects that enable message-based integration even on the
    Cloud--Spring Cloud Stream and Spring Cloud Data Flow.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Spring Integration helps integrate microservices seamlessly over a message
    broker. It allows programmers to focus on business logic and give control of the
    technical infrastructure (what message format to use? How to connect to message
    broker?) to the framework. Spring Integration provide a variety of configuration
    options through well-defined interfaces and message adapters. Spring Integration
    website ([https://projects.spring.io/spring-integration/](https://projects.spring.io/spring-integration/)):'
  prefs: []
  type: TYPE_NORMAL
- en: Extends the Spring programming model to support the well-known Enterprise Integration
    Patterns. Spring Integration enables lightweight messaging within Spring-based
    applications and supports integration with external systems via declarative adapters.
    Those adapters provide a higher-level of abstraction over Spring's support for
    remoting, messaging, and scheduling. Spring Integration's primary goal is to provide
    a simple model for building enterprise integration solutions while maintaining
    the separation of concerns that is essential for producing maintainable, testable
    code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Features provided by Spring Integration include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Simple implementations for enterprise integration patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aggregation of responses from multiple services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filtering results from the service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service message transformation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple protocol support--HTTP, FTP/SFTP, TCP/UDP, JMS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for different styles of Webservices (SOAP and REST)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for multiple message brokers, for example, RabbitMQ
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the previous chapter, we used Spring Cloud to make our microservices Cloud-Native--to
    be deployed in the Cloud and utilize all the benefits of Cloud deployment.
  prefs: []
  type: TYPE_NORMAL
- en: However, applications built with Spring Integration, especially those that interact
    with message brokers, need a lot of configuration to be deployed into the Cloud.
    This prevents them from taking advantage of the typical benefits of the Cloud,
    such as automatic scaling.
  prefs: []
  type: TYPE_NORMAL
- en: We would want to extend the features provided by Spring Integration and make
    them available on the Cloud. We would want new instances of our microservice cloud
    instances to be able to automatically integrate with message brokers. We would
    want to be able to scale our microservice cloud instances automatically without
    manual configuration. That's where Spring Cloud Stream and Spring Cloud Data Flow
    come in.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud Stream
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring Cloud Stream is the framework of choice to build message-driven microservices
    for the Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spring Cloud Stream allows programmers to focus on building microservices around
    the business logic of event processing, leaving infrastructure concerns, listed
    here, to the framework(s):'
  prefs: []
  type: TYPE_NORMAL
- en: Message broker configuration and channel creation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Message-broker-specific conversions for message
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating binders to connect to the message broker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Cloud Stream fits hand in glove into the microservices architecture.
    The typical microservices needed in use cases of event processing or data streaming
    can be designed with a clear separation of concerns. Individual microservices
    can handle business logic, define the input/output channels and leave the infrastructure
    concerns to the framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'Typical stream applications involve the creation of events, processing of events,
    and storing down to a data store. Spring Cloud Stream provides three simple kinds
    of applications to support typical stream flows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Source**: Source is the creator of events, for example, the application that
    triggers a stock price change event.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Processor**: Processor consumes an even, that is, processes a message, does
    some processing around it, and creates an event with the result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sink**: Sink consumes events. It listens on to a message broker and stores
    the event to a persistent data store.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Cloud Stream is used to create individual microservices in the data flow.
    Spring Cloud Stream microservices define business logic and the connection points,
    the inputs and/or outputs. Spring Cloud Data Flow helps in defining the flow,
    that is, connecting different applications.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow helps in establishing message flows between different
    kinds of microservices created using Spring Cloud Stream.
  prefs: []
  type: TYPE_NORMAL
- en: Built on top of popular open source projects, **Spring XD** simplifies the creation
    of data pipelines and workflows--especially for Big Data use cases. However, Spring
    XD has challenges adapting to newer requirements (canary deployments and distributed
    tracing, for example) related to data pipelines. Spring XD architecture is based
    on a run-time dependent on a number of peripherals. This makes sizing the cluster
    a challenging exercise. Spring XD is now resigned as Spring Cloud Data Flow. The
    architecture of Spring Cloud Data Flow is based on composable microservice applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Important features in Spring Cloud Data Flow are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a stream, that is, how data or events flow from one application
    to another. Stream DSL is used to define the flow between applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establishing a connection between the applications and the message broker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing analytics around applications and streams.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying applications defined in streams to the target runtime.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for multiple target runtimes. Almost every popular cloud platform is
    supported.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling up applications on the Cloud.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating and invoking tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sometimes, the terminology can get a little confusing. A stream is an alternate
    terminology for a flow. It's important to remember that Spring Cloud Stream actually
    does not define the entire stream. It only helps in creating one of the microservices
    involved in the entire stream. As we will see in the next sections, streams are
    actually defined using Stream DSL in Spring Cloud Data Flow.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud Stream
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring Cloud Stream is used to create individual microservices involved in a
    stream and define the connection points to a message broker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spring Cloud Stream is built on top of two important Spring Projects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Spring Boot**: To enable the creation of production-ready microservices'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spring Integration**: To enable microservices to communicate over message
    brokers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some of the important features of Spring Cloud Stream are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Bare minimum configuration to connect a microservice to a message broker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for a variety of message brokers--RabbitMQ, Kafka, Redis, and GemFire.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for persistence of messages--in case a service is down, it can start
    processing the messages once it is back up.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for consumer groups--in cases of heavy loads, you need multiple instances
    of the same microservice. You can group all these microservice instances under
    a single consumer group so that the message is picked up only by one of the available
    instances.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for partitioning--there can be situations where you would want to ensure
    that a specific set of messages are addressed by the same instance. Partitioning
    allows you to configure the criteria to identify messages to be handled by the
    same partition instance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Cloud Stream architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following figure shows an architecture of a typical Spring Cloud Stream
    microservice. A source would only have an input channel, the processor would have
    both the input and output channel, and a sink would have only an output channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4a31fe0b-fb4e-420d-9a05-a11cdff9254a.png)'
  prefs: []
  type: TYPE_IMG
- en: Applications declare what kind of connection they would want--an input and/or
    an output. Spring Cloud Stream will establish all that would be needed to connect
    applications over the message broker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Spring Cloud Stream would do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Inject the input and/or output channels into the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish connections with the message broker through a message=broker-specific
    binder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Binders bring configurability to Spring Cloud Stream applications. A String
    Cloud Stream application only declares the channels. Deployment team can configure,
    at runtime, which message broker (Kafka or RabbitMQ) the channels connect to.
    Spring Cloud Stream uses auto-configuration to detect the binder available on
    the classpath. To connect to a different message broker, all that we need to do
    is change the dependency for the project. Another option is to include multiple
    binders in the classpath and choose the one to use at runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Event processing - stock trading example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s imagine a scenario. A stock trader is interested in significant stock
    price changes of stocks that he/she has invested in. The following figure shows
    a simple architecture of such an application built with Spring Cloud Stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/07fb81a0-b47c-43c0-91de-bf6dedf0db93.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Important things to note are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Significant stock price change microservice**: This triggers an event on
    the message broker whenever there is a significant change in the price of any
    stock listed on the exchange. This is the **Source** application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stock intelligence microservice**: This listens to the message brokers for
    stock price change events. When there is a new message, it checks the stock against
    inventory and adds information on the user''s current holdings to the message
    and puts another message on the message broker. This is the **Processor** application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Event store microservice**: This listens on the message broker for stock
    price change on an invested stock alert. When there is a new message, it stores
    it down in data store. This is the **Sink** application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The preceding architecture gives us the flexibility to enhance our systems
    without major changes:'
  prefs: []
  type: TYPE_NORMAL
- en: E-mail microservice and SMS microservice listens on the message broker for stock
    price change on an invested stock alert and sends an e-mail/SMS alert.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A stock trader might want to make significant changes in other stocks they have
    not invested in. Stock intelligence microservice can be enhanced further.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we discussed earlier, Spring Cloud Stream helps us build the basic building
    blocks of a stream, that is, the microservices. We will create three microservices
    using Spring Cloud Stream. We will later use these three microservices and create
    a stream, that is, a flow between the applications using Spring Cloud Data Flow.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start with creating the microservices using Spring Cloud Stream in
    the next section. Before we start with source, processor, and sink stream applications,
    we will set up a simple model project:'
  prefs: []
  type: TYPE_NORMAL
- en: Model for stock trading example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `StockPriceChangeEvent` class contains the ticker of the stock, the old
    price of the stock, and the new prices of the stock:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The `StockPriceChangeEventWithHoldings` class extends `StockPriceChangeEvent`.
    It has one additional property--`holdings`. The `holdings` variable is used to
    store the number of stocks the trader currently owns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The `StockTicker` enum stores list of stocks that the application supports:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The source application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The source application will be the producer of stock price change events. It
    will define an output channel and put a message on the message broker.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use Spring Initializr ([https://start.spring.io](https://start.spring.io))
    to set up the application. Provide the details listed here and click on Generate
    Project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Group: `com.mastering.spring.cloud.data.flow`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Artifact: `significant-stock-change-source`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dependencies: `Stream Rabbit`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Listed here are some of the important dependencies from the `pom.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the `SpringBootApplication` file with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'A few important things to note are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`@EnableBinding(Source.class)`: The `EnableBinding` annotation enables binding
    a class with the respective channel it needs--an input and/or an output. The source
    class is used to register a Cloud Stream with one output channel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`@Bean @InboundChannelAdapter(value = Source.OUTPUT, poller = @Poller(fixedDelay
    = "60000", maxMessagesPerPoll = "1"))`: The `InboundChannelAdapter` annotation
    is used to indicate that this method can create a message to be put on a message
    broker. The value attribute is used to indicate the name of the channel where
    the message is to be put. `Poller` is used to schedule the generation of messages.
    In this example, we are using `fixedDelay` to generate messages every minute (60
    * 1000 ms).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`private int getRandomNumber(int min, int max)`: This method is used to create
    a random number in the range passed as parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `Source` interface defines an output channel, as shown in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Processor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The processor application will pick up the message from the input channel on
    the message broker. It will process the message and put it out on the output channel
    of the message broker. In this specific example, processing involves adding the
    position of current holdings to the message.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use Spring Initializr ([https://start.spring.io](https://start.spring.io))
    to set up the application. Provide the details listed here and click on Generate
    Project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Group: `com.mastering.spring.cloud.data.flow`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Artifact: `stock-intelligence-processor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dependencies: `Stream Rabbit`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Update the `SpringBootApplication` file with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'A few important things to note are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`@EnableBinding(Processor.class)`: The `EnableBinding` annotation enables binding
    a class with the respective channel it needs--an input and/or an output. The `Processor`
    class is used to register a Cloud Stream with one input channel and one output
    channel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`private static Map<StockTicker, Integer> getHoldingsFromDatabase()`: This
    method processes a message, updates the holdings, and return a new object, which
    will be put as a new message into the output channel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`@Transformer(inputChannel = Processor.INPUT, outputChannel = Processor.OUTPUT)`:
    The `Transformer` annotation is used to indicate a method that is capable of transforming/enhancing
    one message format into another.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As shown in the following code, the `Processor` class extends the `Source`
    and `Sink` classes. Hence, it defines both the output and input channels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Sink
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sink will pick the message from the message broker and process it. In this example,
    we will pick the message and log it. A Sink will define an input channel only.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use Spring Initializr ([https://start.spring.io](https://start.spring.io))
    to set up the application. Provide the details listed here and click on Generate
    Project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Group: `com.mastering.spring.cloud.data.flow`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Artifact: `event-store-sink`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dependencies: `Stream Rabbit`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Update the `SpringBootApplication` file with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'A few important things to note are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`@EnableBinding(Sink.class)`: The `EnableBinding` annotation enables binding
    a class with the respective channel it needs--an input and/or an output. The `Sink`
    class is used to register a Cloud Stream with one input channel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`public void loggerSink(StockPriceChangeEventWithHoldings event)`: This method
    typically contains the logic to store a message to the data store. In this example,
    we are printing the message to the log.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`@StreamListener(Sink.INPUT)`: The `StreamListener` annotation is used to listen
    on a channel for incoming messages. In this example, `StreamListener` is configured
    to listen on the default input channel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As shown in the following snippet, the `Sink` interface defines an input channel:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have the three stream applications ready, we will need to connect
    them. In the next section, we will cover how Spring Cloud Data Flow helps in connecting
    different streams.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow helps in establishing message flows between different
    kinds of microservices created using Spring Cloud Stream. All the microservices
    that are deployed through the Spring Cloud Data Flow server should be Spring Boot
    microservices that define appropriate channels.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow provides interfaces to define applications and define
    flows between them using Spring DSL. Spring Data Flow Server understands the DSL
    and establishes the flow between applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, this involves multiple steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Using a mapping between the application name and the deployable unit of the
    application to download the application artifacts from repositories. Spring Data
    Flow Server supports Maven and Docker repositories.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying the applications to the target runtime.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating channels on the message broker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establishing connections between the applications and the message broker channels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spring Cloud Data Flow also provides options for the scaling of the applications
    involved when needed. A deployment manifest maps applications to target runtime.
    A couple of questions that a deployment manifest answers are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: How many instances of an application need to be created?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much memory is needed by each instance of an application?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data Flow Server understands the deployment manifests and creates the target
    runtime as specified. Spring Cloud Data Flow supports a variety of runtimes:'
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Foundry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache YARN
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apache Mesos
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Local server for development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use the local server in our examples in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: High-level architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the preceding example, we have three microservices that need to be connected
    in a data flow. The following figure represents the high-level architecture of
    implementing the solution with Spring Cloud Data Flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/60d12ed9-8204-48cf-a89f-6c162c9e5427.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the preceding figure, source, sink, and processor are Spring Boot microservices
    created using Spring Cloud Stream:'
  prefs: []
  type: TYPE_NORMAL
- en: The source microservice defines an output channel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The processor microservice defines both input and output channels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sink microservice defines an input channel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing Spring Cloud Data Flow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Implementing Spring Cloud Data Flow involves five steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Spring Cloud Data Flow server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Setting up the Data Flow Shell project.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configuring the apps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configuring the stream.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Running the stream.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Setting up Spring Cloud Data Flow server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s use Spring Initializr ([https://start.spring.io](https://start.spring.io))
    to set up the application. Provide the details listed here and click on Generate
    Project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Group: `com.mastering.spring.cloud.data.flow`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Artifact: `local-data-flow-server`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dependencies: `Local Data Flow Server`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Listed here are some of the important dependencies from the `pom.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the `SpringBootApplication` file with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `@EnableDataFlowServer` annotation is used to activate a Spring Cloud Data
    Flow Server implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Before you run the Local Data Flow Server, ensure that the message broker RabbitMQ
    is up and running.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an important extract from the start up log when `LocalDataFlowServerApplication`
    is launched:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'A few important things to note are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The default port for Spring Cloud Data Flow server is `9393`. This can be changed
    by specifying a different port as `server.port` in `application.properties`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow Server uses an internal schema to store all the configuration
    of applications, tasks, and streams. In this example, we have not configured any
    database. So, by default, the `H2` in-memory database is used. Spring Cloud Data
    Flow Server supports a variety of databases, including MySQL and Oracle, to store
    the configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since `H2` in-memory database is used, you can see that different schemas are
    set up during start up and also the different SQL scripts to set up data are executed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow Server exposes a number of APIs around its configuration,
    applications, tasks, and streams. We will discuss more about these APIs in a later
    section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot shows the launch screen of Spring Cloud Data Flow
    at `http://localhost:9393/dashboard`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/077ee2c6-bf62-4989-824f-c19fb814bed1.png)'
  prefs: []
  type: TYPE_IMG
- en: There are different tabs that can be used to view and modify applications, streams,
    and tasks. In the next step, we will use the command-line interface--the Data
    Flow Shell to set up applications and streams.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Data Flow Shell project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data Flow Shell provides options to use commands to configure streams and other
    things in Spring Data Flow Server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use Spring Initializr ([https://start.spring.io](https://start.spring.io))
    to set up the application. Provide the details listed here and click on Generate
    Project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Group: `com.mastering.spring.cloud.data.flow`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Artifact: `data-flow-shell`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dependencies: `Data Flow Shell`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Listed here are some of the important dependencies from the `pom.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the `SpringBootApplication` file with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `@EnableDataFlowShell` annotation is used to activate the Spring Cloud Data
    Flow shell.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the message shown when Data Flow Shell application
    is launched. We can type in commands at command prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fc3c5ba3-ba93-471c-baf6-5189345a510c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You can try the "help" command to get the list of the commands supported. The
    following screenshot shows some of the commands that are printed when the `help`
    command is executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3593bc81-bec4-4e65-8a50-c3637dcce671.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You will see that when you executed any of the following commands, you would
    find empty lists printed, as we do not have any of these configured yet:'
  prefs: []
  type: TYPE_NORMAL
- en: '`app list`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stream list`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`task list`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`runtime apps`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring the apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we would start configuring the stream, we would need to register the
    applications that constitute the stream. We have three applications to register--source,
    processor, and sink.
  prefs: []
  type: TYPE_NORMAL
- en: To register an application in Spring Cloud Data Flow, you would need to access
    the application deployable. Spring Cloud Data Flow gives the option of picking
    up the application deployable from a Maven repository. To keep things simple,
    we will pick up the applications from a local Maven repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run `mvn clean install` on all the three applications that we created using
    Spring Cloud Stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '`significant-stock-change-source`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stock-intelligence-processor`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`event-store-sink`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This will ensure that all these applications are built and stored in your local
    Maven repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'The syntax of the command to register an app from a Maven repository is shown
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The Maven URIs for the three applications are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The commands to create the apps are listed here. These commands can be executed
    on the Data Flow Shell application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the messages shown here when the app is successfully registered:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also see the registered apps on the Spring Cloud Data Flow Dashboard
    at `http://localhost:9393/dashboard`, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c6e3de16-73b2-40f4-9082-5cc2b80f568c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can also register an app using the dashboard, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15363632-47c4-45e1-822d-cf56cbe4ba9e.png)'
  prefs: []
  type: TYPE_IMG
- en: Configuring the stream
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Stream DSL can be used to configure a stream--a simple example has been shown
    here to connect `app1` to `app2`. The messages put on the output channel by `app1`
    will be received on the input channel of `app2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We would want to connect the three applications. The following snippet shows
    an example of a DSL used to connect the preceding applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This indicates the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The output channel of the source should be linked to the input channel of processor
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output channel of the processor should be linked to the input channel of
    sink
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The entire command to create a stream is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output if the stream is successfully created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also see the registered stream on the Streams tab of Spring Cloud Data
    Flow dashboard at `http://localhost:9393/dashboard`, as shown in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bbeb68d5-8170-4ce3-8230-3559120b0a4c.png)'
  prefs: []
  type: TYPE_IMG
- en: Deploying the stream
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To deploy the stream, we can execute the following command on the Data Flow
    Shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the message shown here when the request is sent for the creation
    of stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The following extract shows an extract from the Local Data Flow Server log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'A few important things to note are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: When we deploy a stream, Spring Cloud Data Flow will deploy all the applications
    in the stream and set up the connections between the applications through the
    message broker. The application code is independent of the message broker. Kafka
    has a different message broker setup compared to RabbitMQ. Spring Cloud Data Flow
    will take care of it. If you want to switch from RabbitMQ to Kafka, the application
    code does not need to change.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Local Data Flow Server log contains the path to logs of all the applications--
    source, processor, and sink.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log messages - setting up connections to the message factory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following snippet shows extracts related to setting up the message broker
    from the `Source`, `Transformer`, and `Sink` applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'A few things to note are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Created new connection: SimpleConnection@725b3815 [delegate=amqp://guest@127.0.0.1:5672/,
    localPort= 58373]`: Since we added `spring-cloud-starter-stream-rabbit` into the
    classpath of all three applications, the message broker used is RabbitMQ.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Adding {transformer:stockIntelligenceProcessorApplication.addOurInventory.transformer}
    as a subscriber to the ''input'' channel`: Similar to this, the input and/or output
    channels of each application are set up on the message broker. Source and processor
    applications listen on the channels for incoming messages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log messages - the flow of events
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Extracts related to processing of the message are shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The source application sends `StockPriceChangeEvent`. The `Transformer` application
    receives the event, adds the holdings to the message, and creates a new `StockPriceChangeEventWithHoldings`
    event. The sink application receives and logs this message.
  prefs: []
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow REST APIs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow offers RESTful APIs around applications, streams, tasks,
    jobs, and metrics. A complete list can be obtained by sending a `GET` request
    to `http://localhost:9393/`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the response for the `GET` request:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/317bf00f-c9e2-4511-b441-bbe455c25296.png)'
  prefs: []
  type: TYPE_IMG
- en: 'All the APIs are self-explanatory. Let''s look at an example of sending a `GET`
    request to `http://localhost:9393/streams/definitions`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Important things to note are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The API is RESTful. `_embedded` element contains the data for the request. `_links`
    element contains HATEOAS links. The page element contains pagination information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_embedded.streamDefinitionResourceList.dslText` contains the definition of
    the stream `"significant-stock-change-source|stock-intelligence-processor|event-store-sink"`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_embedded.streamDefinitionResourceList.status`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spring Cloud Task
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow can also be used to create and schedule batch applications.
    For the last decade, Spring Batch has been the framework of choice to develop
    batch applications. Spring Cloud Task extends this and enables execution of batch
    programs on the Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use Spring Initializr ([https://start.spring.io](https://start.spring.io))
    to set up the application. Provide the details listed here and click on Generate
    Project:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Group: `com.mastering.spring.cloud.data.flow`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Artifact: `simple-logging-task`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dependencies: `Cloud Task`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Update the `SimpleLoggingTaskApplication` class with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This code simply puts a sysout with the current timestamp. The `@EnableTask`
    annotation enables the task features in a Spring Boot application.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can register the task on the data flow shell using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The commands are very similar to those used to register the stream apps we created
    earlier. We are adding a task definition to be able to execute the task.
  prefs: []
  type: TYPE_NORMAL
- en: 'The task can be launched using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Task executions can be triggered and monitored on the Spring Cloud Flow dashboard
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spring Cloud Data Flow brings Cloud-Native features to data flow and event flow
    streams. It makes it easy to create and deploy streams on the Cloud. In this chapter,
    we covered how individual applications in event-driven flows can be set up using
    Spring Cloud Stream. We took a 1000 feet view on creating tasks with Spring Cloud
    Task. We used Spring Cloud Data Flow to set up streams and also execute simple
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will start understanding a new way of building web applications--
    the reactive style. We will understand why nonblocking applications are being
    hyped up and how reactive applications can be built using Spring Reactive.
  prefs: []
  type: TYPE_NORMAL
