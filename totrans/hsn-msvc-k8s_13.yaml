- en: Service Mesh - Working with Istio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will review the hot topic of service meshes and, in particular,
    Istio. This is exciting because service meshes are a real game changer. They remove
    many complicated tasks from services into independent proxies. This is a huge
    win, especially in a polyglot environment, where different services are implemented
    in different programming languages or if you need to migrate some legacy applications
    into your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: What a service mesh is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What Istio brings to the table
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delinkcious on Istio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatives to Istio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will work with Istio. I chose to use **Google Kubernetes
    Engine** (**GKE**) in this chapter because Istio can be enabled on GKE as an add-on
    and doesn''t require you to install it. This has the following two benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: It saves time on installation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It demonstrates that Delinkcious can run in the cloud and not just locally
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To install Istio, you simply have to enable it in the GKE console and select
    an mTLS mode, which is the mutual authentication between services. I chose permissive,
    which means that the internal communication inside the cluster is not encrypted
    by default, and the services will accept both encrypted and non-encrypted connections.
    You can override it per service. For production clusters, I recommend using the
    strict mTLS mode, where all connections must be encrypted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/d238fcb7-04c2-42cd-afcc-b988619fbac2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Istio gets installed in its own `istio-system` namespace, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the updated Delinkcious application at [https://github.com/the-gigi/delinkcious/releases/tag/v0.11](https://github.com/the-gigi/delinkcious/releases/tag/v0.11).
  prefs: []
  type: TYPE_NORMAL
- en: What is a service mesh?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's start by reviewing the problems microservices face compared to monoliths,
    see how service mesh addresses them, and then you'll see why I'm so excited about
    them. When designing and writing Delinkcious, the application code was fairly
    simple. We keep track of users, their links, and their follower/following relationships.
    We also do some link checking and store recent links in the news service. Finally,
    we expose all of this functionality through an API.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing monoliths to microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It would have been pretty easy to implement all this functionality in a single
    monolith. It would also be pretty simple to deploy, monitor, and debug a Delinkcious
    monolith. However, as Delinkcious grows in functionality, as well as users and
    the team developing it, the downsides of monolith applications become much more
    pronounced. That's why we embarked on this journey with the microservice-based
    approach. However, along the way, we had to write a lot of code, install a lot
    of additional tools, and configure many components that have nothing to do with
    the Delinkcious application itself. We wisely took advantage of Kubernetes and
    Go kit to cleanly separate all of these additional concerns from the Delinkcious
    domain code, but it was a lot of hard work.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if security is a high priority, you would want to authenticate
    and authorize inter-service calls in your system. We have done this in Delinkcious
    by introducing a mutual secret between the link service and the social graph service.
    We have to configure a secret, make sure it is accessible only to these two services,
    and add code to verify that each call is coming from the correct service. Maintaining
    (for example, rotating secrets) and evolving this across many services is not
    an easy task.
  prefs: []
  type: TYPE_NORMAL
- en: Another example of this is distributed tracing. In a monolith, the entire chain
    of calls can be captured by a stack trace. In Delinkcious, you have to install
    a distributed tracing service, such as Jaeger, and modify the code to record spans.
  prefs: []
  type: TYPE_NORMAL
- en: Centralized logging in a monolith is trivial since the monolith is already a
    single centralized entity.
  prefs: []
  type: TYPE_NORMAL
- en: The bottom line is that microservices bring a lot of benefits, but they are
    much harder to manage and reign in.
  prefs: []
  type: TYPE_NORMAL
- en: Using a shared library to manage the cross-cutting concerns of microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most common approaches is to implement all these concerns in a library
    or a set of libraries. All the microservices include or depend on the shared library
    that takes care of all these cross-cutting aspects, such as configuration, logging,
    secret management, tracing, rate limiting, and fault tolerance. This sounds great
    in theory; let the services deal with the application domain and let a shared
    library or libraries deal with the common concerns. Hystrix from Netflix is a
    great example of a Java library that takes care of managing latency and fault
    tolerance. Finagle from Twitter is another good example of a Scala library (targeting
    the JVM). Many organizations use a collection of such libraries and often write
    their own.
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, however, this approach has severe downsides. The first issue is
    that, being a programming language library, it is naturally implemented in a specific
    language (for example, Java, in the case of Hystrix). Your system may have microservices
    in multiple languages (even Delinkcious has both Go and Python services). Having
    microservices implemented in different programming languages is one of the greatest
    benefits. A shared library (or libraries) significantly hinders this aspect. This
    is because you end up with several unappealing options, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: You restrict all your microservices to a single programming language.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You maintain cross-language shared libraries for each programming language you
    use that behaves the same.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You accept that different services will interact differently with your centralized
    services (for example, different logging formats or missing tracing).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these options are pretty bad. But that's not the end of it; let's say
    you've picked a combination of the preceding options. This will very likely include
    a significant amount of custom code, because no off-the-shelve library will provide
    you with everything that you need. Now, you want to update your shared code library.
    Since it's shared by all or most of your services, this means you have to do an
    across-the-board upgrade of all your services. However, it's likely that you can't
    just shut down your system and upgrade all the services at once.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, you'll have to do it in the form of a rolling update. Even blue-green
    deployment can't be done instantly across multiple services. The problem is that,
    often, the shared code is related to how you manage mutual secrets or authentication
    between services. For example, if service A upgrades to the new version of the
    shared library and service B is still on the previous version, they might not
    be able to communicate. This results in an outage, which can cascade and impact
    many services. You can find a way to introduce changes in a backward-compatible
    way, but this is more difficult and error-prone.
  prefs: []
  type: TYPE_NORMAL
- en: Okay, so shared libraries across all services are useful but hard to manage.
    Let's take a look at how a service mesh can help.
  prefs: []
  type: TYPE_NORMAL
- en: Using a service mesh to manage the cross-cutting concerns of microservices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A service mesh is a set of intelligent proxies and additional control infrastructure
    components. The proxies are deployed on every node in your cluster. The proxies
    intercept all communication between the services and can do a lot of work on your
    behalf that previously had to be done by the service (or a shared library used
    by the service). Some of the responsibilities of a service mesh are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Reliable delivery of requests between services through retries and automatic
    failovers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Latency-aware load balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Route requests based on flexible and dynamic routing rules (this is also known
    as traffic shaping)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circuit breaking through deadlines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service-to-service authentication and authorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Report metrics and support for distributed tracing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these capabilities are important for many large-scale cloud-native applications.
    Offloading them from the services is a huge win. Features such as smart traffic
    shaping require building dedicated and reliable services without a service mesh.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates how a service mesh is embedded into a Kubernetes
    cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/3c4edd51-3de0-4ed9-bedf-806b3153a883.png)'
  prefs: []
  type: TYPE_IMG
- en: Service meshes sound revolutionary indeed. Let's take a look at how they fit
    into Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the relationship between Kubernetes and a service mesh
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At first glance, the service mesh sounds very similar to Kubernetes itself.
    Kubernetes deploys the kubelet and the kube-proxy into each node and the service
    mesh deploys its own proxy. Kubernetes has a control plane that kubelet/kube-proxy
    interacts with, and the service mesh has its own control plane that the mesh proxies
    interact with.
  prefs: []
  type: TYPE_NORMAL
- en: I like to think of a service mesh as a complement to Kubernetes. Kubernetes
    is primarily in charge of scheduling pods and providing it with the flat networking
    model and service discovery, so different pods and services can communicate with
    each other. This is where the service mesh takes over and manages this service-to-service
    communication in a much more fine-grained way. There is a thin layer of overlap
    in responsibilities around load balancing and network policies but, overall, the
    service mesh is a great complement to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: It's also important to realize that these two amazing technologies don't depend
    on each other. Obviously, you can run a Kubernetes cluster without a service mesh.
    Additionally, many service meshes can work with other non-Kubernetes platforms,
    such as Mesos, Nomad, Cloud Foundry, and Consul-based deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand what a service mesh is, let's take a look at a specific
    example.
  prefs: []
  type: TYPE_NORMAL
- en: What does Istio bring to the table?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Istio is a service mesh that was originally developed by Google, IBM, and Lyft.
    It was introduced in mid-2017 and took off like a rocket. It brings a coherent
    model with a control and data plane, is built around the Envoy proxy, has a lot
    of momentum, and already serves as the foundation for additional projects. It
    is, of course, open source and a **Cloud Native Computing Foundation** (**CNCF**)
    project. In Kubernetes, each Envoy proxy is injected as a sidecar container to
    each pod that participates in the mesh.
  prefs: []
  type: TYPE_NORMAL
- en: Let's explore the Istio architecture, and then dive into the services that it
    provides.
  prefs: []
  type: TYPE_NORMAL
- en: Getting to know the Istio architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Istio is a large framework that provides a lot of capabilities, and it has multiple
    parts that interact with each other and with Kubernetes components (mostly indirectly
    and unobtrusively). It is divided into a control plane and a data plane. The data
    plane is a set of proxies (one per pod). Their control plane is a set of components
    that are responsible for configuring the proxies and collecting telemetry of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the different parts of Istio, how they are
    related to each other, and what information is exchanged between them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bcf2a6b9-cc37-4580-9cb4-28ad191e5c04.png)'
  prefs: []
  type: TYPE_IMG
- en: Let's go a little deeper into each component, starting with the Envoy proxy.
  prefs: []
  type: TYPE_NORMAL
- en: Envoy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Envoy is a high-performance proxy that''s implemented in C++. It was developed
    by Lyft and functions as the data plane of Istio, but it is also an independent
    CNCF project and can be used on its own. For each pod in the service mesh, Istio
    injects (either automatically or through the `istioctl` CLI) an Envoy side container
    that does the heavy lifting:'
  prefs: []
  type: TYPE_NORMAL
- en: Proxy HTTP, HTTP/2, and gRPC traffic between pods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sophisticated load balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: mTLS termination
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HTTP/2 and gRPC proxies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing service health
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circuit breaking for unhealthy services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Percent-based traffic shaping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Injecting faults for testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detailed metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Envoy proxy controls all the incoming and outgoing communication to its
    pod. It is, by far, the most important component of Istio. The configuration of
    Envoy is not trivial, and this is a large part of what the Istio control plane
    deals with.
  prefs: []
  type: TYPE_NORMAL
- en: The next component is Pilot.
  prefs: []
  type: TYPE_NORMAL
- en: Pilot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pilot is responsible for platform-agnostic service discovery, dynamic load balancing,
    and routing. It translates high-level routing rules and resiliency from its own
    rules API into an Envoy configuration. This abstraction layer allows Istio to
    run on multiple orchestration platforms. Pilot takes all the platform-specific
    information, converts it into the Envoy data plane configuration format, and propagates
    it to each Envoy proxy with the Envoy data plane API. Pilot is stateless; in Kubernetes,
    all the configuration is stored as **custom resources definitions** (**CRDs**)
    on etcd.
  prefs: []
  type: TYPE_NORMAL
- en: Mixer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Mixer is responsible for abstracting the metrics collection and policies. These
    aspects are typically implemented in services by accessing APIs directly for specific
    backends. This has the benefit of offloading this burden from service developers
    and putting the control into the hands of the operators that configure Istio.
    It also allows you to switch backends easily without code changes. The types of
    backends that Mixer can work with include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Logging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quota
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Telemetry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Billing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The interaction between the Envoy proxy and Mixer is straightforward – before
    each request, the proxy calls Mixer for precondition checks, which might cause
    the request to be rejected; after each request, the proxy reports the metrics
    to Mixer. Mixer has an adapter API to facilitate extensions for arbitrary infrastructure
    backends. It is a major part of its design.
  prefs: []
  type: TYPE_NORMAL
- en: Citadel
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Citadel is responsible for certificate and key management in Istio. It integrates
    with various platforms and aligns with their identity mechanisms. For example,
    in Kubernetes, it uses service accounts; on AWS, it uses AWS IAM; and on GCP/GKE,
    it can use GCP IAM. The Istio PKI is based on Citadel. It uses X.509 certificates
    in SPIFEE format as a vehicle for service identity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the workflow in Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: Citadel creates certificates and key pairs for existing service accounts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Citadel watches the Kubernetes API server for new service accounts to provision
    with a certificate a key pair.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Citadel stores the certificates and keys as Kubernetes secrets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes mounts the secrets into each new pod that is associated with the
    service account (this is standard Kubernetes practice).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Citadel automatically rotates the Kubernetes secrets when the certificates expire.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pilot generates secure naming information that associates a service account
    with an Istio service. Pilot then passes the secure naming information to the
    Envoy proxy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final major component that we will cover is Galley.
  prefs: []
  type: TYPE_NORMAL
- en: Galley
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Galley is a relatively simple component. Its job is to abstract away the user
    configuration on different platforms. It provides the ingested configuration to
    Pilot and Mixer.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have broken down Istio into its major components, let's take a look
    at how it accomplishes its duties as a service mesh. The number one capability
    is traffic management.
  prefs: []
  type: TYPE_NORMAL
- en: Managing traffic with Istio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Istio operates at the network level inside the cluster between your services,
    as well as managing how you expose your services to the world. It provides many
    capabilities, such as request routing, load balancing, automatic retries, and
    fault injection. Let's review all of these, starting with routing requests.
  prefs: []
  type: TYPE_NORMAL
- en: Routing requests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Istio introduces its own virtual services as a CRD. Istio services have a concept
    of a version that doesn't exist for Kubernetes services. The same image can be
    deployed as different versions of a virtual service. For example, you can represent
    the production or staging environment as different versions of the same service.
    Istio allows you to configure rules that determine how to route traffic to different
    versions of a service.
  prefs: []
  type: TYPE_NORMAL
- en: 'The way this works is that Pilot sends ingress and egress rules to the proxies
    that determine where requests should be handled. You then define the rules as
    a CRD in Kubernetes. Here is a simple example that defines a virtual service for
    the `link-manager` service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Let's take a look at how Istio does load balancing.
  prefs: []
  type: TYPE_NORMAL
- en: Load balancing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Istio has its own platform-independent service discovery with adapters for
    the underlying platform (for example, Kubernetes). It relies on the existence
    of a service registry that the underlying platform manages, and removes unhealthy
    instances in order to update its load balancing pools. There are currently three
    supported load balancing algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: Round robin
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weighted least request
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Envoy has a few more algorithms, such as Maglev, ring hash, and weighted round
    robin, that Istio doesn't support yet.
  prefs: []
  type: TYPE_NORMAL
- en: Istio also performs periodic health checks to verify that instances in the pool
    are actually healthy, and can remove them from load balancing temporarily if they
    fail the configured health check threshold.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can configure load balancing through the destination rules in a separate
    `DestinationRule` CRD, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'You can specify different algorithms by the port, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's take a look at how Istio can help us deal with failures automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Handling failures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Istio provides many mechanisms to deal with failure, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Timeouts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retries (including backoff and jitter)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rate limiting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Health checks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circuit breakers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these can be configured through Istio CRDs.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the following code demonstrates how to set the connection limits
    and timeout for the `link-manager` service at the TCP level (HTTP is supported
    too):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Circuit breaking is done by explicitly checking for application errors (for
    example, the 5XX HTTP status code) within a given time period. This is done in
    an `outlierDetection` section. The following example checks for 10 consecutive
    errors every 2 minutes. If the service crosses this threshold, the instance will
    be ejected from the pool for a period of 5 minutes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note that, as far as Kubernetes is concerned, the service may be fine because
    the container is running.
  prefs: []
  type: TYPE_NORMAL
- en: It's great that Istio provides so many ways to deal with errors and failures
    at the operational level. When testing distributed systems, it is important to
    test the behavior when certain components fail. Istio supports this use case by
    allowing you to inject faults on purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Injecting faults for testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The failure handling mechanisms of Istio don''t magically fix errors. Automatic
    retries can automatically address intermittent failures, but some failures need
    to be handled by the application or even a human operator. In fact, the misconfiguration
    of Istio failure handling can itself cause failures (for example, configuring
    timeouts that are too short). Testing how the system behaves in the presence of
    failures can be done by artificially injecting faults. There are two types of
    faults that Istio can inject: aborts and delays. You can configure fault injection
    at the virtual service level.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of where a delay of 5 seconds is added to 10% of all requests
    to the `link-manager` service in order to simulate a heavy load on the system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Testing under stress and in the presence of faults is a tremendous boon, but
    all testing is incomplete. When it's time to deploy the new version, you may want
    to deploy it to a small percentage of users or have the new version handle just
    a small percentage of all requests. This is where canary deployments come in.
  prefs: []
  type: TYPE_NORMAL
- en: Doing canary deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We previously discovered how to perform canary deployments in Kubernetes. If
    we want to divert 10% of requests to our canary version, we have to deploy nine
    pods of the current version and one canary pod to get the correct ratio. Kubernetes'
    load balancing is tightly coupled to deployed pods. This is suboptimal. Istio
    has a better load balancing approach since it operates at the network level. You
    can simply configure two versions of your service and decide what percentage of
    requests go to each version, regardless of how many pods run each version.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of where Istio will split the traffic and send 95% to v1
    of the service and 5% to v2 of the service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The subsets named v1 and v2 are defined in a destination rule based on labels.
    In this case, the label are `version: v1` and `version: v2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This was a pretty comprehensive coverage of the traffic management capabilities
    of Istio, but there is much more to discover. Let's turn our attention to security.
  prefs: []
  type: TYPE_NORMAL
- en: Securing your cluster with Istio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The security model of Istio revolves around three themes: identity, authentication,
    and authorization.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Istio identity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Istio manages its own identity model, which can represent human users, services,
    or groups of services. In Kubernetes, Istio uses Kubernetes' service account to
    represent identity. Istio uses its PKI (through Citadel) to create a strong cryptographic
    identity for each pod that it manages. It creates a x.509 certificate (in SPIFEE
    format) and a key pair for each service account and injects them as secrets to
    the pod. Pilot manages a map between the DNS service names and the identities
    that are allowed to run them. When clients call into services, they can verify
    that the services are indeed run by allowed identities and can detect rogue services.
    With a strong identity in place, let's take a look at how authentication works
    with Istio.
  prefs: []
  type: TYPE_NORMAL
- en: Authenticating users with Istio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Istio authentication is based on policies. There are two kinds of policies:
    namespace policies and mesh policies. A namespace policy applies to a single namespace.
    A mesh policy applies to the entire cluster. There can be only one mesh policy
    with a kind of `MeshPolicy` and it must be named `default`. Here is an example
    of a mesh policy that requires all services to use mTLS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Namespace policies have a kind of `Policy`. If you don''t specify a namespace,
    then it will apply to the default namespace. There can be only one policy per
    namespace and it must be called `default` too. The following policy uses the targets
    selector to apply only to the `api-gateway` service and port `8080` of the link
    service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The idea is to avoid ambiguity; policies are resolved from a service to a namespace
    to a mesh. If a narrow policy exists, it takes precedence.
  prefs: []
  type: TYPE_NORMAL
- en: Istio provides either peer authentication through mTLS or origin authentication
    through JWT.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can configure peer authentication through the `peers` section, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You can configure the origin through the `origins` section, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, origin authentication can be configured for specific paths (through
    the include or exclude paths). In the preceding example, the `/healthcheck` path
    is exempt from authentication, which makes sense for a health check endpoint that
    often needs to be called from a load balancer or remote monitoring service.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, peer authentication is used if there is a peers section. If not,
    then authentication will not be set. To force origin authentication, you can add
    the following to the policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Now that we've discovered how Istio authenticates requests, let's take a look
    at how it does authorization.
  prefs: []
  type: TYPE_NORMAL
- en: Authorizing requests with Istio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Services usually expose multiple endpoints. Service A may be allowed to call
    only specific endpoints of service B. Service A must first authenticate against
    service B, and then the specific request must be authorized as well. Istio supports
    this by extending the** role-based access control** (**RBAC**) that Kubernetes
    uses to authorize requests to its API server.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''s important to note that authorization is turned off by default. To turn
    it on, you can create a `ClusterRbacConfig` object. The mode controls how authorization
    is enabled, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`OFF` means authorization is disabled (the default).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ON` means authorization is enabled for all the services in the entire mesh.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ON_WITH_INCLUSION` means authorization is enabled for all the included namespaces
    and services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ON_WITH_EXCLUSION` means authorization is enabled for all namespaces and services
    except the excluded ones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is an example of when authorization is enabled on all the namespaces except
    `kube-system` and `development`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The actual authorization operates at the service level and is very similar to
    the RBAC model of Kubernetes. Where in Kubernetes there is `Role`, `ClusterRole`,
    `RoleBinding`, and `ClusterRoleBinding`, in Istio, there is `ServiceRole` and
    `ServiceRoleBinding`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic level of granularity is `namespace/service/path/method`. You can
    use wildcards for grouping. For example, the following role grants GET and HEAD
    access to all the Delinkcious managers and the API gateway in the default namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: However, Istio offers even further control with constraints and properties.
    You can limit a rule by the source namespace or the IP, labels, request headers,
    and other attributes.
  prefs: []
  type: TYPE_NORMAL
- en: You can refer to [https://istio.io/docs/reference/config/authorization/constraints-and-properties/](https://istio.io/docs/reference/config/authorization/constraints-and-properties/)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have a `ServiceRole`, you need to associate it with a list of subjects
    (such as service accounts or human users) that will be allowed to perform the
    requested operations. Here is how you can define `ServiceRoleBinding`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: You can make a role publicly available to authenticated or unauthenticated users
    by setting the subject user to `*`.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is much to Istio authorization that we can cover here. You can read up
    on the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Authorization for TCP protocols
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Permissive mode (experimental)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging authorization problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authorization through Envoy filters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once a request is authorized there, it may still be rejected if it fails to
    comply with policy checks.
  prefs: []
  type: TYPE_NORMAL
- en: Enforcing policies with Istio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Istio policy enforcement is similar to the way admission controllers work in
    Kubernetes. Mixer has a set of adapters that are invoked before and after a request
    is processed. Before we dive in further, it''s important to note that policy enforcement
    is disabled by default. If you install Istio using helm, you can enable it by
    providing the following flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'On GKE, it is enabled; here is how to check this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If the result is `disablePolicyChecks: false`, then it''s already enabled.
    Otherwise, enable it by editing the Istio ConfigMap and setting it to false.'
  prefs: []
  type: TYPE_NORMAL
- en: One common type of policy is rate limiting. You can enforce rate limits by configuring
    quota objects, binding them to specific services, and defining mixer rules. A
    good example from the Istio demo application can be found at [https://raw.githubusercontent.com/istio/istio/release-1.1/samples/bookinfo/policy/mixer-rule-productpage-ratelimit.yaml](https://raw.githubusercontent.com/istio/istio/release-1.1/samples/bookinfo/policy/mixer-rule-productpage-ratelimit.yaml).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also add your own policies by creating a Mixer adapter. There are three
    built-in types of adapters, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Check
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quota
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Report
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is not trivial; you'll have to implement a gRPC service that can handle
    the data specified in a dedicated template. Now, let's take a look at the metrics
    Istio collects for us.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting metrics with Istio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Istio collects metrics after each request. The metrics are sent to Mixer. Envoy
    is the primary producer of metrics, but you can add your own metrics if you wish.
    The configuration model for metrics is based on multiple Istio concepts: attributes,
    instances, templates, handlers, rules, and Mixer adapters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a sample instance that counts all the requests and reports them as
    the `request-count` metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'apiVersion: config.istio.io/v1alpha2'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: handler'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: request-count-handler'
  prefs: []
  type: TYPE_NORMAL
- en: 'namespace: istio-system'
  prefs: []
  type: TYPE_NORMAL
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'compiledAdapter: prometheus'
  prefs: []
  type: TYPE_NORMAL
- en: 'params:'
  prefs: []
  type: TYPE_NORMAL
- en: 'metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '- name: request_count # Prometheus metric name'
  prefs: []
  type: TYPE_NORMAL
- en: 'instance_name: request-count.instance.istio-system # Mixer instance name (fully-qualified)'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: COUNTER'
  prefs: []
  type: TYPE_NORMAL
- en: 'label_names:'
  prefs: []
  type: TYPE_NORMAL
- en: '- reporter'
  prefs: []
  type: TYPE_NORMAL
- en: '- source'
  prefs: []
  type: TYPE_NORMAL
- en: '- destination'
  prefs: []
  type: TYPE_NORMAL
- en: '- message'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'apiVersion: config.istio.io/v1alpha2'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: rule'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: prom-request-counter'
  prefs: []
  type: TYPE_NORMAL
- en: 'namespace: istio-system'
  prefs: []
  type: TYPE_NORMAL
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'actions:'
  prefs: []
  type: TYPE_NORMAL
- en: '- handler: request-count-handler'
  prefs: []
  type: TYPE_NORMAL
- en: 'instances: [ request-count ]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: $ kubectl get secret | grep mutual
  prefs: []
  type: TYPE_NORMAL
- en: link-mutual-auth             Opaque          1      9d
  prefs: []
  type: TYPE_NORMAL
- en: social-graph-mutual-auth    Opaque          1      5d19h
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '- name: link-manager'
  prefs: []
  type: TYPE_NORMAL
- en: 'image: g1g1/delinkcious-link:0.3'
  prefs: []
  type: TYPE_NORMAL
- en: 'imagePullPolicy: Always'
  prefs: []
  type: TYPE_NORMAL
- en: 'ports:'
  prefs: []
  type: TYPE_NORMAL
- en: '- containerPort: 8080'
  prefs: []
  type: TYPE_NORMAL
- en: 'envFrom:'
  prefs: []
  type: TYPE_NORMAL
- en: '- configMapRef:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: link-manager-config'
  prefs: []
  type: TYPE_NORMAL
- en: 'volumeMounts:'
  prefs: []
  type: TYPE_NORMAL
- en: '- name: mutual-auth'
  prefs: []
  type: TYPE_NORMAL
- en: 'mountPath: /etc/delinkcious'
  prefs: []
  type: TYPE_NORMAL
- en: 'readOnly: true'
  prefs: []
  type: TYPE_NORMAL
- en: 'volumes:'
  prefs: []
  type: TYPE_NORMAL
- en: '- name: mutual-auth'
  prefs: []
  type: TYPE_NORMAL
- en: 'secret:'
  prefs: []
  type: TYPE_NORMAL
- en: 'secretName: link-mutual-auth'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: // encodeHTTPGenericRequest is a transport/http.EncodeRequestFunc that
  prefs: []
  type: TYPE_NORMAL
- en: // JSON-encodes any request to the request body. Primarily useful in a client.
  prefs: []
  type: TYPE_NORMAL
- en: func encodeHTTPGenericRequest(_ context.Context, r *http.Request, request interface{})
    error {
  prefs: []
  type: TYPE_NORMAL
- en: var buf bytes.Buffer
  prefs: []
  type: TYPE_NORMAL
- en: if err := json.NewEncoder(&buf).Encode(request); err != nil {
  prefs: []
  type: TYPE_NORMAL
- en: return err
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: r.Body = ioutil.NopCloser(&buf)
  prefs: []
  type: TYPE_NORMAL
- en: if os.Getenv("DELINKCIOUS_MUTUAL_AUTH") != "false" {
  prefs: []
  type: TYPE_NORMAL
- en: token := auth_util.GetToken(SERVICE_NAME)
  prefs: []
  type: TYPE_NORMAL
- en: r.Header["Delinkcious-Caller-Token"] = []string{token}
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: return nil
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: func decodeGetFollowersRequest(_ context.Context, r *http.Request) (interface{},
    error){
  prefs: []
  type: TYPE_NORMAL
- en: if os.Getenv("DELINKCIOUS_MUTUAL_AUTH") != "false" {
  prefs: []
  type: TYPE_NORMAL
- en: token := r.Header["Delinkcious-Caller-Token"]
  prefs: []
  type: TYPE_NORMAL
- en: if len(token) == 0 || token[0] == "" {
  prefs: []
  type: TYPE_NORMAL
- en: return nil, errors.New("Missing caller token")
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: if !auth_util.HasCaller("link-manager", token[0]) {
  prefs: []
  type: TYPE_NORMAL
- en: return nil, errors.New("Unauthorized caller")
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '...'
  prefs: []
  type: TYPE_NORMAL
- en: '}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'apiVersion: "rbac.istio.io/v1alpha1"'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: ServiceRole'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: get-following'
  prefs: []
  type: TYPE_NORMAL
- en: 'namespace: default'
  prefs: []
  type: TYPE_NORMAL
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '- services: ["social-graph.default.svc.cluster.local"]'
  prefs: []
  type: TYPE_NORMAL
- en: 'paths: ["/following"]'
  prefs: []
  type: TYPE_NORMAL
- en: 'methods: ["GET"]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'apiVersion: "rbac.istio.io/v1alpha1"'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: ServiceRoleBinding'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: get-following'
  prefs: []
  type: TYPE_NORMAL
- en: 'namespace: default'
  prefs: []
  type: TYPE_NORMAL
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'subjects:'
  prefs: []
  type: TYPE_NORMAL
- en: '- user: "cluster.local/ns/default/sa/link-manager"'
  prefs: []
  type: TYPE_NORMAL
- en: 'roleRef:'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: ServiceRole'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: "get-following"'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: $ kubectl scale --replicas=9 deployment/green-link-manager
  prefs: []
  type: TYPE_NORMAL
- en: deployment.extensions/green-link-manager scaled
  prefs: []
  type: TYPE_NORMAL
- en: $ kubectl get po -l svc=link,app=manager
  prefs: []
  type: TYPE_NORMAL
- en: NAME                                 READY  STATUS    RESTARTS   AGE
  prefs: []
  type: TYPE_NORMAL
- en: green-link-manager-5874c6cd4f-2ldfn   1/1   Running   10         15h
  prefs: []
  type: TYPE_NORMAL
- en: green-link-manager-5874c6cd4f-9csxz   1/1   Running   0          52s
  prefs: []
  type: TYPE_NORMAL
- en: green-link-manager-5874c6cd4f-c5rqn   1/1   Running   0          52s
  prefs: []
  type: TYPE_NORMAL
- en: green-link-manager-5874c6cd4f-mvm5v   1/1   Running   10         15h
  prefs: []
  type: TYPE_NORMAL
- en: green-link-manager-5874c6cd4f-qn4zj   1/1   Running   0          52s
  prefs: []
  type: TYPE_NORMAL
- en: green-link-manager-5874c6cd4f-r2jxf   1/1   Running   0          52s
  prefs: []
  type: TYPE_NORMAL
- en: green-link-manager-5874c6cd4f-rtwsj   1/1   Running   0          52s
  prefs: []
  type: TYPE_NORMAL
- en: green-link-manager-5874c6cd4f-sw27r   1/1   Running   0          52s
  prefs: []
  type: TYPE_NORMAL
- en: green-link-manager-5874c6cd4f-vcj9s   1/1   Running   10         15h
  prefs: []
  type: TYPE_NORMAL
- en: yellow-link-manager-67847d6b85-n97b5  1/1   Running   4          6m20s
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'apiVersion: networking.istio.io/v1alpha3'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: VirtualService'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: social-graph-manager'
  prefs: []
  type: TYPE_NORMAL
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'hosts:'
  prefs: []
  type: TYPE_NORMAL
- en: '- social-graph-manager'
  prefs: []
  type: TYPE_NORMAL
- en: 'http:'
  prefs: []
  type: TYPE_NORMAL
- en: '- route:'
  prefs: []
  type: TYPE_NORMAL
- en: '- destination:'
  prefs: []
  type: TYPE_NORMAL
- en: 'host: social-graph-manager'
  prefs: []
  type: TYPE_NORMAL
- en: 'subset: v0.5'
  prefs: []
  type: TYPE_NORMAL
- en: 'weight: 90'
  prefs: []
  type: TYPE_NORMAL
- en: '- destination:'
  prefs: []
  type: TYPE_NORMAL
- en: 'host: social-graph-manager'
  prefs: []
  type: TYPE_NORMAL
- en: 'subset: canary'
  prefs: []
  type: TYPE_NORMAL
- en: 'weight: 10'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'apiVersion: nats.io/v1alpha2'
  prefs: []
  type: TYPE_NORMAL
- en: 'kind: NatsCluster'
  prefs: []
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: 'name: nats-cluster'
  prefs: []
  type: TYPE_NORMAL
- en: 'spec:'
  prefs: []
  type: TYPE_NORMAL
- en: 'pod:'
  prefs: []
  type: TYPE_NORMAL
- en: Disable istio on nats pods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'annotations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'sidecar.istio.io/inject: "false"'
  prefs: []
  type: TYPE_NORMAL
- en: 'size: 1'
  prefs: []
  type: TYPE_NORMAL
- en: 'version: "1.4.0"'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: $ kubectl get crd -l k8s-app=istio -o custom-columns="NAME:.metadata.name"
  prefs: []
  type: TYPE_NORMAL
- en: NAME
  prefs: []
  type: TYPE_NORMAL
- en: adapters.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: apikeys.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: attributemanifests.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: authorizations.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: bypasses.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: checknothings.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: circonuses.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: deniers.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: destinationrules.networking.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: edges.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: envoyfilters.networking.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: fluentds.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: gateways.networking.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: handlers.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: httpapispecbindings.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: httpapispecs.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: instances.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: kubernetesenvs.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: kuberneteses.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: listcheckers.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: listentries.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: logentries.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: memquotas.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: metrics.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: noops.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: opas.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: prometheuses.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: quotas.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: quotaspecbindings.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: quotaspecs.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: rbacconfigs.rbac.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: rbacs.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: redisquotas.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: reportnothings.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: rules.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: servicecontrolreports.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: servicecontrols.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: serviceentries.networking.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: servicerolebindings.rbac.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: serviceroles.rbac.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: signalfxs.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: solarwindses.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: stackdrivers.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: statsds.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: stdios.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: templates.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: tracespans.config.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: virtualservices.networking.istio.io
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: $ kubectl -n istio-system get all -o name
  prefs: []
  type: TYPE_NORMAL
- en: pod/istio-citadel-6995f7bd9-7c7x9
  prefs: []
  type: TYPE_NORMAL
- en: pod/istio-egressgateway-57b96d87bd-cnc2s
  prefs: []
  type: TYPE_NORMAL
- en: pod/istio-galley-6d7dd498f6-b29sk
  prefs: []
  type: TYPE_NORMAL
- en: pod/istio-ingressgateway-ddd557db7-glwm2
  prefs: []
  type: TYPE_NORMAL
- en: pod/istio-pilot-5765d76b8c-d9hq7
  prefs: []
  type: TYPE_NORMAL
- en: pod/istio-policy-5b47b88467-x7pqf
  prefs: []
  type: TYPE_NORMAL
- en: pod/istio-sidecar-injector-6b9fbbfcf6-fhc4k
  prefs: []
  type: TYPE_NORMAL
- en: pod/istio-telemetry-65dcd9ff85-bkjtd
  prefs: []
  type: TYPE_NORMAL
- en: pod/promsd-7b49dcb96c-wrfs8
  prefs: []
  type: TYPE_NORMAL
- en: service/istio-citadel
  prefs: []
  type: TYPE_NORMAL
- en: service/istio-egressgateway
  prefs: []
  type: TYPE_NORMAL
- en: service/istio-galley
  prefs: []
  type: TYPE_NORMAL
- en: service/istio-ingressgateway
  prefs: []
  type: TYPE_NORMAL
- en: service/istio-pilot
  prefs: []
  type: TYPE_NORMAL
- en: service/istio-policy
  prefs: []
  type: TYPE_NORMAL
- en: service/istio-sidecar-injector
  prefs: []
  type: TYPE_NORMAL
- en: service/istio-telemetry
  prefs: []
  type: TYPE_NORMAL
- en: service/promsd
  prefs: []
  type: TYPE_NORMAL
- en: deployment.apps/istio-citadel
  prefs: []
  type: TYPE_NORMAL
- en: deployment.apps/istio-egressgateway
  prefs: []
  type: TYPE_NORMAL
- en: deployment.apps/istio-galley
  prefs: []
  type: TYPE_NORMAL
- en: deployment.apps/istio-ingressgateway
  prefs: []
  type: TYPE_NORMAL
- en: deployment.apps/istio-pilot
  prefs: []
  type: TYPE_NORMAL
- en: deployment.apps/istio-policy
  prefs: []
  type: TYPE_NORMAL
- en: deployment.apps/istio-sidecar-injector
  prefs: []
  type: TYPE_NORMAL
- en: deployment.apps/istio-telemetry
  prefs: []
  type: TYPE_NORMAL
- en: deployment.apps/promsd
  prefs: []
  type: TYPE_NORMAL
- en: replicaset.apps/istio-citadel-6995f7bd9
  prefs: []
  type: TYPE_NORMAL
- en: replicaset.apps/istio-egressgateway-57b96d87bd
  prefs: []
  type: TYPE_NORMAL
- en: replicaset.apps/istio-galley-6d7dd498f6
  prefs: []
  type: TYPE_NORMAL
- en: replicaset.apps/istio-ingressgateway-ddd557db7
  prefs: []
  type: TYPE_NORMAL
- en: replicaset.apps/istio-pilot-5765d76b8c
  prefs: []
  type: TYPE_NORMAL
- en: replicaset.apps/istio-policy-5b47b88467
  prefs: []
  type: TYPE_NORMAL
- en: replicaset.apps/istio-sidecar-injector-6b9fbbfcf6
  prefs: []
  type: TYPE_NORMAL
- en: replicaset.apps/istio-telemetry-65dcd9ff85
  prefs: []
  type: TYPE_NORMAL
- en: replicaset.apps/promsd-7b49dcb96c
  prefs: []
  type: TYPE_NORMAL
- en: horizontalpodautoscaler.autoscaling/istio-egressgateway
  prefs: []
  type: TYPE_NORMAL
- en: horizontalpodautoscaler.autoscaling/istio-ingressgateway
  prefs: []
  type: TYPE_NORMAL
- en: horizontalpodautoscaler.autoscaling/istio-pilot
  prefs: []
  type: TYPE_NORMAL
- en: horizontalpodautoscaler.autoscaling/istio-policy
  prefs: []
  type: TYPE_NORMAL
- en: horizontalpodautoscaler.autoscaling/istio-telemetry
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: $ kubectl get po
  prefs: []
  type: TYPE_NORMAL
- en: NAME READY STATUS RESTARTS AGE
  prefs: []
  type: TYPE_NORMAL
- en: api-gateway-5497d95c74-zlgnm 2/2 Running 0 4d11h
  prefs: []
  type: TYPE_NORMAL
- en: link-db-7445d6cbf7-wdfsb 2/2 Running 0 4d22h
  prefs: []
  type: TYPE_NORMAL
- en: link-manager-54968ff8cf-vtpqr 2/2 Running 1 4d13h
  prefs: []
  type: TYPE_NORMAL
- en: nats-cluster-1 1/1 Running 0 4d20h
  prefs: []
  type: TYPE_NORMAL
- en: nats-operator-55dfdc6868-2b57q 2/2 Running 3 4d22h
  prefs: []
  type: TYPE_NORMAL
- en: news-manager-7f447f5c9f-n2v2v 2/2 Running 1 4d20h
  prefs: []
  type: TYPE_NORMAL
- en: news-manager-redis-0 2/2 Running 0 4d22h
  prefs: []
  type: TYPE_NORMAL
- en: social-graph-db-7d8ffb877b-nrzxh 2/2 Running 0 4d11h
  prefs: []
  type: TYPE_NORMAL
- en: social-graph-manager-59b464456f-48lrn 2/2 Running 1 4d11h
  prefs: []
  type: TYPE_NORMAL
- en: trouble-64554479d-rjszv 2/2 Running 0 4d17h
  prefs: []
  type: TYPE_NORMAL
- en: user-db-0 2/2 Running 0 4d22h
  prefs: []
  type: TYPE_NORMAL
- en: user-manager-699458447-9h64n 2/2 Running 2 4d22h
  prefs: []
  type: TYPE_NORMAL
- en: '```'
  prefs: []
  type: TYPE_NORMAL
- en: If you think that Istio is too big and complicated, you may still want to enjoy
    the benefits of a service mesh by pursuing one of the alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatives to Istio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Istio has a lot of momentum, but it's not necessarily the best service mesh
    for you. Let's take a look at some other service meshes and consider their attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Linkerd 2.0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Buoyant is the company that coined the term *Service Mesh* in 2016 and came
    out with the first service mesh – Linkerd. It was based on Twitter's Finagle and
    was implemented in Scala. Since then, Buoyant developed a new service mesh that
    focused on Kubernetes, called Conduit (which was implemented in Rust and Go),
    and later (in July 2018) renamed it to Linkerd 2.0\. It is a CNCF project like
    Istio. Linkerd 2.0 also uses sidecar containers that can be automatically or manually
    injected.
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to its lightweight design and tighter implementation of the data plane
    proxies in Rust, Linkerd 2.0 is supposed to outperform Istio and consume far fewer
    resources in the control plane. You can refer to the following resources for more
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CPU and memory**: [https://istio.io/docs/concepts/performance-and-scalability/#cpu-and-memory](https://istio.io/docs/concepts/performance-and-scalability/#cpu-and-memory)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Linkerd 2.0 and Istio Performance Benchmark**: [https://medium.com/@ihcsim/linkerd-2-0-and-istio-performance-benchmark-df290101c2bb](https://medium.com/@ihcsim/linkerd-2-0-and-istio-performance-benchmark-df290101c2bb)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Benchmarking Istio and Linkerd CPU**: [https://medium.com/@michael_87395/benchmarking-istio-linkerd-cpu-c36287e32781](https://medium.com/@michael_87395/benchmarking-istio-linkerd-cpu-c36287e32781)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Buoyant is a smaller company and it seems to lag slightly behind Istio in functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Envoy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Istio data plane is Envoy, which does all the heavy lifting. You may find
    the Istio control plane too complicated and prefer to remove this layer of indirection
    and build your own control plane to interact directly with Envoy. This can be
    useful in some specialized circumstances; for example, if you want to use a load
    balancing algorithm offered by Envoy that Istio doesn't support.
  prefs: []
  type: TYPE_NORMAL
- en: HashiCorp Consul
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Consul doesn't tick all the checkboxes for a service mesh, but it provides service
    discovery, service identity, and mTLS authorization. It is not Kubernetes-specific
    and isn't endorsed by the CNCF. If you already use Consul or other HashiCorp products,
    you may prefer to use it as a service mesh too.
  prefs: []
  type: TYPE_NORMAL
- en: AWS App Mesh
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you run your infrastructure on AWS, you should consider the AWS App Mesh.
    It is a newer project, AWS-specific, and also uses Envoy as its data plane. It
    is safe to assume that it will integrate the best with AWS IAM networking and
    monitoring technologies. It's not clear at this point as to whether AWS App Mesh
    is going to be a better service mesh for Kubernetes or if its main purpose is
    to provide service mesh benefits for ECS – AWS' proprietary container orchestration
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: Others
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There a few other service meshes out there. I will just mention them here so
    that you can pursue them further if you''re interested. Some of them have some
    form of integration with Istio. It''s not always clear what their value is since
    they are not open:'
  prefs: []
  type: TYPE_NORMAL
- en: Aspen Mesh
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kong Mesh
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AVI Networks Universal Service Mesh
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The no mesh option
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can always avoid a service mesh completely and use a library such as Go
    kit, Hystrix, or Finagle. You might lose the benefits of the external service
    mesh, but if you tightly control all your microservices and they all use the same
    programming language, then the library approach may work just fine for you. It
    is conceptually and operationally simpler and it shifts the responsibility for
    managing cross-cutting concerns toward developers.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we've looked at service meshes and Istio in particular. Istio
    is a complex project; it sits on top of Kubernetes and creates a type of shadow
    cluster with its proxies. Istio has outstanding features; it can shape traffic
    at a very fine-grained level, provide sophisticated authentication and authorization,
    enforce advanced policies, collect a lot of information, and help scale your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: We covered the Istio architecture, its powerful capabilities, and explored how
    Delinkcious can benefit from these capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: However, Istio is far from simple. It creates a plethora of custom resources,
    and it overlaps and extends existing Kubernetes resources in complex ways (VirtualService
    versus Service).
  prefs: []
  type: TYPE_NORMAL
- en: We also reviewed alternatives to Istio, including Linkerd 2.0, straight Envoy,
    AWS App Mesh, and Consul.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you should have a good understanding of the benefits of service
    meshes and what Istio can do for your projects. You may have to do some extra
    reading and experimentation to make an informed decision of whether you should
    incorporate Istio into your system right away, consider one of the alternatives,
    or just wait.
  prefs: []
  type: TYPE_NORMAL
- en: I believe that services meshes and Istio, in particular, will be very important
    and will become a standard best practice to incorporate into large Kubernetes
    clusters.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, which is the last chapter, we will continue our discussion
    about the future of microservices, Kubernetes, and other emerging trends, such
    as serverless.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can refer to the following resources for more information regarding what
    was covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Istio**: [https://istio.io](https://istio.io)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hystrix**:[ https://github.com/Netflix/Hystrix](https://github.com/Netflix/Hystrix)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Finagle**:[ https://twitter.github.io/finagle/](https://twitter.github.io/finagle/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Envo**:[ https://www.envoyproxy.io/](https://www.envoyproxy.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spiffe**:[ https://spiffe.io](https://spiffe.io)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configuration**:[ https://istio.io/docs/reference/config/](https://istio.io/docs/reference/config/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
