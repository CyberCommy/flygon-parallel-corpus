- en: Digging into Data Structures and Algorithms in STL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mastering data structures is essential for programmers. The way you store your
    data most of the time defines the overall efficiency of the application. Consider
    an email client, for example. You can design an email client that shows the 10
    latest emails and it could have the best UI out there; displaying 10 recent emails
    will work smoothly on almost any device. The user of your email application will
    receive hundreds of thousands of emails, say, in two years of using your application.
    When the user needs to search for an email, that's where your data structure knowledge
    will play a significant role. The way you store the hundreds of thousands of emails
    and the methods (algorithms) you use to sort and search them will be what differentiates
    your program from all the others out there.
  prefs: []
  type: TYPE_NORMAL
- en: Programmers strive to find the best solutions to daily problems while working
    on projects. Using proven data structures and algorithms can drastically improve
    the work of the programmer. One of the most important features of a good program
    is its speed, which we gain by devising new algorithms or using existing ones.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, C++20 introduces **concepts** for defining **metatypes**—types describing
    other types. This powerful feature of the language makes the data architecting
    complete.
  prefs: []
  type: TYPE_NORMAL
- en: There are plenty of data structures and algorithms covered in the C++ **Standard
    Template Library** (**STL**). We will explore the ways to organize data efficiently
    using data structures by leveraging STL containers. And then we will dive into
    algorithm implementations provided by the STL. It's crucial to understand and
    use concepts in STL containers, because C++20 introduces big improvements in iterators
    by introducing iterator concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Data structures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: STL containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concepts and iterators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mastering algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring trees and graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The g++ compiler with the option `-std=c++2a` is used to compile the examples
    throughout the chapter. You can find the source files used in this chapter in
    the GitHub repository for this book at [https://github.com/PacktPublishing/Expert-CPP](https://github.com/PacktPublishing/Expert-CPP)
    .
  prefs: []
  type: TYPE_NORMAL
- en: Data structures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a programmer, you are probably familiar with using an array for storing and
    ordering a collection of data. Programmers intensively use data structures other
    than arrays in their projects. Knowing and applying proper data structures may
    play a significant role in program performance. To choose the right data structure,
    you need to get to know them better. An obvious question might arise of whether
    we need to study the zoo of data structures— vectors, linked lists, hash tables,
    graphs, trees, and so on. To answer this question, let's have an imaginary scenario
    where the necessity for a better data structure will become apparent naturally.
  prefs: []
  type: TYPE_NORMAL
- en: In the introductory content, we mentioned designing an email client. Let's get
    a general understanding of the basic tasks during its design and implementation.
  prefs: []
  type: TYPE_NORMAL
- en: An email client is an application that lists emails received from various senders.
    We can install it on desktop computers or smartphones, or use a browser version.
    The main tasks of an email client application involve sending and receiving emails.
    Now let's suppose that we are designing a simple-enough email client. As usually
    happens in programming books, let's suppose that we use some library that encapsulates
    the job of sending and receiving emails. We'd rather concentrate on designing
    mechanisms specifically for storing and retrieving emails. An email client user
    should be able to view a list of emails that reside in the **Inbox** section of
    the app. We should also take into account the operations that the user might want
    to perform on emails. They can delete them one by one, or many at once. They can
    choose any email selected at random and reply to its sender or forward the email
    to someone else.
  prefs: []
  type: TYPE_NORMAL
- en: 'We discuss the software design process and best practices in [Chapter 10](069ab9af-21a4-4b8c-bc3f-f7bc0d9e4712.xhtml),
    *Designing Real-World Applications*. For now, let''s sketch a simple struct that
    describes an email object, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The first thing that should bother us is storing a collection of emails in
    an easily accessible structure. An array might sound fine. Let''s suppose we store
    all the incoming emails in an array, as shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We can store 10 emails in any form – it won't affect the application's performance.
    However, it's obvious that, over time, the number of emails will grow. For each
    newly received email, we push an `Email` object with the corresponding fields
    into the `inbox` array. The last element of the array represents the most recently
    received email. So, to show the list of ten recent emails, we need to read and
    return the last ten elements of the array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Issues arise when we try to manipulate the thousands of emails stored in the
    `inbox` array. What if we want to search for the word `friend` in all the emails?
    We have to scan all the emails in the array and collect the ones containing the
    word `friend` in a separate array. Look at the following pseudocode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Using an array to store all the data is more than enough for small collections.
    The situation changes drastically in real-world applications dealing with bigger
    sets of data. The point of using a specific data structure is to make the application
    run more smoothly. The preceding example shows a simple problem: searching through
    a list of emails to match a particular value. Finding that value in one email
    takes a reasonable amount of time.'
  prefs: []
  type: TYPE_NORMAL
- en: If we suppose that the subject field of an email might consist of up to ten
    words, then searching for a particular word in an email subject requires comparing
    the word against all the words in the subject. In the *worst case*, there is no
    match. We emphasize the worst case because it's the only case when the lookup
    will require checking each word in the subject. Doing the same for thousands or
    hundreds of thousands of emails will make the user wait unreasonably long.
  prefs: []
  type: TYPE_NORMAL
- en: 'Choosing the right data structure for the specific problem is crucial in terms
    of application efficiency. For example, let''s suppose we use a hash table to
    map words to email objects. Each word will be mapped to a list of email objects
    that contain that word. This approach will increase the efficiency of the searching
    operation, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f7318cbc-fefa-41f1-a377-9bf8ebd60b26.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The `search()` function will just return the list referred to by the hash table
    key:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This approach will just require processing each received email to split it into
    words and update the hash table.
  prefs: []
  type: TYPE_NORMAL
- en: For the sake of simplicity, we use `Email` objects as values rather than references.
    Note that it would be better to store pointers to `Email` in the vector.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now take a look at different data structures and their applications.
  prefs: []
  type: TYPE_NORMAL
- en: Sequential data structures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'One of the most common data structures that developers use is the dynamically
    growing one-dimensional array, usually referred to as a vector. The STL provides
    a container with the same name: `std::vector`. The key idea behind the vector
    is that it contains items of the same type placed sequentially in memory. For
    example, a vector consisting of 4 byte integers would have the following memory
    layout. Each box represents a four byte space. The indexes of the vector are on
    the right-hand side of the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8f1961c0-dcd6-481f-8ae8-3ba43902ba49.png)'
  prefs: []
  type: TYPE_IMG
- en: The physical structure of the vector allows any of its elements to be accessed
    in real time.
  prefs: []
  type: TYPE_NORMAL
- en: We should differentiate containers with their operations in order to apply them
    properly in specific problems. To do so we usually define the complexity of running
    time of their operations in relation to the number of elements in the container.
    For example, the vector's element access is defined as a constant time operation,
    which means that it takes the same number of instructions to fetch a vector item
    regardless of the vector length.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the first element of the vector and accessing the 100^(th) element
    of the vector take the same amount of work, therefore, we call it a constant time
    operation, also known as ***O(1)* operation**.
  prefs: []
  type: TYPE_NORMAL
- en: 'While the element access is fast in vector, adding new elements is somewhat tricky.
    Whenever we insert a new item at the end of the vector, we should also consider
    the capacity of the vector. It should dynamically grow in size when there is no
    more space allocated for the vector. Take a look at the following `Vector` class
    with its `push_back()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Before diving into the implementation of the `push_back()` function, let''s
    take a look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/11cb3eec-b2a8-4166-8fdf-a58cf516bf90.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We should allocate a brand-new array, copy all the elements of the old one
    into the new array, and then add the newly inserted element at the next free slot
    at the end of the new array. This is shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The resizing factor can be chosen differently – we set it to `2`, which makes
    the vector grow twice of its size whenever it's full. So we could insist that,
    most of the time, inserting a new item at the end of the vector takes constant
    time. It just adds the item at the free slot and increases its `private size_`
    variable. From time to time, adding a new element will require allocating a new,
    bigger vector and copying the old one into the new one. For cases like this, the
    operation is said to take **amortized** constant time to complete.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can''t say the same when we add an element at the front of the vector. The
    point is, all the other elements should be moved by one slot to the right in order to
    free up a slot for the new element, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0f4021af-1ec3-4d9d-85ca-891a7e16e42a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here''s how we would implement it in our `Vector` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In cases where you need to insert new elements only at the front of the container,
    choosing a vector is not a good option. That's one of the examples where other
    containers should be considered.
  prefs: []
  type: TYPE_NORMAL
- en: Node-based data structures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Node-based data structures don't take contiguous blocks of memory. A node-based
    data structure allocates nodes for its elements without any order – they might
    be spread randomly in memory. We express each item as a node linked to the other
    nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most popular and introductory node-based data structure is the linked list.
    The following diagram shows the visual structure of a doubly linked list:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de263cb6-41ed-4f47-a59e-1a9e01261f64.png)'
  prefs: []
  type: TYPE_IMG
- en: A linked list is very different from a vector. Some of its operations are faster,
    though it lacks the compactness of a vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'To keep it short, let''s implement the element insertion at the front of the
    list. We will keep each node as a struct:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Pay attention to the `next` member – it points to the same struct, this way
    allowing the chaining of nodes together, as shown in the preceding illustration.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement a linked list, all we need is to keep a pointer to its first node,
    usually called the head of the list. Inserting an element at the front of the
    list is simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'There are three cases that we should consider when inserting an element into
    a list:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Inserting an element at the front of the list, as discussed earlier, takes
    the following steps:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/06be3736-adbe-4388-9396-677b0a094a7f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Inserting an element at the end of the list is shown in the following diagram:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/6f88bf92-0a38-448d-a32c-8a92883f53ab.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, inserting an element in the middle of the list is done as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/75876dd0-13a8-4b23-a1be-68ac50c50dd0.png)'
  prefs: []
  type: TYPE_IMG
- en: In the preceding diagrams, inserting an element into a vector is obviously different
    from inserting an element into the list. How would you choose between a vector
    and a list? You should concentrate on the operations and their speed. For example,
    reading any element from the vector takes constant time. We can store a one million
    emails in a vector, and retrieve the one at position 834,000 without any additional
    effort. For linked lists, the operation is linear. So, if you need to store a
    collection of data that will be mostly read, but not written, then using a vector
    is obviously a reasonable choice.
  prefs: []
  type: TYPE_NORMAL
- en: Inserting an element at any position in the list takes a constant-time operation,
    while the vector will strive to insert an element at a random position. Therefore,
    when you need a collection of objects to/from which data can be intensively added/removed,
    the better choice would be a linked list.
  prefs: []
  type: TYPE_NORMAL
- en: We should also take into account the cache memory. Vectors have good data locality.
    Reading the first element of a vector involves copying the first *N* elements
    into the cache. Further reads of vector elements will be even faster. We can't
    say the same for linked lists. To find out the reason, let's move ahead to compare
    the memory layouts of a vector and a linked list.
  prefs: []
  type: TYPE_NORMAL
- en: Containers in memory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you already know from the previous chapters, an object takes memory space
    on one of the memory segments provided to the process. Most of the time, we are
    interested in the stack or heap memory. An automatic object takes space on the
    stack. The following two declarations both reside on the stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Although `ptr` represents a pointer to an `Email` object, it takes space on
    the stack. It can point to a memory location allocated on the heap, but the pointer
    itself (the variable storing the address of a memory location) resides on the
    stack. This is crucial to understand and remember before going further with vectors
    and lists.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we saw earlier in the chapter, implementing a vector involves encapsulating
    a pointer to an inner buffer that represents an array of elements of the specified
    type. When we declare a `Vector` object, it takes the necessary amount of stack
    memory to store its member data. The `Vector` class has the following three members:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Supposing that an integer takes 4 bytes and a pointer takes 8 bytes, the following
    `Vector` object declaration will take at least 16 bytes of stack memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s how we picture the memory layout for the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5b07753c-2089-4701-a865-3e98d597197f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After inserting elements, the size of the vector on the stack will stay the
    same. The heap comes to the scene. The `buffer_` array points to a memory location
    allocated using the `new[]` operator. For example, look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Each new element that we push to the vector will take space on the heap, as
    shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ffb6f27e-00ca-4b30-86b7-4cdfd6c1530e.png)'
  prefs: []
  type: TYPE_IMG
- en: Each newly inserted element resides right after the last element of the `buffer_`
    array. That's why we can say the vector is a cache-friendly container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Declaring a linked-list object also takes memory space on the stack for its
    data members. If we discuss the simple implementation that stores only the `head_`
    pointer, the following list object declaration will take at least 8 bytes of memory
    (for the `head_` pointer only):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The following illustration depicts the memory layout for the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/62daaf10-d88c-4439-a8e8-4bb85feb15e4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Inserting a new element creates an object of type `node` on the heap. Take
    a look at the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s how the memory illustration will change after inserting a new element:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/62c34472-4720-43f8-80c1-71ac1b5ab204.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Take care that the node with all its data members resides on the heap. The
    item stores the value that we have inserted. When we insert another element, again
    a new node will be created. This time, the next pointer of the first node will
    point to the newly inserted element. And the newly inserted node''s prev pointer
    will point to the previous node of the list. The following illustration depicts
    the linked list''s memory layout after inserting the second element:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/080ab163-ffd0-4b7b-8ff8-2ba3e9dfed60.png)'
  prefs: []
  type: TYPE_IMG
- en: 'An interesting thing happens when we allocate some random objects on the heap
    in between inserting elements into the list. For example, the following code inserts
    a node into the list, then allocates space for an integer (not related to the
    list). Finally, it again inserts an element into the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This intermediate random object declaration spoils the order of list elements,
    as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bff12ecb-958e-4b6b-95b1-d731f5a627a6.png)'
  prefs: []
  type: TYPE_IMG
- en: The preceding diagram gives us a hint that the list is not a cache-friendly
    container, because of its structure and the allocation of its elements.
  prefs: []
  type: TYPE_NORMAL
- en: Pay attention to the memory overhead created by incorporating each new node
    into the code. We pay an additional 16 bytes (considering the pointer takes 8
    bytes of memory) for one element. Thus, lists lose the game of optimal memory
    use to vectors.
  prefs: []
  type: TYPE_NORMAL
- en: We can try to fix the situation by introducing a preallocated buffer in the
    list. Each new node creation will then pass via the **placement new** operator.
    However, it's wiser to choose a data structure that better fits the problem of
    interest.
  prefs: []
  type: TYPE_NORMAL
- en: In real-world application development, programmers rarely implement their own
    vectors or linked lists. They usually use tested and stable library versions.
    C++ provides standard containers for both vectors and linked lists. Moreover,
    it provides two separate containers for singly and doubly linked lists.
  prefs: []
  type: TYPE_NORMAL
- en: STL containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The STL is a powerful collection of algorithms and containers. Although understanding
    and implementing data structures is a great skill for programmers, you don't have
    to implement them each time you need one in the project. The library providers
    take care of implementing stable and tested data structures and algorithms for
    us. By understanding the inner details of data structures and algorithms, we are
    making better choices of STL containers and algorithms while solving problems.
  prefs: []
  type: TYPE_NORMAL
- en: 'The vectors and linked lists discussed previously are implemented in the STL
    as `std::vector<T>` and `std::list<T>`, where `T` is the type of each element
    of the collection. Besides the type, containers also take a second default `template`
    parameter as an allocator. The `std::vector`, for example, is declared as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'As introduced in the previous chapter, an allocator handles the efficient allocation/deallocation
    of container elements. The `std::allocator` is the default allocator for all standard
    containers in the STL. A more sophisticated allocator that behaves differently
    based on the memory resource is the `std::pmr::polymorphic_allocator`. The STL
    provides `std::pmr::vector` as an alias template that uses a polymorphic allocator,
    defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Let's now take a closer look at `std::vector` and `std::list`.
  prefs: []
  type: TYPE_NORMAL
- en: Using std::vector and std::list
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The `std::vector` is defined in the `<vector>` header. Here''s the simplest
    usage example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The `std::vector` grows dynamically. We should consider the growth factor.
    When declaring a vector, it has some default capacity, which will then grow upon
    element insertion. Each time the number of elements exceeds the capacity of the
    vector, it increases its capacity by a given factor (usually, it doubles its capacity).
    If we know the approximate number of elements that we will need in the vector,
    we can optimize its use by initially allocating that capacity for the vector using
    the `reserve()` method. For example, the following code reserves a 10,000-element
    capacity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: It forces the vector to allocate space for 10,000 elements, thereby avoiding
    resizing during element insertion (unless we reach the 10,000-element threshold).
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, if we encounter a scenario where the capacity is much bigger
    than the actual number of elements in the vector, we can shrink the vector to
    free the unused memory. We need to call the `shrink_to_fit()` function, as shown
    in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This reduces the capacity to fit the size of the vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Accessing vector elements is done the same way we access a regular array, using
    the `operator[]`. However, the `std::vector` provides two options for accessing
    its elements. One of them is considered a safe approach and is done via the `at()`
    function, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The difference between `at()` and `operator[]` is that `at()` accesses the
    specified element with bounds checking; that is, the following line throws an
    `std::out_of_range` exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We use the `std::list` almost the same way. These lists mostly have a similar
    public interface. Later in the chapter, we will discuss iterators that allow abstracting
    from specific containers so that we can replace a list with a vector without much
    of a penalty. Before that, let's see the difference between the list's and vector's
    public interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides the standard set of functions that both containers support, such as
    `size()`, `resize()`, `empty()`, `clear()`, `erase()`, and others, the list has
    the `push_front()` function that inserts an element at the front of the list.
    This is done efficiently because the `std::list` represents a doubly linked list.
    As shown in the following code, the `std::list` supports `push_back()` as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The list supports additional operations that come in handy in many situations.
    For example, to merge two sorted lists, we use the `merge()` method. It takes
    another list as its argument and moves all of its elements to the current list.
    The list passed as an argument to the `merge()` method becomes empty after the
    operation.
  prefs: []
  type: TYPE_NORMAL
- en: The STL also provides a singly linked list, represented by `std::forward_list`.
    To use it, you should include the `<forward_list>` header. As the singly linked
    list node has only one pointer, it's cheaper in terms of memory than the doubly
    linked list.
  prefs: []
  type: TYPE_NORMAL
- en: The `splice()` method is somewhat similar to `merge()`, except that it moves
    a portion of the list provided as an argument. By moving, we mean re-pointing
    internal pointers to proper list nodes. This is true for both `merge()` and `splice()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we use containers for storing and manipulating complex objects, the price
    of copying elements plays a big role in the program''s performance. Consider the
    following struct representing a three-dimensional point:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, look at the following code, which inserts a `Point` object into a vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'A temporary object is constructed and then moved to the vector''s corresponding
    slot. We can represent it visually as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d94643e3-cbfa-4816-8059-4ac126c1bbcb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Obviously, the vector occupies more space beforehand to delay resize operations
    for as long as possible. When we insert a new element, the vector copies it to
    the next available slot (and will reallocate more space if it''s full). We can
    use that uninitialized space for creating a new element in place. The vector provides
    the `emplace_back()` function for that purpose. Here''s how we can use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Pay attention to the arguments we passed directly to the function. The following
    illustration depicts the use of `emplace_back()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/47e01350-abf8-4a83-8eba-70afe1301af7.png)'
  prefs: []
  type: TYPE_IMG
- en: The `emplace_back()` constructs the element through `std::allocator_traits::construct()`.
    The latter typically uses the placement of new operator to construct the element
    at already allocated uninitialized space.
  prefs: []
  type: TYPE_NORMAL
- en: The `std::list` also provides an `emplace_front()` method. Both functions return
    a reference to the inserted element. The only requirement is for the type of element
    to be `EmplaceConstructible`. For vectors, the type should also be `MoveInsertable`.
  prefs: []
  type: TYPE_NORMAL
- en: Using container adapters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might have encountered descriptions of the stack and the queue as data structures
    (or *containers*, in terms of C++). Technically, they are not data structures,
    but data structure adapters. In STL, `std::stack` and `std::queue` adapt containers
    by providing a special interface to access them. The term *stack* is almost everywhere.
    So far, we have used it to describe a memory segment for objects with automatic
    storage duration. The segment takes the name *stack* because of its allocation/deallocation
    strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 'We say that objects are pushed to the stack each time we declare them, and
    popped out on destruction. The objects are popped in the reverse order in which
    they have been pushed. That''s the reason for calling the memory segment the stack.
    The same **last-in, first-out** (**LIFO**) method applies to the stack adapter.
    The crucial functions provided by `std::stack` are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The `push()` function effectively calls the `push_back()` of the underlying
    container. Usually, the stack is implemented using a vector. We've already discussed
    such a scenario in [Chapter 3](c0982ed5-7e38-4bd3-9c4d-37b0d2f01691.xhtml), *Details
    of Object-Oriented Programming*, when we introduced protected inheritance. `std::stack`
    has two template parameters; one of them is the container. It doesn't matter what
    you choose, but it must have a `push_back()` member function. The default container
    for `std::stack` and `std::queue` is `std::deque`.
  prefs: []
  type: TYPE_NORMAL
- en: '`std::deque` allows fast insertion at its beginning and its end. It is an indexed
    sequential container similar to `std::vector`. The name deque stands for *double-ended
    queue*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see stack in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: A better alternative to the `push()` function is the `emplace()`. It calls the
    `emplace_back()` of the underlying container, therefore, constructs element in
    place.
  prefs: []
  type: TYPE_NORMAL
- en: 'To pull the element out, we call the `pop()` function. It doesn''t take any
    arguments and doesn''t return anything, it just removes the top element from the
    stack. To access the top element of the stack, we call the `top()` function. Let''s
    modify the previous example to print all the stack elements before popping them
    out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The `top()` function returns a reference to the top element. It calls the `back()`
    function of the underlying container. Pay attention to the last `top()` function that
    we called on the empty stack. We suggest you check the size of the stack using
    `size()` before calling `top()` on the empty one.
  prefs: []
  type: TYPE_NORMAL
- en: '`queue` is another adapter with slightly different behavior from the stack.
    The logic behind the queue is that it returns the first inserted element first:
    it maintains the **first-in, first-out** (**FIFO**) principle. Look at the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/04d19255-e43e-485b-af2f-6269d220bd0e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The formal names for inserting and retrieving operations in a queue are **enqeue**
    and **dequeue**. `std::queue` keeps a consistent approach and provides the `push()`
    and `pop()` functions. To access the first and last elements of the queue, you
    should use `front()` and `back()`. Both return references to elements. Here''s
    a simple usage example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Knowing various containers and adapters is useful when you apply them correctly.
    There isn''t a silver bullet in choosing the right container for all kinds of
    problems. Many compilers use the stack to parse code expressions. For example,
    it''s easy to validate the parentheses in the following expression using the stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Try it for practice. Write a small program that validates the preceding expression
    using a stack.
  prefs: []
  type: TYPE_NORMAL
- en: The applications of queues are even wider. We will see one of them in [Chapter
    11](0e28887e-1a43-4510-a8ef-b3ad7531868d.xhtml), *Designing a Strategy Game using
    Design Patterns*, where we design a strategy game.
  prefs: []
  type: TYPE_NORMAL
- en: Another container adapter is `std::priority_queue`. A priority queue usually
    adapts a balanced, node-based data structure, such as max- or min-heap. We will
    examine trees and graphs toward the end of this chapter and see how the priority
    queue works under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: Iterating containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The idea of a container that is not iterable is like a car that cannot be driven. After
    all, a container is a collection of items. One of the common ways to iterate over
    container elements is to use the plain old `for` loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Containers provide a different set of operations for element access. For example,
    the vector provides the `operator[]`, whereas the list does not. The `std::list`
    has the `front()` and `back()` methods, which return the first and last elements,
    respectively. The `std::vector`, as already discussed, additionally provides `at()`
    and `operator[]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that we can''t use the preceding loop for iterating list elements.
    But we can loop over a list (and vector) with a range-based `for` loop as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: It might seem confusing, but the trick is hidden in the range-based `for` implementation.
    It retrieves an iterator pointing to the first element of the container using
    the `std::begin()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'An **iterator** is an object that points to the container element and can be
    advanced to the next element based on the physical structure of the container.
    The following code declares a `vector` iterator and initializes it with an iterator
    pointing to the beginning of the `vector`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Containers provide two member functions, `begin()` and `end()`, returning iterators
    to the beginning and the end of the container, respectively. The following diagram
    shows how we treat the beginning and the end of the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4a058f5f-c5de-47fb-94e4-a5e25dbf0440.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The previous code that iterated over the list elements using a range-based
    `for` can be considered something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Pay attention to the `*` operator that we used in the previous code to access
    the underlying element by an iterator. We consider an iterator a *clever *pointer
    to the container element.
  prefs: []
  type: TYPE_NORMAL
- en: The `std::begin()` and `std::end()` functions typically call the containers' `begin()`
    and `end()` methods, respectively. However, they are also applicable to regular
    arrays.
  prefs: []
  type: TYPE_NORMAL
- en: 'The container iterator knows exactly how to work with the container elements.
    For example, advancing a vector iterator moves it to the next slot of the array,
    while advancing a list iterator moves it to the next node using the corresponding
    pointer, as illustrated in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Each container has its own iterator implementation; that''s why list and vector
    iterators have the same interface but behave differently. The behavior of the
    iterator is defined by its *category*. For example, a vector''s iterator is a
    random-access iterator, which means we can randomly access any element using the
    iterator. The following code accesses the fourth element of the vector via its
    iterator by adding `3` to it, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'There are six iterator categories in STL:'
  prefs: []
  type: TYPE_NORMAL
- en: Input
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Output (the same as input, but supporting write access)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forward
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bidirectional
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contiguous
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **i****nput iterator** provides read access (by calling the `*` operator) and enables
    forwarding the iterator position using prefix and postfix increment operators.
    An input iterator doesn't support multiple passes, that is, we can use an iterator
    to iterate over the container only once. The **forward iterator**, on the other
    hand, supports multiple passes. Multiple-pass support means we can read the value
    of the element through the iterator more than once.
  prefs: []
  type: TYPE_NORMAL
- en: The **output iterator** doesn't provide access to the element, but it allows
    assigning new values to it. A combination of an input iterator and output iterator
    with the multiple passes feature comprises the forward iterator. However, the
    forward iterator supports only increment operations, whereas the **bidirectional
    iterators** support moving the iterator to any position. They support decrementing
    operations. For example, the `std::list` supports bidirectional iterators.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the **random access iterator** allows *jumping* through elements by
    adding/subtracting a number to/from the iterator. The iterator will jump to the
    position specified by the arithmetic operation. The `std::vector` provides random
    access iterators.
  prefs: []
  type: TYPE_NORMAL
- en: Each of the categories defines the set of operations that can be applied to
    the iterator. For example, the input iterator can be used to read the value of
    the element and advance to the next element by incrementing the iterator. On the
    other hand, the random access iterator allows incrementing and decrementing the
    iterator with arbitrary values, reading and writing the value of the element,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: A combination of all of the features described thus far in this section falls
    into the **contiguous iterator** category, which also expects the container to
    be a contiguous one. This means that container elements are guaranteed to reside
    right next to the other. An example of a contiguous container is the `std::array`.
  prefs: []
  type: TYPE_NORMAL
- en: Functions such as `distance()` use the information about the iterator to achieve
    the fastest result in execution. For example, the `distance()` function between
    two bidirectional iterators takes a linear time of execution, while the same function
    for random access iterators runs in constant time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following pseudocode demonstrates a sample implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Although the pseudocode shown in the preceding example works fine, we should
    consider that checking the category of an iterator at runtime is not an option.
    It is defined at compile time, so we need to use template specialization in order to
    generate the `distance()` function for random access iterators. A better solution
    would be using the `std::is_same` type trait, defined in `<type_traits>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '`std::is_same_v` is a helper template for the `std::is_same`, defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The most important quality of iterators is providing loose coupling between
    containers and algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2d7a6c25-7b1f-4a4d-a3c1-80259c833393.png)'
  prefs: []
  type: TYPE_IMG
- en: 'STL is based upon those three concepts: containers, algorithms, and iterators.
    While a vector, a list, or any other container is different, they serve the same
    purpose: storing data.'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, algorithms are functions that work with data; most of the
    time they work with collections of data. An algorithm definition usually represents
    a generic way of specifying the steps that should be taken to handle container
    elements. For example, a sorting algorithm sorts container elements in ascending
    or descending order.
  prefs: []
  type: TYPE_NORMAL
- en: Vectors are contiguous containers, while lists are node-based containers. Sorting
    them will require a deeper understanding of the particular container's physical
    structure. To properly sort a vector, a separate sort function should be implemented
    for it. The same logic applies to lists.
  prefs: []
  type: TYPE_NORMAL
- en: 'Iterators take this multiplicity of implementations to a generic level. They
    provide the library designers the ability to implement just one sorting function,
    which will deal only with iterators, abstracting from the container type. In the
    STL, the `sort()` algorithm (defined in `<algorithm>`) deals with iterators, and
    we can sort both vectors and lists with the same function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The iterators described in this section are now considered legacy features.
    C++20 introduces a new system of iterators based on **concepts**.
  prefs: []
  type: TYPE_NORMAL
- en: Concepts and iterators
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: C++20 introduces **concepts** as one of its major features. Along with concepts,
    C++20 has new iterators based on concepts. Although the iterators discussed in
    this chapter up to here are now considered legacy features, lots of lines of code
    have already been written using them. That's why we introduced them first before
    continuing with the new iterator concepts. Now, let's find out what concepts are
    and how to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Abstraction is essential in computer programming. We introduced classes in
    [Chapter 3](c0982ed5-7e38-4bd3-9c4d-37b0d2f01691.xhtml), *Details of Object-Oriented
    Programming, *as a way to represent data and operations as an abstract entity.
    After that, in [Chapter 4](c0e82f94-f2ed-4f17-98c9-1c3d3b27ae3d.xhtml), *Understanding
    and Designing Templates*, we dove into templates and saw how we can make classes
    even more flexible by reusing them for various aggregate types. Templates not
    only provide abstraction from the specific type, but also incorporate loose coupling
    between the entity and aggregate types. Take, for example, `std::vector`. It provides
    a generic interface to store and manipulate collections of objects. We can easily
    declare three different vectors that will contain three different types of objects,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'If not templates, we would have to do something like the following for the
    preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Although the preceding code is ridiculously unacceptable, we should agree on
    the fact that templates are the basis of generic programming. Concepts introduce
    even more flexibility to generic programming. Now it is possible to set restrictions
    on template parameters, check for constraints, and discover inconsistent behavior
    at compile time. A template class declaration has the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Pay attention to the `typename` keyword in the preceding code block. Concepts
    go even further: they allow replacing it with a type description that describes
    the template parameter. Let''s say we want the `Wallet` to work with types that
    can be added together, that is, they should be *addable*. Here''s how using a
    concept will help us achieve that in the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'So, now we can create `Wallet` instances by providing types that are addable.
    Whenever the type doesn''t satisfy the constraint, the compiler will throw an
    error. It looks a bit supernatural. The following snippet declares two `Wallet`
    objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The `Book` class has no `+` operator, so the construction of `g` will fail because
    of the `template` parameter type restriction.
  prefs: []
  type: TYPE_NORMAL
- en: 'The declaration of a concept is done using the `concept` keyword and has the
    following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, a concept is also declared using templates. We can refer to
    them as types that describe other types. Concepts rely heavily on **constraints**.
    A constraint is a way to specify requirements for template arguments, and, as
    follows, a concept is a set of constraints. Here''s how we can implement the preceding
    addable concept:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Standard concepts are defined in the `<concepts>` header.
  prefs: []
  type: TYPE_NORMAL
- en: We can also combine several concepts into one by requiring the new concept to
    support the others. To achieve that we use the `&&` operator. Let's see how iterators
    leverage concepts and bring an example of an `incrementable` iterator concept
    that combines other concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Using iterators in C++20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After the introduction to concepts, it is obvious that iterators are first
    to leverage them to the fullest. Iterators and their categories are now considered
    legacy because, starting from C++20, we use iterator concepts such as **`readable`**
    (which specifies that the type is readable by applying the `*` operator) and `writable`
    (which specifies that a value can be written to an object referenced by the iterator).
    As promised, let''s see how `incrementable` is defined in the `<iterator>` header:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: So, the `incrementable` concept requires the type to be `std::regular`. That
    means it should be constructible by default and have a copy constructor and `operator==()`.
    Besides that, the `incrementable` concept requires the type to be `weakly_incrementable`,
    which means the type supports pre- and post-increment operators, except that the
    type is not required to be equality-comparable. That's why the `incrementable`
    joins `std::regular` to require the type to be equality-comparable. Finally, the
    addition `requires` constraint points to the fact that the type should not change
    after an increment, that is, it should be the same type as before. Although `std::same_as` is represented
    as a concept (defined in `<concepts>`), in previous versions we used to use `std::is_same` defined
    in `<type_traits>`. They basically do the same thing, but the C++17 version – `std::is_same_v` –
    was verbose, with additional suffixes.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, instead of iterator categories, we now refer to iterator concepts. Besides
    the ones we introduced earlier, the following concepts should also be taken into
    consideration:'
  prefs: []
  type: TYPE_NORMAL
- en: '`input_iterator` specifies that the type allows its referenced values to be
    read and is both pre- and post-**incrementable**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_iterator` specifies that values of the type can be written to and the
    type is both pre- and post-**incrementable**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`input_or_output_iterator`, the unnecessarily long name aside, specifies that
    the type is **incrementable** and can be dereferenced.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`forward_iterator` specifies that the type is an `input_iterator` that additionally
    supports equality comparison and multi-pass.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bidirectional_iterator` specifies that the type supports `forward_iterator`
    and additionally supports the backward movement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_access_iterator` specifies that the type as a `bidirectional_iterator`,
    supporting advancement in constant time and subscripting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`contiguous_iterator` specifies that the type is a `random_access_iterator`,
    referring to elements that are contiguous in memory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They almost repeat the legacy iterators that we discussed earlier, but now they
    can be used when declaring template parameters so that the compiler will take
    care of the rest.
  prefs: []
  type: TYPE_NORMAL
- en: Mastering algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As already mentioned, algorithms are functions taking some input, processing
    it, and returning an output. Usually, an algorithm in the context of the STL implies
    a function processing a collection of data. Collections of data are presented
    in the form of containers, such as `std::vector`, `std::list`, and others.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing an efficient algorithm is a common task in a programmer's routine.
    For example, searching a sorted vector using the binary search algorithm will
    be much more efficient than using sequential searching. To compare the efficiency
    of algorithms, a so-called **asymptotic analysis** is performed, which takes into
    consideration the speed of the algorithm with regard to the input data size. This
    means that we shouldn't actually compare two algorithms by applying them to a
    container with ten or a 100 elements.
  prefs: []
  type: TYPE_NORMAL
- en: The actual difference of algorithms shows itself when applied to *big enough*
    containers, having a one million or even a one billion records. Measuring the
    efficiency of an algorithm is also known as verifying its complexity. You might've
    encountered *O(n)* algorithms or *O(log N)* algorithms. The *O()* function (pronounced *big-oh*)
    defines the complexity of an algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at the searching algorithms and compare their complexity along
    the way.
  prefs: []
  type: TYPE_NORMAL
- en: Searching
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Searching an element in the container is a common task. Let''s implement sequential
    searching of an element in a vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a simple algorithm that iterates through a vector and returns the index
    at which the element is equal to the value passed as the search key. We name it
    sequential searching because it sequentially scans the vector elements. Its complexity
    is linear: *O(n)*. To measure it, we should somehow define the number of operations
    that the algorithm takes to find the result. Supposing the vector contains *n*
    elements, the following code contains a comment on each line of the search function
    about its operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: We have three copy operations, *n + 1* and *n* (that is, *2n + 1*) comparisons,
    and *n + 1* increment operations. What if the desired element is in the first
    position of the vector? Well, in that case, we would scan only the first element
    of the vector and return from the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, it doesn''t mean that our algorithm is so efficient that it takes
    just one step to perform its task. In order to measure the complexity of an algorithm,
    we should take into consideration the worst-case scenario: the desired element
    either doesn''t exist in the vector or resides in the last position of the vector.
    The following diagram shows the three scenarios for the element that we are about
    to find:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/89c34b2d-9597-4ea4-ac1a-a32ef5031eb7.png)'
  prefs: []
  type: TYPE_IMG
- en: We should consider the worst-case scenario only because it covers all the other
    cases as well. If we define the complexity of an algorithm for the worst case,
    we can be sure it won't ever work slower than that.
  prefs: []
  type: TYPE_NORMAL
- en: 'To find out the complexity of an algorithm, we should find the connection between
    the number of operations and the size of the input. In this case, the size of
    the input is the length of the container. Let''s denote copies as A, comparisons
    as C, and increment operations as I, so that we have 3A + (2n + 1)C + (n + 1)I
    operations. The complexity of the algorithm will be defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*O(3A + (2n + 1)C + (n + 1)I)*'
  prefs: []
  type: TYPE_NORMAL
- en: 'This then can be simplified in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '*O(3A + (2n + 1)C + (n + 1)I) =*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*O(3A + 2nC + C + nI + I) = *'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*O(n(2C + I) + (3A + C + I)) = *'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*O(n(2C + I))*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the *O()'s* properties allow us to get rid of the constant coefficients
    and smaller members, because the actual algorithm complexity is related only to
    the size of the input, which is *n*, and we get the final complexity equal to
    *O(n)*. In other words, the sequential searching algorithm has linear time complexity.
  prefs: []
  type: TYPE_NORMAL
- en: 'As already mentioned, the essence of the STL is to connect containers and algorithms
    via iterators. That''s why the sequential search implementation is not considered
    STL-compatible: because it has strict restrictions on input parameters. To make
    it generic, we should consider implementing it using iterators only. To cover
    a wide range of container types, use forward iterators. The following code uses
    operators on the type `Iter`, assuming it''s a forward iterator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Actually, any type of iterators can be passed to the `search()` function. We
    ensure that we use forward iterators just by applied operations on iterators themselves.
    We use only the increment (move forward), reading (the `*` operator), and strict
    comparisons (`==` and `!=`), which are supported by forward iterators.
  prefs: []
  type: TYPE_NORMAL
- en: Binary search
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'On the other hand is the binary search algorithm, which is simple to explain.
    At first, it looks for the middle element of the vector and compares the search
    key with it, and if it is equal, then the algorithm is done: it returns the index.
    Otherwise, if the search key is less than the middle element, it proceeds to the
    left of the vector. If the search key is greater than the middle element, the
    algorithm proceeds to the right-hand subvector.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to get the binary search to work correctly for a vector, it should
    be sorted. The very essence of the binary search implies comparing the search
    key with vector elements and proceeding to the left- or right-hand subvectors,
    each of which contains a smaller or greater element compared to the middle element
    of the vector. Take a look at the following diagram, which depicts the binary
    search algorithm in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c478e0fd-ae7e-4b99-8bec-7c288cd13272.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The binary search algorithm has an elegant recursive implementation (though
    it''s better to use an iterative implementation) – take a look at it in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Pay attention to the middle element calculation. Instead of the `(start + end)
    / 2;`, we used the `start + (end - start) / 2;` technique just to avoid the famous
    bug in binary search implementations (assuming we didn't leave other bugs). The
    point is that for big values of start and end, their sum (*start + end*) will
    produce an integer overflow, which will make the program crash at some point.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's find the complexity of the binary search. It's obvious that on each
    step of the execution, the source array gets halved so that we deal with the smaller
    or greater half of it in the next step. This means that the worst-case scenario
    is the case when we divide the vector until there is one or no element left. To
    find the number of steps in the algorithm, we should find the number of divisions
    with regard to the size of the vector. If the vector has 10 elements, then we
    divide it and get a subvector of five elements; by dividing it again, we get two-element
    subvector, and finally, dividing it again will bring us to a single element. So,
    for the 10-element vector, the number of divisions is 3\. For the *n*-element
    vector, the number of divisions is *log(n)*, because, on each step, *n* becomes
    *n/2*, which then becomes *n/4*, and so on. The complexity of the binary search
    is *O(logn)* (that is, logarithmic).
  prefs: []
  type: TYPE_NORMAL
- en: 'STL algorithms are defined in the `<algorithm>` header file; where the implementation
    of the binary search resides. The STL implementation returns true if the element
    exists in the container. Take a look at its prototype:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'STL algorithms don''t work directly with containers, instead, they work with
    iterators. This allows us to abstract from the specific container and to use the
    `binary_search()` with all the containers supporting a forward iterator. The following
    example calls the `binary_search()` function for both vectors and lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: The `binary_search()` checks the category of the iterator, and in the case of
    a random access iterator, it uses the full power of the binary search algorithm
    (otherwise, it falls back to sequential search).
  prefs: []
  type: TYPE_NORMAL
- en: Sorting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The binary search algorithm is applicable only to sorted containers. Sorting
    is a known and old task for computer programmers, who nowadays rarely write their
    own implementation of a sorting algorithm. You might've used `std::sort()` many
    times without even caring about its implementation. Basically, a sorting algorithm
    takes a collection as an input and returns a new sorted collection (in the order
    defined by the algorithm user).
  prefs: []
  type: TYPE_NORMAL
- en: 'Of the many sorting algorithms out there, the most popular (or even the fastest
    one) is **quicksort**. The basic idea of any sorting algorithm is to find smaller
    (or greater) elements and exchange them with greater (or smaller) elements until
    the whole collection is sorted. For example, the selection sort logically divides
    the collection into two parts, sorted and unsorted, where the sorted subarray
    is initially empty like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/303865f2-ae26-44a9-bce2-0f8cefb9cc6f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The algorithm starts to look for the smallest element in the unsorted subarray
    and put it to the sorted subarray by exchanging it with the first element of the
    unsorted subarray. After the each step, the length of the sorted subarray increases
    by one, whereas the length of the unsorted subarray decreases like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/995dc143-d05a-4a3d-b808-de3d058583c5.png)'
  prefs: []
  type: TYPE_IMG
- en: The process continues until the unsorted subarray becomes empty.
  prefs: []
  type: TYPE_NORMAL
- en: 'The STL provides the `std::sort()` function, taking two random-access iterators:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: The sort function can't be applied to `std::list` because it doesn't support
    random access iterators. Instead, you should call the `sort()` member function
    of the list. Though this contradicts the idea of the STL having generic functions,
    it is done for efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sort()` function has a third parameter: a comparing function that can
    be used to compare container elements. Let''s suppose we store `Product` objects
    in our vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'To sort the container properly, its elements must support the less-than operator,
    or `<`. We should define the corresponding operator for our custom type. However,
    we can omit the operator definition if we create a separate comparator function
    for our custom type, as shown in the following block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Passing `ProductComparator` to the `std::sort()` function allows it to compare
    the vector elements without diving into details of the type of its elements, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'While this is a good technique, it would be more elegant to use lambda functions
    instead, which are anonymous functions just perfect for scenarios like the preceding
    one. Here''s how we can overwrite it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code allows omitting the declaration of `ProductComparator`.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring trees and graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The binary search algorithm and sorting algorithms combined together lead to
    the idea of having a container that keeps items sorted by default. One such container
    is the `std::set`, based on a balanced tree. Before discussing the balanced tree
    itself, let's take a look at the binary search tree, a perfect candidate for fast
    lookups.
  prefs: []
  type: TYPE_NORMAL
- en: 'The idea of the binary search tree is that the values of the left-hand subtree
    of a node are less than the node''s value. By contrast, the values of the right-hand
    subtree of a node are greater than the node''s value. Here''s an example of a
    binary search tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c361b58-ff03-4ab1-bffc-dd29595f2378.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see in the preceding diagram, the element with the value 15 resides
    in the left-hand subtree because it's less than 30 (the root element). On the
    other hand, the element with the value 60 resides in the right-hand subtree because
    it's greater than the root element. The same logic applies to the rest of the
    tree elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'A binary tree node is represented as a struct containing the item and two pointers
    to each child. Here''s a sample code representation of a tree node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Searching, inserting, or removing an element takes *O(logn)* in a fully balanced
    binary search tree. The STL doesn''t provide a separate container for trees, but
    it has similar ones that are based on a tree implementation. For example, the
    `std::set` container is based on a balanced tree that uniquely stores elements
    in sorted order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The `std::map` is also based on a balanced tree, but this one provides a container
    that maps a key to some value, as follows, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: As shown in the preceding code, the function `map` `numbers` maps integers to
    strings. So when we tell the map to store the value of `3` as a key and the string
    `three` as a value, it adds a new node to its inner tree with the key equal to
    `3` and the value equal to `three`.
  prefs: []
  type: TYPE_NORMAL
- en: '`set` and `map` operations are logarithmic, which makes it a very efficient
    data structure in most cases. However, a more efficient data structure comes next.'
  prefs: []
  type: TYPE_NORMAL
- en: Hash tables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The hash table is the fastest data structure out there. It is based on the
    simple idea of a vector indexing. Imagine a big vector that contains pointers
    to lists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Access to vector elements takes constant time. That''s the main superpower
    of vectors. The hash table allows us to use any type as the key of the container.
    The basic idea of the hash table is to use a well-curated hash function that will
    generate a unique index for the input key. For example, when we use a string as
    a hash table key, the hash table uses a hash function to generate the hash as
    the index value for the underlying vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s how we can illustrate a hash table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5623724b-8217-4b70-8fac-b52b713d8435.png)'
  prefs: []
  type: TYPE_IMG
- en: Accessing a hash table takes constant time because it operates based on the
    vector. Though there could be different keys that will result in the same hash
    value, these collisions are fixed by using a list of values as the vector element
    (as shown in the preceding diagram).
  prefs: []
  type: TYPE_NORMAL
- en: 'The STL supports a hash table named `std::unordered_map`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: To generate the hash value for provided keys, the function  `std::unordered_map`
    uses the `std::hash()` function defined in the `<functional>` header. You can
    specify a custom implementation for the hash function. The third `template` parameter
    of the `std::unordered_map` is the hash function, which defaults to `std::hash`.
  prefs: []
  type: TYPE_NORMAL
- en: Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The balancing nature of the binary search tree is based upon many search index
    implementations. For example, database systems use a balanced tree called a B-tree
    for table indexing. The B-tree is not a *binary* tree, but it follows the same
    balancing logic, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/92b32da1-8667-447b-b087-481c79ac0dc4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Graphs, on the other hand, represent connected nodes with no proper order:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/84949559-6f1a-41a6-8b34-746c60392218.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s suppose we are building a social network that will eventually beat Facebook
    off the market. The users in the social network can follow each other, which can
    be represented as a graph. For example, if A follows B, B follows C, and C both
    follows B back and follows A at the same time, then we can represent the relationships
    as the following graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/afd3b4ab-05ed-448a-8612-d596cce84d88.png)'
  prefs: []
  type: TYPE_IMG
- en: A node is called a **vertex** in the graph. The link between two nodes is called
    an **edge**. There isn't actually a fixed graph representation, so we should choose
    from several. Let's think of our social network – how would we represent the information
    that user A follows user B?
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the best options here is using a hash table. We can map each user to
    all of the users they follow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ff9a742f-9d83-4b1d-b655-77d3f57fe938.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The graph implementation becomes a hybrid container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: To make an STL-compatible container, let's add an iterator for the graph. Though
    iterating a graph is not a good idea, adding an iterator is not a bad idea.
  prefs: []
  type: TYPE_NORMAL
- en: Strings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Strings are similar to vectors: they store characters, they expose iterators,
    and they are containers. However, they are somewhat different because they specifically
    express one kind of data: strings. The following diagram depicts the string **hello,
    C++** as an array of characters ending with a special **\0** character:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c99154de-7f04-4bfe-8ae5-b8ba7ed23ecb.png)'
  prefs: []
  type: TYPE_IMG
- en: The special **\0** character (also known as the null character) serves as a
    string termination. The compiler reads characters one after the other until it
    encounters the null character.
  prefs: []
  type: TYPE_NORMAL
- en: 'A string is implemented the same way we implemented a vector at the beginning
    of the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: C++ has its powerful `std::string` class, which provides a bunch of functions
    to work with. Besides `std::string` member functions, algorithms defined in `<algorithm>`
    are also applicable to strings.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data structures and algorithms are crucial in developing efficient software.
    By understanding and leveraging the data structures discussed in this chapter,
    you will have the full power of C++20 to make your programs run faster. It's not
    a secret that a programmer with strong problem-solving skills is more desired
    in the market. Problem-solving skills are gained first of all by deeply understanding
    the fundamental algorithms and data structures. As you've seen already in this
    chapter, leveraging a binary search algorithm in searching tasks makes the code
    run much faster compared to its sequential alternative. Efficient software saves
    time and provides a better user experience, which eventually makes your software
    an outstanding alternative to existing ones.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we have discussed fundamental data structures and their differences.
    We learned to use them based on problem analysis. For example, applying a linked
    list in problems requiring random lookups is considered time-consuming because
    of the complexity of the linked-list element access operations. In such scenarios,
    using a dynamically growing vector is more appropriate due to its constant-time
    element access. On the contrary, using a vector in problems requiring fast insertions
    at the front of the container is more expensive compared to, for example, the
    list.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter also introduced algorithms and ways to measure their efficiency.
    We compared several problems to apply better algorithms to solve them more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we are going to discuss functional programming in C++.
    Having studied the essentials of the STL, we are now going to apply functional
    programming techniques on containers.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Describe the insertion of an element into a dynamically growing vector.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the difference between inserting an element at the front of a linked
    list and at the front of a vector?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement a hybrid data structure that will store its elements in both a vector
    and a list. For each operation, choose the underlying data structure with the
    fastest implementation of the operation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How would a binary search tree look if we insert 100 elements in increasing
    order?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between the selection sort and insertion sort algorithms?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement the sorting algorithm described in the chapter, known as the counting
    sort.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For more information, refer to the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Programming Pearls* by Jon Bentley, available from [https://www.amazon.com/Programming-Pearls-2nd-Jon-Bentley/dp/0201657880/](https://www.amazon.com/Programming-Pearls-2nd-Jon-Bentley/dp/0201657880/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data Abstraction and Problem Solving Using C++: Walls and Mirrors* by Frank
    Carrano,and Timothy Henry, available from [https://www.amazon.com/Data-Abstraction-Problem-Solving-Mirrors/dp/0134463978/](https://www.amazon.com/Data-Abstraction-Problem-Solving-Mirrors/dp/0134463978/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Introduction to Algorithms* by Cormen, Leiserson, Rivest, and Stein, available
    from [https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844/](https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*C++ Data Structures and Algorithms* by Wisnu Anggoro, available from [https://www.packtpub.com/application-development/c-data-structures-and-algorithms](https://www.packtpub.com/application-development/c-data-structures-and-algorithms)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
