- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having already written an introductory book on the Hadoop ecosystem, I was pleased
    to be asked by Packt to write a book on Apache Spark. Being a practical person
    with a support and maintenance background, I am drawn to system builds and integration.
    So, I always ask the questions "how can the systems be used?", "how do they fit
    together?" and "what do they integrate with?" In this book, I will describe each
    module of Spark, and explain how they can be used with practical examples. I will
    also show how the functionality of Spark can be extended with extra libraries
    like H2O from [http://h2o.ai/](http://h2o.ai/).
  prefs: []
  type: TYPE_NORMAL
- en: I will show how Apache Spark's Graph processing module can be used in conjunction
    with the Titan graph database from Aurelius (now DataStax). This provides a coupling
    of graph-based processing and storage by grouping together Spark GraphX and Titan.
    The streaming chapter will show how data can be passed to Spark streams using
    tools like Apache Flume and Kafka.
  prefs: []
  type: TYPE_NORMAL
- en: Given that in the last few years there has been a large-scale migration to cloud-based
    services, I will examine the Spark cloud service available at [https://databricks.com/](https://databricks.com/).
    I will do so from a practical viewpoint, this book does not attempt to answer
    the question "server or cloud", as I believe it to be a subject of a separate
    book; it just examines the service that is available.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 1](ch01.html "Chapter 1. Apache Spark"), *Apache Spark*, will give
    a complete overview of Spark, functionalities of its modules, and the tools available
    for processing and storage. This chapter will briefly give the details of SQL,
    Streaming, GraphX, MLlib, Databricks, and Hive on Spark.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 2](ch02.html "Chapter 2. Apache Spark MLlib"), *Apache Spark MLlib*,
    covers the MLlib module, where MLlib stands for Machine Learning Library. This
    describes the Apache Hadoop and Spark cluster that I will be using during this
    book, as well as the operating system that is involved—CentOS. It also describes
    the development environment that is being used: Scala and SBT. It provides examples
    of both installing and building Apache Spark. A worked example of classification
    using the Naïve Bayes algorithm is explained, as is clustering with KMeans. Finally,
    an example build is used to extend Spark to include some Artificial Neural Network
    (ANN) work by Bert Greevenbosch ([www.bertgreevenbosch.nl](http://www.bertgreevenbosch.nl)).
    I have always been interested in neural nets, and being able to use Bert''s work
    (with his permission) in this chapter was enjoyable. So, the final topic in this
    chapter classifies some small images including distorted images using a simple
    ANN. The results and the resulting score are quite good!'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 3](ch03.html "Chapter 3. Apache Spark Streaming"), *Apache Spark Streaming*,
    covers the comparison of Apache Spark to Storm and especially Spark Streaming,
    but I think that Spark offers much more functionality. For instance, the data
    used in one Spark module can be passed to and used in another. Also, as shown
    in this chapter, Spark streaming integrates easily with big data movement technologies
    like Flume and Kafka.'
  prefs: []
  type: TYPE_NORMAL
- en: So, the streaming chapter starts by giving an overview of checkpointing, and
    explains when you might want to use it. It gives Scala code examples of how it
    can be used, and shows the data can be stored on HDFS. It then moves on to give
    practical examples in Scala, as well as execution examples of TCP, File, Flume,
    and the Kafka streaming. The last two options are shown by processing an RSS data
    stream and finally storing it on HDFS.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 4](ch04.html "Chapter 4. Apache Spark SQL"), *Apache Spark SQL*, explains
    the Spark SQL context in Scala code terms. It explains File I/O as text, Parquet,
    and JSON formats. Using Apache Spark 1.3 it explains the use of data frames by
    example, and shows the methods that they make available for data analytics. It
    also introduces Spark SQL by Scala-based example, showing how temporary tables
    can be created, and how the SQL-based operations can be used against them.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, the Hive context is introduced. Initially, a local context is created
    and the Hive QL operations are then executed against it. Then, a method is introduced
    to integrate an existing distributed CDH 5.3 Hive installation to a Spark Hive
    context. Operations against this context are then shown to update a Hive database
    on the cluster. In this way, the Spark applications can be created and scheduled
    so that the Hive operations are driven by the real-time Spark engine.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the ability to create user-defined functions (UDFs) is introduced,
    and the UDFs that are created are then used in the SQL calls against the temporary
    tables.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 5](ch05.html "Chapter 5. Apache Spark GraphX"), *Apache Spark GraphX*,
    introduces the Apache Spark GraphX module and the graph processing module. It
    works through a series of graph functions by example from based counting to triangle
    processing. It then introduces Kenny Bastani''s Mazerunner work which integrates
    the Neo4j NoSQL database with Apache Spark. This work has been introduced with
    Kenny''s permission; take a look at [www.kennybastani.com](http://www.kennybastani.com).'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter works through the introduction of Docker, then Neo4j, and then
    it gives an introduction to the Neo4j interface. Finally, it works through some
    of the Mazerunner supplied functionality via the supplied REST interface.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 6](ch06.html "Chapter 6. Graph-based Storage"), *Graph-based Storage*,
    examines graph-based storage as Apache Spark Graph processing was introduced in
    this book. I looked for a product that could integrate with Hadoop, was open sourced,
    could scale to a very high degree, and could integrate with Apache Spark.'
  prefs: []
  type: TYPE_NORMAL
- en: Although it is still a relatively young product both in terms of community support
    and development, I think that Titan from Aurelius (now DataStax) fits the bill.
    The 0.9.x releases that are available, as I write now, use Apache TinkerPop for
    graph processing.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter provides worked examples of graph creation and storage using Gremlin
    shell and Titan. It shows how both HBase and Cassandra can be used for backend
    Titan storage.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 7](ch07.html "Chapter 7. Extending Spark with H2O"), *Extending Spark
    with H2O*, talks about the H2O library set developed at [http://h2o.ai/](http://h2o.ai/),
    which is a machine learning library system that can be used to extend the functionality
    of Apache Spark. In this chapter, I examine the sourcing and installation of H2O,
    as well as the Flow interface for data analytics. The architecture of Sparkling
    Water is examined, as is data quality and performance tuning.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, a worked example of deep learning is created and executed. [Chapter
    2](ch02.html "Chapter 2. Apache Spark MLlib"), *Spark MLlib*, used a simple ANN
    for neural classification. This chapter uses a highly configurable and tunable
    H2O deep learning neural network for classification. The result is a fast and
    accurate trained neural model, as you will see.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 8](ch08.html "Chapter 8. Spark Databricks"), *Spark Databricks*, introduces
    the [https://databricks.com/](https://databricks.com/) AWS cloud-based Apache
    Spark cluster system. It offers a step-by-step process of setting up both an AWS
    account and the Databricks account. It then steps through the [https://databricks.com/](https://databricks.com/)
    account functionality in terms of Notebooks, Folders, Jobs, Libraries, development
    environments, and more.'
  prefs: []
  type: TYPE_NORMAL
- en: It examines the table-based storage and processing in Databricks, and also introduces
    the DBUtils package for Databricks utilities functionality. This is all done by
    example to give you a good understanding of how this cloud-based system can be
    used.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 9](ch09.html "Chapter 9. Databricks Visualization"), *Databricks Visualization*,
    extends the Databricks coverage by concentrating on data visualization and dashboards.
    It then examines the Databricks REST interface, showing how clusters can be managed
    remotely using various example REST API calls. Finally, it looks at data movement
    in terms of table''s folders and libraries.'
  prefs: []
  type: TYPE_NORMAL
- en: The cluster management section of this chapter shows that it is possible to
    launch Apache Spark on AWS EC2 using scripts supplied with the Spark release.
    The [https://databricks.com/](https://databricks.com/) service takes this functionality
    a step further by providing a method to easily create and resize multiple EC2-based
    Spark clusters. It provides extra functionality for cluster management and usage,
    as well as user access and security as these two chapters show. Given that the
    people who brought us Apache Spark have created this service, it must be worth
    considering and examining.
  prefs: []
  type: TYPE_NORMAL
- en: What you need for this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The practical examples in this book use Scala and SBT for Apache Spark-based
    code development and compilation. A Cloudera CDH 5.3 Hadoop cluster on CentOS
    6.5 Linux servers is also used. Linux Bash shell and Perl scripts are used both,
    to assist in Spark applications and provide data feeds. Hadoop administration
    commands are used to move and examine data during Spark applications tests.
  prefs: []
  type: TYPE_NORMAL
- en: Given the skill overview previously, it would be useful for the reader to have
    a basic understanding of Linux, Apache Hadoop, and Spark. Having said that, and
    given that there is an abundant amount of information available on the internet
    today, I would not want to stop an intrepid reader from just having a go. I believe
    that it is possible to learn more from mistakes than successes.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is for anyone interested in Apache Hadoop and Spark who would like
    to learn more about Spark. It is for the user who would like to learn how the
    usage of Spark can be extended with systems like H2O. It is for the user who is
    interested in graph processing but would like to learn more about graph storage.
    If the reader wants to know about Apache Spark in the cloud then he/she can learn
    about [https://databricks.com/](https://databricks.com/), the cloud-based system
    developed by the people who brought them Spark. If you are a developer with some
    experience with Spark and want to strengthen your knowledge of how to get around
    in the world of Spark, then this book is ideal for you. Basic knowledge of Linux,
    Hadoop, and Spark is required to understand this book; reasonable knowledge of
    Scala is also expected.
  prefs: []
  type: TYPE_NORMAL
- en: Conventions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, you will find a number of text styles that distinguish between
    different kinds of information. Here are some examples of these styles and an
    explanation of their meaning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "The
    first step is to ensure that a Cloudera repository file exists under the `/etc/yum.repos.d`
    directory, on the server hc2nn and all of the other Hadoop cluster servers."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**New terms** and **important words** are shown in bold. Words that you see
    on the screen, for example, in menus or dialog boxes, appear in the text like
    this: "Select the **User Actions** option, and then select **Manage Access Keys**."'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Warnings or important notes appear in a box like this.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Tips and tricks appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Reader feedback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome. Let us know what you think about
    this book—what you liked or disliked. Reader feedback is important for us as it
    helps us develop titles that you will really get the most out of.
  prefs: []
  type: TYPE_NORMAL
- en: To send us general feedback, simply e-mail `<[feedback@packtpub.com](mailto:feedback@packtpub.com)>`,
    and mention the book's title in the subject of your message.
  prefs: []
  type: TYPE_NORMAL
- en: If there is a topic that you have expertise in and you are interested in either
    writing or contributing to a book, see our author guide at [www.packtpub.com/authors](http://www.packtpub.com/authors).
  prefs: []
  type: TYPE_NORMAL
- en: Customer support
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you are the proud owner of a Packt book, we have a number of things
    to help you to get the most from your purchase.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading the example code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can download the example code files from your account at [http://www.packtpub.com](http://www.packtpub.com)
    for all the Packt Publishing books you have purchased. If you purchased this book
    elsewhere, you can visit [http://www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files e-mailed directly to you.
  prefs: []
  type: TYPE_NORMAL
- en: Errata
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although we have taken every care to ensure the accuracy of our content, mistakes
    do happen. If you find a mistake in one of our books—maybe a mistake in the text
    or the code—we would be grateful if you could report this to us. By doing so,
    you can save other readers from frustration and help us improve subsequent versions
    of this book. If you find any errata, please report them by visiting [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the **Errata Submission Form** link, and entering
    the details of your errata. Once your errata are verified, your submission will
    be accepted and the errata will be uploaded to our website or added to any list
    of existing errata under the Errata section of that title.
  prefs: []
  type: TYPE_NORMAL
- en: To view the previously submitted errata, go to [https://www.packtpub.com/books/content/support](https://www.packtpub.com/books/content/support)
    and enter the name of the book in the search field. The required information will
    appear under the **Errata** section.
  prefs: []
  type: TYPE_NORMAL
- en: Piracy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Piracy of copyrighted material on the Internet is an ongoing problem across
    all media. At Packt, we take the protection of our copyright and licenses very
    seriously. If you come across any illegal copies of our works in any form on the
    Internet, please provide us with the location address or website name immediately
    so that we can pursue a remedy.
  prefs: []
  type: TYPE_NORMAL
- en: Please contact us at `<[copyright@packtpub.com](mailto:copyright@packtpub.com)>`
    with a link to the suspected pirated material.
  prefs: []
  type: TYPE_NORMAL
- en: We appreciate your help in protecting our authors and our ability to bring you
    valuable content.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have a problem with any aspect of this book, you can contact us at `<[questions@packtpub.com](mailto:questions@packtpub.com)>`,
    and we will do our best to address the problem.
  prefs: []
  type: TYPE_NORMAL
