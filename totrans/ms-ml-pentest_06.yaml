- en: Machine Learning in Anomaly Detection Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unauthorized activity on a network can be a nightmare for any business. Protecting
    customers' data is the ultimate concern, and is the responsibility of every business
    owner. Deploying intrusion detection systems is a wise decision modern organizations
    can make to defend against malicious intrusions. Unfortunately, attackers and
    black hat hackers are always inventing new techniques to bypass protection, in
    order to gain unauthorized access to networks. That is why machine learning techniques
    are a good solution to protect networks from even sophisticated and  attacks.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will be a one-stop guide for discovering network anomalies and
    learning how to build intrusion detection systems from scratch, using publicly
    available datasets and cutting-edge, open source Python data science libraries.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of anomaly detection techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network attacks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting network anomalies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Host-based intrusion detection systems** (**HIDS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network-based intrusion detection systems** (**NIDS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'These are the requirements needed in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: A working knowledge of networking is required for this chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are going to use the same Python libraries that we saw in earlier chapters,
    with the addition of a new library, called **Yellowbrick**. (You will find the
    installation instructions in this chapter.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can find the code files used in this chapter in the GitHub repository at [https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter06](https://github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing/tree/master/Chapter06).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of anomaly detection techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will now discuss network anomalies (which are our prime concern) and their
    detection methods. By definition, an anomaly is something outside of the norm,
    an unexpected pattern in data. The term anomaly is used widely in data mining,
    and is sometimes called an outlier. Anomaly detection techniques are often used
    for fraud detection and to find malicious activities. In networking, anomalies
    can occur for many reasons, but what is important to us, in this case, is malicious
    activity detection. Generally, we see three types of anomalies:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Point anomalies**: Anomalous individual data instances, compared to the rest
    of the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Contextual anomalies**: Anomalous behaviors that occur only during specific
    contexts (periods of time, regions, and so on).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collective anomalies**: A collection of anomalous activities, compared to
    the rest of the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These anomalies can be detected using many techniques, based on the data that
    is available.
  prefs: []
  type: TYPE_NORMAL
- en: Static rules technique
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If we have training data, then we need to check that the data is balanced. If
    we don't have training data, the decision will be made based on the anomaly type;
    to detect point anomalies, it is recommended that you use percentiles and histograms.
    To detect collective anomalies, the decision will be based on the variance of
    the anomalies; to detect univariate anomalies, you can use Markov chains, or you
    can build a model and look at the residue. In a multivariate situation, we can
    use clustering and Markov models (if the anomalies are ordered) or k-Nearest-Neighbors
    (if the anomalies are unordered).
  prefs: []
  type: TYPE_NORMAL
- en: 'The different techniques are represented in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00130.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Network attacks taxonomy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When it comes to network anomalies, our job is protecting the organization''s
    network from intruders. A network intrusion is a malicious activity that threatens
    the security of the network. Information security professionals have suggested
    many categorizations to classify network attacks for better study. For example,
    they have classified network attacks into the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Infection (malware)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploding (buffer overflow)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probing (sniffing)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheating (spoofing)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traverse (brute-forcing)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concurrency (DDoS)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Attacks can also be categorized into passive and active attacks. An active
    attack is when the attacker has a direct effect on the network. The **Defense
    Advanced Research Projects Agency** (**DARPA**) has classified active attacks
    into four major categories, in its intrusion detection evaluation plan. The four
    categories are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Denial of Service (DoS)**: DoS attacks are attempts to interrupt an authorized
    user''s access to the network. In other words, they block users from access to
    online services, like email.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User to Root (U2R) attacks**: U2R attacks are hard to detect; they attempt
    to gain high (superuser) privileges. This is achieved by accessing systems as
    normal users and trying to exploit the system''s weaknesses later on, to escalate
    the privileges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Remote to Local (R2L)**: An R2L attack is an attempt to interact with remote
    machines to gain access. One technique that is used is password guessing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Probe**: A probe is an attempt to gain information about the hosts in the
    network, including valid IP addresses, running services, and open ports. It is
    usually done by scanning. As you know, the information gathered will later be
    used to identify vulnerabilities in order to exploit them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The detection of network anomalies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Network **intrusion detection systems** (**IDSs**) are not a new idea. They
    have been proposed since the earliest network attacks. IDS can be categorized
    into two major categories, based on their deployment: HIDS and NIDS. The following
    diagram illustrates a high-level overview of an IDS architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00131.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: HIDS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: HIDS are able to collect and monitor computer systems (especially their internals)
    in order to give security analysts a deep visibility into what's happening on
    critical systems, such as workstations, servers, and mobile devices. The main
    goal of an HIDS is to detect intrusions.
  prefs: []
  type: TYPE_NORMAL
- en: NIDS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: NIDS are responsible for detecting intrusions in network data. Basically, the
    detection is made based on specific patterns in sequential data. In other words,
    NIDSs read all of the incoming packets and try to find anomalies in them.
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly-based IDS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When it comes to IDS, we are generally talking about two categories: host-based
    and network-based. But a new class of IDS has also arisen. The new category is
    anomaly-based. These systems work by using machine learning techniques to identify
    intrusions and anomalies in data. In the previous chapters, especially in [Chapter
    1](part0021.html#K0RQ0-49a67f1d6e7843d3b2296f38e3fe05f5), *Introduction to Machine
    Learning in Pen Testing*, we looked at the different models of machine learning:
    supervised, unsupervised, semi-supervised, and reinforcement learning. Anomaly-based
    IDS are also categorized into supervised and unsupervised systems, depending on
    the machine learning model used to detect the network intrusion. The information
    security community, after many years of research, has succeeded in providing a
    classification of the different methods used in IDS. One of the proposals, called
    *Shallow and Deep Networks Intrusion Detection System: A Taxonomy and Survey,* delivered
    by Elike Hodo, Xavier J. A. Bellekens, Andrew Hamilton, Christos Tachtatzis, and
    Robert C. Atkinson, gives a detailed overview of many machine learning techniques
    for reliable intrusion detection. Some of the techniques are presented in the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00132.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, we discussed many of the suggested techniques in previous chapters.
    Generally, in supervised anomaly detection, the input data and the anomaly classes
    are known. In other words, all of the data is labeled; even collecting labeled
    data is an exhausting and time-consuming task. The data that is captured will
    be processed before being sent to the detection engine. Unsupervised anomaly detection systems
    could be  novel solutions while they are working even if the data is not labeled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Clustering is one of the most common techniques used in unsupervised systems.
    The two different systems can be combined into one hybrid intrusion detection
    system. An overall hybrid anomaly intrusion detection system is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00133.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'If you want to build a successful and reliable anomaly-based network intrusion
    detection system, you need to consider many important factors. One of these factors
    is proximity measure; by definition, proximity means a measurement of the similarity,
    or dissimilarity, of objects. Thus, as discussed previously, these systems are
    trying to classify or cluster data into groups and so respectively measuring the
    proximity of objects to one another. Similarity measures take values between `0`
    and `1`, where `1` is the greatest similarity value. Euclidean distance and Manhattan
    distance are some common proximity measures. The selection of a suitable measure
    depends on the type of data (numeric or categorical). The anomalies are not detected
    arbitrarily, but are based on a scoring system. Sub-samples are marked by intrusion
    scores called **anomaly scores**. This scoring system is very beneficial to information
    security analysts; based on an ordered and ranked list of anomalies, they can
    select a threshold to work by, according to the severity. The following are some
    common anomaly scoring techniques used by anomaly network intrusion detection
    systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Distance-based anomaly score estimation**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Link-based outlier and anomaly detection in evolving datasets**: The dataset
    contains both continuous and categorical attributes. It uses a similarity metric
    to measure the link strength and the degree of association between two points.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduced memory load**: This defines an anomaly as a data point that has subset
    attributes that take on unusual values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Density-based anomaly score estimation**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Outlier detection for mixed attribute datasets**: This detects anomalies
    by computing the irregularity of values and the relationships between different
    types of attributes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building your own IDS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By now, you know the different network anomaly detection techniques. We are
    now going to build our own network IDS with Python, from scratch. The University
    of California hosted a competition called *The Third International Knowledge Discovery
    and Data Mining Tools Competition*, and they provided a dataset called **KDD Cup
    1999 Data,** or **KDD 1990**. You can find it at [http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html).
  prefs: []
  type: TYPE_NORMAL
- en: The main aim of the competition was building a system that was able to distinguish
    between bad (attack) and good (normal) connections. Many modern proposals and
    machine learning solutions were made using the dataset. But as you can see, the
    dataset is old; the models were not able to detect modern network attacks, in
    addition to other issues, like data redundancy. A great study called *A Detailed
    Analysis of the KDD CUP 99 Data Set,* done by Mahbod Tavallaee, Ebrahim Bagheri,
    Wei Lu, and Ali A. Ghorbani, highlighted many issues in the KDD99 dataset. A new
    dataset arose to solve the issues, named NSL-KDD ([http://www.unb.ca/cic/datasets/nsl.html](http://www.unb.ca/cic/datasets/nsl.html)).
    Even that didn't solve all of the issues, but many improvements were made. The
    improvements reduced the data by about 75%.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are some additional, publicly available datasets that can help you to
    build your own intrusion detection systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Coburg Intrusion Detection Data Sets** (**CIDDS**): [https://www.hs-coburg.de/index.php?id=927](https://www.hs-coburg.de/index.php?id=927)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**UGR''16, A New Dataset for the Evaluation of Cyclostationarity-Based Network
    IDSs**: [https://nesg.ugr.es/nesg-ugr16/index.php#CAL](https://nesg.ugr.es/nesg-ugr16/index.php#CAL)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Intrusion Detection Evaluation Dataset (CICIDS2017)**: [http://www.unb.ca/cic/datasets/ids-2017.html](http://www.unb.ca/cic/datasets/ids-2017.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our model, we are going to use the **NSL_KDD **as a dataset for training
    and testing. To get it, just clone it from GitHub, or simply use it directly,
    since we are providing all of the datasets discussed in this book in the book''s
    GitHub repository. You can find it in the `Chapter 06` folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00134.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'The dataset contains different files:'
  prefs: []
  type: TYPE_NORMAL
- en: '`KDDTrain+.arff`: The full NSL-KDD training set, with binary labels in ARFF
    format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`KDDTrain+.txt`: The full NSL-KDD training set, including attack-type labels
    and difficulty levels in CSV format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`KDDTrain+_20Percent.ARFF`: A 20% subset of the `KDDTrain+.arff` file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`KDDTrain+_20Percent.TXT`: A 20% subset of the `KDDTrain+.txt` file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`KDDTest+.ARFF`: The full NSL-KDD test set, with binary labels in ARFF format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`KDDTest+.TXT`: The full NSL-KDD test set, including attack-type labels and
    difficulty levels in CSV format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`KDDTest-21.ARFF`: A subset of the `KDDTest+.arff` file, which does not include
    records, with difficulty levels of 21 out of 21.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`KDDTest-21.TXT`: A subset of the `KDDTest+.txt` file, which does not include
    records, with difficulty levels of 21 out of 21.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you open `Field Names.csv`, you will see all of the 40 fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00135.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To import this dataset, we will use `pandas`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If we check the columns with  `Data.columns`, we will see that the columns,
    or fields, are represented as numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00136.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'To make our feature analysis easier, let''s assign a field name to a number
    for better feature representation. To do that, we will create an array called
    `Columns`, filled with field names, and load the dataset with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Load the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'These are the feature names:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00137.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'To better understand the dataset, we can use `pandas.DataFrame.describe`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00138.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'Before training the model, some additional processing is needed. `sklearn.preprocessing.LabelEncoder` encodes
    labels with values between `0` and `n_classes-1` and `fit_transform(y)`. Fit the
    label encoder and return encoded labels. In our case, we are transforming non-numerical
    labels into numerical labels. Also, we need to pre-process four labels: `protocol_type`,
    `service`, `flag`, and `label`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To do that, we use `fit.transform()`, which calibrates our measurements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00139.gif)'
  prefs: []
  type: TYPE_IMG
- en: In scikit-learn, there are two different methods: `fit` and `fit_transform`.
    The difference between the two methods is that `fit` calculates the parameters
    (μ and σ, where μ is the mean of the population and σ is the standard deviation
    of the population) and saves them internally, while `fit_transform` does the same
    task  but also applies a transformation to a particular set of samples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s identify our data. In the following lines, we have used an additional
    NumPy method, `as_matrix()`, to convert the frame to its NumPy-array representation.
    In a NumPy-array, the return is not a NumPy matrix, but a NumPy array, according
    to the official documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Usually, after this step, we would perform the model training; but this time,
    we are going to take more time to analyze and visualize our data and features.
    One of the tasks of data science is obtaining insights and knowledge, and visualization
    is essential to data science and machine learning. My recommendation is to play
    with data as much as you can, and poke around with different techniques. As you
    will have noticed, a machine learning system generally respects the same techniques,
    and your job, as a data scientist or machine learning expert, is to select the
    right features from the data. Machine learning algorithms are based on mathematics,
    and usually, you are not going to change the algorithm itself; instead, you'll
    want to perform some good feature engineering to build a reliable and good model
    with high accuracy that meets your goals.
  prefs: []
  type: TYPE_NORMAL
- en: 'Yellowbrick is a great visualization library and suite of visual diagnostic
    tools (visualizers). This library depends on scikit-learn and Matplotlib. You
    can install it by using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This library is very rich, letting you visualize features, classification,
    regression, clustering, and even text (for example, visualizing the frequency
    distribution of terms in a corpus):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00140.gif)'
  prefs: []
  type: TYPE_IMG
- en: '`visualizer.poof()` will display the plot as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00141.gif)'
  prefs: []
  type: TYPE_IMG
- en: 'To save the plot, you can add `outpath`, like in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You can even export it as a PDF file. You may have noticed that in the line `visualizer
    = Rank1D(features=Columns, algorithm='shapiro')`, we used a method called `Rank1D` and
    an algorithm called `shapiro`, to rank features and detect the relationships between
    them. `Rank1D` and `Rank2D` evaluate single features or pairs of features. In
    our case, we used a one-dimensional ranking of features.
  prefs: []
  type: TYPE_NORMAL
- en: '`Rank2D` is a two-dimensional ranking of features. The following shows how
    to implement it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You can select from `pearson` or `covariance`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00142.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s go back to the ranking algorithms we used. The `shapiro` parameter refers
    to the Shapiro-Wilk ranking algorithm. You can select your ranking algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00143.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'We previously discovered **P****rincipal Component Analysis** (**PCA**). Yellowbrick
    gives you the ability to decompose high-dimensional data into two or three dimensions,
    and plot them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00144.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Also, the plot can be in 3D:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code is presented in this graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/00145.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now it is time to train our intrusion detection machine learning model. As
    usual, we split the data, select the classifier used, fit the model, and get the
    scoring results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/00146.gif)'
  prefs: []
  type: TYPE_IMG
- en: The score of our intrusion detection system is 85.7%. For more details, you
    can output the evaluation metrics (TF, FP, TN, FN, and Recall), as done in the
    previous models.
  prefs: []
  type: TYPE_NORMAL
- en: The Kale stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Monitoring is a difficult mission, especially when it comes to a team of hundreds
    of engineers, where metrics overload can occur. To solve this problem, in addition
    to a time series-based anomaly detection ability, there are many projects that
    we can use. One of them is the Kale stack. It consists of two parts: Skyline and
    Oculus. The role of Skyline is to detect anomalous metrics (an anomaly detection
    system), while Oculus is the anomaly correlation component. To download the two
    components, you can check the following repositories:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Skyline: [http://github.com/etsy/skyline](http://github.com/etsy/skyline)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Oculus: [http://github.com/etsy/oculus](http://github.com/etsy/oculus)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: At least 8 GB RAM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quad Core Xeon 5620 CPU, or comparable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 GB disk space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the fundamentals of network anomaly detection techniques,
    and the theories behind them. You learned how to build a machine learning based
    network anomaly detector with Python. There are many other techniques that you
    can use to build a machine learning IDS. The next chapter will enhance your skills
    by guiding you through deploying a fully-working threat hunting platform, using
    an amazing stack for open source projects called the ELK stack.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is an anomaly?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a Markov chain?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are hidden Markov models?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we detect anomalies with hidden Markov models?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the difference between time series anomaly detection and the other types
    of anomaly detection?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the difference between time series anomaly detection and other types
    of anomaly detection?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What's the difference between supervised and unsupervised machine learning anomaly
    detection?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Blog posts**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Anomaly detection articles**: [https://www.kdnuggets.com/tag/anomaly-detection](https://www.kdnuggets.com/tag/anomaly-detection)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A practical guide to anomaly detection for DevOps**: [https://www.bigpanda.io/blog/a-practical-guide-to-anomaly-detection/](https://www.bigpanda.io/blog/a-practical-guide-to-anomaly-detection/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Papers**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Root-Cause Analysis for Time-Series Anomalies via Spatiotemporal Graphical
    Modeling in Distributed Complex Systems**:[https://arxiv.org/abs/1805.12296](https://arxiv.org/abs/1805.12296)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A Generalized Active Learning Approach for Unsupervised Anomaly Detection**:[https://arxiv.org/abs/1805.09411](https://arxiv.org/abs/1805.09411)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Towards Explaining Anomalies: A Deep Taylor Decomposition of One-Class Models**:[https://arxiv.org/abs/1805.06230](https://arxiv.org/abs/1805.06230)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Towards an Efficient Anomaly-Based Intrusion Detection for Software-Defined
    Networks**:[https://arxiv.org/abs/1803.06762](https://arxiv.org/abs/1803.06762)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
