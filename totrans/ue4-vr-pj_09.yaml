- en: Displaying Media in VR
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we focused on creating real-time 3D media for VR,
    and spent a lot of time looking at player characters, interface elements, and
    building the world. Now, we're going to shift gears a bit and explore another
    important application for VR—displaying movies both on flat screens and in immersive
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: VR is very good at this. Because it's possible to create a nearly infinite space
    within the headset, users can experience movies and media on enormous virtual
    screens with no distractions to take them out of the experience. These screens
    can take any shape as well. In addition to flat and curved screens, photos and
    movies of entire environments can be presented in a sphere surrounding the player
    so that they feel totally immersed in the space. In this chapter, we're going
    to learn how to create these things.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Displaying video on a virtual screen
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Displaying video with stereo depth from side-to-side and over/under video sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Displaying media in 360-degree spherical environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Displaying 360-degree media in stereo
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating interactive controls to allow the player to start, stop, and rewind
    their media
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's get to it and learn how to play movies!
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter''s project, we don''t need anything from our previous work,
    so we''re going to begin simply by creating a new project with the following settings:'
  prefs: []
  type: TYPE_NORMAL
- en: Blank Blueprint template
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mobile / Tablet hardware target
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalable 3D or 2D graphics target
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With Starter Content (we'll use some of the starter content in this one)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We still need to set our settings appropriately for VR, as we do with each
    project. Here''s the cheat sheet:'
  prefs: []
  type: TYPE_NORMAL
- en: Project | Description | Settings | Start in VR: True
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Engine | Rendering | Forward Renderer | Forward Shading: True
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Engine | Rendering | Default Settings | Ambient Occlusion Static Fraction: False
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Engine | Rendering | Default Settings | Anti-Aliasing Method: MSAA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Engine | Rendering | VR | Instanced Stereo: True
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Engine | Rendering | VR | Round Robin Occlusion Queries: True
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allow the project to restart once all of these settings have been set. Once
    your project has reopened, you'll be ready to begin learning about how media works
    in Unreal Engine.
  prefs: []
  type: TYPE_NORMAL
- en: Playing movies in Unreal Engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We're going to begin by learning how we can play movies and other media in Unreal
    Engine in general. Of course, to get started, we're going to need a movie to play.
  prefs: []
  type: TYPE_NORMAL
- en: Video files come in a confusing array of configurations, and there are a few
    things you should know about them.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding containers and codecs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first point of confusion most people run into when they start learning about
    video files is not understanding that the container that a video file is wrapped
    in doesn't necessarily tell you much about how it was encoded. Let's take a moment
    to talk about this.
  prefs: []
  type: TYPE_NORMAL
- en: Video files consist of a lot of information, all packed into one file. There's
    the stream of images representing the video track. Often, there's audio, sometimes
    there are subtitles, and sometimes there's other additional information as well.
    All of this information gets bundled together inside a wrapping format called
    a **container**. You've no doubt seen video files with the `.mp4` extension. That's
    the extension used by the MPEG-4 container format. AVI is Microsoft's standard
    container format, and there are many others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the thing to remember, though: the container format specifies how these
    different parts of information are held together in the file, but it doesn''t
    tell us how the video and audio streams were actually made. Just because you see
    the `.mp4` extension on a file doesn''t necessarily mean it''s going to work for
    what you''re trying to use it for. There''s another factor you need to take into
    consideration: the **codec**.'
  prefs: []
  type: TYPE_NORMAL
- en: The word **codec** is a shortened combination of the words **compressor** and
    **decompressor**. Video files in their raw state can become huge. How big? Let's
    run some numbers. Say we have a 1080p video file. Its dimensions are 1920 x 1080
    pixels. That's 2,073,600 pixels per frame. Let's say that we're displaying this
    video file in 24-bit color (8 bits per channel), which allows us to display a
    little over 16 million colors, which comes out to about 50 MB per frame. If we're
    running at 30 frames per second, that's going to eat up around 1.49 gigabytes
    per second. You're going to run out of space in a big hurry doing that.
  prefs: []
  type: TYPE_NORMAL
- en: We deal with this by compressing video files heavily when we store them, and
    then decompressing them in real time when it's time to stream them to the screen.
    This work is handled by the codec. Its compressor component is responsible for
    taking the raw source video and packing it into a format that can fit on disc,
    and its decompressor component handles unpacking it so that it can be displayed.
    Discussions of how video codecs work fill entire books of their own, so we're
    not going to get into the weeds on this, but the part that you do need to know
    is that while many codecs exist, not all of them work with all software solutions,
    and not all of them work on all hardware configurations. The most commonly used
    codec, and the most broadly compatible, is called **H.264**, but many codecs exist.
    Some are designed to be broadly used and some are very specifically made for certain
    applications, such as video editing. It's worthwhile spending a bit of time learning
    about these.
  prefs: []
  type: TYPE_NORMAL
- en: So, now you know a secret about video files. The container doesn't necessarily
    tell you about the codec, and you need to know about both to know whether the
    file will work. (So the next time you ask someone what kind of video file they've
    given you, and they answer that they've given you an `.mp4`, you'll know they
    haven't really answered your question.) Some container formats only work on specific
    operating systems or hardware, while others, such as `.mp4`, will work nearly
    anywhere.
  prefs: []
  type: TYPE_NORMAL
- en: For video files you intend to use with Unreal Engine, you should generally choose
    to wrap them in the `.mp4` container and compress them using the **H.264** codec. For
    more information on supported codecs, check out the following link: [https://docs.unrealengine.com/en-US/Engine/MediaFramework/TechReference](https://docs.unrealengine.com/en-US/Engine/MediaFramework/TechReference).
  prefs: []
  type: TYPE_NORMAL
- en: We're not going to cover the topic of compressing your own video files here
    in this book – there's quite a lot to say about that, and quite a lot of information
    available online about how to do it. If you have access to the Adobe Creative
    Suite, the included Adobe Media Encoder application is an excellent tool for converting
    video into nearly any format you need. If you need a free video encoder, AVC Free
    is excellent and commonly used. You can find it at the following link: [https://www.any-video-converter.com/products/for_video_free/](https://www.any-video-converter.com/products/for_video_free/).
  prefs: []
  type: TYPE_NORMAL
- en: Finding a video file to test with
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's find a file that meets these standards. If we navigate to the "Video For
    Everybody" Test Page, we can find a suitable video for testing. Go to [http://camendesign.com/code/video_for_everybody/test.html](http://camendesign.com/code/video_for_everybody/test.html) and
    find the Download Video link for the `.mp4` container format. Right-click the
    link and select Save Link As... to save the `big_buck_bunny.mp4` video file to
    your hard drive.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you don''t already have the VLC Media Player installed on your system, download
    and install it from: [https://www.videolan.org/vlc/index.html](https://www.videolan.org/vlc/index.html).
    In practice, you could use any video player to check your files, but VLC is a
    good tool to know about. It''ll play nearly anything and gives you good information
    about the file you''re playing. Refer to the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the video file you just downloaded in VLC and play it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pause the video somewhere and hit *Ctrl* + *J* to open its Codec information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4295505a-7d98-4ee1-9997-0a90fc9ede18.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see here that this file has been encoded using H.264, and we can see
    from its file extension that it's using an `.mp4` container. This file should
    work correctly for us on any platform in Unreal.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a video file to an Unreal project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's add this file to our Unreal project.
  prefs: []
  type: TYPE_NORMAL
- en: For other asset types, you use the `Import` method from within Unreal Editor
    to add them to your project, but video files are different. To add a video file
    to an Unreal project, you must manually place it in a subdirectory of the `Content`
    folder named `Movies`.
  prefs: []
  type: TYPE_NORMAL
- en: The name and location are important. The engine will look for movies in `Content/Movies` by
    default, and your movies may not package correctly if you put them in another
    location.
  prefs: []
  type: TYPE_NORMAL
- en: From your Content Browser, make sure you're at the root `Content` folder and
    right-click to create a new folder.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Name it `Movies`, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/80a8ac75-1f4e-4798-be6a-3424678c30a0.png)'
  prefs: []
  type: TYPE_IMG
- en: From your Windows Explorer, find the `.mp4` file you downloaded, and move it
    to your project's `Content\Movies` directory. (You can right-click this directory
    in your Content Browser and select Show in Explorer to navigate to the directory.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating a File Media Source asset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, return to the Unreal Editor, and in your `Content/Movies` directory, right-click
    and select Create Advanced Asset | Media | File Media Source to create a new file
    media source asset. It''s often easier to name file media sources using the same
    names as their source assets, so it makes sense to name it `big_buck_bunny` since
    that''s the name of the file we''re about to attach:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/119994b5-0f77-47f5-baef-e148450a59b4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Open it up and use the ellipsis (...) button to select the video file you placed
    in your `Content/Movies` directory as its File Path:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2056807e-b88a-4ed4-b074-e0f85028d826.png)'
  prefs: []
  type: TYPE_IMG
- en: A File Media Source asset is simply a resolver that allows a media player to
    find a movie on disk. Media players point to file media sources, and those file
    media sources point to the actual file in the `Movies` directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'File media sources also provide a few additional options:'
  prefs: []
  type: TYPE_NORMAL
- en: The advanced Precache File option can be used to force the entire media file
    into memory and play from there.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Player Overrides list allows you to force a specific player to decode the
    media on a specific platform. Leave these alone unless you're sure you need to
    override the automatic choice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Three other media source types exist, and while we''re not going to dive into
    them in depth here, you should know about them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Img** Media Sources are used to display image sequences – individual images
    intended to be streamed in series as a movie. For detailed information on playing
    image sequences, check out the following link: [https://api.unrealengine.com/INT/Engine/MediaFramework/HowTo/ImgMediaSource/index.html](https://api.unrealengine.com/INT/Engine/MediaFramework/HowTo/ImgMediaSource/index.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stream** Media Sources allow you to specify a video file hosted at a specific
    URL for playback. For more information, check out the following link: [https://api.unrealengine.com/INT/Engine/MediaFramework/HowTo/StreamMediaSource/index.html](https://api.unrealengine.com/INT/Engine/MediaFramework/HowTo/StreamMediaSource/index.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Platform** Media Sources allow you to specify different media to play on
    different hardware platforms. Check out the following link for details: [https://api.unrealengine.com/INT/Engine/MediaFramework/HowTo/PlatformMedia/index.html](https://api.unrealengine.com/INT/Engine/MediaFramework/HowTo/PlatformMedia/index.html).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Media Player
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have a media source set up, let''s create a Media Player to play
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Right-click in your `Content/Movies` directory and select Create Advanced Asset
    | Media | Media Player. We''ll be using the same media player for all of our media
    sources, so a general name such as `MediaPlayer` is fine. Refer to the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7b558498-cc11-4ec0-98db-63b96dcdd1f8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When you create it, a new dialog will appear, asking whether you whether you''d
    like to create a Media Texture asset to handle the video output. Let''s allow
    it to do so, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c7e0e588-13b0-4e27-af01-1d491afdb502.png)'
  prefs: []
  type: TYPE_IMG
- en: We could just as well have created it by creating a Media/Media Texture asset
    from our content browser, but this saved us a step.
  prefs: []
  type: TYPE_NORMAL
- en: Using Media Textures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Media Texture assets display the streamed video or images from their bound
    Media Player asset. If you open the one we just created, you''ll see that it''s
    bound to the Media Player we just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9e3838eb-6072-46c9-b3cc-deaa1ba7d252.png)'
  prefs: []
  type: TYPE_IMG
- en: Don't worry if your media texture looks blank. It won't display anything until
    you've played something on its associated Media Player.
  prefs: []
  type: TYPE_NORMAL
- en: In general, you're going to want to leave your properties of Media Texture alone.
    Make sure it's bound to your Media Player, but you're unlikely to need to change
    any of its other properties.
  prefs: []
  type: TYPE_NORMAL
- en: Testing your Media Player
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Open up the new Media Player asset you just created. You should see the file
    media source we set up a moment ago in its list of available media sources. Select
    it and play it to verify that it''s playable in Unreal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/15bf0d29-ee25-4c02-8c13-5b1b7c6333d1.png)'
  prefs: []
  type: TYPE_IMG
- en: Ensure that Play on Open is selected for this file source, and turn on the Loop option
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: Once we've verified that the video file plays in our media player, let's add
    it to an object in the world.
  prefs: []
  type: TYPE_NORMAL
- en: Adding video to an object in the world
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we included Starter Content in this project, instead of launching with
    a blank map, our project launches with a simple map named Minimal Default by default,
    which contains a pair of chairs and a table. We can use this as a starting point
    for our movie playback map. Save the map by selecting File | Save Current As... and
    save it as `Content/Chapter08/Maps/MoviePlayback2D`. (Remember, it's a good idea
    to put your work into a subdirectory of your `Content` directory for your project.
    Otherwise, you're going to have a mess when you migrate something else in.)
  prefs: []
  type: TYPE_NORMAL
- en: If you'd like, feel free to use the starter content to arrange a more comfortable
    theater or viewing room set. We're not going to cover that here, but if you're
    up for it, create a living room or movie theater set, or anything that sparks
    your imagination.
  prefs: []
  type: TYPE_NORMAL
- en: 'What we do need in our scene is a screen to display our media. Follow these
    steps to create one:'
  prefs: []
  type: TYPE_NORMAL
- en: From the Modes panel, select Place | Basic | Plane, and drag a plane onto the
    scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set its Location to `(X=-730.0, Y=0.0, Z=210.0)` (or wherever fits the environment
    you've built).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set its Rotation to `(Pitch=0.0, Yaw=-90, Roll=90)` (in the editor, this reads
    as `X=90.0, Y=0.0, Z=-90.0`).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set its Scale to `(X=8.0, Y=4.5, Z=1.0)`. By doing this, we've matched the shape
    of the screen to the 16:9 aspect ratio of the video we intend to play.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, we''re going to assign our Media Texture to this plane:'
  prefs: []
  type: TYPE_NORMAL
- en: Drag the Media Texture we created for our Media Player onto the plane.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A material will automatically be created to display the texture.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is how you get media into a 3D scene. Assign a material or a material instance
    that uses a Media Texture as a source, and make sure that the Media Texture points
    back at a Media Player.
  prefs: []
  type: TYPE_NORMAL
- en: Using a media playback material
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We should look at this material for a moment. Open it up. If you look at its
    material properties, you can see that it's an ordinary Surface material using
    the Default Lit shading model. There's nothing special here.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Texture Sample, on the other hand, is interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/73ddbe24-a1f9-4d42-ba09-ecdc288c3044.png)'
  prefs: []
  type: TYPE_IMG
- en: The important details here are that its Texture source has been set to our media
    texture, and its Sampler Type has been set to `External`. This is what will allow
    it to display our media in real time. We're going to do more work with this material
    shortly, but for now you can close it.
  prefs: []
  type: TYPE_NORMAL
- en: Adding sound to our media playback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We also want to be able to play sound in our scene. Follow these steps to do
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: With our screen actor still selected, click the Add Component button in its
    details panel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add a Media Sound component and set its Media Player property to our media
    player:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c12ba22d-91c5-4783-a63f-0ab77c7b26e8.png)'
  prefs: []
  type: TYPE_IMG
- en: This Media Sound component will play whatever audio the associated media player
    is streaming. By default, it handles stereo audio, but it can be used for mono
    or surround audio sources as well.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we've set everything up and placed an object in the world with video
    material and a sound component, let's get our media player playing our test video.
  prefs: []
  type: TYPE_NORMAL
- en: Playing media
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''re going to start simply here, and just make the movie play when the level
    starts. Later on, we''re going to do more to control our media player. Follow
    these steps to get started:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on Open Level Blueprint, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d8e4fde2-2bbc-47a3-a6ff-3c58027502b9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Create a new variable and set its type to Media Player | Object Reference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/468083f7-fc09-4a90-b026-7e225176b7cf.png)'
  prefs: []
  type: TYPE_IMG
- en: Compile the blueprint and change the variable's default value from `None` to
    the media player we created a moment ago.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Ctrl* + drag the media player variable onto your event graph.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Find or create the Event BeginPlay node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag a connector from your Media Player variable and call Open Source on it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the call''s Media Source to the file media source we created from our movie:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/59ba5fd7-06e4-4ead-ae84-d1051406354f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Launch it in your VR Preview, and let''s see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5a021a75-c653-4784-98c3-6fbf35abfc43.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Nice. The video is playing. We''ll take a moment to review what we did to set
    this up, and then we''re going to look at ways to improve it. Refer to the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d28eb0ce-ff29-45b6-b634-d735808cefdb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Media playback works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Any media you want to play in engine begins as a file in `Content/Movies`. The
    source movie isn't imported into the engine and doesn't appear in your content
    browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To access it in the engine, you create a File Media Source asset that points
    to the media file on disk.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Media is played through a Media Player object that you can control through Blueprint
    calls.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Media Texture assets sample the video from their associated Media Player. These
    are included in materials.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: MediaSound components on objects play audio from their associated Media Player.
    These are usually added to the object acting as a screen in your scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Going deeper with the playback material
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's take a look at a few things we can do with our media playback materials.
    The right choices to make here entirely depend on what effect you're trying to
    create, so we'll talk about a few things you might want to do, but you'll want
    to decide on your own whether they fit what you're going for.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing we need to talk about is how the screen responds to light. The
    material we created for our Media Texture uses the Default Lit shading model.
    What this means is that lights in the environment that fall on this material will
    affect it as they normally would. If the aesthetic effect you're going for is
    that this is a physical screen in the space, this may be exactly what you want,
    but if the purpose of your application is to show the media itself, you may not
    want any stray light falling on the screen and changing the way its colors appear
    to the viewer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at what we''re talking about. From your Modes panel, drag
    a Point Light onto the scene and put it right in front of your screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/faa3e5ea-f7e6-4759-9655-054992d80619.png)'
  prefs: []
  type: TYPE_IMG
- en: You'll see that the light creates a specular highlight on the screen, just as
    it would for any other surface in the scene. Things get worse if we turn off the
    rest of the lights in the scene. Now, parts of our screen are going dark, while
    others are obscured by the highlights from our remaining lights.
  prefs: []
  type: TYPE_NORMAL
- en: 'If this is how we want it, that''s fine, but if it isn''t, we can correct this
    by changing our material to use an unlit shading model and feeding the video signal
    into its emissive channel. Let''s give it a try:'
  prefs: []
  type: TYPE_NORMAL
- en: Open your media material.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With the output node selected, change the material''s Details | Material |
    Shading Model from Default Lit to Unlit:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/7eed7b1a-02e4-460e-914a-1344c5bfc119.png)'
  prefs: []
  type: TYPE_IMG
- en: You'll see that its Base Color input becomes disabled. *Alt* + click that input
    to disconnect your Texture Sample from it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Feed the results of your texture sample into the material's Emissive Color input
    instead.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Save the material and return to your scene. Now, because your material uses
    the Unlit model, it''s no longer affected by lights in the world. The media appears
    exactly as it does in its source:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c9999575-bdfa-40e2-b8e5-5a4a82ac8787.png)'
  prefs: []
  type: TYPE_IMG
- en: Adding additional controls to our video appearance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can also use our material graph to exercise a lot of additional control
    over how the video signal appears. Let''s take a look at this:'
  prefs: []
  type: TYPE_NORMAL
- en: Return to your material.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hold down the *S* key and click in the workspace to create a scalar parameter.
    Name it `Brightness` and set its default value to `1.0`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hold the *M* key and click to create a multiplier node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multiply your output of Texture Sample by the `Brightness` parameter you just
    made.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hold the *S* key and click to create another scalar parameter. Name this one
    `Contrast` and leave its default at `0.0`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click in the graph and create a `CheapContrast_RGB` node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the result of the Multiply node to its In (V3) input, and feed your
    `Contrast` parameter into its Contrast input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Feed the result into the material''s Emissive Color input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/66cc6e54-8343-4f89-a985-7c79bb8072b4.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, we've now created a simple material that uses two scalar parameters
    to allow our user to control the image's brightness and contrast.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a material instance from this material so that we can see the
    effect of these parameters in real time:'
  prefs: []
  type: TYPE_NORMAL
- en: Right-click your material in the Content Browser and select Material Instance
    Actions | Create Material Instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag the material instance onto your screen to assign it to the object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the material instance and try changing the `Brightness` and `Contrast`
    values you just created. (Remember that you need to check the box beside a parameter
    to enable modification.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Switch the material''s preview mesh to a cube primitive so that you can see
    what you''re doing more easily:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/5c7fa939-7659-4aea-872b-b667bf252f2c.png)'
  prefs: []
  type: TYPE_IMG
- en: There's quite a lot we can do here, and we encourage you to explore and learn
    more about what you can do.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you know the basics of playing video in Unreal Engine, let's start
    diving into some VR-specific work and learn how to display video in stereo 3D.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying stereo video
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's begin by creating another map to hold our stereo video screen. With your
    `MoviePlayback2D` scene open, hit File | Save Current As... and save the map as
    `MoviePlayback3D`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to find a stereo video file to test with. They''re out there on
    the web, but they can be challenging to find since we need to download ours. stereomaker.net
    has a few example files here: [http://stereomaker.net/sample/](http://stereomaker.net/sample/).
    Let''s pull down the Cycling in Hibaya Park video from here. We can also find
    more example files here: [http://photocreations.ca/3D/index.html](http://photocreations.ca/3D/index.html).
    Download the Bellagio Fountains, Las Vegas, Nevada 3D 2048 x 2048 clip. This will
    give us a side-by-side stereo clip and an over/under stereo clip that we can use
    for our experiments. The Hibaya clip is wrapped in an `.AVI` container, but as
    long as we''re running the clip on Windows, that will work. To run it on another
    platform, we''d have to use an application such as Adobe Media Encoder or AVC
    to convert it:'
  prefs: []
  type: TYPE_NORMAL
- en: Place each of these files in your `Content/Movies` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a File Media Source asset for each of your new video files. Again, it's
    often easier to use a name for the file media source that matches the movie clip
    on disk.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, open up your media player. You should see these new clips in its available
    file list, and you should be able to play them. You should see two frames side-by-side,
    representing the left and right stereo images (make sure you do this first test
    with a side-by-side stereo video – we''ll handle over/under later on):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0e48c311-c995-4fa1-8562-a698e39aa6d8.png)'
  prefs: []
  type: TYPE_IMG
- en: The trick now will be to interpret the side-by side or over/under images as
    stereo images and feed one frame to the left eye while we feed the other to the
    right.
  prefs: []
  type: TYPE_NORMAL
- en: We're going to handle that in our material. Specifically, what we want to do
    is modify the texture coordinates we feed to the texture's UV map.
  prefs: []
  type: TYPE_NORMAL
- en: A UV map determines the way a texture aligns itself on a mesh in a 3D space.
    By manipulating the texture coordinates we're using to apply textures in our material,
    we can choose to display only parts of the texture at a time.
  prefs: []
  type: TYPE_NORMAL
- en: Open up your media player material.
  prefs: []
  type: TYPE_NORMAL
- en: Since we want this material to be able to handle mono video sources as well,
    we're going to use a Static Switch Parameter to switch between mono and stereo
    modes. This will allow us to use this material as a master material but set up
    individual material instances that handle whatever specific settings we want.
  prefs: []
  type: TYPE_NORMAL
- en: Static Switch Parameters are valuable tools that you can use to build a lot
    of behavior into a master material, and derive material instances from it that
    handle specific cases. As an added benefit, when those materials are compiled,
    anything that's turned off by your static switches simply doesn't even compile
    into the material instance, so you get it essentially for free. What this means
    is that you can make fairly complex master materials and only pay for the parts
    you use by using static switches to turn off functionality that you're not using.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s add a switch to our material so that we can create a stereo path without
    messing up our mono display:'
  prefs: []
  type: TYPE_NORMAL
- en: Right-click in the material editing graph and create a Static Switch Parameter.
    Name it `SplitStereoMedia`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click and create a Texture Coordinate node, and feed its output into the
    switch parameter's False input. This will display in the graph as a TexCoord node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, it's time to split the image. When images are rendered to the VR headset,
    they're rendered in two separate passes, and we can use this information to determine
    which side of the image to display.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying half of the video
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To split the image, we first need to get access to the two separate axes of
    our texture coordinates so that we can manipulate them individually:'
  prefs: []
  type: TYPE_NORMAL
- en: Drag the output from the Texture Coordinate input and create a BreakOutFloat2Components
    node from it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hold down the *M* key and click to create a Multiply node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the Break node's R output to the Multiply node's A input and set its
    Const B parameter to 0.5.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an Append Vector node and connect the multiplier's output to the A input,
    and the G output from the Break node to its B input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Feed the result of the Append node into the Split Stereo Media switch's True
    input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Feed the result of the Switch node into the UVs input of Texture Sample:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/684588f3-1f2d-45fc-a84b-90d86478bb8c.png)'
  prefs: []
  type: TYPE_IMG
- en: What we've just done here is split our texture coordinates into two channels,
    labeled R and G. We then cut the R channel in half while leaving the G channel
    alone, and then reassembled the vector and told our texture sample to use the
    result to map the image to the object it's applied to.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s test this to see what it does:'
  prefs: []
  type: TYPE_NORMAL
- en: Open your scene's Level Blueprint. It should still contain the Open Source call
    to the Media Player.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Switch its Media Source to your side-by-side video. Since we need a place to
    set our Static Switch parameter, we need a new material instance to display our
    side-by-side image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Duplicate the material instance we made a moment ago when we adjusted our contrast
    and brightness.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name this one `MI_MediaPlayer_SBS` or something similar to remind us that it's
    intended to display side-by-side stereo media.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open it up and set its SplitStereoMedia switch parameter to true.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign it to your screen object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test it out. You should now see only the video's left frame displayed on the
    screen. You won't see any stereo depth yet since we're still displaying the same
    image to each eye.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying a different half of the video to each eye
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s get the right frame to display in the right eye:'
  prefs: []
  type: TYPE_NORMAL
- en: Return to your material.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click in the material graph and create a Custom node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In its Code property, enter the following: `return ResolvedView.StereoPassIndex;`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set its Output Type to CMOT Float 1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set its Description to StereoPassIndex.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This creates a Material Expression Custom node that will return a `0` when we're
    rendering the left eye, and a `1` when we're rendering the right eye. We can use
    this information to choose which half of the frame we display for each eye.
  prefs: []
  type: TYPE_NORMAL
- en: Hold down the *M* key and click to create a Multiply node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Pass the output from StereoPassIndex into its A input, and set its Const B
    parameter to 0.5:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/2596c43f-929c-4ed5-ae88-8240fa87646d.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, hold down the *A* key and click to create an Add node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Feed the result of the multiplied R channel from the texture coordinates into
    its A input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Feed the result of the multiplied stereo pass index into its B input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Feed the result of the Add node into the Append node''s A input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fce2da5c-8bf6-4b1e-9a47-d968fa3a534b.png)'
  prefs: []
  type: TYPE_IMG
- en: Test it again. You should now see stereo depth in the video image when you view
    it in your VR headset.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a moment to make sense of what we just created here.
  prefs: []
  type: TYPE_NORMAL
- en: When we break our texture coordinates and modify the R value, we're modifying
    the horizontal axis of the texture mapping. By multiplying it by 0.5, we're splashing
    half of the texture over the entire surface of the mesh. The Stereo Pass Index
    node we made returns a value of 0 for the left stereo pass, and 1 for the right
    stereo pass, so when we multiply this value by 0.5, we get either a 0 for the
    left eye or an 0.5 for the right eye. When we then add this value to our texture
    coordinate's R component, we're offsetting it by half its width. So, when the
    left eye is rendered, it simply divides the texture space in half, and when the
    right eye is rendered, it divides it in half and offsets it by half, displaying
    the right frame. This is how we're getting our stereo image.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying over/under stereo video
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Modifying our material to handle over/under stereo video is fairly easy. We
    just need to do our operation on the G channel instead of the R channel. Follow
    these steps to get started:'
  prefs: []
  type: TYPE_NORMAL
- en: Reopen your media player material.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new Static Switch Parameter node. Name it `OverUnderStereo`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Ctrl* + drag the SplitStereoMedia switch''s True input to move it into the
    OverUnderStereo switch''s False input.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Connect the output from the OverUnderStereo switch to the SplitStereoMedia
    switch''s True input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/ae258fcc-2219-420b-86fd-ee22c072de84.png)'
  prefs: []
  type: TYPE_IMG
- en: If OverUnderStereo is set to False, our material continues to use the side-by-side
    split we set up a moment ago. Now, let's set up its behavior when this is set
    to True.
  prefs: []
  type: TYPE_NORMAL
- en: Select the chain of nodes that includes the BreakOutFloat2Components node, all
    the way to the Append node, and hit *Ctrl + W* to duplicate them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the R output from the BreakOut node directly to the Append node's A
    input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the G output from the BreakOut node to the Multiply node's A input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the output from the Add node to the Append node's B input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We've just swapped things, so we're now performing the same operation on the
    vertical axis as we'd previously performed on the horizontal axis.
  prefs: []
  type: TYPE_NORMAL
- en: Feed the output of the Multiply node from your Stereo Pass Index into the new
    Add node's B input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Feed the Texture Coordinates into your BreakOut node's input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Feed the output of the Append node into your OverUnderStereo switch''s True
    input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fbdb464b-83a9-424e-b7a5-83b53a64338f.png)'
  prefs: []
  type: TYPE_IMG
- en: This material can now handle mono, side-by-side stereo, and over/under stereo
    sources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s test this out:'
  prefs: []
  type: TYPE_NORMAL
- en: Close your material and in your Content Browser, duplicate one of the material
    instances you've already made from it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure that its SplitStereoMedia parameter is set to True, and set its OverUnderStereo
    parameter to True.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assign it to your screen object in your scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open your scene's Level Blueprint and switch the Media Source on your Open Source
    node to your over/under stereo video.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch it into VR preview mode. We should now see our over/under stereo video
    playing correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying 360 degree spherical media in VR
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we've done a decent job of reproducing 2D and 3D traditional screens
    in VR, but let's take things a step further and do something we can't easily do
    in the outside world. One of the most compelling and common uses of VR is to display immersive
    360 degree video that surrounds the viewer. Even in mono, this can create a fairly
    deep sense of presence in users, and can be produced fairly easily using an ordinary
    camera and stitching software, or a dedicated camera that's been purpose-built
    to create spherical images.
  prefs: []
  type: TYPE_NORMAL
- en: Displaying spherical media, for the most part, works exactly as it does on the
    flat screen, but of course we'll need new geometry for our screen.
  prefs: []
  type: TYPE_NORMAL
- en: Finding 360 degree video
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, let's find a video to play. A few good options live here: [https://www.mettle.com/360vr-master-series-free-360-downloads-page/](https://www.mettle.com/360vr-master-series-free-360-downloads-page/).
  prefs: []
  type: TYPE_NORMAL
- en: 'The Crystal Shower Falls link takes us to a Vimeo page that allows us to download
    the video. For our test here, the 1080p version should be fine:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the video and place it in your `Content/Movies` directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a File Media Source for your video.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Check it in your Media Player to be sure it plays.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, we need an environment to display it.
  prefs: []
  type: TYPE_NORMAL
- en: Create a new empty level and name it `MoviePlayback2DSpherical` (or anything
    you like, really – it's your map).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating a spherical movie screen
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, we''re going to take an ordinary sphere and modify it to flip its normals
    inward so that we can see our material while we''re inside the sphere:'
  prefs: []
  type: TYPE_NORMAL
- en: From your Modes panel, grab a Basic | Sphere actor and place it in your scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Look at its Details panel, and under Static Mesh, hit the Browse to Asset button
    (the magnifier) to navigate the Content Browser to the sphere's static mesh. We're
    going to make a copy of it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag the Sphere static mesh from `Engine Content/BasicShapes` into your project's
    `Content` directory (`Content/Chapter08/Environments` would be a good choice).
    Select Copy Here to make a copy of the sphere.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Rename it `MovieSphere`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open it up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From your Static Mesh editor, select the Mesh Editing tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Activate Edit Mode by hitting the toolbar button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag to select all of the mesh's faces.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Hit the Flip button to invert their normals:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d056a7ea-49e4-488a-acb6-db04d862e487.png)'
  prefs: []
  type: TYPE_IMG
- en: Save it and close the Static Mesh editor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Place an instance of your MovieSphere mesh in your level and delete the old
    Sphere.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set its Location to (X=0.0, Y=0.0, Z=0.0) and its Scale to (X=200.0, Y=200.0,
    Z=200.0).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With the MovieSphere selected, set its Materials_Element 0 to your MI_MediaPlayer_Mono
    material instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hit Add Component, add a MediaSound component, and set its associated Media
    Player to your media player.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, just as we did with our previous scenes, we need to tell the media player
    to load our media.
  prefs: []
  type: TYPE_NORMAL
- en: In your map's Level Blueprint, create a variable named `MediaPlayer`, set its
    Type to Media Player | Object Reference, compile it, and set its Default Value
    to your Media Player.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Call Open Source on your Media Player variable with your new 360 video as its
    Media Source.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Execute this call from your Event BeginPlay.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test your scene. You should now see the movie playing all around you.
  prefs: []
  type: TYPE_NORMAL
- en: Playing stereoscopic 360 degree video
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we're going to do the same thing for stereoscopic 360 degree video. At
    the time of writing, stereoscopic 360 degree video is much less common than its
    2D counterpart, in part because it consumes so much more disk space, and also
    because it's significantly more difficult to produce, but it's reasonable to expect
    that things will continue to evolve.
  prefs: []
  type: TYPE_NORMAL
- en: In the meantime, we can find a viable test file here: [https://www.dareful.com/products/free-virtual-reality-video-sequoia-national-park-vr-360-stereoscopic](https://www.dareful.com/products/free-virtual-reality-video-sequoia-national-park-vr-360-stereoscopic).
  prefs: []
  type: TYPE_NORMAL
- en: As always, download the file, put it in your Content/Movies directory, create
    a File Media Source asset that points to it, and test it in your Media Player
    to ensure that it plays on your system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s make a copy of our 2D spherical test map to use for our 3D test:'
  prefs: []
  type: TYPE_NORMAL
- en: Take the MoviePlayback2DSpherical map and hit File | Save Current As... to MoviePlayback3DSpherical.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the MovieSphere asset and change its assigned material to your OverUnder
    material instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the level blueprint and change the Open Source node to point to our new
    file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s test it. We have spherical 3D, but our stereo is flipped (on this file,
    at least). Everything that should be close looks far away. We can correct this
    by adding another option to our master material:'
  prefs: []
  type: TYPE_NORMAL
- en: Open your media master material.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add a new Static Switch Parameter and name it FlipStereo.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag the output from your StereoPassIndex node into the FlipStereo switch's
    False input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a OneMinus node, drag the output from StereoPassIndex into its input,
    and connect its output to the FlipStereo switch's True input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Connect the FlipStereo switch''s output to the Multiply node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4bd3f97c-6e26-415d-bda0-0ec5f83a9b2e.png)'
  prefs: []
  type: TYPE_IMG
- en: What we've done here is simply set up an option so that if FlipStereo is true,
    we'll receive a 1 for the left eye and a 0 for the right eye instead of the other
    way around.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create another material instance to hold this option setting and
    apply it to our sphere:'
  prefs: []
  type: TYPE_NORMAL
- en: Duplicate your OverUnder material instance and name it something like MI_MediaPlayer_OverUnderFlipped.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open up the new material instance and set its FlipStereo parameter to True.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Apply it to your movie sphere:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/09007cba-e69e-45a0-9d28-24d8666e51de.png)'
  prefs: []
  type: TYPE_IMG
- en: Test the map – you should now be seeing the stereo imagery sorted correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Spend some time looking around. This video runs at a fairly high bitrate, so
    you may experience occasional frame drops and there are a few perspective glitches,
    but the stereo effect is pretty compelling. It's clear that we're going to be
    able to do some astonishing work as this tech evolves.
  prefs: []
  type: TYPE_NORMAL
- en: Controlling your Media Player
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we wrap things up for this chapter, let's give our players a few ways
    to control their Media Player.
  prefs: []
  type: TYPE_NORMAL
- en: We could do this work from within the level blueprint, and that's what we've
    been doing so far, but that's not an ideal solution if we're going to have multiple
    maps in our project. We're going to wind up copying and pasting Blueprint code
    from one level to another, and if we update one of them, we have to remember to
    update the rest. This is bad practice.
  prefs: []
  type: TYPE_NORMAL
- en: A much better idea is to create a manager actor that contains all the code we
    need to manage our media player, and that we can just drop into any level that
    needs to support it. This way, we're writing our code once, and as we update it,
    the effects are seen everywhere. Let's do this.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Media Manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s create a new Blueprints subdirectory inside our project''s content directory:'
  prefs: []
  type: TYPE_NORMAL
- en: Right-click inside it and select Create Basic Asset | Blueprint Class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For its Parent Class, select Actor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name it `BP_MediaManager`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Up until this point, we''ve been using our level blueprints to open media on
    our media player. We''re going to move that functionality into our media manager
    first:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up BP_MediaManager.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a new variable named `MediaPlayer` and set its Type to Media Player |
    Object Reference.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compile it and set its default value to your media player.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create another new variable named `FileMediaSource` and set its Type to File
    Media Source | Object Reference.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set Instance Editable to True for this variable since we're going to need to
    set different values on it for each map.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set its Category to Config so that it's clear to the user that they have to
    edit this value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now that we''ve set up our variables, let''s use this actor''s BeginPlay to
    load our media. To start with, we''re just going to recreate what we''ve already
    been doing in our level Blueprints:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the Event Graph of BP_MediaManager.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Ctrl* + drag the MediaPlayer variable onto the graph.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Call Open Source on it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Ctrl* + drag your File Media Source variable onto the graph.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click it and select Convert to Validated Get. (We don't want to try and
    open a file media source if we haven't set it yet.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag the execution line from Event BeginPlay into your File Media Source Get.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag the getter's Is Valid execution line into your Open Source call's execution
    input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag the output of GET into your Open Source call's Media Source input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click and create a Print String node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set its In String value to Media Manager's file media source is not set!.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Drag the Is Not Valid execution line of GET to the Print String we just created:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0bba401a-4b4a-45da-8506-da227ef389cf.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, if we place this actor in any level and set its File Media Source, it will
    start playing that source on the project's Media Player. If there's an object
    in that level with a material reading a Media Texture that points to this media
    player, whatever we're playing will show up there.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever you set up a system that could fail if the developer or user fails
    to do something, as is the case here with our File Media Source variable, get
    in the habit of using validated gets and printing out warnings if the get fails.
    You'll save yourself a lot of debugging time if you train yourself to write code
    that tells you on its own when something is wrong.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s put a Media Manager in our current level and replace the work we''re
    doing in the Level Blueprint:'
  prefs: []
  type: TYPE_NORMAL
- en: Drag an instance of BP_MediaManager into your scene and zero out its Location.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set its Config | File Media Source to whichever media source you were previously
    playing in the scene.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open the scene's Level Blueprint and delete the code we previously put there
    on BeginPlay.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test the scene. The media should still play, but now the Media Manager is handling
    opening the source.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat this for your other test levels so that they're all using the Media Manager
    blueprint.
  prefs: []
  type: TYPE_NORMAL
- en: Now that each of our levels is using an instance of our Media Manager class
    to operate the Media Player, we can much more easily add functionality that will
    apply everywhere.
  prefs: []
  type: TYPE_NORMAL
- en: Let's do this now.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Pause and Resume function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s give our users a way to pause and play the video:'
  prefs: []
  type: TYPE_NORMAL
- en: Open BP_MediaManager.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In its Details panel, set Input | Auto Receive Input to Player 0 and Block Input
    to True.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click in its Event Graph and select Input | Keyboard Events | Space Bar
    to create a new keyboard event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Right-click again and select Input | Gamepad Events | MotionController (R) Trigger
    to create another input event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Ctrl* + drag your media player variable onto your graph.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag its output and create an Is Playing node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect a Branch node to the Is Playing node's result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect the Pressed execution line of Space Bar to the Branch node's execution
    input. Do the same for the Trigger input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag another connector from your Media Player variable and create a Pause node
    for it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect your Branch node's True execution line to the Pause node's execution
    input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag another connector from the Media Player variable (or create a reroute node
    and branch from it) and create a Play call.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Connect the Branch node''s False execution line to the Play node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/27992c6b-7ab6-4256-a16e-75d420392544.png)'
  prefs: []
  type: TYPE_IMG
- en: We've done a few things here that are worth talking about.
  prefs: []
  type: TYPE_NORMAL
- en: First, we're using a different means of capturing keyboard and motion controller
    input than we previously have. For everything we've done up until now, we've relied
    on the Project Settings and the `DefaultInput.ini` file to capture input from
    our hardware devices and remap it to named input events. In truth, this remains
    a better way to do it, but we wanted to show you another way it could be done.
    Very often, it can make sense to prototype your systems using input events mapped
    directly in your Blueprints like this one, and then once you've got your systems
    worked out, move them into your Project Settings so it's easier to remap them
    for different controllers.
  prefs: []
  type: TYPE_NORMAL
- en: It's important to note as well that this object is only able to hear input because
    we set its Auto Receive Input. Otherwise, it won't listen for input from other
    devices by default.
  prefs: []
  type: TYPE_NORMAL
- en: What we're doing here is querying the Media Player to see whether it's playing
    anything at present, pausing it if it is, and playing it if it isn't.
  prefs: []
  type: TYPE_NORMAL
- en: While we're not going to cover it here because it would become a project on
    its own, if you wanted to create a button-based user interface and use a widget
    interaction component to allow the user to interact with the controls, you could
    do so by having this Media Manager object own the interface and using the button
    events to manage the media player's behavior.
  prefs: []
  type: TYPE_NORMAL
- en: This is a fairly simple example, but it demonstrates a few ways you can interact
    with a media player. You can query its status, control playback, open new media,
    and even assign events to it so that it responds when it finishes loading media.
  prefs: []
  type: TYPE_NORMAL
- en: Assigning events to a media player
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's demonstrate a way we can use an event on our media player. We're going
    to turn off our Media Player's Play on Open setting, and instead have our Media
    Manager play a file once it's finished opening. This is an important pattern to
    learn because large media files won't be ready to play immediately after you call
    Open Source. Depending on how big they are and how fast the hard drive they're
    stored on is, they're going to take a moment to open, so it's good practice after
    you open a file to instruct your media player to listen for when the file finishes
    loading, and to start playing it then.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the Play on Open setting already does this, but it's valuable for
    you to learn about this pattern so that you can use it when you need to do something
    more complex with your media player.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s set it up:'
  prefs: []
  type: TYPE_NORMAL
- en: Open your media player asset and turn off its Play on Open setting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you test one of your maps now, you'll see that the media no longer plays
    until you tap the *spacebar* or pull the trigger to start it.
  prefs: []
  type: TYPE_NORMAL
- en: Open BP_MediaManager and find the Open Source call you're making on Event BeginPlay.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Connect a Branch node to its Return Value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Open Source call is going to return True if it found the file to open and
    is will opening it, and False if it couldn't. We only want our Media Player to
    wait for the file to open if we know it's actually opening it.
  prefs: []
  type: TYPE_NORMAL
- en: Drag a connector from your Media Player variable and select Media | Media Player
    | Bind Event to OnMediaOpened.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag a connector from the Bind node's Event input and select Add Event | Add
    Custom Event.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Name it `MediaOpened`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Drag a connector from your Media Player variable and call Play on it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Connect the execution output from your custom event to the Play call''s input:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/6fe223d6-2bfa-4190-a586-caea4c58c79f.png)'
  prefs: []
  type: TYPE_IMG
- en: Test it. Your media should play when it finishes opening. In practice, it will
    behave exactly as it did when Play on Open was still true, but there's some important
    stuff to talk about here.
  prefs: []
  type: TYPE_NORMAL
- en: Most function calls will continue their execution only when they've finished
    whatever job it was they were supposed to do. Open Source is a little different.
    This is what's known as an **Async Task**. When you call Open Source, the execution
    will continue immediately, but the task itself will take an indeterminate amount
    of time to finish. You'll run into this a lot when opening large files, accessing
    URLs on the web, or doing any other task where you really don't know when you
    begin how long it's actually going to take. An **asynchronous** (**Async**) task
    starts up when you call it, and then finishes at some point in the future. The
    object that you call an Async task on is pretty much always going to have some
    sort of event it throws when the task finishes so that you can do whatever you
    need to do when it's done.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of the Open Source task on a Media Player object, the OnMediaOpened
    event is called when the source finishes opening. By binding a custom event to
    this event, we're telling it to trigger that event in our blueprint when the media
    finishes opening, and call the `Play` method on the media player when this happens.
  prefs: []
  type: TYPE_NORMAL
- en: When creating custom events for bindings, it's a good idea to create them by
    dragging out the event connector and creating the custom event from there, as
    we did in this example. This is because many bindings will require that their
    bound events include certain inputs (this is called a signature), and if you just
    create a basic custom event that doesn't match the required signature, it won't
    let you bind it. If you create your custom events directly from the event connector,
    it will automatically set up the correct signature for you. In this case, the
    bound event for OnMediaOpened is required to pass an Opened URL argument.
  prefs: []
  type: TYPE_NORMAL
- en: This is an important pattern and it's worth learning. Video files are big, and
    sometimes operations on them are going to take time. Get to know the events you
    can bind on your media player objects, and make sure you're doing whatever it
    is you're trying to do once you know the job has finished and succeeded.
  prefs: []
  type: TYPE_NORMAL
- en: You will, at some point in your travels, come across a developer who handles
    asynchronous tasks by putting delays into their blueprints. They will discover
    through trial and error that the call they're trying to make works if they delay
    it and fails if they try to do it immediately, so they just stick a delay on there
    with some random duration and call the bug fixed. You, however, are not going
    to do this. It's amateur hour stuff, and will just fail later on if they try to
    open a larger file or something else changes. The correct way to deal with async
    tasks is always to find out what event gets called when they finish, and then
    bind whatever else you need to do to that event. Never use a delay to solve a
    problem unless you can describe in positive terms why you know the delay is the
    correct solution. The correct solution is almost always a bound event that will
    work no matter how long the task takes.
  prefs: []
  type: TYPE_NORMAL
- en: You've now seen examples of each of the ways you can interact with a media player
    object. We've polled its status, made calls to it, and bound additional code to
    its events so that we can respond when the media player tells us something has
    happened. There's more you can do with media players, and we encourage you to
    play with this. Try binding an event to its OnEndReached, or some other bindable
    event. Try using Get Time and Duration calls on the Media Player to create a progress
    bar. There's a lot you can do with this.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned a lot about how video files play in Unreal Engine.
    We learned a bit about containers and codecs and how to understand what a video
    file contains, and then we learned a variety of ways to play them back, both on
    flat screens and on spheres. We learned how we can create materials to display
    3D video as well as 2D, and learned how to create a media manager class to manage
    their playback.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we're going to learn about how multiplayer networking works
    in Unreal.
  prefs: []
  type: TYPE_NORMAL
