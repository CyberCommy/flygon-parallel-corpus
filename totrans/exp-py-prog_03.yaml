- en: Chapter 3. Syntax Best Practices – above the Class Level
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will now focus on syntax best practices for classes. It is not intended to
    cover design patterns here, as they will be discussed in [Chapter 14](ch14.html
    "Chapter 14. Useful Design Patterns"), *Useful Design Patterns*. This chapter
    gives an overview of the advanced Python syntax to manipulate and enhance the
    class code.
  prefs: []
  type: TYPE_NORMAL
- en: Object model evolved greatly during history of Python 2\. For a long time we
    lived in a world where two implementations of the object-oriented programming
    paradigm coexisted in the same language. These two models were simply referred
    to as *old-style* and *new-style* classes. Python 3 ended this dichotomy and only
    model known as *new-style* classes is available to the developers. Anyway, it
    is still important to know how both of them worked in Python 2 because it will
    help you in porting old code and writing backwards compatible applications. Knowing
    how the object model changed will also help you in understanding why it is designed
    that way right now. This is the reason why the following chapter will have a relatively
    large number of notes about old Python 2 features despite this book targets the
    latest Python 3 releases.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be discussed in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Subclassing built-in types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accessing methods from super classes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using properties and slots
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metaprogramming
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subclassing built-in types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Subclassing built-in types in Python is pretty straightforward. A built-in type
    called `object` is a common ancestor for all built-in types as well as all user-defined
    classes that have no explicit parent class specified. Thanks to this, every time
    a class that behaves almost like one of the built-in types needs to be implemented,
    the best practice is to subtype it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will show you the code for a class called `distinctdict`, which uses
    this technique. It is a subclass of the usual Python `dict` type. This new class
    behaves in most ways like an ordinary Python `dict`. But instead of allowing multiple
    keys with the same value, when someone tries to add a new entry with an identical
    value, it raises a `ValueError` subclass with a help message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is an example of using `distictdict` in interactive session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you take a look at your existing code, you may find a lot of classes that
    partially implement the built-in types, and could be faster and cleaner as subtypes.
    The `list` type, for instance, manages the sequences and could be used every time
    a class works internally with a sequence:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an example usage in interactive session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Built-in types cover most use cases**'
  prefs: []
  type: TYPE_NORMAL
- en: When you are about to create a new class that acts like a sequence or a mapping,
    think about its features and look over the existing built-in types. The `collections`
    module extends basic built-in types with many useful containers. You will end
    up using one of them most of the time.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing methods from superclasses
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`super` is a built-in class that can be used to access an attribute belonging
    to an object''s superclass.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Python official documentation lists `super` as a built-in function. But
    it''s a built-in class, even if it is used like a function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Its usage is a bit confusing when you are used to accessing a class attribute
    or method by calling the parent class directly and passing `self` as the first
    argument. This is really old pattern but still can be found in some codebases
    (especially in legacy projects). See the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'When run in an interpreter session it gives following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Look particularly at the line `Mama.says(self)`, where we use the technique
    just described to call the `says()` method of the superclass (that is, the `Mama`
    class), and pass `self` as the argument. This means, the `says()` method belonging
    to `Mama` will be called. But the instance on which it will be called is provided
    as the `self` argument, which is an instance of `Sister` in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, the `super` usage would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can also use the shorter form of the `super()` call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The shorter form of `super` (without passing any arguments) is allowed inside
    the methods but `super` is not limited to methods. It can be used in any place
    of code where a call to the given instance superclass method implementation is
    required. Still, if `super` is not used inside the method, then its arguments
    are mandatory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The last and most important thing that should be noted about `super` is that
    its second argument is optional. When only the first argument is provided, then
    `super` returns an unbounded type. This is especially useful when working with
    `classmethod`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note that the zero-argument `super()` form is also allowed for methods decorated
    with the `classmethod` decorator. `super()` called without arguments in such a
    method is treated as having only the first argument defined.
  prefs: []
  type: TYPE_NORMAL
- en: The use cases presented earlier are very simple to follow and understand, but
    when you face a multiple inheritance schema, it becomes hard to use `super`. Before
    explaining these problems, understanding when `super` should be avoided and how
    the **Method Resolution** **Order** (**MRO**) works in Python is important.
  prefs: []
  type: TYPE_NORMAL
- en: Old-style classes and super in Python 2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`super()` in Python 2 works almost exactly the same. The only difference in
    call signature is that the shorter, zero-argument form is not available, so at
    least one of the expected arguments must be provided always.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important thing for programmers who want to write cross-version compatible
    code is that `super` in Python 2 works only for new-style classes. The earlier
    versions of Python did not have a common ancestor for all classes in the form
    of `object`. The old behavior was left in every Python 2.x branch release for
    backwards compatibility, so in those versions, if the class definition has no
    ancestor specified, it is interpreted as an old-style class and it cannot use
    `super`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The new-style class in Python 2 must explicitly inherit from the object or
    other new-style class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Python 3 no longer maintains the concept of old-style classes, so any class
    that does not inherit from any other class implicitly inherits from `object`.
    This means that explicitly stating that a class inherits from `object` may seem
    redundant. The general good practice is to not include redundant code, but removing
    such redundancy in this case is a good approach only for projects that no longer
    target any of the Python 2 versions. Code that aims for cross-version compatibility
    of Python must always include `object` as an ancestor of base classes even if
    this is redundant in Python 3\. Not doing so will result in such classes being
    interpreted as old style, and this will eventually lead to issues that are very
    hard to diagnose.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Python's Method Resolution Order
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python's Method Resolution Order is based on **C3**, the MRO built for the Dylan
    programming language ([http://opendylan.org](http://opendylan.org)). The reference
    document, written by Michele Simionato, is located at [http://www.python.org/download/releases/2.3/mro](http://www.python.org/download/releases/2.3/mro).
    It describes how C3 builds the **linearization** of a class, also called **precedence**,
    which is an ordered list of the ancestors. This list is used to seek an attribute.
    The C3 algorithm is described in more detail later in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The MRO change was made to resolve an issue introduced with the creation of
    a common base type (`object`). Before the change to the C3 linearization method,
    if a class had two ancestors (refer to *Figure 1*), the order in which methods
    were resolved was quite simple to compute and track for simple cases that do not
    use the multiple inheritance model. Here is an example of code that under Python
    2 would not use C3 as a Method Resolution Order:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The following transcript from interactive session shows this method resolution
    at work:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'When `MyClass().method()` is called, the interpreter looks for the method in
    `MyClass`, then `Base1`, and then eventually finds it in `Base2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding Python''s Method Resolution Order](graphics/5295_03_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1 Classical hierarchy
  prefs: []
  type: TYPE_NORMAL
- en: When we introduce some `CommonBase` class on top of the two base classes (both
    `Base1` and `Base2` inherit from it, refer to *Figure 2*), things get more complicated.
    As a result, the simple resolution order that behaves according to the *left to
    right depth first* rule is getting back to the top through the `Base1` class before
    looking into the `Base2` class. This algorithm results in a counterintuitive output.
    In some cases, the method that is executed may not be the one that is the closest
    in the inheritance tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Such an algorithm is still available in Python 2 when old-style classes (not
    inheriting from `object`) are used. Here is an example of the old method resolution
    in Python 2 using old-style classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The following transcript from interactive session shows that `Base2.method()`
    will not be called despite `Base2` is closer in the class hierarchy than `CommonBase`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![Understanding Python''s Method Resolution Order](graphics/5295_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2 The Diamond class hierarchy
  prefs: []
  type: TYPE_NORMAL
- en: Such an inheritance scenario is extremely uncommon, so this is more a problem
    of theory than practice. The standard library does not structure the inheritance
    hierarchies in this way, and many developers think it is a bad practice. But with
    the introduction of `object` at the top of the types hierarchy, the multiple inheritance
    problem pops up on the C side of the language, resulting in conflicts when doing
    subtyping. Note also that every class in Python 3 has now the same common ancestor.
    Since making it work properly with the existing MRO involved too much work, a
    new MRO was a simpler and quicker solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, the same example run under Python 3 gives a different result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is usage showing that C3 serialization will pick method of the closest
    ancestor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Note that the above behavior cannot be replicated in Python 2 without the `CommonBase`
    class explicitly inheriting from `object`. The reasons why it may be useful to
    specify `object` as a class ancestor in Python 3 even if this is redundant were
    mentioned in the previous section, *Old-style classes and super in Python 2*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Python MRO is based on a recursive call over the base classes. To summarize
    the Michele Simionato paper referenced at the beginning of this section, the C3
    symbolic notation applied to our example is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Here, `L[MyClass]` is the linearization of the `MyClass` class, and `merge`
    is a specific algorithm that merges several linearization results.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, a synthetic description would be, as Simionato says:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"The linearization of C is the sum of C plus the merge of the linearizations
    of the parents and the list of the parents"*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The `merge` algorithm is responsible for removing the duplicates and preserving
    the correct ordering. It is described in the paper like this (adapted to our example):'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Take the head of the first list, that is, L[Base1][0]; if this head is not
    in the tail of any of the other lists, then add it to the linearization of MyClass
    and remove it from the lists in the merge, otherwise look at the head of the next
    list and take it, if it is a good head.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '>'
  prefs: []
  type: TYPE_NORMAL
- en: '*Then, repeat the operation until all the classes are removed or it is impossible
    to find good heads. In this case, it is impossible to construct the merge, Python
    2.3 will refuse to create the class MyClass and will raise an exception."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The `head` is the first element of a list and the `tail` contains the rest of
    the elements. For example, in `(Base1, Base2, ..., BaseN), Base1` is the `head`,
    and `(Base2, ..., BaseN)` the `tail`.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, C3 does a recursive depth lookup on each parent to get a sequence
    of lists. Then it computes a left-to-right rule to merge all lists with a hierarchy
    disambiguation, when a class is involved in several lists.
  prefs: []
  type: TYPE_NORMAL
- en: 'So the result is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `__mro__` attribute of a class (which is read-only) stores the result of
    the linearization computation, which is done when the class definition is loaded.
  prefs: []
  type: TYPE_NORMAL
- en: You can also call `MyClass.mro()` to compute and get the result. This is another
    reason why classes in Python 2 should be taken with extra case. While old-style
    classes in Python 2 have a defined order in which methods are resolved, they do
    not provide the `__mro__` attribute and the `mro()` method. So, despite the order
    of resolution, it is wrong to say that they have MRO. In most cases, whenever
    someone refers to MRO in Python, it means that they refer to the C3 algorithm
    described in this section.
  prefs: []
  type: TYPE_NORMAL
- en: super pitfalls
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Back to `super`. Its usage, when using the multiple inheritance hierarchy, can
    be quite dangerous, mainly because of the initialization of classes. In Python,
    the base classes are not implicitly called in `__init__()`, and so it is up to
    the developer to call them. We will see a few examples.
  prefs: []
  type: TYPE_NORMAL
- en: Mixing super and explicit class calls
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the following example taken from James Knight''s website ([http://fuhm.net/super-harmful](http://fuhm.net/super-harmful)),
    a `C` class that calls its base classes using the `__init__()` method will make
    the `B` class be called twice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This happens due to the `A.__init__(self)` call, which is made with the `C`
    instance, thus making the `super(A, self).__init__()` call the `B.__init__()`
    method. In other words, `super` should be used in the whole class hierarchy. The
    problem is that sometimes a part of this hierarchy is located in third-party code.
    Many related pitfalls on the hierarchy calls introduced by multiple inheritances
    can be found on James's page.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, you cannot be sure that external packages use `super()` in their
    code. Whenever you need to subclass some third-party class, it is always a good
    approach to take a look inside of its code and code of other classes in the MRO.
    This may be tedious, but as a bonus you get some information about the quality
    of code provided by such a package and more understanding of its implementation.
    You may learn something new that way.
  prefs: []
  type: TYPE_NORMAL
- en: Heterogeneous arguments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another issue with `super` usage is the argument passing in initialization.
    How can a class call its base class `__init__()` code if it doesn''t have the
    same signature? This leads to the following problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'An attempt to create a `MyClass` instance will raise `TypeError` due to the
    mismatch of the parent classes'' `__init__()` signatures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'One solution would be to use arguments and keyword arguments packed with `*args`
    and `**kwargs` magic so that all constructors pass along all the parameters even
    if they do not use them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'With this approach the parent class signatures will always match:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: This is an awful fix though, because it makes all constructors accept any kind
    of parameter. It leads to weak code, since anything can be passed and gone through.
    Another solution is to use the explicit `__init__()` calls of specific classes
    in `MyClass`, but this would lead to the first pitfall.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To avoid all the mentioned problems, and until Python evolves in this field,
    we need to take into consideration the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multiple inheritance should be avoided**: It can be replaced with some design
    patterns presented in [Chapter 14](ch14.html "Chapter 14. Useful Design Patterns"),
    *Useful Design Patterns*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**super usage has to be consistent**: In a class hierarchy, `super` should
    be used everywhere or nowhere. Mixing `super` and classic calls is a confusing
    practice. People tend to avoid `super`, for their code to be more explicit.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explicitly inherit from object in Python 3 if you target Python 2 too**:
    Classes without any ancestor specified are recognized as old-style classes in
    Python 2\. Mixing old-style classes with new-style classes should be avoided in
    Python 2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Class hierarchy has to** **be looked over when a parent class is called**:
    To avoid any problems, every time a parent class is called, a quick glance at
    the involved MRO (with `__mro__`) has to be done.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Advanced attribute access patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When many C++ and Java programmers first learn Python, they are surprised by
    Python''s lack of a `private` keyword. The nearest concept is *name mangling*.
    Every time an attribute is prefixed by `__`, it is renamed by the interpreter
    on the fly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Accessing the `__secret_value` attribute by its initial name will raise an
    `AttributeError` exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This feature is provided to avoid name collision under inheritance, as the attribute
    is renamed with the class name as a prefix. It is not a real lock, since the attribute
    can be accessed through its composed name. This feature could be used to protect
    the access of some attributes, but in practice, `__` should never be used. When
    an attribute is not public, the convention to use is a `_` prefix. This does not
    call any mangling algorithm, but just documents the attribute as a private element
    of the class and is the prevailing style.
  prefs: []
  type: TYPE_NORMAL
- en: Other mechanisms are available in Python to build the public part of the class
    together with the private code. The descriptors and properties that are the key
    features to OOP design should be used to design a clean API.
  prefs: []
  type: TYPE_NORMAL
- en: Descriptors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A descriptor lets you customize what should be done when you refer to an attribute
    on an object.
  prefs: []
  type: TYPE_NORMAL
- en: Descriptors are the base of a complex attribute access in Python. They are used
    internally to implement properties, methods, class methods, static methods, and
    the `super` type. They are classes that define how attributes of another class
    can be accessed. In other words, a class can delegate the management of an attribute
    to another one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The descriptor classes are based on three special methods that form the **descriptor
    protocol**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`__set__(self, obj, type=None)`: This is called whenever the attribute is set.
    In the following examples, we will refer to this as a **setter**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__get__(self, obj, value)`: This is called whenever the attribute is read
    (referred to as a **getter**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__delete__(self, obj)`: This is called when `del` is invoked on the attribute.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A descriptor that implements `__get__()` and `__set__()` is called a **data
    descriptor**. If it just implements `__get__()`, then it is called a **non-data
    descriptor**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Methods of this protocol are in fact called by the object''s special `__getattribute__()`
    method (do not confuse it with `__getattr__()`, which has a different purpose)
    on every attribute lookup. Whenever such a lookup is performed, either by using
    dotted notation in the form of `instance.attribute` or by using the `getattr(instance,
    ''attribute'')` function call, the `__getattribute__()` method is implicitly invoked
    and it looks for an attribute in the following order:'
  prefs: []
  type: TYPE_NORMAL
- en: It verifies if the attribute is a data descriptor on the class object of the
    instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If not, it looks to see if the attribute can be found in the `__dict__` of the
    instance object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, it looks to see if the attribute is a non-data descriptor on the class
    object of the instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In other words, data descriptors take precedence over `__dict__` lookup and
    `__dict__` lookup takes precedence over non-data descriptors.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make it more clear, here is an example from the official Python documentation
    that shows how descriptors work on real code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is an example of using it in the interactive session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding example clearly shows that if a class has the data descriptor
    for the given attribute, then the descriptor''s `__get__()` method is called to
    return the value every time the instance attribute is retrieved, and `__set__()`
    is called whenever a value is assigned to such an attribute. Although the case
    for the descriptor''s `__del__` method is not shown in the preceding example,
    it should be obvious now: it is called whenever an instance attribute is deleted
    with the `del instance.attribute` statement or the `delattr(instance, ''attribute'')`
    call.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The difference between data and non-data descriptors is important due to the
    fact stated at the beginning. Python already uses the descriptor protocol to bind
    class functions to instances as a methods. They also power the mechanism behind
    the `classmethod` and `staticmethod` decorators. This is because, in fact, the
    function objects are non-data descriptors too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'And this is also true for functions created with lambda expressions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: So, without `__dict__` taking precedence over non-data descriptors, we would
    not be able to dynamically override specific methods on already constructed instances
    at runtime. Fortunately, thanks to how descriptors work in Python. It is available,
    so developers may use a popular technique called monkey-patching to change the
    way how instances work without the need of subclassing.
  prefs: []
  type: TYPE_NORMAL
- en: Real-life example – lazily evaluated attributes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One example usage of descriptors may be to delay initialization of the class
    attribute to the moment when it is accessed from the instance. This may be useful
    if initialization of such attributes depends on the global application context.
    The other case is when such initialization is simply expensive but it is not known
    whether it will be used anyway when the class is imported. Such a descriptor could
    be implemented as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is example usage:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The official OpenGL Python library available on PyPI under the `PyOpenGL` name
    uses a similar technique to implement `lazy_property` that is both a decorator
    and a data descriptor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Such an implementation is similar to using the `property` decorator (described
    later), but the function that is wrapped with it is executed only once and then
    the class attribute is replaced with a value returned by such a property. Such
    a technique is often useful when the developer needs to fulfill the following
    two requirements at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: An object instance needs to be stored as a class attribute shared between its
    instances to save resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This object cannot be initialized on import time because its creation process
    depends on some global application state/context
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of applications written using OpenGL, this is very often true. For
    example, the creation of shaders in OpenGL is expensive because it requires compilation
    of code written in **GLSL** (**OpenGL Shading Language**). It is reasonable to
    create them only once and include their definition in close proximity to classes
    that require them. On the other hand, shader compilation cannot be performed without
    having initialized the OpenGL context, so it is hard to define and compile them
    reliably in global module namespace at import time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example shows the possible usage of the modified version of PyOpenGL''s
    `lazy_property` decorator (here `lazy_class_attribute`) in some imaginary OpenGL-based
    application. The highlighted change to the original `lazy_property` decorator
    was required in order to allow sharing the attribute between different class instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Like every advanced Python syntax feature, this one should also be used with
    caution and documented well in code. For unexperienced developers, the altered
    class behavior might be very confusing and unexpected because descriptors affect
    the very basic part of class behavior such as attribute access. Because of that,
    it is very important to make sure that all team members are familiar with descriptors
    and understand this concept well if it plays an important role in the project's
    codebase.
  prefs: []
  type: TYPE_NORMAL
- en: Properties
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The properties provide a built-in descriptor type that knows how to link an
    attribute to a set of methods. A `property` takes four optional arguments: `fget`,
    `fset`, `fdel`, and `doc`. The last one can be provided to define a `docstring`
    that is linked to the attribute as if it were a method. Here is an example of
    a `Rectangle` class that can be controlled either by direct access to attributes
    that store two corner points or by using the `width`, and `height` properties:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The example usage of such defined properties in an interactive session is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The properties make it easier to write descriptors, but must be handled carefully
    when using inheritance over classes. The created attribute is made on the fly
    using the methods of the current class and will not use methods that are overridden
    in the derived classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, the following example will fail to override the implementation
    of the `fget` method of the parent''s class (`Rectangle`) `width` property:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to solve this, the whole property simply needs to be overwritten in
    the derived class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Unfortunately, the preceding code has some maintainability issues. It can be
    a source of issue if the developer decides to change the parent class, but forgets
    about updating the property call. This is why overriding only parts of the property
    behavior is not advised. Instead of relying on the parent class's implementation,
    it is recommended to rewrite all the property methods in the derived classes,
    if there is need to change how they work. In most cases, this is the only option
    anyway, because usually the change to property `setter` behavior implies a change
    to the behavior of the `getter` as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to the preceding reason, the best syntax for creating properties is using
    `property` as a decorator. This will reduce the number of method signatures inside
    of the class and make code more readable and maintainable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Slots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An interesting feature that is almost never used by developers is slots. They
    allow you to set a static attribute list for a given class with the `__slots__`
    attribute, and skip the creation of the `__dict__` dictionary in each instance
    of the class. They were intended to save memory space for classes with very few
    attributes, since `__dict__` is not created at every instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides this, they can help to design classes whose signature needs to be frozen.
    For instance, if you need to restrict the dynamic features of the language over
    a class, defining slots can help:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This feature should be used carefully. When a set of available attributes is
    limited using `__slots__`, it is much harder to add something to the object dynamically.
    Some techniques, such as monkey-patching, will not work with instances of classes
    that have slots defined. Fortunately, the new attributes can be added to the derived
    class if it does not have its own slots defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Metaprogramming
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There may be a good definition of metaprogramming from some academy paper that
    could be cited here, but this is rather a book about good software craftsmanship
    than about computer science theory. This is why we will use a simple one:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"Metaprogramming is a technique of writing computer programs that can treat
    themselves as data, so you can introspect, generate, and/or modify itself while
    running."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using this definition, we can distinguish two major approaches to metaprogramming
    in Python.
  prefs: []
  type: TYPE_NORMAL
- en: The first approach concentrates on the language's ability to introspect its
    basic elements such as functions, classes, or types and to create or modify them
    on the fly. Python gives a lot of tools to developers in this area. The easiest
    ones are decorators that allow to add additional functionality to the existing
    functions, methods, or classes. Next are special methods of classes that allow
    you to interfere with class instance process creation. The most powerful are metaclasses
    that allow programmers to even completely redesign the Python's implementation
    of the object-oriented programming paradigm. Here also, we have a good selection
    of different tools that allow programmers to work directly with code either in
    its raw plain text format or in the more programmatically accessible **Abstract
    Syntax Tree** (**AST**) form. This second approach is of course more complicated
    and difficult to work with but allows for really extraordinary things, such as
    extending Python's language syntax or even creating your own **Domain Specific
    Language** (**DSL**).
  prefs: []
  type: TYPE_NORMAL
- en: Decorators – a method of metaprogramming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The decorator syntax is explained in [Chapter 2](ch02.html "Chapter 2. Syntax
    Best Practices – below the Class Level"), *Syntax Best Practices – below the Class
    Level*, as a simple pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: This clearly shows what the decorator does. It takes a function object and modifies
    it at run time. As a result, a new function (or anything else) is created based
    on the previous function object with the same name. This may be even a complex
    operation that performs some introspection to give different results depending
    on how the original function is implemented. All this means is that decorators
    can be considered as a metaprogramming tool.
  prefs: []
  type: TYPE_NORMAL
- en: This are good news. Decorators are relatively easy to catch and in most cases
    make code shorter, easier to read, and also cheaper to maintain. Other metaprogramming
    tools available in Python are more difficult to grasp and master. Also, they might
    not make the code simple at all.
  prefs: []
  type: TYPE_NORMAL
- en: Class decorators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the less known syntax features of Python is the class decorator. The
    syntax and the way that they work is exactly the same as with function decorators
    mentioned in [Chapter 2](ch02.html "Chapter 2. Syntax Best Practices – below the
    Class Level"), *Syntax Best Practices – below the Class Level*. The only difference
    is that they are expected to return a class instead of the function object. Here
    is an example class decorator that modifies the `__repr__()` method to return
    the printable object representation that is shortened to some arbitrary number
    of characters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is what you will see in the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, the preceding code snippet is not an example of a good code by any
    means because it is too cryptic. Still, it shows how multiple language features
    explained in this chapter can be used together:'
  prefs: []
  type: TYPE_NORMAL
- en: Not only instances but also class objects can be modified at runtime
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions are descriptors too, so they can be added to the class at runtime
    because the actual binding instance is performed on the attribute lookup as part
    of the descriptor protocol
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `super()` call can be used outside of a class definition scope as long as
    proper arguments are provided
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, class decorators can be used on class definitions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The other aspects of the writing function decorators apply to the class decorators
    as well. Most importantly, they can use closures and be parametrized. Taking advantage
    of these facts, the previous example can be rewritten into a more readable and
    maintainable form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The major drawback of using closures this way in class decorators is that the
    resulting objects are no longer instances of the class that was decorated but
    instances of the subclass created dynamically in the decorator function. Among
    others, this will affect the class''s `__name__` and `__doc__` attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Such usage of class decorators will result in following changes to the class
    metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Unfortunately, this cannot be fixed as simply as explained in the *Introspection
    Preserving Decorators* section of [Chapter 2](ch02.html "Chapter 2. Syntax Best
    Practices – below the Class Level"), *Syntax Best Practices – below the Class
    Level*, using the additional `wraps` decorator. This makes use of the class decorators
    in this form limited in some circumstances. If no additional work is performed
    to preserve the old class's metadata, then this can break results of many automated
    documentation generation tools.
  prefs: []
  type: TYPE_NORMAL
- en: Still, despite this single caveat, class decorators are a simple and lightweight
    alternative to the popular mixin class pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'A mixin in Python is a class that is not meant to be instantiated, but is instead
    used to provide some reusable API or functionality to other existing classes.
    Mixin classes are almost always added using multiple inheritance in the form of:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Mixins are useful design patterns that are used in many libraries. To name one,
    Django is one of the frameworks that uses them extensively. While useful and popular,
    the mixins can cause some trouble if not designed well, because, in most cases,
    they require the developer to rely on multiple inheritance. As was said earlier,
    Python handles multiple inheritance relatively well, thanks to the MRO. Anyway,
    it may be better to avoid subclassing multiple classes if it only does not require
    too much additional work and makes code simpler. This is why class decorators
    may be a good replacement of mixins.
  prefs: []
  type: TYPE_NORMAL
- en: Using the __new__() method to override instance creation process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The special method `__new__()` is a static method responsible for creating
    class instances. It is special-cased, so there is no need to declare it as a static
    using the `staticmethod` decorator. This `__new__(cls, [,...])` method is called
    prior to the `__init__()` initialization method. Typically, the implementation
    of overridden `__new__()` invokes its superclass version using `super().__new__()`
    with suitable arguments and modifies the instance before returning it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the log of example interactive session that shows how our `InstanceCountingClass`
    implementation works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The `__new__()` method should usually return an instance of featured class
    but it is also possible that it returns other class instances. If it does happen
    (different class instance is returned) then the call to the `__init__()` method
    is skipped. This fact is useful when there is a need to modify creation behavior
    of non-mutable class instances such as some of Python''s built-in types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see this in the interactive session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'So, when to use `__new__()`? The answer is simple: only when `__init__()` is
    not enough. One such case was already mentioned. This is subclassing of non-mutable
    built-in Python types such as `int`, `str`, `float`, `frozenset`, and so on. It''s
    because there is no way to modify such a nonmutable object instance in the `__init__()`
    method once it is created.'
  prefs: []
  type: TYPE_NORMAL
- en: Some programmers can argue that `__new__()` may be useful for performing important
    object initialization that may be missed if the user forgets to use `super()`.The
    _`_init__()` call is the overridden initialization method. While it sounds reasonable,
    this has a major drawback. If such an approach is used, then it becomes harder
    for the programmer to explicitly skip previous initialization steps if this is
    the already desired behavior. It also breaks an unspoken rule of all initializations
    performed in `__init__()`.
  prefs: []
  type: TYPE_NORMAL
- en: Because `__new__()` is not constrained to return the same class instance, it
    can be easily abused. Irresponsible usage of this method might do a lot of harm
    to the code, so it should always be used carefully and backed with extensive documentation.
    Generally, it is better to search for other solutions that may be available for
    the given problem, instead of affecting object creation in a way that will break
    basic programmers' expectations. Even overridden initialization of non-mutable
    types mentioned earlier can be replaced with more predictable and well-established
    design patterns, such as the Factory Method, which is described in [Chapter 14](ch14.html
    "Chapter 14. Useful Design Patterns"), *Useful Design Patterns*.
  prefs: []
  type: TYPE_NORMAL
- en: There is at least one aspect of Python programming where extensive usage of
    the `__new__()` method is well justified. These are metaclasses that are described
    in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Metaclasses
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Metaclass is a Python feature that is considered by many as one of the most
    difficult thing in this language and thus avoided by a great number of developers.
    In reality, it is not as complicated as it sounds once you understand few basic
    concepts. As a reward, knowing this feature grants the ability to do some things
    that were not possible using other approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'Metaclass is a type (class) that defines other types (classes). The most important
    thing to know in order to understand how they work is that classes that define
    object instances are objects too. So, if they are objects, then they have an associated
    class. The basic type of every class definition is simply the built-in `type`
    class. Here is a simple diagram that should make it clear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Metaclasses](graphics/5295_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3 How classes are typed
  prefs: []
  type: TYPE_NORMAL
- en: In Python, it is possible to substitute the metaclass for a class object with
    our own type. Usually, the new metaclass is still the subclass of the `type` class
    (refer to *Figure 4*) because not doing so would make the resulting classes highly
    incompatible with other classes in terms of inheritance.
  prefs: []
  type: TYPE_NORMAL
- en: '![Metaclasses](graphics/5295_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4 Usual implementation of custom metaclasses
  prefs: []
  type: TYPE_NORMAL
- en: The general syntax
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The call to the built-in `type()` class can be used as a dynamic equivalent
    of the class statement. It creates a new class object given its name, its base
    classes, and a mapping containing its attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'This is equivalent to the explicit definition of the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is what you will get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Every class created with the class statement implicitly uses `type` as its
    metaclass. This default behavior can be changed by providing the `metaclass` keyword
    argument to the class statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The value provided as a `metaclass` argument is usually another class object,
    but it can be any other callable that accepts the same arguments as the `type`
    class and is expected to return another class object. The call signature is `type(name,
    bases, namespace)`, which is explained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`name`: This is the name of class that will be stored in the `__name__` attribute'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bases`: This is the list of parent classes that will become the `__bases__`
    attribute and will be used to construct the MRO of a newly created class'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`namespace`: This is a namespace (mapping) with definitions for the class body
    that will become the `__dict__` attribute'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One way of thinking about metaclasses is the `__new__()` method, but at a higher
    level of class definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite the fact that functions that explicitly call `type()` can be used in
    place of metaclasses, the usual approach is to use a different class that inherits
    from `type` for this purpose. The common template for a metaclass is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The `name`, `bases`, and `namespace` arguments have the same meaning as in
    the `type()` call explained earlier, but each of these four methods can have different
    purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`__new__(mcs, name, bases, namespace)`: This is responsible for the actual
    creation of the class object in the same way as it does for ordinary classes.
    The first positional argument is a metaclass object. In the preceding example,
    it would simply be a `Metaclass`. Note that `mcs` is the popular naming convention
    for this argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__prepare__(mcs, name, bases, **kwargs)`: This creates an empty namespace
    object. By default, it returns an empty `dict`, but it can be overridden to return
    any other mapping type. Note that it does not accept `namespace` as an argument
    because before calling it the namespace does not exist.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__init__(cls, name, bases, namespace, **kwargs)`: This is not seen popularly
    in metaclass implementations but has the same meaning as in ordinary classes.
    It can perform additional class object initialization once it was created with
    `__new__()`. The first positional argument is now named `cls` by convention to
    mark that this is already a created class object (metaclass instance) and not
    a metaclass object. When `__init__()` gets called, the class was already constructed
    and so this method can do less things than the `__new__()` method. Implementing
    such a method is very similar to using class decorators, but the main difference
    is that `__init__()` will be called for every subclass, while class decorators
    are not called for subclasses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__call__(cls, *args, **kwargs)`: This is called when an instance of a metaclass
    is called. The instance of a metaclass is a class object (refer to *Figure 3*);
    it is invoked when you create new instances of a class. This can be used to override
    the default way how class instances are created and initialized.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each of the preceding methods can accept additional extra keyword arguments
    here represented by `**kwargs`. These arguments can be passed to the metaclass
    object using extra keyword arguments in the class definition in the form of the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Such amount of information can be overwhelming at the beginning without proper
    examples, so let''s trace the creation of metaclasses, classes, and instances
    with some `print()` calls:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `RevealingMeta` as a metaclass to create a new class definition will
    give the following output in the Python interactive session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: New Python 3 syntax for metaclasses
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Metaclasses are not a new feature and are available in Python since version
    2.2\. Anyway, the syntax of this changed significantly and this change is neither
    backwards nor forwards compatible. While the new syntax is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'In Python 2, this must be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Class statements in Python 2 do not accept keyword arguments, so Python 3 syntax
    for defining `metaclasses` will raise the `SyntaxError` exception on import. It
    is still possible to write a code using metaclasses that will run on both Python
    versions, but it requires some extra work. Fortunately, compatibility-related
    packages such as `six` provide simple and reusable solutions to this problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'The other important difference is the lack of the `__prepare__()` hook in Python
    2 metaclasses. Implementing such a function will not raise any exceptions under
    Python 2 but is pointless because it will not be called in order to provide a
    clean namespace object. This is why packages that need to maintain Python 2 compatibility
    need to rely on more complex tricks if they want to achieve things that are a
    lot easier to implement using `__prepare__()`. For instance, the Django REST Framework
    ([http://www.django-rest-framework.org](http://www.django-rest-framework.org))
    uses the following approach to preserve the order in which attributes are added
    to a class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the workaround if the default namespace type, which is `dict`, does
    not guarantee to preserve the order of the key-value tuples. The `_creation_counter`
    attribute is expected to be in every instance of the `Field` class. This `Field.creation_counter`
    attribute is created in the same way as `InstanceCountingClass.instance_number`
    that was presented in the section about the `__new__()` method. This is a rather
    complex solution that breaks a single responsibility principle by sharing its
    implementation across two different classes only to ensure a trackable order of
    attributes. In Python 3, this could be simpler because `__prepare__()` can return
    other mapping types such as `OrderedDict`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is what you will see:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more examples, there's a great introduction to metaclass programming in
    Python 2 by David Mertz, which is available at [http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html](http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html).
  prefs: []
  type: TYPE_NORMAL
- en: Metaclass usage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Metaclasses once mastered are a powerful feature but always complicate the code.
    They might also make the code less robust that is intended to work on any kind
    of class. For instance, you might encounter bad interactions when slots are used
    in the class, or when some base class already implements a metaclass, which conflicts
    with what yours does. They just do not compose well.
  prefs: []
  type: TYPE_NORMAL
- en: For simple things like changing the read/write attributes or adding new ones,
    metaclasses can be avoided in favor of simpler solutions such as properties, descriptors,
    or class decorators.
  prefs: []
  type: TYPE_NORMAL
- en: It is also true that often metaclasses can be replaced with other simpler approaches,
    but there are situations where things cannot be easily done without them. For
    instance, it is hard to imagine Django's ORM implementation built without extensive
    use of metaclasses. It could be possible, but it is rather unlikely that the resulting
    solution would be similarly easy to use. And frameworks are the place where metaclasses
    are really well-suited. They usually have a lot of complex solutions that are
    not easy to understand and follow, but eventually allow other programmers to write
    more condensed and readable code that operates on a higher level of abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: Metaclass pitfalls
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Like some other advanced Python features, metaclasses are very elastic and can
    be easily abused. While the call signature of the class is rather strict, Python
    does not enforce the type of the return parameter. It can be anything as long
    as it accepts incoming arguments on calls and has the required attributes whenever
    it is needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'One such object that can be *anything-anywhere* is the instance of the `Mock`
    class provided in the `unittest.mock` module. `Mock` is not a metaclass and also
    does not inherit from the `type` class. It also does not return the class object
    on instantiating. Still, it can be included as a metaclass keyword argument in
    the class definition and this will not raise any issues, despite, it is pointless
    to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding example, of course, completely does not make sense and will fail
    on any attempt to instantiate such a `Nonsense` pseudo-class. It is still important
    to know that such things are possible because issues with `metaclass` types that
    do not result in the creation of the `type` subclass are sometimes very hard to
    spot and understand. As a proof, here is a traceback of the exception raised when
    we try to create a new instance of the `Nonsense` class presented earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Some tips on code generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As already mentioned, dynamic code generation is the most difficult approach
    to code generation. There are some tools in Python that allow you to generate
    and execute code or even do some modifications to the already compiled code objects.
    A complete book could be written about this and even that will not exhaust the
    topic completely.
  prefs: []
  type: TYPE_NORMAL
- en: Various projects, such as **Hy** (mentioned later), show that even whole languages
    can be re-implemented in Python using code generation techniques. This proves
    that the possibilities are practically limitless. Knowing how vast this topic
    is and how badly it is riddled with various pitfalls, I won't even try to give
    detailed suggestions on how to create code this way or to provide useful code
    samples.
  prefs: []
  type: TYPE_NORMAL
- en: Anyway, knowing what is possible may be useful for you if you plan to study
    this field deeper by yourself. So, treat this section only as a short summary
    of possible starting points for further learning. Most of it is flavored with
    many warnings in case you would like to eagerly jump into calling `exec()` and
    `eval()` in your own project.
  prefs: []
  type: TYPE_NORMAL
- en: exec, eval, and compile
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Python provides three built-in functions to manually execute, evaluate, and
    compile arbitrary Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`exec(object, globals, locals)`: This allows you to dynamically execute the
    Python code. `object` should be a string or a code object (see the `compile()`
    function). The `globals` and `locals` arguments provide global and local namespaces
    for the executed code and are optional. If they are not provided, then the code
    is executed in the current scope. If provided, `globals` must be dictionary, while
    `locals` might be any mapping object; it always returns `None`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eval(expression, globals, locals)`: This is used to evaluate the given expression
    returning its value. It is similar to `exec()`, but it accepts that `expression`
    should be a single Python expression and not a sequence of statements. It returns
    the value of the evaluated expression.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`compile(source, filename, mode)`: This compiles the source into the code object
    or AST object. The code to be compiled is provided as a string in the source argument.
    The filename should be the file from which the code was read. If it has no file
    associated because its source was created dynamically, then `<string>` is the
    value that is commonly used. Mode should be either `exec` (sequence of statements),
    `eval` (single expression), or `single` (a single interactive statement such as
    in Python interactive session).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `exec()` and `eval()` functions are the easiest to start with when trying
    to dynamically generate code because they can operate on strings. If you already
    know how to program in Python, then you may know how to correctly generate a working
    source code programmatically. I hope you do.
  prefs: []
  type: TYPE_NORMAL
- en: The most useful in the context of metaprogramming is obviously `exec()` because
    it allows us to execute any sequence of Python statements. And the word *any*
    should be alarming for you. Even `eval()`, which only allows evaluation of expressions
    in the hands of a skillful programmer (when fed with the user input), can lead
    to serious security holes. Note that crashing the Python interpreter is the least
    scary scenario you should be afraid of. Introducing vulnerability to remote execution
    exploits due to irresponsible use of `exec()` and `eval()` can cost you your image
    as a professional developer, or even your job.
  prefs: []
  type: TYPE_NORMAL
- en: Even if used with a trusted input, there is a long list of little details about
    `exec()` and `eval()` that is too long to be included here, but might affect how
    your application works in the ways you would not expect. Armin Ronacher has a
    good article that lists the most important of them called *Be careful with exec
    and eval in Python* (refer to [http://lucumr.pocoo.org/2011/2/1/exec-in-python/](http://lucumr.pocoo.org/2011/2/1/exec-in-python/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite all these frightening warnings, there are natural situations where
    the usage of `exec()` and `eval()` is really justified. The popular statement
    about when you have to use them is: *you will know*. In other words, in case of
    even the tiniest doubt, you should not use them and try to find a different solution.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**eval() and untrusted input**'
  prefs: []
  type: TYPE_NORMAL
- en: The signature of the `eval()` function might make you think that if you provide
    empty `globals` and `locals` namespaces and wrap it with proper `try ... except`
    statements, then it will be reasonably safe. There could be nothing more wrong.
    Ned Batcheler has written a very good article in which he shows how to cause an
    interpreter segmentation fault in the `eval()` call even with erased access to
    all Python built-ins ([http://nedbatchelder.com/blog/201206/eval_really_is_dangerous.html](http://nedbatchelder.com/blog/201206/eval_really_is_dangerous.html)).
    This is a single proof that both `exec()` and `eval()` should never be used with
    untrusted input.
  prefs: []
  type: TYPE_NORMAL
- en: Abstract Syntax Tree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Python syntax is converted to **Abstract Syntax Tree** (**AST**) before
    it is compiled to byte code. This is a tree representation of the abstract syntactic
    structure of the source code. The processing of Python grammar is available thanks
    to the built-in `ast` module. Raw AST of Python code can be created using the
    `compile()` function with the `ast.PyCF_ONLY_AST` flag, or using the `ast.parse()`
    helper. Direct translation in reverse is not that simple and there is no function
    provided in the built-ins for that. Some projects, such as PyPy, do such things
    though.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ast` module provides some helper functions that allow working with the
    AST:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of `ast.dump()` in the preceding example was reformatted to increase
    the readability and better show the tree-like structure of the AST. It is important
    to know that the AST can be modified before being passed to the `compile()` call
    that gives many new possibilities. For instance, new syntax nodes can be used
    for additional instrumentation such as test coverage measurement. It is also possible
    to modify the existing code tree in order to add new semantics to the existing
    syntax. Such a technique is used by the MacroPy project ([https://github.com/lihaoyi/macropy](https://github.com/lihaoyi/macropy))
    to add syntactic macros to Python using the already existing syntax (refer to
    *Figure 5*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Abstract Syntax Tree](graphics/5295_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: How MacroPy adds syntactic macros to Python modules on import'
  prefs: []
  type: TYPE_NORMAL
- en: AST can also be created in a purely artificial manner and there is no need to
    parse any source at all. This gives Python programmers the ability to create Python
    bytecode for custom domain-specific languages or even completely implement other
    existing programming languages on top of Python VM.
  prefs: []
  type: TYPE_NORMAL
- en: Import hooks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Taking advantage of the MacroPy''s ability to modify original AST would not
    be as easy as using the `import macropy.activate` statement if it would not somehow
    override the Python import behavior. Fortunately, Python provides a way to intercept
    imports using two kinds of import hooks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Meta hooks**: These are called before any other `import` processing has occurred.
    Using meta hooks, you can override the way how `sys.path` is processed or even
    frozen and built-in modules. In order to add new meta hook, a new **meta path
    finder** object must be added to the `sys.meta_path` list.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Import path hooks**: These are called as part of `sys.path` processing. They
    are used if the path item associated with the given hook is encountered. The import
    path hooks are added by extending the `sys.path_hooks` list with a new **path
    finder** object.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The details on implementing both path finders and meta path finders are extensively
    implemented in the official Python documentation ([https://docs.python.org/3/reference/import.html](https://docs.python.org/3/reference/import.html)).
    The official documentation should be your primary resource if you want to interact
    with imports on that level. It's so because import machinery in Python is rather
    complex and any attempt to summarize it in a few paragraphs would inevitably fail.
    Treat this section rather as a note that such things are possible and as a reference
    to more detailed information.
  prefs: []
  type: TYPE_NORMAL
- en: Projects using code generation patterns
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is really hard to find a really usable implementation of the library that
    relies on code generation patterns that is not only an experiment or simple proof
    of concepts. The reasons for that situation are fairly obvious:'
  prefs: []
  type: TYPE_NORMAL
- en: Deserved fear of the `exec()` and `eval()` functions because if used irresponsibly
    they can cause real disasters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Successful code generation is simply very difficult because it requires a deep
    understanding of the featured language and exceptional programming skills in general
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despite these difficulties, there are some projects that successfully take this
    approach either to improve performance or achieve things that would be impossible
    by other means.
  prefs: []
  type: TYPE_NORMAL
- en: Falcon's compiled router
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Falcon ([http://falconframework.org/](http://falconframework.org/)) is a minimalist
    Python WSGI web framework for building fast and lightweight APIs. It strongly
    encourages REST architectural style that is currently very popular around the
    Web. It is a good alternative to other rather heavy frameworks such as Django
    or Pyramid. It is also a strong competitor to other micro-frameworks that aim
    for simplicity such as Flask, Bottle, and web2py.
  prefs: []
  type: TYPE_NORMAL
- en: One of its features is its very simple routing mechanism. It is not as complex
    as the routing provided by Django `urlconf` and does not provide as many features
    but in most cases is just enough for any API that follows the REST architectural
    design. What is most interesting about falcon's routing is that the actual router
    is implemented using the code generated from the list of routes provided to the
    object that defines the API configuration. This is the effort to make routing
    fast.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this very short API example taken from falcon''s web documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The highlighted call to the `api.add_route()` method in brief words translates
    to updating the whole dynamically generated router code tree, compiling using
    `compile()` and generating the new route-finding function using `eval()`. Looking
    at the `__code__` attribute of the `api._router._find()` function shows that it
    was generated from the string and that it changes with every call to `api.add_route()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Hy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Hy ([http://docs.hylang.org/](http://docs.hylang.org/)) is the dialect of Lisp
    written entirely in Python. Many similar projects implementing other code in Python
    usually try only to tokenize the plain form of code provided either as a file-like
    object or string and interpret it as a series of explicit Python calls. Unlike
    others, Hy can be considered a language that runs fully in the Python run-time
    environment just as Python does. Code written in Hy can use the existing built-in
    modules and external packages and vice versa. Code written with Hy can be imported
    back to Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to embed Lisp in Python, Hy translates Lisp code directly to Python
    Abstract Syntax Tree. Import interoperability is achieved using import hook that
    is registered once the Hy module is imported in Python. Every module with the
    `.hy` extension is treated as the Hy module and can be imported like the ordinary
    Python module. Thanks to this fact, the following "hello world" program is written
    in this Lisp dialect:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'It can be imported and executed by the following Python code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'If we dig deeper and try to disassemble `hyllo.hello` using the built-in `dis`
    module, we will notice that the byte code of the Hy function does not differ significantly
    from its pure Python counterpart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter presented the best syntax practices related with classes. It started
    with basic information on how to subclass built-in types and call the method from
    superclasses. After that, more advanced concepts of object oriented programing
    in Python were presented. These were useful syntax features that focus on instance
    attribute access: descriptors and properties. It was shown how they can be used
    to create cleaner and more maintainable code. Slots too were featured, with an
    important note that they should always be used with caution.'
  prefs: []
  type: TYPE_NORMAL
- en: The rest of the chapter explored the vast topic of metaprogramming in Python.
    The syntax features that favor the various metaprogramming patterns such as decorators
    and metaclasses were described in detail with some examples taken from real-life
    code.
  prefs: []
  type: TYPE_NORMAL
- en: The other important aspect of metaprogramming in the form of dynamic code generation
    was described only briefly as it is too vast to fit in the limited space of this
    book. However, it should be a good starting point that gives a quick summary of
    the possible options in that field.
  prefs: []
  type: TYPE_NORMAL
