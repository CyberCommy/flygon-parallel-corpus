- en: '*Chapter 11*: Minimizing Downtime with Rolling Deployments'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ansible is well suited to the task of upgrading or deploying applications in
    a live service environment. Of course, application deployments and upgrades can
    be approached with a variety of different strategies. The best approach depends
    on the application itself, the capabilities of the infrastructure the application
    runs on, and any promised **service-level agreements** (**SLAs**) with the users
    of the application. Whatever the approach, it is vital that the application deployment
    or upgrade is controlled, predictable, and repeatable in order to ensure that
    users experience a stable service while automated deployments occur in the background.
    The last thing anyone wants is an outage caused by unexpected behavior from their
    automation tool; an automation tool should be trustworthy and not an additional
    risk factor.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although there is a myriad of choices, some deployment strategies are more
    common than others, and in this chapter, we''ll walk through a couple of the more
    common ones. In doing so, we will showcase the Ansible features that will be useful
    within those strategies. We''ll also discuss a couple of other deployment considerations
    that are common across both deployment strategies. To achieve this, we will delve
    into the details of the following subjects, in the context of a rolling Ansible
    deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: In-place upgrades
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expanding and contracting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Failing fast
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimizing disruptions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serializing single tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To follow the examples presented in this chapter, you will need a Linux machine
    running **Ansible 4.3** or a newer version. Almost any flavor of Linux should
    do—for those interested in specifics, all the code presented in this chapter was
    tested on **Ubuntu Server 20.04 Long-Term Support (LTS)** unless stated otherwise,
    and on Ansible 4.3\. The example code that accompanies this chapter can be downloaded
    from GitHub at [https://github.com/PacktPublishing/Mastering-Ansible-Fourth-Edition/tree/main/Chapter11](https://github.com/PacktPublishing/Mastering-Ansible-Fourth-Edition/tree/main/Chapter11).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following video to see the code in action: [https://bit.ly/3lZ6Y9W](https://bit.ly/3lZ6Y9W)'
  prefs: []
  type: TYPE_NORMAL
- en: In-place upgrades
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first type of deployment that we'll cover is in-place upgrades. This style
    of deployment operates on an infrastructure that already exists, in order to upgrade
    the existing application. This model is a traditional model that was used when
    the creation of new infrastructure was a costly endeavor, in terms of both time
    and money.
  prefs: []
  type: TYPE_NORMAL
- en: A general design pattern to minimize the downtime during this type of upgrade
    is to deploy the application across multiple hosts, behind a load balancer. The
    load balancer will act as a gateway between users of the application and the servers
    that run the application. Requests for the application will come to the load balancer,
    and, depending on the configuration, the load balancer will decide which backend
    server to direct the requests to.
  prefs: []
  type: TYPE_NORMAL
- en: To perform a rolling in-place upgrade of an application deployed with this pattern,
    each server (or a small subset of the servers) will be disabled at the load balancer,
    upgraded, and then re-enabled to take on new requests. This process will be repeated
    for the remaining servers in the pool until all servers have been upgraded. As
    only a portion of the available application servers is taken offline to be upgraded,
    the application as a whole remains available for requests. Of course, this assumes
    that an application can perform well with mixed versions running at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Let's build a playbook to upgrade a fictional application. Our fictional application
    will run on servers `foo-app01` through `foo-app08`, which exist in the `foo-app`
    group. These servers will have a simple website that's served via the `nginx` web
    server, with the content coming from a `foo-app` Git repository, defined by the `foo-app.repo` variable.
    A load-balancer server, `foo-lb`, running the `haproxy` software, will front these
    app servers.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to operate on a subset of our `foo-app` servers, we need to employ
    the `serial` mode. This mode changes how Ansible will execute a play. By default,
    Ansible will execute the tasks of a play across each host in the order that the
    tasks are listed. Ansible executes each task of the play on every host before
    it moves on to the next task in the play. If we were to use the default method,
    our first task would remove every server from the load balancer, which would result
    in the complete outage of our application. Instead, the `serial` mode lets us
    operate on a subset so that the application as a whole stays available, even if
    some of the members are offline. In our example, we''ll use a serial count of
    `2` in order to keep the majority of the application members online:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Ansible 2.2 introduced the concept of serial batches: a list of numbers that
    can increase the number of hosts addressed serially each time through the play.
    This allows the size of the hosts addressed to increase as confidence increases.
    Where a batch of numbers is provided to the `serial` keyword, the last number
    provided will be the size of any remaining batch, until all hosts in the inventory
    have been completed.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can start to create our tasks. The first task will be to disable the
    host from the load balancer. The load balancer runs on the `foo-lb` host; however,
    we''re operating on the `foo-app` hosts. Therefore, we need to delegate the task
    by using the `delegate_to` task operator. This operator redirects where Ansible
    will connect to in order to execute the task, but it keeps all of the variable
    contexts of the original host. We''ll use the `community.general.haproxy` module
    to disable the current host from the `foo-app` backend pool. The code is illustrated
    in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'With the host disabled, we can now update the `foo-app` content. We''ll use
    the `ansible.builtin.git` module to update the content path with the desired version,
    defined as `foo-version`. We''ll add a `notify` handler to this task to reload
    the `nginx` server if the content update results in a change. This restart can
    be done every time, but we''re also using this as an example usage of `notify`.
    You can view the code in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Our next step would be to re-enable the host in the load balancer; however,
    if we did that task next, we''d put the old version back in place, as our notified
    handler hasn''t run yet. So, we need to trigger our handlers early, by way of
    the `meta: flush_handlers` call, which you learned about in [*Chapter 10*](B17462_10_Final_JC_ePub.xhtml#_idTextAnchor183),
    *Extending Ansible*. You can see this again here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can re-enable the host in the load balancer. We can just enable it
    right away and rely on the load balancer to wait until the host is healthy before
    sending requests to it. However, because we are running with a reduced number
    of available hosts, we need to ensure that all of the remaining hosts are healthy.
    We can make use of an `ansible.builtin.wait_for` task to wait until the `nginx` service
    is once again serving connections. The `ansible.builtin.wait_for` module will
    wait for a condition on either a port or a file path. In the following example,
    we will wait for port `80` and the condition that the port should be in. If it
    is started (the default), that means it is accepting connections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can re-enable the member within `haproxy`. Once again, we''ll delegate
    the task to `foo-lb`, as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Of course, we still need to define our `reload nginx` handler. We can do this
    by running the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This playbook, when run, will now perform a rolling in-place upgrade of our
    application. Of course, it's not always desirable to run an upgrade in place—there's
    always the chance that this could be service-impacting, especially if the service
    comes under unexpected load. An alternate strategy that prevents this, expanding
    and contracting, is explored in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Expanding and contracting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An alternative to the in-place upgrade strategy is the **expand and contract** strategy.
    This strategy has become popular of late, thanks to the self-service nature of
    on-demand infrastructures, such as cloud computing or virtualization pools. The
    ability to create new servers on-demand from a large pool of available resources
    means that every deployment of an application can happen on brand new systems.
    This strategy avoids a host of issues, such as a buildup of cruft on long-running
    systems, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Configuration files that are no longer managed by Ansible being left behind
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Runaway processes consuming resources in the background
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Changes being made to the server manually by human beings without updating the
    Ansible playbooks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starting fresh each time also removes the differences between initial deployment
    and an upgrade. The same code path can be used, reducing the risk of surprises
    when upgrading an application. This type of installation can also make it extremely
    easy to roll back if the new version does not perform as expected. In addition
    to this, as new systems are created to replace old systems, the application does
    not need to go into a degraded state during the upgrade.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s re-approach our previous upgrade playbook with the expand and contract
    strategy. Our pattern will be to create new servers, deploy our application, verify
    our application, add new servers to the load balancer, and remove old servers
    from the load balancer. Let''s start by creating new servers. For this example,
    we''ll make use of an OpenStack compute cloud to launch new instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In this task, we''re looping over a count of `8`, using the new `loop` with
    `range` syntax that was introduced in Ansible 2.5\. For each iteration of the
    loop, the `item` variable will be replaced by a number. This allows us to create
    eight new server instances with names based on the version of our application
    and the number of the loop. We''re also assuming a prebuilt image to us so that
    we do not need to do any further configuration on the instance. In order to use
    the servers in future plays, we need to add their details to the inventory. To
    accomplish this, we register the results of the run in the `launch` variable,
    which we''ll use to create runtime inventory entries. The code is illustrated
    in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This task will create new inventory items with the same names as those of our
    server instance. To help Ansible know how to connect, we'll set `ansible_ssh_host` to
    the **Internet Protocol** (**IP**) address that our cloud provider assigned to
    the instance (this is assuming that the address is reachable by the host running
    Ansible). Finally, we'll add the hosts to the `new-foo-app` group. As our `launch` variable
    comes from a task with a loop, we need to iterate over the results of that loop
    by accessing the `results` key. This allows us to loop over each launch action
    to access the data specific to that task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we''ll operate on the servers to ensure that the new service is ready
    for use. We''ll use `ansible.builtin.wait_for` again, just as we did earlier,
    as a part of a new play operating on our `new-foo-app` group. The code is illustrated
    in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Once they''re all ready to go, we can reconfigure the load balancer to make
    use of our new servers. For the sake of simplicity, we will assume a template
    for the `haproxy` configuration that expects hosts in a `new-foo-app` group, and
    the end result will be a configuration that knows all about our new hosts and
    forgets about our old hosts. This means that we can simply call an `ansible.builtin.template`
    task on the load-balancer system itself, rather than attempting to manipulate
    the running state of the balancer. The code is illustrated in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Once the new configuration file is in place, we can issue a reload of the `haproxy` service.
    This will parse the new configuration file and start a new listening process for
    new incoming connections. The existing connections will eventually close, and
    the old processes will terminate. All new connections will be routed to the new
    servers running our new application version.
  prefs: []
  type: TYPE_NORMAL
- en: This playbook can be extended to decommission the old version of the servers,
    or that action may happen at a different time when it has been decided that a
    rollback to the old-version capability is no longer necessary.
  prefs: []
  type: TYPE_NORMAL
- en: The expand and contract strategy can involve more tasks, and even separate playbooks
    for creating a golden image set, but the benefits of a fresh infrastructure for
    every release far outweigh the extra tasks or added complexity of creation followed
    by deletion.
  prefs: []
  type: TYPE_NORMAL
- en: Failing fast
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When performing an upgrade of an application, it may be desirable to fully stop
    the deployment at any sign of an error. A partially upgraded system with mixed versions may
    not work at all, so continuing with part of the infrastructure while leaving the
    failed systems behind can lead to big problems. Fortunately, Ansible provides
    a mechanism to decide when to reach a fatal-error scenario.
  prefs: []
  type: TYPE_NORMAL
- en: By default, when Ansible is running through a playbook and encounters an error,
    it will remove the failed host from the list of play hosts and continue with the
    tasks or plays. Ansible will stop executing either when all the requested hosts
    for a play have failed or when all the plays have been completed. To change this
    behavior, there are a couple of play controls that can be employed. Those controls
    are `any_errors_fatal`, `max_fail_percentage`, and `force_handlers`, and these
    are discussed next.
  prefs: []
  type: TYPE_NORMAL
- en: The any_errors_fatal option
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This setting instructs Ansible to consider the entire operation fatal and to
    stop executing immediately if any host encounters an error. To demonstrate this,
    we''ll edit our `mastery-hosts` inventory, defining a pattern that will expand
    up to 10 new hosts, as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we''ll create a play on this group with `any_errors_fatal` set to `true`.
    We''ll also turn off fact-gathering since these hosts do not exist. The code is
    illustrated in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We want a task that will fail for one of the hosts but not the others. Then,
    we''ll want a second task as well, just to demonstrate how it will not run. Here''s
    the code we need to execute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We now execute the playbook using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'When we do this, we''ll see one host fail, but the entire play will stop after
    the first task, and the `ansible.builtin.debug` task is never attempted, as illustrated
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Failing an entire playbook early when just one host in the
    inventory fails'
  prefs: []
  type: TYPE_NORMAL
- en: '](Images/B17462_11_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.1 – Failing an entire playbook early when just one host in the inventory
    fails
  prefs: []
  type: TYPE_NORMAL
- en: We can see that just one host failed; however, Ansible reported `NO MORE HOSTS
    LEFT` (implying that all hosts failed) and aborted the playbook before getting
    to the next play.
  prefs: []
  type: TYPE_NORMAL
- en: The max_fail_percentage option
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This setting allows play developers to define a percentage of hosts that can
    fail before the whole operation is aborted. At the end of each task, Ansible will
    perform a calculation to determine the number of hosts targeted by the play that
    have reached a failure state, and if that number is greater than the number allowed,
    Ansible will abort the playbook. This is similar to `any_errors_fatal`; in fact,
    `any_errors_fatal` just internally expresses a `max_fail_percentage` parameter
    of `0`, where any failure is considered fatal. Let''s edit our play from the preceding
    section and remove `any_errors_fatal`, replacing it with the `max_fail_percentage`
    parameter set to `20`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'By making that change and running our playbook with the same command as we
    used previously, our play should complete both tasks without aborting, as the
    following screenshot shows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Demonstrating our previous failure-test playbook proceeding
    with fewer than 20 percent failed hosts'
  prefs: []
  type: TYPE_NORMAL
- en: '](Images/B17462_11_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.2 – Demonstrating our previous failure-test playbook proceeding with
    fewer than 20 percent failed hosts
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if we change the condition on our first task so that we deliberately fail
    on over `20` percent of the hosts, we''ll see the playbook abort early:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We''re deliberately setting up three hosts to fail, which will give us a failure
    rate of greater than `20` percent. The `max_fail_percentage` setting is the maximum
    allowed, so our setting of `20` would allow two out of the ten hosts to fail.
    With three hosts failing, we will see a fatal error before the second task is
    allowed to execute, as the following screenshot illustrates:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – Demonstrating the max_fail_percentage operation failing a play
    when the percentage is exceeded'
  prefs: []
  type: TYPE_NORMAL
- en: '](Images/B17462_11_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.3 – Demonstrating the max_fail_percentage operation failing a play
    when the percentage is exceeded
  prefs: []
  type: TYPE_NORMAL
- en: With this combination of parameters, we can easily set up and control **fail-fast** conditions
    on a group of hosts, which is incredibly valuable if our goal is to maintain the
    integrity of an environment during an Ansible deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Forcing handlers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Normally, when Ansible fails a host, it stops executing anything on that host.
    This means that any pending handlers will not be run. This can be undesirable,
    and there is a play control that will force Ansible to process pending handlers
    for failed hosts. This play control is `force_handlers`, which must be set to
    the `true` Boolean value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s modify our preceding example a little in order to demonstrate this functionality.
    We''ll remove our `max_fail_percentage` parameter and add a new first task. We
    need to create a task that will return successfully with a change. This is possible
    with the `ansible.builtin.debug` module, using the `changed_when` task control,
    as this module will never register a change otherwise. We''ll revert our `ansible.builtin.fail` task
    conditional to our original one, as well. The code is illustrated in the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Our third task remains unchanged, but we will define our critical handler,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s run this new play to show the default behavior of the handler not being
    executed. In the interest of reduced output, we''ll limit execution to just one
    of the hosts with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that although the handler is referenced in the play output, it is not
    actually run, as evidenced by the lack of any debug message, which the following
    screenshot clearly shows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4 – Demonstrating how handlers are not run even when notified if
    a play fails'
  prefs: []
  type: TYPE_NORMAL
- en: '](Images/B17462_11_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.4 – Demonstrating how handlers are not run even when notified if a
    play fails
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we add the `force_handlers` play control and set it to `true`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, when we run the playbook (using the same command as before), we
    should see the handler run even for the failed hosts, as demonstrated in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – Demonstrating that handlers can be forced to run, even for
    failed hosts in a failed play'
  prefs: []
  type: TYPE_NORMAL
- en: '](Images/B17462_11_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.5 – Demonstrating that handlers can be forced to run, even for failed
    hosts in a failed play
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Forcing handlers can be a runtime decision as well, using the `--force-handlers` command-line
    argument on `ansible-playbook`. It can also be set globally, as a parameter in `ansible.cfg`.
  prefs: []
  type: TYPE_NORMAL
- en: Forcing handlers to run can be really useful for repeated playbook runs. The
    first run may result in some changes, but if a fatal error is encountered before
    the handlers are flushed, those handler calls will be lost. Repeated runs will
    not result in the same changes, so the handler will never run without manual interaction.
    Forcing handlers ensures that those handler calls are not lost, and so the handlers
    are always run regardless of the task outcomes. Of course, the whole objective
    of any upgrade strategy is to keep the impact on any given service as low as possible—can
    you imagine your favorite retail site going down for someone to upgrade software?
    It is unthinkable in this day and age! In the next section, we explore ways to
    minimize potentially disruptive actions using Ansible.
  prefs: []
  type: TYPE_NORMAL
- en: Minimizing disruptions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During deployment, there are often tasks that can be considered disruptive or
    destructive. These tasks may include restarting services, performing database
    migrations, and so on. Disruptive tasks should be clustered together to minimize
    the overall impact on an application, while destructive tasks should only be performed
    once. The next two subsections explore how you can meet both these targets using
    Ansible.
  prefs: []
  type: TYPE_NORMAL
- en: Delaying a disruption
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Restarting services for a new configuration or code version is a very common
    requirement. When viewed in isolation, a single service can be restarted whenever
    the code and configuration for the application have changed, without concern for
    the overall distributed system health. Typically, a distributed system will have
    roles for each part of the system, and each role will essentially operate in isolation
    on the hosts targeted to perform those roles. When deploying an application for
    the first time, there is no existing uptime of the whole system to worry about,
    so services can be restarted at will. However, during an upgrade, it may be desirable
    to delay all service restarts until every service is ready, to minimize interruptions.
  prefs: []
  type: TYPE_NORMAL
- en: The reuse of role code is strongly encouraged, as opposed to designing a completely
    separate upgrade code path. To accommodate a coordinated reboot, the role code
    for a particular service needs protection around the service restart. A common
    pattern is to put a conditional statement on the disruptive tasks that check a
    variable's value. When performing an upgrade, the variable can be defined at runtime
    to trigger this alternative behavior. This variable can also trigger a coordinated
    restart of services at the end of the main playbook once all of the roles have
    been completed, in order to cluster the disruption and minimize the total outage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a fictional application upgrade that involves two roles with
    simulated service restarts. We''ll call these roles `microA` and `microB`. The
    code is illustrated in the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'For both roles, we''ll have a simple debug task that simulates the installation
    of a package. We''ll notify a handler to simulate the restart of a service, and
    to ensure that the handler will trigger, we''ll force the task to always register
    as changed. The following code snippet shows the content of `roles/microA/tasks/main.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The content of `roles/microB/tasks/main.yaml` is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The handlers for these roles will be debug actions as well, and we''ll attach
    a conditional statement to the handler task to only restart if the upgrade variable
    evaluates to the `false` Boolean value. We''ll also use the default filter to
    give this variable a default value of `false`. The content of `roles/microA/handlers/main.yaml`
    is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The content of `roles/microB/handlers/main.yaml` is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'For our top-level playbook, we''ll create four plays (remember that a playbook
    can consist of one or more plays). The first two plays will apply each of the
    micro roles, and the last two plays will do the restarts. The last two plays will
    only be executed if performing an upgrade; so, they will make use of the `upgrade`
    variable as a condition. Let''s take a look at the following code snippet (called `micro.yaml`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We execute this playbook without defining the `upgrade` variable, using the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'When we do this, we will see the execution of each role, and the handlers within.
    The final two plays will have skipped tasks, as the following screenshot shows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.6 – Demonstrating a role-based playbook for installing a microservice
    architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](Images/B17462_11_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.6 – Demonstrating a role-based playbook for installing a microservice
    architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s execute the playbook again; this time, we''ll define the `upgrade`
    variable as `true` at runtime, using the `-e` flag as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This time, the results should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.7 – Demonstrating the same playbook, but in an upgrade scenario'
  prefs: []
  type: TYPE_NORMAL
- en: with all restarts batched at the end
  prefs: []
  type: TYPE_NORMAL
- en: '](Images/B17462_11_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.7 – Demonstrating the same playbook, but in an upgrade scenario with
    all restarts batched at the end
  prefs: []
  type: TYPE_NORMAL
- en: This time, we can see that our handlers are skipped, but the final two plays
    have tasks that execute. In a real-world scenario, where many more things are
    happening in the `microA` and `microB` roles (and, potentially, other microservice
    roles on other hosts), the difference could be of many minutes or more. Clustering
    the restarts at the end can reduce the interruption period significantly.
  prefs: []
  type: TYPE_NORMAL
- en: Running destructive tasks only once
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Destructive tasks come in many flavors. They can be one-way tasks that are extremely
    difficult to roll back, one-time tasks that cannot be rerun easily, or race-condition
    tasks that, if performed in parallel, would result in catastrophic failure. For
    these reasons and more, it is essential that these tasks be performed only once,
    from a single host. Ansible provides a mechanism to accomplish this by way of
    the `run_once` task control.
  prefs: []
  type: TYPE_NORMAL
- en: The `run_once` task control will ensure that the task only executes a single
    time from a single host, regardless of how many hosts happen to be in a play.
    While there are other methods to accomplish this goal, such as using a conditional
    statement to make the task execute only on the first host of a play, the `run_once`
    control is the most simple and direct way to express this wish. Additionally,
    any variable data registered from a task controlled by `run_once` will be made
    available to all hosts of the play, not just the host that was selected by Ansible
    to perform the action. This can simplify later retrieval of the variable data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create an example playbook to demonstrate this functionality. We''ll
    reuse our `failtest` hosts that were created in an earlier example, in order to
    have a pool of hosts, and we''ll select two of them by using a host pattern. We''ll
    create an `ansible.builtin.debug` task set to `run_once` and register the results,
    then we''ll access the results in a different task with a different host. The
    code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We run this play with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'When we do this, we''ll pay special attention to the hostnames listed for each
    task operation shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – Demonstrating the use of the run_once task parameter, and the
    availability of variable data from that task on other hosts in the play'
  prefs: []
  type: TYPE_NORMAL
- en: '](Images/B17462_11_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.8 – Demonstrating the use of the run_once task parameter, and the
    availability of variable data from that task on other hosts in the play
  prefs: []
  type: TYPE_NORMAL
- en: We can see that the `do a thing` task is executed on the `failer01` host, while
    the `what is groot` task, which examines the data from the `do a thing` task,
    operates on the `failer02` host. Of course, while you can reduce the risk of disruption
    to your production services using the techniques we have discussed here, there
    is even more we can do, such as limiting the number of times a task is run or
    the number of hosts it is run against. We will explore this very topic in the
    next section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Serializing single tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Certain applications that run multiple copies of a service may not react well
    to all of those services being restarted at once. Typically, when upgrading this
    type of application, a `serial` play is used. However, if the application is of
    a large enough scale, serializing the entire play may be wildly inefficient. A
    different approach can be used, which is to serialize only the sensitive tasks
    (often the handlers to restart services).
  prefs: []
  type: TYPE_NORMAL
- en: To serialize a specific handler task, we can make use of a built-in variable, `play_hosts`.
    This variable holds a list of hosts that should be used for a given task as a
    part of the play. It is kept up to date with hosts that have failed or are unreachable.
    Using this variable, we can construct a loop to iterate over each host that could
    potentially run a handler task. Instead of using the `item` value in the module
    arguments, we'll use the `item` value in a `when` conditional and a `delegate_to` directive.
    In this manner, handler tasks that get notified within the playbook can be delegated
    to a host in the aforementioned loop, rather than the original host. However,
    if we just use this as the list for a `loop` directive, we'll end up executing
    the task for every host that triggers a handler. That's obviously unwanted, so
    we can use a task directive, `run_once`, to change the behavior. The `run_once`
    directive instructs Ansible to only execute the task for one host, instead of
    for every host that it would normally target. Combining `run_once` and our loop
    of `play_hosts` creates a scenario where Ansible will run through the loop only
    once. Finally, we want to wait a small amount of time between each loop so that
    the restarted service can become functional before we restart the next one. We
    can make use of a `loop_control` parameter called `pause` (introduced in Ansible
    version 2.2) to insert a pause between each iteration of the loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'To demonstrate how this serialization will work, we''ll write a play using
    a few hosts from our `failtest` group, with a task that creates a change and registers
    the output so that we can check this output in the handler task we notify, called `restart
    groot`. We then create a serialized handler task itself at the bottom of the playbook.
    The code is illustrated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Upon execution of this playbook, we can see the handler notification (thanks
    to double verbosity using the following command):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'In the handler task, we can see the loop, conditional, and delegation, as the
    following screenshot shows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – A playbook with a serialized handler routing for the restart
    of services'
  prefs: []
  type: TYPE_NORMAL
- en: '](Images/B17462_11_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.9 – A playbook with a serialized handler routing for the restart of
    services
  prefs: []
  type: TYPE_NORMAL
- en: If you have tried this code out for yourself, you will notice the delay between
    each handler run, just as we specified in the `loop_control` part of the task.
    Using these techniques, you can confidently roll out updates and upgrades to your
    environment while keeping disruption to a minimum. It is hoped that this chapter
    has given you the tools and techniques to confidently perform such actions on
    your environment.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deployment and upgrade strategies are a matter of taste. Each strategy comes
    with distinct advantages and disadvantages. Ansible does not declare an opinion
    about which is better, and therefore it is well suited to perform deployments
    and upgrades regardless of the strategy. Ansible provides features and design
    patterns that facilitate a variety of styles with ease. Understanding the nature
    of each strategy and how Ansible can be tuned for that strategy will empower you
    to decide on and design deployments for each of your applications. Task controls
    and built-in variables provide methods to efficiently upgrade large-scale applications
    while treating specific tasks carefully.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you learned how to use Ansible to perform in-place upgrades
    and some different methodologies for these, including techniques such as expanding
    and contracting an environment. You learned about failing fast to ensure that
    playbooks don't cause extensive damage if an early part of a play goes wrong,
    and how to minimize both disruptive and destructive actions. Finally, you learned
    about serializing single tasks to minimize disruption to running services by taking
    nodes out of service in a minimal controlled manner. This ensures that services
    remain operational while maintenance work (such as an upgrade) occurs behind the
    scenes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll go into detail about using Ansible to work with cloud
    infrastructure providers and container systems in order to create an infrastructure
    to manage.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is a valid strategy for minimizing disruption when in-place upgrades are
    performed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Use the `serial` mode to alter how many hosts Ansible performs the upgrade
    on at one time.
  prefs: []
  type: TYPE_NORMAL
- en: b) Use the `limit` parameter to alter how many hosts Ansible performs the upgrade
    on at one time.
  prefs: []
  type: TYPE_NORMAL
- en: c) Have lots of small inventories, each with just a few hosts in.
  prefs: []
  type: TYPE_NORMAL
- en: d) Revoke access to the hosts by Ansible.
  prefs: []
  type: TYPE_NORMAL
- en: What is a key benefit of expanding and contracting as an upgrade strategy?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) Reduced cloud operating costs.
  prefs: []
  type: TYPE_NORMAL
- en: b) It fits well with a **development-operations** (**DevOps**) culture.
  prefs: []
  type: TYPE_NORMAL
- en: c) All hosts are newly built for each application deployment or upgrade, reducing
    the possibility of stale libraries and configurations.
  prefs: []
  type: TYPE_NORMAL
- en: d) It provides flexibility in your approach to upgrades.
  prefs: []
  type: TYPE_NORMAL
- en: Why would you want to fail fast?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) So that you know about your playbook errors as soon as possible.
  prefs: []
  type: TYPE_NORMAL
- en: b) So that you minimize the damage or disruption caused by a failed play.
  prefs: []
  type: TYPE_NORMAL
- en: c) So that you can debug your code.
  prefs: []
  type: TYPE_NORMAL
- en: d) So that you can be agile in your deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Which Ansible play option would you use to ensure that your play stops executing
    early in the event of errors on any single host?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `ansible.builtin.fail`
  prefs: []
  type: TYPE_NORMAL
- en: b) `any_errors_fatal`
  prefs: []
  type: TYPE_NORMAL
- en: 'c) `when: failed`'
  prefs: []
  type: TYPE_NORMAL
- en: 'd) `max_fail_percentage: 50`'
  prefs: []
  type: TYPE_NORMAL
- en: Which Ansible play option would you use to ensure that your play stops executing
    early in the event of errors on more than 30 percent of the hosts in your inventory?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `any_errors_fatal`
  prefs: []
  type: TYPE_NORMAL
- en: 'b) `max_fail_percentage: 30%`'
  prefs: []
  type: TYPE_NORMAL
- en: 'c) `max_fail_percentage: 30`'
  prefs: []
  type: TYPE_NORMAL
- en: 'd) `max_fail: 30%`'
  prefs: []
  type: TYPE_NORMAL
- en: Which play-level option can you specify to ensure that your handlers are run
    even if your play fails?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `handlers_on_fail`
  prefs: []
  type: TYPE_NORMAL
- en: b) `handlers_on_failure`
  prefs: []
  type: TYPE_NORMAL
- en: c) `always_handlers`
  prefs: []
  type: TYPE_NORMAL
- en: d) `force_handlers`
  prefs: []
  type: TYPE_NORMAL
- en: Why might you want to delay the running of handlers to the end of your play?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) It could save time on the execution of the play as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: b) It makes the operation more predictable.
  prefs: []
  type: TYPE_NORMAL
- en: c) It reduces the risk of downtime.
  prefs: []
  type: TYPE_NORMAL
- en: d) It might help increase your chances of a successful upgrade.
  prefs: []
  type: TYPE_NORMAL
- en: Which task-level parameter can you use to ensure that a task does not get executed
    more than once, even when you have multiple hosts in your inventory?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `task_once`
  prefs: []
  type: TYPE_NORMAL
- en: b) `run_once`
  prefs: []
  type: TYPE_NORMAL
- en: 'c) `limit: 1`'
  prefs: []
  type: TYPE_NORMAL
- en: 'd) `run: once`'
  prefs: []
  type: TYPE_NORMAL
- en: Which `loop_control` parameter can insert a delay between iterations of a loop
    in Ansible?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a) `pause`
  prefs: []
  type: TYPE_NORMAL
- en: b) `sleep`
  prefs: []
  type: TYPE_NORMAL
- en: c) `delay`
  prefs: []
  type: TYPE_NORMAL
- en: d) `wait_for`
  prefs: []
  type: TYPE_NORMAL
- en: Which task conditional could you use to ensure you only run a task on the first
    four hosts in an inventory?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'a) `when: inventory_hostname in play_hosts[0:3]`'
  prefs: []
  type: TYPE_NORMAL
- en: 'b) `when: inventory_hostname in play_hosts[1:4]`'
  prefs: []
  type: TYPE_NORMAL
- en: 'c) `when: inventory_hostname[0:3]`'
  prefs: []
  type: TYPE_NORMAL
- en: 'd) `when: play_hosts[0:3]`'
  prefs: []
  type: TYPE_NORMAL
