- en: Chapter 7. Python Extensions in Other Languages
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When writing Python-based applications, you are not limited to the Python language
    alone. There are tools such as Hy, mentioned briefly in [Chapter 3](ch03.html
    "Chapter 3. Syntax Best Practices – above the Class Level"), *Syntax Best Practices
    – above the Class Level*. It allows you to write modules, packages, or even whole
    applications with some other language (dialect of Lisp) that will run in Python
    virtual machine. Although it gives you the ability to express program logic with
    completely different syntax, it is still quite the same language because it compiles
    to the same bytecode. It means that it has the same limitations as ordinary Python
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: Threading usability is greatly reduced due to the existence of GIL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is not compiled
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It does not provide static typing and possible optimizations that come with
    it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The solution that helps in overcoming such core limitations are extensions that
    are entirely written in a different language and expose their interface through
    Python extension APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will discuss the main reasons for writing your own extensions
    in other languages and introduce you to the popular tools that help to create
    them. You will learn:'
  prefs: []
  type: TYPE_NORMAL
- en: How to write simple extensions in C using the Python/C API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do the same using Cython
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the main challenges and problems introduced by extensions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to interface with compiled dynamic libraries without creating dedicated
    extensions and using only Python code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different language means – C or C++
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we talk about extensions in different languages, we think almost exclusively
    about C and C++. Even tools such as Cython or Pyrex that provide Python language
    supersets only for the purpose of extensions are in fact source-to-source compilers
    that generate the C code from extended Python-like syntax.
  prefs: []
  type: TYPE_NORMAL
- en: It's true that you can use dynamic/shared libraries written in any language
    in Python if only such compilation is possible and so it goes a way beyond C and
    C++. But shared libraries are intrinsically generic. They can be used in any language
    that supports their loading. So, even if you write such a library in a completely
    different language (let's say Delphi or Prolog), it is hard to name such library
    a Python extension if it does not use the Python/C API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, writing your own extensions only in C or C++ using the bare
    Python/C API is quite demanding. Not only because it requires a good understanding
    of one of the two languages that are relatively hard to master, but also because
    it requires exceptional amount of boilerplate. There is a lot of repetitive code
    that must be written only to provide an interface that will glue your implemented
    logic with Python and its datatypes. Anyway, it is good to know how pure C extensions
    are built because:'
  prefs: []
  type: TYPE_NORMAL
- en: You will understand better how Python works in general
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One day you may need to debug or maintain a native C/C++ extension
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It helps with understanding how higher-level tools for building extensions work
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do extensions in C or C++ work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python interpreter is able to load extensions from dynamic/shared libraries
    if they provide an applicable interface using Python/C API. This API must be incorporated
    in source code of extension using the `Python.h` C header file that is distributed
    with Python sources. In many distributions of Linux, this header file is contained
    in a separate package (for example, `python-dev` in Debian/Ubuntu) but under Windows,
    it is distributed by default and can be found in the `includes/` directory of
    your Python installation.
  prefs: []
  type: TYPE_NORMAL
- en: Python/C API traditionally changes with every release of Python. In most cases,
    these are only additions of new features to the API, so it is typically source-compatible.
    Anyway, in most cases, they are not binary compatible due to changes in the **Application
    Binary Interface** (**ABI**). This means that extensions must be built separately
    for every version of Python. Note also that different operating systems have noncompatible
    ABIs, so this makes it practically impossible to create a binary distribution
    for every possible environment. This is the reason why most Python extensions
    are distributed in source form.
  prefs: []
  type: TYPE_NORMAL
- en: Since Python 3.2, a subset of Python/C API has been defined to have stable ABIs.
    It is possible then to build extensions using this limited API (with a stable
    ABI), so extensions can be built only once and will work with any version of Python
    higher than or equal to 3.2 without the need for recompilation. Anyway, this limits
    the amount of API features and does not solve the problems of older Python versions
    or the distribution of the extension in binary form to environments using different
    operating systems. So this is a trade-off, and price of the stable ABI seems to
    be a bit high for very low gain.
  prefs: []
  type: TYPE_NORMAL
- en: One thing you need to know is that Python/C API is a feature that is limited
    to CPython implementations. Some efforts were made to bring extension support
    to alternative implementations such as PyPI, Jython, or IronPython, but it seems
    that there is no viable solution for them at the moment. The only alternative
    Python implementation that should deal easily with extensions is Stackless Python
    because it is in fact only a modified version of CPython.
  prefs: []
  type: TYPE_NORMAL
- en: 'C extensions for Python need to be compiled into shared/dynamic libraries before
    they will be available to use because obviously there is no native way to import
    C/C++ code into Python directly from sources. Fortunately, `distutils` and `setuptools`
    provide helpers to define compiled extensions as modules so compilation and distribution
    can be handled using the `setup.py` script as if they were ordinary Python packages.
    This is an example of the `setup.py` script from the official documentation that
    handles the packaging of simple packages with built extensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once prepared that way, there is one additional step required in your distribution
    flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This will compile all your extensions provided as the `ext_modules` argument
    according to all additional compiler settings provided with the `Extension()`
    call. The compiler that will be used is the one that is default for your environment.
    This compilation step is not required if the package is going to be distributed
    with source distribution. In that case, you need to be sure that the target environment
    has all compilation prerequisites, such as a compiler, header files, and additional
    libraries that are going to be linked to the binary (if your extension needs any).
    More details of packaging the Python extensions will be explained later in the
    *Challenges* section.
  prefs: []
  type: TYPE_NORMAL
- en: Why you might want to use extensions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It''s not easy to say when it is a reasonable decision to write extensions
    in C/C++. The general rule of thumb could be, *never, unless you have no other
    choice*. But this is a very subjective statement that leaves a lot of room for
    interpretation of what is not doable in Python. In fact, it is hard to find a
    thing that cannot be done using pure Python code, but there are some problems
    where extensions may be especially useful:'
  prefs: []
  type: TYPE_NORMAL
- en: Bypassing **GIL** (**Global Interpreter Lock**) in the Python threading model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improving performance in critical code sections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating third-party dynamic libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating source code written in different languages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating custom datatypes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, the core language constraints such as GIL can easily be overcome
    with a different approach to concurrency, such as green threads or multiprocessing
    instead of a threading model.
  prefs: []
  type: TYPE_NORMAL
- en: Improving performance in critical code sections
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's be honest. Python is not chosen by developers because of performance.
    It does not execute quickly, but allows you to develop quickly. Still, no matter
    how performant we are as programmers, thanks to this language, we may sometimes
    find a problem that may not be solved efficiently using pure Python.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, solving performance problems is really only about choosing proper
    algorithms and data structures and not about limiting the constant factor of language
    overhead. And it is not actually a good solution to rely on extensions in order
    to shave off some CPU cycles if the code is already written poorly or does not
    use proper algorithms. It is often possible that performance can be improved to
    an acceptable level without the need to increase the complexity of your project
    by looping in another language to the stack. And if it is possible, it should
    be done that way in the first place. Anyway, it is also very likely that even
    with *state of the art* algorithmic approach and the best suited data structures
    that are available to our disposal, we will not be able to fit some arbitrary
    technological constraints using Python alone.
  prefs: []
  type: TYPE_NORMAL
- en: 'The example field that puts some well-defined limits on the application''s
    performance is the **Real Time Bidding** (**RTB**) business. In short, the whole
    RTB is about buying and selling advertisement inventory (places for ads) in a
    way similar to real auctions or stock exchanges. The trading usually takes place
    through some ad exchange service that sends information about available inventory
    to **demand-side platforms** (**DSP**) interested in buying them. And this is
    the place where things get exciting. Most ad exchanges use the OpenRTB protocol
    (which is based on HTTP) for communication with potential bidders where DSP is
    the site responsible for serving responses to its HTTP requests. And ad exchanges
    always put very limited time constraints (usually between 50 and 100 ms) on the
    whole process—from the first TPC packet received to the last byte written by the
    server. To spice things up, it is not uncommon for DSP platforms to process tens
    of thousands of requests per second. Being able to push the time of request processing
    even by a few milliseconds is the *to be or not to be* in this business. This
    means that porting even trivial code to C may be reasonable in that situation
    but only if it''s a part of some performance bottleneck and cannot be improved
    any further algorithmically. As someone once said:'
  prefs: []
  type: TYPE_NORMAL
- en: '*"You can''t beat a loop written in C."*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Integrating existing code written in different languages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A lot of useful libraries have been written during the short history of computer
    science. It would be a great loss to forget about all that heritage every time
    a new programming language pops out, but it is also impossible to reliably port
    any piece of software that was ever written to any available language.
  prefs: []
  type: TYPE_NORMAL
- en: The C and C++ languages seem to be the most important languages that provide
    a lot of libraries and implementation that you would like to integrate in your
    application code without the need to port them completely to Python. Fortunately,
    CPython is already written in C, so the most natural way to integrate such code
    is precisely through custom extensions.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating third-party dynamic libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Integration of code written using different technologies does not end with C/C++.
    A lot of libraries, especially third-party software with closed sources, are distributed
    as compiled binaries. In C, it is really easy to load such shared/dynamic libraries
    and call their functions. This means that you can use any C library as long as
    you wrap it with extensions using Python/C API.
  prefs: []
  type: TYPE_NORMAL
- en: This, of course, is not the only solution and there are tools such as `ctypes`
    or CFFI that allow you to interact with dynamic libraries using pure Python without
    the need of writing extensions in C. Very often, the Python/C API may still be
    a better choice because it provides a better separation between the integration
    layer (written in C) and the rest of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Creating custom datatypes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python provides a very versatile selection of built-in datatypes. Some of them
    really use state of the art internal implementations (at least in CPython) that
    are specifically tailored for usage in the Python language. The number of basic
    types and collections available out-of-the-box may look impressive for newcomers,
    but it is clear that it does not cover all of our possible needs.
  prefs: []
  type: TYPE_NORMAL
- en: You can, of course, create many custom data structures in Python either by basing
    them completely on some built-in types or by building them from scratch as completely
    new classes. Unfortunately, for some applications that may heavily rely on such
    custom data structures, the performance might not be enough. The whole power of
    complex collections such as `dict` or `set` comes from their underlying C implementation.
    Why not do the same and implement some of your custom data structures in C too?
  prefs: []
  type: TYPE_NORMAL
- en: Writing extensions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As already said, writing extensions is not a simple task but in exchange for
    your hard work, it can give you a lot of advantages. The easiest and recommended
    approach to your own extensions is to use tools such as Cython or Pyrex or simply
    integrate the existing dynamic libraries with `ctypes` or `cffi`. These projects
    will increase your productivity and also make code easier to develop, read, and
    maintain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyway, if you are new to this topic, it is good to know that you can start
    your adventure with extensions by writing one using nothing more than bare C code
    and Python/C API. This will improve your understanding of how extensions work
    and will also help you to appreciate the advantages of alternative solutions.
    For the sake of simplicity, we will take a simple algorithmic problem as an example
    and try to implement it using three different approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Writing a pure C extension
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Cython
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Pyrex
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our problem will be finding the *nth* number of the Fibonacci sequence. It
    is very unlikely that you would like to create compiled extensions solely for
    this problem, but it is very simple so it will serve as a very good example of
    wiring any C function to Python/C APIs. Our only goals are clarity and simplicity,
    so we won''t try to provide the most efficient solution. Once we know this, our
    reference implementation of the Fibonacci function implemented in Python looks
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Note that this is one of the most simple implementations of the `fibonnaci()`
    function and a lot of improvements could be applied to it. We refuse to improve
    our implementation (using a memoization pattern, for instance) though because
    this is not the purpose of our example. In the same manner, we won't optimize
    our code later when discussing implementations in C or Cython even though the
    compiled code gives many more possibilities to do so.
  prefs: []
  type: TYPE_NORMAL
- en: Pure C extensions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we fully dive into the code examples of Python extensions written in
    C, here is a huge warning. If you want to extend Python with C, you need to already
    know both of these languages well. This is especially true for C. Lack of proficiency
    with it can lead to real disasters because it can be easily mishandled.
  prefs: []
  type: TYPE_NORMAL
- en: If you have decided that you need to write C extension for Python, I assume
    that you already know the C language to a level that will allow you to fully understand
    the examples that are presented. Nothing other than Python/C API details will
    be explained here. This book is about Python and not any other language. If you
    don't know C at all, you should definitely not try to write your own Python extensions
    in C until you gain enough experience and skills. Leave it to others and stick
    with Cython or Pyrex because they are a lot safer from the beginner's perspective.
    This is mostly because Python/C API, despite having been crafted with great care,
    is definitely not a good introduction to C.
  prefs: []
  type: TYPE_NORMAL
- en: 'As proposed earlier, we will try to port the `fibonacci()` function to C and
    expose it to Python code as an extension. The bare implementation without the
    wiring to Python/C API that is analogous to the previous Python example could
    be roughly as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is the example of a complete, fully functional extension that exposes
    this single function in a compiled module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding example might be a bit overwhelming at first glance because we
    had to add four times more code just to make the `fibonacci()` C function accessible
    from Python. We will discuss every bit of that code later, so don''t worry. But
    before we do that, let''s see how it can be packaged and executed in Python. The
    minimal `setuptools` configuration for our module needs to use the `setuptools.Extension`
    class in order to instruct the interpreter how our extension is compiled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The build process for the extension can be initialized with Python''s `setup.py`
    build command, but will also be automatically performed on package installation.
    The following transcript presents the result of installation in development mode
    and a simple interactive session where our compiled `fibonacci()` function is
    inspected and executed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: A closer look at Python/C API
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since we know how to properly package, compile, and install custom C extensions
    and we are sure that it works as expected, now it is the right time to discuss
    our code in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'The extensions module starts with a single C preprocessor directive that includes
    the `Python.h` header file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This pulls the whole Python/C API and is everything you need to include to be
    able to write your extensions. In more realistic cases, your code will require
    a lot more preprocessor directives to take benefit from C standard library functions
    or to integrate other source files. Our example was simple, so no more directives
    were required.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next we have the core of our module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The preceding `fibonacci()` function is the only part of our code that does
    something useful. It is pure C implementation that Python by default can't understand.
    The rest of our example will create the interface layer that will expose it through
    Python/C API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step of exposing this code to Python is the creation of the C function
    that is compatible with the CPython interpreter. In Python, everything is an object.
    This means that C functions called in Python also need to return real Python objects.
    Python/C APIs provide a `PyObject` type and every callable must return the pointer
    to it. The signature of our function is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the preceding signature does not specify the exact list of arguments
    but only `PyObject* args` that will hold the pointer to the structure that contains
    the tuple of the provided values. The actual validation of the argument list must
    be performed inside of the function body and this is exactly what `fibonacci_py()`
    does. It parses the `args` argument list assuming it is the single `unsigned int`
    type and uses that value as an argument to the `fibonacci()` function to retrieve
    the Fibonacci sequence element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The preceding example function has some serious bugs, which the eyes of an experienced
    developer should spot very easily. Try to find it as an exercise in working with
    C extensions. For now, we leave it as it is for the sake of brevity. We will try
    to fix it later when discussing details of dealing with errors in the *Exception
    handling* section.
  prefs: []
  type: TYPE_NORMAL
- en: The `"l"` string in the `PyArg_ParseTuple(args, "l", &n)` call means that we
    expect `args` to contain only a single `long` value. In case of failure, it will
    return `NULL` and store information about the exception in the per-thread interpreter
    state. The details of exception handling will be described a bit later in the
    *Exception handling* section.
  prefs: []
  type: TYPE_NORMAL
- en: The actual signature of the parsing function is `int PyArg_ParseTuple(PyObject
    *args, const char *format, ...)` and what goes after the `format` string is a
    variable length list of arguments that represents parsed value output (as pointers).
    This is analogous to how the `scanf()` function from the C standard library works.
    If our assumption fails and the user provides an incompatible arguments list,
    then `PyArg_ParseTuple()` will raise the proper exception. This is a very convenient
    way to encode function signatures once you get used to it but has a huge downside
    when compared to plain Python code. Such Python call signatures implicitly defined
    by the `PyArg_ParseTuple()` calls cannot be easily inspected inside of the Python
    interpreter. You need to remember this fact when using code provided as extensions.
  prefs: []
  type: TYPE_NORMAL
- en: As already said, Python expects objects to be returned from callables. This
    means that we cannot return a raw `long long` value obtained from the `fibonacci()`
    function as a result of `fibonacci_py()`. Such an attempt would not even compile
    and there is no automatic casting of basic C types to Python objects. The `Py_BuildValue(*format,
    ...)` function must be used instead. It is the counterpart of `PyArg_ParseTuple()`
    and accepts a similar set of format strings. The main difference is that the list
    of arguments is not a function output but an input, so actual values must be provided
    instead of pointers.
  prefs: []
  type: TYPE_NORMAL
- en: After `fibonacci_py()` is defined, most of the heavy work is done. The last
    step is to perform module initialization and add metadata to our function that
    will make usage a bit simpler for users. This is the boilerplate part of our extension
    code that for some simple examples, such as this one, can take more place than
    actual functions that we want to expose. In most cases, it simply consists of
    some static structures and one initialization function that will be executed by
    the interpreter on module import.
  prefs: []
  type: TYPE_NORMAL
- en: 'At first, we create a static string that will be a content of Python docstring
    for the `fibonacci_py()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Note that this could be *inlined* somewhere later in `fibonacci_module_methods`,
    but it is a good practice to have docstrings separated and stored in close proximity
    to the actual function definition that they refer to.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next part of our definition is the array of the `PyMethodDef` structures
    that define methods (functions) that will be available in our module. This structure
    contains exactly four fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`char* ml_name`: This is the name of the method.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PyCFunction ml_meth`: This is the pointer to the C implementation of the function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`int ml_flags`: This includes the flags indicating either the calling convention
    or binding convention. The latter is applicable only for definition of class methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`char* ml_doc`: This is the pointer to the content of method/function docstring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Such an array must always end with a sentinel value of `{NULL, NULL, 0, NULL}`
    that indicates its end. In our simple case, we created the `static PyMethodDef
    fibonacci_module_methods[]` array that contains only two elements (including the
    sentinel value):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'And this is how the first entry maps to the `PyMethodDef` structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ml_name = "fibonacci"`: Here, the `fibonacci_py()` C function will be exposed
    as a Python function under the `fibonacci` name'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ml_meth = (PyCFunction)fibonacci_py`: Here, the casting to `PyCFunction` is
    simply required by Python/C API and is dictated by the call convention defined
    later in `ml_flags`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ml_flags = METH_VARARGS`: Here, the `METH_VARARGS` flag indicates that the
    calling convention of our function accepts a variable list of arguments and no
    keyword arguments'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ml_doc = fibonacci_docs`: Here, the Python function will be documented with
    the content of the `fibonacci_docs` string'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When an array of function definitions is complete, we can create another structure
    that contains the definition of the whole module. It is described using the `PyModuleDef`
    type and contains multiple fields. Some of them are useful only for more complex
    scenarios, where fine-grained control over the module initialization process is
    required. Here we are interested only in the first five of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '`PyModuleDef_Base m_base`: This should always be initialized with `PyModuleDef_HEAD_INIT`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`char* m_name`: This is the name of the newly created module. In our case it
    is `fibonacci`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`char* m_doc`: This is the pointer to the docstring content for the module.
    We usually have only a single module defined in one C source file, so it is OK
    to inline our documentation string in the whole structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Py_ssize_t m_size`: This is the size of the memory allocated to keep the module
    state. This is only used when support for multiple subinterpreters or multiphase
    initialization is required. In most cases, you don''t need that and it is gets
    the value `-1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PyMethodDef* m_methods`: This is a pointer to the array containing module-level
    functions described by the `PyMethodDef` values. It could be `NULL` if the module
    does not expose any functions. In our case, it is `fibonacci_module_methods`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The other fields are explained in detail in the official Python documentation
    (refer to [https://docs.python.org/3/c-api/module.html](https://docs.python.org/3/c-api/module.html))
    but are not needed in our example extension. They should be set to `NULL` if not
    required and they will be initialized with that value implicitly when not specified.
    This is why our module description contained in the `fibonacci_module_definition`
    variable can take this simple five-element form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The last piece of code that crowns our work is the module initialization function.
    This must follow a very specific naming convention, so the Python interpreter
    can easily pick it when the dynamic/shared library is loaded. It should be named
    `PyInit_name`, where *name* is your module name. So it is exactly the same string
    that was used as the `m_base` field in the `PyModuleDef` definition and as the
    first argument of the `setuptools.Extension()` call. If you don''t require a complex
    initialization process for the module, it takes a very simple form, exactly like
    in our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The `PyMODINIT_FUNC` macro is a preprocessor macro that will declare the return
    type of this initialization function as `PyObject*` and add any special linkage
    declarations if required by the platform.
  prefs: []
  type: TYPE_NORMAL
- en: Calling and binding conventions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As explained in the *A closer look at Python/C API* section, the `ml_flags`
    bitfield of the `PyMethodDef` structure contains flags for calling and binding
    conventions. **Calling convention flags** are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`METH_VARARGS`: This is a typical convention for the Python function or method
    that only accepts arguments as its parameters. The type provided as the `ml_meth`
    field for such a function should be `PyCFunction`. The function will be provided
    with two arguments of the `PyObject*` type. The first is either the `self` object
    (for methods) or the `module` object (for module functions). A typical signature
    for the C function with that calling convention is `PyObject* function(PyObject*
    self, PyObject* args)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`METH_KEYWORDS`: This is the convention for the Python function that accepts
    keyword arguments when called. Its associated C type is `PyCFunctionWithKeywords`.
    The C function must accept three arguments of the `PyObject*` type: `self`, `args`,
    and a dictionary of keyword arguments. If combined with `METH_VARARGS`, the first
    two arguments have the same meaning as for the previous calling convention, otherwise
    `args` will be `NULL`. The typical C function signature is: `PyObject* function(PyObject*
    self, PyObject* args, PyObject* keywds)`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`METH_NOARGS`: This is the convention for Python functions that do not accept
    any other argument. The C function should be of the `PyCFunction` type, so the
    signature is the same as that of the `METH_VARARGS` convention (two `self` and
    `args` arguments). The only difference is that `args` will always be `NULL`, so
    there is no need to call `PyArg_ParseTuple()`. This cannot be combined with any
    other calling convention flag.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`METH_O`: This is the shorthand for functions and methods accepting single
    object arguments. The type of C function is again `PyCFunction`, so it accepts
    two `PyObject*` arguments: `self` and `args`. Its difference `from METH_VARARGS`
    is that there is no need to call `PyArg_ParseTuple()` because `PyObject*` provided
    as `args` will already represent the single argument provided in the Python call
    to that function. This also cannot be combined with any other calling convention
    flag.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A function that accepts keywords is described either with `METH_KEYWORDS` or
    a bitwise combination of calling convention flags in the form of `METH_VARARGS
    |` `METH_KEYWORDS`. If so, it should parse its arguments with `PyArg_ParseTupleAndKeywords()`
    instead of `PyArg_ParseTuple()` or `PyArg_UnpackTuple()`. Here is an example module
    with a single function that returns `None` and accepts two named keyword arguments
    that are printed on standard output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Argument parsing in Python/C API is very elastic and is extensively described
    in the official documentation at [https://docs.python.org/3.5/c-api/arg.html](https://docs.python.org/3.5/c-api/arg.html).
    The format argument in `PyArg_ParseTuple()` and `PyArg_ParseTupleAndKeywords()`
    allows fine grained control over argument number and types. Every advanced calling
    convention known in Python can be coded in C with this API including:'
  prefs: []
  type: TYPE_NORMAL
- en: Functions with default values for arguments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions with arguments specified as keyword-only
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Functions with a variable number of arguments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **binding convention flags** are `METH_CLASS`, `METH_STATIC`, and `METH_COEXIST`,
    are reserved for methods, and cannot be used to describe module functions. The
    first two are quite self-explanatory. They are the C counterparts of `classmethod`
    and `staticmethod` decorators and change the meaning of the `self` argument passed
    to the C function.
  prefs: []
  type: TYPE_NORMAL
- en: '`METH_COEXIST` allows loading a method in place of the existing definition.
    It is useful very rarely. This is mostly when you would like to provide an implementation
    of the C method that would be generated automatically from the other features
    of the type that was defined. Python documentation gives an example of the `__contains__()`
    wrapper method that would be generated if the type has the `sq_contains` slot
    defined. Unfortunately, defining your own classes and types using Python/C API
    is beyond the scope of this introductory chapter. We will cover creating your
    own types in extensions later when discussing Cython because doing that in pure
    C requires way too much boilerplate code and leaves a lot of room for making mistakes.'
  prefs: []
  type: TYPE_NORMAL
- en: Exception handling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: C, unlike Python, or even C++ does not have syntax for raising and catching
    exceptions. All error handling is usually handled with function return values
    and optional global state for storing details that can explain the cause of the
    last failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exception handling in Python/C API is built around that simple principle. There
    is a global per thread indicator of the last error that occurred and functioned
    in the C API. It is set to describe the cause of a problem. There is also a standardized
    way to inform the caller of a function if this state was changed during the call:'
  prefs: []
  type: TYPE_NORMAL
- en: If the function is supposed to return a pointer, it returns `NULL`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the function is supposed to return an `int` type, it returns `-1`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The only exceptions from the preceding rules in Python/C API are the `PyArg_*()`
    functions that return `1` to indicate success and `0` to indicate failure.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see how this works in practice, let''s recall our `fibonacci_py()` function
    from the example in the previous sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Lines that somehow take part in our error handling are highlighted. It starts
    at the very beginning with the initialization of the `result` variable that is
    supposed to store the return value of our function. It is initialized with `NULL`
    that, as we already know, is an indicator of error. And this is how you will usually
    code your extensions, assuming that error is the default state of your code.
  prefs: []
  type: TYPE_NORMAL
- en: Later we have the `PyArg_ParseTuple()` call that will set error info in case
    of an exception and return `0`. This is part of the `if` statement and in that
    case we don't do anything more and return `NULL`. Whoever calls our function will
    be notified about the error.
  prefs: []
  type: TYPE_NORMAL
- en: '`Py_BuildValue()` can also raise an exception. It is supposed to return `PyObject*`
    (pointer), so in case of failure it gives `NULL`. We can simply store it as our
    result variable and pass further as a return value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'But our job does not end with caring for exceptions raised by Python/C API
    calls. It is very probable that you will need to inform the extension user that
    some other kind of error or failure occurred. Python/C API has multiple functions
    that help you to raise an exception, but the most common one is `PyErr_SetString()`.
    It sets an error indicator with the given exception type with an additional string
    provided as the error cause explanation. The full signature of this function is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'I have already said that implementation of our `fibonacci_py()` function has
    serious bug. Now is the right time to fix it. Fortunately, we have proper tools
    to do that. The problem lies in insecure casting of the `long` type to `unsigned
    int` in the following lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Thanks to the `PyArg_ParseTuple()` call, the first and only argument will be
    interpreted as a `long` type (the `"l"` specifier) and stored in the local `n`
    variable. Then it is cast to `unsigned int` so the issue will occur if the user
    calls the `fibonacci()` function from Python with a negative value. For instance,
    `-1`, as a signed 32-bit integer, will be interpreted as `4294967295` when cast
    to an unsigned 32-bit integer. Such a value will cause deep recursion and will
    result in stack overflow and a segmentation fault. Note that the same may happen
    if the user gives an arbitrarily large positive argument. We cannot fix this without
    a complete redesign of the C `fibonacci()` function, but we can at least try to
    ensure that argument that is passed meets some preconditions. Here we check if
    the value of the `n` argument is greater than or equal to zero and we raise a
    `ValueError` exception if that''s not true:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The last note is that the global error state does not clear by itself. Some
    of the errors can be handled gracefully in your C functions (same as using the
    `try ... except` clause in Python) and you need to be able to clear the error
    indicator if it is no longer valid. The function for that is `PyErr_Clear()`.
  prefs: []
  type: TYPE_NORMAL
- en: Releasing GIL
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I have already mentioned that extensions can be a way to bypass Python GIL.
    There is a famous limitation of the CPython implementation stating that only one
    thread at a time can execute Python code. While multiprocessing is the suggested
    approach to circumvent this problem, it may not be a good solution for some highly
    parallelizable algorithms due to the resource overhead of running additional processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because extensions are mostly used in cases where a bigger part of the work
    is performed in pure C without any calls to Python/C API, it is possible (even
    advisable) to release GIL in some application sections. Thanks to this, you can
    still benefit from having multiple CPU cores and multithreaded application design.
    The only thing you need to do is to wrap blocks of code that are known to not
    use any of Python/C API calls or Python structures with specific macros provided
    by Python/C API. These two preprocessor macros are provided to simplify the whole
    procedure of releasing and reacquiring the Global Interpreter Lock:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Py_BEGIN_ALLOW_THREADS`: This declares the hidden local variable where the
    current thread state is saved and it releases GIL'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Py_END_ALLOW_THREADS`: This reacquires GIL and restores the thread state from
    the local variable declared with the previous macro'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When we look carefully at our `fibonacci` extension example, we can clearly
    see that the `fibonacci()` function does not execute any Python code and does
    not touch any of the Python structures. This means that the `fibonacci_py()` function
    that simply wraps the `fibonacci(n)` execution could be updated to release GIL
    around that call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Reference counting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, we come to the important topic of memory management in Python. Python
    has its own garbage collector, but it is designed only to solve the issue of cyclic
    references in the **reference counting** algorithm. Reference counting is the
    primary method of managing the deallocation of objects that are no longer needed.
  prefs: []
  type: TYPE_NORMAL
- en: Python/C API documentation introduces an *ownership of references* to explain
    how it deals with deallocation of objects. Objects in Python are never owned and
    they are always shared. The actual creation of objects is managed by Python's
    memory manager. It is the component of CPython interpreter that is responsible
    for allocating and deallocating memory for objects that are stored in a private
    heap. What can be owned instead is a reference to the object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Every object in Python that is represented by a reference (`PyObject*` pointer)
    has an associated reference count. When it goes to zero, it means that no one
    holds any valid reference to the object and the deallocator associated with its
    type can be called. Python/C API provides two macros for increasing and decreasing
    reference counts: `Py_INCREF()`, and `Py_DECREF()`. But before we discuss their
    details, we need to understand a few more terms related to reference ownership:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Passing of ownership**: Whenever we say that the function *passes the ownership*
    over a reference, it means that it has already increased the reference count and
    it is the responsibility of the caller to decrease the count when the reference
    to the object is no longer needed. Most of the functions that return the newly
    created objects, such as `Py_BuildValue`, do that. If that object is going to
    be returned from our function to another caller, then the ownership is passed
    again. We do not decrease the reference count in that case because it is no longer
    our responsibility. This is why the `fibonacci_py()` function does not call `Py_DECREF()`
    on the `result` variable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Borrowed references**: The *borrowing* of references happens when the function
    receives a reference to some Python object as an argument. The reference count
    for such a reference should never be decreased in that function unless it was
    explicitly increased in its scope. In our `fibonacci_py()` function the `self`
    and `args` arguments are such borrowed references and thus we do not call `PyDECREF()`
    on them. Some of the Python/C API functions may also return borrowed references.
    The notable examples are `PyTuple_GetItem()` and `PyList_GetItem()`. It is often
    said that such references are *unprotected*. There is no need to dispose of its
    ownership unless it will be returned as a function''s return value. In most cases,
    extra care should be taken if we use such borrowed references as arguments of
    other Python/C API calls. It may be necessary in some circumstances to additionally
    protect such references with additional `Py_INCREF()` before using as argument
    to other function and then calling `Py_DECREF()` when it is no longer needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stolen references**: It is also possible for the Python/C API function to
    *steal* the reference instead of *borrowing* it when provided as a call argument.
    This is the case of exactly two functions: `PyTuple_SetItem()` and `PyList_SetItem()`.
    They fully take over the responsibility of the reference passed to them. They
    do not increase the reference count by themselves but will call `Py_DECREF()`
    when the reference is no longer needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping an eye on the reference counts is one of the hardest things when writing
    complex extensions. Some of the not-so-obvious issues may not be noticed until
    the code is run in a multithreaded setup.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other common problem is caused by the very nature of Python''s object model
    and the fact that some functions return borrowed references. When the reference
    count goes to zero, the deallocation function is executed. For user-defined classes,
    it is possible to define a `__del__()` method that will be called at that moment.
    This can be any Python code and it is possible that it will affect other objects
    and their reference counts. The official Python documentation gives the following
    example of code that may be affected by this problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: It looks completely harmless, but the problem is in fact that we cannot know
    what elements the `list` object contains. When `PyList_SetItem()` sets a new value
    on the `list[1]` index, the ownership of the object that was previously stored
    at that index is disposed. If it was the only existing reference, the reference
    count will become 0 and the object will become deallocated. It is possible that
    it was some user-defined class with a custom implementation of the `__del__()`
    method. A serious issue will occur if in the result of such a `__del__()` execution
    `item[0]` will be removed from the list. Note that `PyList_GetItem()` returns
    a *borrowed* reference! It does not call `Py_INCREF()` before returning a reference.
    So in that code, it is possible that `PyObject_Print()` will be called with a
    reference to an object that no longer exists. This will cause a segmentation fault
    and crash the Python interpreter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The proper approach is to protect borrowed references for the whole time we
    need them because there is a possibility that any call in-between may cause deallocation
    of any other object—even if they are seemingly unrelated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Cython
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cython is both an optimizing static compiler and the name of a programming language
    that is a superset of Python. As a compiler, it can perform *source to source*
    compilation of native Python code and its Cython dialect to Python C extensions
    using Python/C API. It allows you to combine the power of Python and C without
    the need to manually deal with Python/C API.
  prefs: []
  type: TYPE_NORMAL
- en: Cython as a source to source compiler
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For extensions created using Cython, the major advantage you will get is using
    the superset language that it provides. Anyway, it is possible to create extensions
    from plain Python code using *source to source* compilation. This is the simplest
    approach to Cython because it requires almost no changes to the code and can give
    some significant performance improvements at a very low development cost.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cython provides a simple `cythonize` utility function that allows you to easily
    integrate the compilation process with `distutils` or `setuptools`. Let''s assume
    that we would like to compile a pure Python implementation of our `fibonacci()`
    function to a C extension. If it is located in the `fibonacci` module, the minimal
    `setup.py` script could be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Cython used as a source compilation tool for the Python language has another
    benefit. Source to source compilation to extensions can be a fully optional part
    of source distribution installation process. If the environment where the package
    needs to be installed does not have Cython or any other building prerequisites,
    it can be installed as a normal *pure Python* package. The user should not notice
    any functional difference in the behavior of code distributed that way.
  prefs: []
  type: TYPE_NORMAL
- en: 'A common approach for distributing extensions built with Cython is to include
    both Python/Cython sources and C code that would be generated from these source
    files. This way the package can be installed in three different ways depending
    on the existence of building prerequisites:'
  prefs: []
  type: TYPE_NORMAL
- en: If the installation environment has Cython available, the extension C code is
    generated from the Python/Cython sources that are provided
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If Cython is not available but there are available building prerequisites (C
    compiler, Python/C API headers), the extension is built from distributed pre-generated
    C files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If neither of the preceding prerequisites is available but the extension is
    created from pure Python sources, the modules are installed like ordinary Python
    code, and the compilation step is skipped
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note that Cython documentation says that including generated C files as well
    as Cython sources is the recommended way of distributing Cython extensions. The
    same documentation says that Cython compilation should be disabled by default
    because the user may not have the required version of Cython in his environment
    and this may result in unexpected compilation issues. Anyway, with the advent
    of environment isolation, this seems to be a less worrying problem today. Also,
    Cython is a valid Python package that is available on PyPI, so it can easily be
    defined as your project requirement in a specific version. Including such a prerequisite
    is, of course, a decision with serious implications and should be considered very
    carefully. The safer solution is to leverage the power of the `extras_require`
    feature in the `setuptools` package and allow the user to decide whether he wants
    to use Cython with a specific environment variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The `pip` installation tool supports the installation of packages with the
    *extras* option by adding the `[extra-name]` suffix to the package name. For the
    preceding example, the optional Cython requirement and compilation during the
    installation from local sources can be enabled using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Cython as a language
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cython is not only a compiler but also a superset of the Python language. Superset
    means that any valid Python code is allowed and it can be further updated with
    additional features, such as support for calling C functions or declaring C types
    on variables and class attributes. So any code written in Python is also written
    in Cython. This explains why ordinary Python modules can be so easily compiled
    to C using the Cython compiler.
  prefs: []
  type: TYPE_NORMAL
- en: But we won't stop on that simple fact. Instead of saying that our reference
    `fibonacci()` function is also code for valid extensions in this superset of Python,
    we will try to improve it a bit. This won't be any real optimization to our function
    design but some minor updates that will allow it to benefit from being written
    in Cython.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cython sources use a different file extension. It is `.pyx` instead of `.py`.
    Let''s assume that we still want to implement our Fibbonacci sequence. The content
    of `fibonacci.pyx` might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the only thing that has really changed is the signature of
    the `fibonacci()` function. Thanks to optional static typing in Cython, we can
    declare the `n` argument as `unsigned int`, and this should slightly improve the
    way our function works. Additionally, it does a lot more than we did previously
    when writing extensions by hand. If the argument of the Cython function is declared
    with a static type, then the extension will automatically handle conversion and
    overflow errors by raising proper exceptions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: We already know that Cython compiles only *source to source* and the generated
    code uses the same Python/C API that we would use when writing C code for extensions
    by hand. Note that `fibonacci()` is a recursive function, so it calls itself very
    often. This will mean that although we declared a static type for input argument,
    during the recursive call it will treat itself like any other Python function.
    So `n-1` and `n-2` will be packed back into the Python object and then passed
    to the hidden wrapper layer of the internal `fibonacci()` implementation that
    will again bring it back to the `unsigned int` type. This will happen again and
    again until we reach the final depth of recursion. This is not necessarily a problem
    but involves a lot more argument processing than really required.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can cut off the overhead of Python function calls and argument processing
    by delegating more of the work to a pure C function that does not know anything
    about Python structures. We did this previously when creating C extensions with
    pure C and we can do that in Cython too. We can use the `cdef` keyword to declare
    C-style functions that accept and return only C types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'We can go even further. With a plain C example, we finally showed how to release
    GIL during the call of our pure C function, so the extension was a bit nicer for
    multithreaded applications. In previous examples, we have used `Py_BEGIN_ALLOW_THREADS`
    and `Py_END_ALLOW_THREADS` preprocessor macros from Python/C API headers to mark
    section of code as free from Python calls. The Cython syntax is a lot shorter
    and easier to remember. GIL can be released around the section of code using a
    simple `with nogil` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also mark the whole C style function as safe to call without GIL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: It is important to know that such functions cannot have Python objects as arguments
    or return types. Whenever a function marked as `nogil` needs to perform any Python/C
    API call, it must acquire GIL using the `with gil` statement.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be honest, I started my adventure with Python only because I was tired of
    all the difficulty of writing software in C and C++. In fact, it is very common
    that programmers start to learn Python when they realize that other languages
    do not deliver what the users need. Programming in Python, when compared to C,
    C++, or Java, is a breeze. Everything seems to be simple and well designed. You
    might think that there are no places where you can trip and there are no other
    programming languages required anymore.
  prefs: []
  type: TYPE_NORMAL
- en: And of course nothing could be more wrong. Yes, Python is an amazing language
    with a lot of cool features and it is used in many fields. But it does not mean
    that it is perfect and does not have any downsides. It is easy to understand and
    write, but this easiness comes with a price. It is not as slow as many think,
    but will never be as fast as C. It is highly portable, but its interpreter is
    not available on as many architectures as compilers for other languages are. We
    could go with that list forever.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the solutions to that problem is to write extensions, so we can bring
    of some of the advantages of *good old C* back to Python. And in most cases, it
    works well. The question is: are we really using Python because we want to extend
    it with C? The answer is *no*. This is only an inconvenient necessity in situations
    where we don''t have any better option.'
  prefs: []
  type: TYPE_NORMAL
- en: Additional complexity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is not a secret that developing applications in many different languages
    is not an easy task. Python and C are completely different technologies and it
    is very hard to find anything that they have in common. It is also true that there
    is no application that is free of bugs. If extensions become common in your codebase,
    debugging can become painful. Not only because debugging of C code requires completely
    different workflow and tools, but also because you will need to switch context
    between two different languages very often.
  prefs: []
  type: TYPE_NORMAL
- en: We are all humans and all have limited cognitive capabilities. There are, of
    course, people who can handle multiple layers of abstraction and technology stacks
    at the same time efficiently but they seem to be very rare specimens. No matter
    how skilled you are, there is always an additional price to pay for maintaining
    such hybrid solutions. This will either involve extra effort and time required
    to switch between C and Python, or additional stress that will make you eventually
    less efficient.
  prefs: []
  type: TYPE_NORMAL
- en: According to the TIOBE index, C is still one of the most popular programming
    languages. Despite this fact, it is very common for Python programmers to know
    very little or almost nothing about it. Personally, I think that C should be *lingua
    franca* in the programming world, but my opinion is very unlikely to change anything
    in this matter. Python also is so seductive and easy to learn that a lot of programmers
    forget about all their previous experiences and completely switch to the new technology.
    And programming is not like riding a bike. This particular skill erodes faster
    if not used and polished sufficiently. Even programmers with strong C background
    are risking to gradually lose their previous knowledge if they decide to dive
    into Python for too long. All of the above leads to one simple conclusion—it is
    harder to find people who will be able to understand and extend your code. For
    open source packages, this means fewer voluntary contributors. In closed source,
    this means that not all of your teammates will be able to develop and maintain
    extensions without breaking things.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When it comes to failures, extensions may break, very badly. Static typing gives
    you a lot of advantages over Python and allows you to catch a lot of issues during
    the compilation step that would be hard to notice in Python without a rigorous
    testing routine and full test coverage. On the other hand, all memory management
    must be performed manually. And faulty memory management is the main reason of
    most programming errors in C. In the best case scenario, such mistakes will only
    result in some memory leaks that will gradually eat all of your environment resources.
    The best case does not mean easy to handle. Memory leaks are really tricky to
    find without using proper external tools such as Valgrind. Anyway, in most cases,
    the memory management issues in your extension's code will result in a segmentation
    fault that is unrecoverable in Python and will cause the interpreter to crash
    without raising any exception. This means that you will eventually need to arm
    up with additional tools that most Python programmers don't need to use. This
    adds complexity to your development environment and workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Interfacing with dynamic libraries without extensions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks to `ctypes` (a module in the standard library) or `cffi` (an external
    package), you can integrate just about every compiled dynamic/shared library in
    Python no matter in what language it was written. And you can do that in pure
    Python without any compilation steps, so this is an interesting alternative to
    writing extensions in C.
  prefs: []
  type: TYPE_NORMAL
- en: This does not mean you don't need to know anything about C. Both solutions require
    from you a reasonable understanding of C and how dynamic libraries work in general.
    On the other hand, they remove the burden of dealing with Python reference counting
    and greatly reduce the risk of making painful mistakes. Also interfacing with
    C code through `ctypes` or `cffi` is more portable than writing and compiling
    the C extension module.
  prefs: []
  type: TYPE_NORMAL
- en: ctypes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`ctypes` is the most popular module to call functions from dynamic or shared
    libraries without the need of writing custom C extensions. The reason for that
    is obvious. It is part of the standard library, so it is always available and
    does not require any external dependencies. It is a **foreign function interface**
    (**FFI**) library and provides an API for creating C-compatible datatypes.'
  prefs: []
  type: TYPE_NORMAL
- en: Loading libraries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are four types of dynamic library loaders available in `ctypes` and two
    conventions to use them. The classes that represent dynamic and shared libraries
    are `ctypes.CDLL`, `ctypes.PyDLL`, `ctypes.OleDLL`, and `ctypes.WinDLL`. The last
    two are only available on Windows, so we won''t discuss them here. The differences
    between `CDLL` and `PyDLL` are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ctypes.CDLL`: This class represents loaded shared libraries. The functions
    in these libraries use the standard calling convention, and are assumed to return
    `int`. GIL is released during the call.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ctypes.PyDLL`: This class works like `CDLL`, but GIL is not released during
    the call. After execution, the Python error flag is checked and an exception is
    raised if it is set. It is only useful when directly calling functions from Python/C
    API.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To load a library, you can either instantiate one of the preceding classes
    with proper arguments or call the `LoadLibrary()` function from the submodule
    associated with a specific class:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ctypes.cdll.LoadLibrary()` for `ctypes.CDLL`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ctypes.pydll.LoadLibrary()` for `ctypes.PyDLL`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ctypes.windll.LoadLibrary()` for `ctypes.WinDLL`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ctypes.oledll.LoadLibrary()` for `ctypes.OleDLL`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main challenge when loading shared libraries is how to find them in a portable
    way. Different systems use different suffixes for shared libraries (`.dll` on
    Windows, `.dylib` on OS X, `.so` on Linux) and search for them in different places.
    The main offender in this area is Windows, that does not have a predefined naming
    scheme for libraries. Because of that, we won't discuss the details of loading
    libraries with `ctypes` on this system and concentrate mainly on Linux and Mac
    OS X that deal with this problem in a consistent and similar way. If you are anyway
    interested in Windows platform, refer to the official `ctypes` documentation that
    has plenty of information about supporting that system (refer to [https://docs.python.org/3.5/library/ctypes.html](https://docs.python.org/3.5/library/ctypes.html)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Both library loading conventions (the `LoadLibrary()` function and specific
    library-type classes) require you to use the full library name. This means all
    the predefined library prefixes and suffixes need to be included. For example,
    to load the C standard library on Linux, you need to write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, for Mac OS X, this would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Fortunately, the `ctypes.util` submodule provides a `find_library()` function
    that allows to load a library using its name without any prefixes or suffixes
    and will work on any system that has a predefined scheme for naming shared libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Calling C functions using ctypes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When the library is successfully loaded, the common pattern is to store it
    as a module-level variable with the same name as library. The functions can be
    accessed as object attributes, so calling them is like calling a Python function
    from any other imported module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Unfortunately, all the built-in Python types except integers, strings, and
    bytes are incompatible with C datatypes and thus must be wrapped in the corresponding
    classes provided by the `ctypes` module. Here is the full list of compatible datatypes
    that comes from the `ctypes` documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ctypes type | C type | Python type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `c_bool` | `_Bool` | `bool` (1) |'
  prefs: []
  type: TYPE_TB
- en: '| `c_char` | `char` | 1-character `bytes` object |'
  prefs: []
  type: TYPE_TB
- en: '| `c_wchar` | `wchar_t` | 1-character `string` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_byte` | `char` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_ubyte` | `unsigned char` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_short` | `short` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_ushort` | `unsigned short` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_int` | `int` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_uint` | `unsigned int` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_long` | `long` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_ulong` | `unsigned long` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_longlong` | `__int64 or long long` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_ulonglong` | `unsigned __int64 or unsigned long long` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_size_t` | `size_t` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_ssize_t` | `ssize_t or Py_ssize_t` | `int` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_float` | `float` | `float` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_double` | `double` | `float` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_longdouble` | `long double` | `float` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_char_p` | `char * (NUL terminated)` | `bytes` object or `None` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_wchar_p` | `wchar_t * (NUL terminated)` | `string` or `None` |'
  prefs: []
  type: TYPE_TB
- en: '| `c_void_p` | `void *` | `int` or `None` |'
  prefs: []
  type: TYPE_TB
- en: 'As you can see, the preceding table does not contain dedicated types that would
    reflect any of the Python collections as C arrays. The recommended way to create
    types for C arrays is to simply use the multiplication operator with the desired
    basic `ctypes` type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Passing Python functions as C callbacks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is a very popular design pattern to delegate part of the work of function
    implementation to custom callbacks provided by the user. The most known function
    from the C standard library that accepts such callbacks is a `qsort()` function
    that provides a generic implementation of the **Quicksort** algorithm. It is rather
    unlikely that you would like to use this algorithm instead of the default Python
    **Timsort** that is more suited for sorting Python collections. Anyway, `qsort()`
    seems to be a canonical example of an efficient sorting algorithm and a C API
    that uses the callback mechanism that is found in many programming books. This
    is why we will try to use it as an example of passing the Python function as a
    C callback.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ordinary Python function type will not be compatible with the callback
    function type required by the `qsort()` specification. Here is the signature of
    `qsort()` from the BSD `man` page that also contains the type of accepted callback
    type (the `compar` argument):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'So in order to execute `qsort()` from `libc`, you need to pass:'
  prefs: []
  type: TYPE_NORMAL
- en: '`base`: This is the array that needs to be sorted as a `void*` pointer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nel`: This is the number of elements as `size_t`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`width`: This is the size of the single element in the array as `size_t`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`compar`: This is the pointer to the function that is supposed to return `int`
    and accepts two `void*` pointers. It points to the function that compares the
    size of two elements being sorted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We already know from the *Calling C functions using ctypes* section how to construct
    the C array from other `ctypes` types using the multiplication operator. `nel`
    should be `size_t`, and it maps to Python `int`, so it does not require any additional
    wrapping and can be passed as `len(iterable)`. The `width` value can be obtained
    using the `ctypes.sizeof()` function once we know the type of our `base` array.
    The last thing we need to know is how to create the pointer to the Python function
    compatible with the `compar` argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `ctypes` module contains a `CFUNTYPE()` factory function that allows us
    to wrap Python functions and represents them as C callable function pointers.
    The first argument is the C return type that the wrapped function should return.
    It is followed by the variable list of C types that the function accepts as its
    arguments. The function type compatible with the `compar` argument of `qsort()`
    will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`CFUNTYPE()` uses the `cdecl` calling convention, so it is compatible only
    with the `CDLL` and `PyDLL` shared libraries. The dynamic libraries on Windows
    that are loaded with `WinDLL` or `OleDLL` use the `stdcall` calling convention.
    This means that the other factory must be used to wrap Python functions as C callable
    function pointers. In `ctypes`, it is `WINFUNCTYPE()`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To wrap everything up, let''s assume that we want to sort a randomly shuffled
    list of integer numbers with a `qsort()` function from the standard C library.
    Here is the example script that shows how to do that using everything that we
    have learned about `ctypes` so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The comparison function provided as a callback has an additional `print` statement,
    so we can see how it is executed during the sorting process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: CFFI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CFFI is a Foreign Function Interface for Python that is an interesting alternative
    to `ctypes`. It is not a part of the standard library but is easily available
    as a `cffi` package on PyPI. It is different from `ctypes` because it puts more
    emphasis on reusing plain C declarations instead of providing extensive Python
    APIs in a single module. It is way more complex and also has a feature that also
    allows you to automatically compile some parts of your integration layer into
    extensions using C compiler. So it can be used as a hybrid solution that fills
    the gap between C extensions and `ctypes`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because it is a very large project, it is impossible to shortly introduce it
    in a few paragraphs. On the other hand, it would be a shame to not say something
    more about it. We have already discussed one example of integrating the `qsort()`
    function from the standard library using `ctypes`. So, the best way to show the
    main differences between these two solutions will be to re-implement the same
    example with `cffi`. I hope that one block of code is worth more than a few paragraphs
    of text:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter explained one of the most advanced topics in the book. We discussed
    the reasons and tools for building Python extensions. We started from writing
    pure C extensions that depend only on Python/C API and then re-implemented them
    with Cython to show how easy it can be if you only choose the proper tool.
  prefs: []
  type: TYPE_NORMAL
- en: There are still some reasons for doing things *the hard way* and using nothing
    more than the pure C compiler and the `Python.h` headers. Anyway, the best recommendation
    is to use tools such as Cython or Pyrex (not featured here) because it will make
    your codebase more readable and maintainable. It will also save you from most
    of the issues caused by incautious reference counting and memory management.
  prefs: []
  type: TYPE_NORMAL
- en: Our discussion of extensions ended with the presentation of `ctypes` and CFFI
    as an alternative way to solve the problems of integrating shared libraries. Because
    they do not require writing custom extensions to call functions from compiled
    binaries, they should be your tools of choice for doing that—especially if you
    don't need to use custom C code.
  prefs: []
  type: TYPE_NORMAL
- en: In next chapter, we will take a short rest from low-level programming techniques
    and delve into topics that are no less important—code management and version control
    systems.
  prefs: []
  type: TYPE_NORMAL
