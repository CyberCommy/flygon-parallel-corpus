- en: Chapter 4. Microservices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章 微服务
- en: As long as we kept talking about the designing, implementation, and tuning of
    one process, we were able to keep illustrating it with vivid images (albeit in
    our imagination only) of pyramid building. Multiple thread management, based on
    the democratic principle of equality between thread pool members, had also a sense
    of centralized planning and supervision. Different priorities were assigned to
    threads programmatically, hardcoded (for most cases) after thoughtful consideration
    by the programmer in accordance with the expected load, and adjusted after monitoring.
    The upper limits of the available resources were fixed, although they could be
    increased after, again, a relatively big centralized decision.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 只要我们一直在谈论一个过程的设计、实施和调优，我们就能够用生动的形象（尽管只存在于我们的想象中）来说明它，比如金字塔建筑。基于平等原则的多线程管理，也具有集中规划和监督的意义。不同的优先级是根据程序员经过深思熟虑后根据预期负载进行编程分配的，并在监控后进行调整。可用资源的上限是固定的，尽管在一个相对较大的集中决策后可以增加。
- en: Such systems had great success and still constitute the majority of the web
    applications currently deployed to production. Many of them are monoliths, sealed
    inside a single `.ear` or `.war` file. This works fine for relatively small applications
    and a corresponding team size that supports them. They are easy (if the code is
    well structured) to maintain, build, and if the production load is not very high,
    they can be easily deployed. If the business does not grow or has little impact
    on the company's internet presence, they continue to do the job and will do so
    probably for the foreseeable future. Many service providers are eager to host
    such websites by charging a small fee and relieving the website owner of the technical
    worries of production maintenance not directly related to the business. But that
    is not the case for everybody.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这些系统取得了巨大的成功，仍然构成当前部署到生产环境的大多数Web应用程序。其中许多是单体应用，封装在一个`.ear`或`.war`文件中。对于相对较小的应用程序和相应的团队规模来说，这样做效果很好。它们易于（如果代码结构良好）维护、构建，并且如果生产负载不是很高，它们可以很容易地部署。如果业务不增长或对公司的互联网存在影响不大，它们将继续发挥作用，可能在可预见的未来也是如此。许多服务提供商急于通过收取少量费用来托管这样的网站，并解除网站所有者与业务无直接关系的生产维护的技术烦恼。但并非所有情况都是如此。
- en: The higher the load, the more difficult and expensive the scaling becomes unless
    the code and the overall architecture is restructured in order to become more
    flexible and resilient to the growing load. This lesson describes the solution
    many leaders of the industry have adopted while addressing the issue and the motivation
    behind it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 负载越高，扩展就会变得越困难和昂贵，除非代码和整体架构进行重构，以使其更灵活和能够承受不断增长的负载。本课程描述了许多行业领袖在解决这个问题时采取的解决方案以及背后的动机。
- en: 'The particular aspects of the microservices we are going to discuss in this
    lesson include the following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本课程中讨论微服务的特定方面，包括以下内容：
- en: The motivation for the microservices rising
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务兴起的动机
- en: The frameworks that were developed recently in support of microservices
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近开发的支持微服务的框架
- en: The process of microservices development with practical examples, including
    the considerations and decision-making process during microservices building
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务开发过程，包括实际示例，以及在微服务构建过程中的考虑和决策过程
- en: Pros and cons of the three main deployment methods such as container-less, self-contained,
    and in-container
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无容器、自包含和容器内三种主要部署方法的优缺点
- en: Why Microservices?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要使用微服务？
- en: Some businesses have a higher demand for the deployment plan because of the
    need to keep up with the bigger volume of traffic. The natural answer to this
    challenge would be and was to add servers with the same `.ear` or `.war` file
    deployed and join all the servers into a cluster. So, one failed server could
    be automatically replaced with another one from the cluster, and the site user
    would never experience disconnect of the service. The database that backed all
    the clustered servers could be clustered too. A connection to each of the clusters
    went through a load balancer, making sure that none of the cluster members worked
    more than the others.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一些企业由于需要跟上更大量的流量，对部署计划有更高的需求。对这一挑战的自然回答是并且已经是将具有相同`.ear`或`.war`文件部署的服务器加入到集群中。因此，一个失败的服务器可以自动被集群中的另一个服务器替换，用户不会感受到服务中断。支持所有集群服务器的数据库也可以进行集群化。连接到每个集群的连接都通过负载均衡器，确保没有一个集群成员比其他成员工作更多。
- en: 'The web server and database clustering help but only to a degree, because as
    the code base grows, its structure can create one or several bottlenecks unless
    such and similar issues are addressed with a scalable design. One of the ways
    to do it is to split the code into tiers: front end (or web tier), middle tier
    (or app tier) and back end (or backend tier). Then, again, each tier can be deployed
    independently (if the protocol between tiers has not changed) and in its own cluster
    of servers, as each tier can grow horizontally as needed independently of other
    tiers. Such a solution provides more flexibility for scaling up, but makes the
    deployment plan more complex, especially if the new code introduces breaking changes.
    One of the approaches is to create a second cluster that will host a new code,
    then take the servers one by one from the old cluster, deploy the new code, and
    put them in the new cluster. The new cluster would be turned on as soon as at
    least one server in each tier has the new code. This approach worked fine for
    the web and app tiers but was more complex for the backend, which once in a while
    required data migration and similar joyful exercises. Add to it unexpected outages
    in the middle of the deployment caused by human errors, defects in the code, pure
    accidents, or some combination of all the earlier mentioned (one time, for example,
    an electric power cable was cut by an excavator in the nearby construction site),
    and it is easy to understand why very few people love a deployment of a major
    release to production.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Web服务器和数据库集群有所帮助，但只能在一定程度上，因为随着代码库的增长，其结构可能会产生一个或多个瓶颈，除非采用可扩展的设计来解决这些问题。其中一种方法是将代码分成层：前端（或Web层）、中间层（或应用层）和后端（或后端层）。然后，每个层都可以独立部署（如果层之间的协议没有改变），并在自己的服务器集群中，因为每个层都可以根据需要独立地水平扩展。这样的解决方案提供了更多的扩展灵活性，但使部署计划更加复杂，特别是如果新代码引入了破坏性变化。其中一种方法是创建一个将托管新代码的第二个集群，然后逐个从旧集群中取出服务器，部署新代码，并将它们放入新集群。只要每个层中至少有一个服务器具有新代码，新集群就会启动。这种方法对Web和应用层效果很好，但对后端来说更复杂，因为偶尔需要数据迁移和类似的愉快练习。加上部署过程中由人为错误、代码缺陷、纯粹的意外或所有前述因素的组合引起的意外中断，很容易理解为什么很少有人喜欢将主要版本发布到生产环境。
- en: Programmers, being by nature problem solvers, tried to prevent the earlier scenario
    as best as they could by writing defensive code, deprecating instead of changing,
    testing, and so on. One of the approaches was to break the application into more
    independently deployable parts with the hope of avoiding deploying everything
    at the same time. They called these independent units **services**, and **Service-Oriented
    Architecture** (**SOA**) was born.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 程序员天生是问题解决者，他们尽力防止早期的情景，通过编写防御性代码、弃用而不是更改、测试等。其中一种方法是将应用程序分解为更独立部署的部分，希望避免同时部署所有内容。他们称这些独立单元为**服务**，**面向服务的架构**（**SOA**）应运而生。
- en: Unfortunately, in many companies, the natural growth of the code base was not
    adjusted to the new challenges in a timely manner. Like the frog that was eventually
    boiled in a slowly heated pot of water, they never had time to jump out of the
    hot spot by changing the design. It was always cheaper to add another feature
    to the blob of the existing functionality than redesign the whole app. Business
    metrics of the time-to-market and keeping the bottom line in the black always
    were and will remain the main criterion for the decision making, until the poorly
    structured source code eventually stops working, pulling down all the business
    transactions with it or, if the company is lucky, allows them to weather the storm
    and shows the importance of the investment in the redesign.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 很不幸，在许多公司中，代码库的自然增长没有及时调整到新的挑战。就像那只最终在慢慢加热的水壶里被煮熟的青蛙一样，他们从来没有时间通过改变设计来跳出热点。向现有功能的一团泥中添加另一个功能总是比重新设计整个应用程序更便宜。时间到市场和保持盈利始终是决策的主要标准，直到结构不良的源代码最终停止工作，将所有业务交易一并拖垮，或者，如果公司幸运的话，让他们度过风暴并显示重新设计的重要性。
- en: As a result of all that, some lucky companies remained in the business with
    their monolithic application still running as expected (maybe not for long, but
    who knows), some went out of business, some learned from their mistakes and progressed
    into the brave world of the new challenges, and others learned from their mistakes
    and designed their systems to be SOA upfront.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由此产生的结果是，一些幸运的公司仍然在经营中，他们的单片应用程序仍然如预期般运行（也许不久，但谁知道），一些公司倒闭，一些从错误中吸取教训，进入新挑战的勇敢世界，另一些则从错误中吸取教训，并从一开始就设计他们的系统为SOA。
- en: It is interesting to observe similar tendencies in the social sphere. Society
    moved from the strong centralized governments to more loosely coupled confederations
    of semi-independent states tied together by the mutually beneficial economic and
    cultural exchange.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是观察社会领域中类似的趋势。社会从强大的中央集权政府转向更松散耦合的半独立国家联盟，通过相互有利的经济和文化交流联系在一起。
- en: Unfortunately, maintaining such a loose structure comes with a price. Each participant
    has to be more responsible in maintaining the contract (social, in the case of
    a society, and API, in the case of the software) not only formally but also in
    spirit. Otherwise, for example, the data flowing from a new version of one component,
    although correct by type, might be unacceptable to another component by value
    (too big or too small). Maintaining a cross-team understanding and overlapping
    of responsibility requires constant vigilance in keeping the culture alive and
    enlightening. Encouraging innovation and risk taking, which can lead to a business
    breakthrough, contradict the protecting tendencies for stability and risk aversion
    coming from the same business people.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Moving from monolithic single-team development to multiple teams and an independent
    components-based system requires an effort on all levels of the enterprise. What
    do you mean by **No more Quality Assurance Department**? Who then will care about
    the professional growth of the testers? And what about the IT group? What do you
    mean by **The developers are going to support production**? Such changes affect
    human lives and are not easy to implement. That's why SOA architecture is not
    just a software principle. It affects everybody in the company.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, the industry leaders, who have managed to grow beyond anything we
    could imagine just a decade ago, were forced to solve even more daunting problems
    and came back to the software community with their solutions. And that is where
    our analogy with the pyramid building does not work anymore. Because the new challenge
    is not just to build something so big that was never built before but also to
    do it quickly not in a matter of years, but in a few weeks and even days. And
    the result has to last not for a thousand years but has to be able to evolve constantly
    and be flexible enough to adapt to new, unexpected requirements in real time.
    If only one aspect of the functionality has changed, we should be able to redeploy
    only this one service. If the demand for any service grows, we should be able
    to scale only along this one service and release resources when the demand drops.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: To avoid big deployments with all hands on deck and to come closer to the continuous
    deployment (which decreases time-to-market and is thus supported by business),
    the functionality continued to split into smaller chunks of services. In response
    to the demand, more sophisticated and robust cloud environments, deployment tools
    (including containers and container orchestration), and monitoring systems supported
    this move. The reactive streams, described in the previous lesson, started to
    develop even before the Reactive Manifesto came out and plugged a snag into the
    stack of modern frameworks.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Splitting an application into independent deployment units brought several not
    quite expected benefits that have increased the motivation for plowing ahead.
    The physical isolation of services allows more flexibility in choosing a programming
    language and platform of implementation. It helps not only to select technology
    that is the best for the job but also to hire people able to implement it, not
    being bound by a certain technological stack of the company. It also helped the
    recruiters to spread the net wider and use smaller cells for bringing in new talent,
    which is not a small advantage with a limited number of available specialists
    and the unlimited demand of the fast-growing data processing industry.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Also, such architecture enforced a discussion and explicit definition of the
    interfaces between smaller parts of the complex system, thus creating a solid
    foundation for further growth and tuning of the processing sophistication.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: And that is how microservices came into the picture and were put to work by
    giants of traffic such as Netflix, Google, Twitter, eBay, Amazon, and Uber. Now,
    let's talk about the results of this effort and the lessons learned.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Building Microservices
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before diving into the building process, let''s revisit the characteristics
    a chunk of code has to possess in order to be qualified as a microservice. We
    will do it in no particular order:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: The size of the source code of one microservice should be smaller to that of
    an SOA, and one development team should be able to support several of them.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has to be deployed independently of other services.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each has to have its own database (or schema or set of tables), although this
    statement is still under debate, especially in cases when several services modify
    the same data set or the inter-dependent data sets; if the same team owns all
    of the related services, it is easier to accomplish. Otherwise, there are several
    possible strategies we will discuss later.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has to be stateless and idempotent. If one instance of the service has failed,
    another should be able to accomplish what was expected from the service.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It should provide a way to check its **health**, meaning that the service is
    up and running and ready to do the job.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharing resources has to be considered during the design, development, and,
    after deployment, monitored for validation of the assumptions. In the previous
    lesson, we talked about threads synchronization. You could see that this problem
    was not easy to solve, and we have presented several possible ways to do it. Similar
    approaches can be applied toward microservices. Although they are run in different
    processes, they can communicate to each other if need be, so they can coordinate
    and synchronize their actions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Special care has to be taken during modification of the same persistent data
    whether shared across databases, schemas, or tables within the same schema. If
    an eventual consistency is acceptable (which is often the case for larger sets
    of data, used for statistical purposes, for example) then no special measures
    are necessary. However, the need for transactional integrity poses a more difficult
    problem.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: One way to support a transaction across several microservices is to create a
    service that would play the role of a **Distributed Transaction Manager** (**DTM**).
    Other services that need coordination would pass to it the new modified values.
    The DTM service could keep the concurrently modified data temporarily in a database
    table and would move it into the main table(s) in one transaction after all the
    data is ready (and consistent).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: If the time to access the data is an issue or you need to protect the database
    from an excessive number of concurrent connections, dedicating a database to some
    services may be an answer. Alternatively, if you would like to try another option,
    memory cache could be the way to go. Adding a service that provides access to
    the cache (and updates it as needed) increases isolation from the services that
    use it, but requires (sometimes difficult) synchronization between the peers that
    are managing the same cache too.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: After considering all the options and possible solutions for data sharing, it
    is often helpful to revisit the idea of creating its own database (or schema)
    for each microservice. One may discover that the effort of the data isolation
    (and subsequent synchronization on the database level) does not look as daunting
    as before if compared with the effort to synchronize the data dynamically.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: That said, let's look over the field of the frameworks for microservices implementation.
    One can definitely write the microservices from scratch, but before doing that,
    it is always worth looking at what is out there already, even if to find eventually
    that nothing fits your particular needs.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: There are more than a dozen frameworks that are currently used for building
    microservices. Two most popular are Spring Boot ([https://projects.spring.io/spring-boot/](https://projects.spring.io/spring-boot/))
    and raw J2EE. The J2EE community founded the initiative MicroProfile ([https://microprofile.io/](https://microprofile.io/))
    with a declared goal of **Optimizing Enterprise Java** for a microservices architecture.
    KumuluzEE ([https://ee.kumuluz.com/](https://ee.kumuluz.com/)) is a lightweight
    open-source microservice framework coplined with MicroProfile.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 'The list of some other frameworks include the following (in alphabetical order):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: '**Akka**: This is a toolkit for building highly concurrent, distributed, and
    resilient message-driven applications for Java and Scala ([akka.io](https://akka.io/))'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bootique**: This is a minimally opinionated framework for runnable Java apps
    ([bootique.io](http://bootique.io))'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dropwizard**: This is a Java framework for developing ops-friendly, high-performance,
    RESTful web services ([www.dropwizard.io](http://www.dropwizard.io))'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Jodd**: This is a set of Java microframeworks, tools, and utilities, under
    1.7 MB ([jodd.org](http://jodd.org))'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lightbend Lagom**: This is an opinionated microservice framework built on
    Akka and Play ([www.lightbend.com](http://www.lightbend.com))'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ninja**: This is a full stack web framework for Java ([www.ninjaframework.org](http://www.ninjaframework.org))'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spotify Apollo**: This is a set of Java libraries used at Spotify for writing
    microservices ([spotify.github.io/apollo](http://spotify.github.io/apollo))'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Vert.x**: This is a toolkit for building reactive applications on the JVM
    ([vertx.io](http://vertx.io))'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All frameworks support HTTP/JSON communication between microservices; some of
    them also have an additional way to send messages. If not the latter, any lightweight
    messaging system can be used. We mentioned it here because, as you may recall,
    message-driven asynchronous processing is a foundation for elasticity, responsiveness,
    and resilience of a reactive system composed of microservices.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the process of microservices building, we will use Vert.x, an
    event-driven, non-blocking, lightweight, and polyglot toolkit (components can
    be written in Java, JavaScript, Groovy, Ruby, Scala, Kotlin, and Ceylon). It supports
    an asynchronous programming model and a distributed event bus that reaches even
    into in-browser JavaScript (thus allowing the creation of real-time web applications).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'One starts using Vert.x by creating a `Verticle` class that implements the
    interface `io.vertx.core.Verticle`:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The method names previously mentioned are self-explanatory. The method `getVertex()`
    provides access to the `Vertx` object the entry point into the Vert.x Core API.
    It provides access to the following functionality necessary for the microservices
    building:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Creating TCP and HTTP clients and servers
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating DNS clients
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating Datagram sockets
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating periodic services
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing access to the event bus and file system API
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Providing access to the shared data API
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying and undeploying verticles
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using this Vertx object, various verticles can be deployed, which talk to each
    other, receive an external request, and process and store data as any other Java
    application, thus forming a system of microservices. Using RxJava implementation
    from the package `io.vertx.rxjava`, we will show how one can create a reactive
    system of microservices.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'A verticle is a building block in Vert.`x` world. It can easily be created
    by extending the `io.vertx.rxjava.core.AbstractVerticle` class:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The earlier mentioned class, in turn, extends `io.vertx.core.AbstractVerticle`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: A verticle can be created by extending the class `io.vertx.core.AbstractVerticle`,
    too. However, we will write reactive microservices, so we will extend its rx-fied
    version, `io.vertx.rxjava.core.AbstractVerticle`.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'To use Vert.x and run the provided example, all you need to do is to add the
    following dependencies:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Vert.x并运行提供的示例，您只需要添加以下依赖项：
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Other Vert.x functionality can be added as needed by including other Maven dependencies.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 其他Vert.x功能可以根据需要添加其他Maven依赖项。
- en: What makes `Vert.x` `Verticle` reactive is the underlying implementation of
    an event loop (a thread) that receives an event and delivers it a `Handler` (we
    will show how to write the code for it). When a `Handler` gets the result, the
    event loop invokes the callback.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使`Vert.x` `Verticle`具有反应性的是事件循环（线程）的底层实现，它接收事件并将其传递给`Handler`（我们将展示如何为其编写代码）。当`Handler`获得结果时，事件循环将调用回调函数。
- en: Note
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'As you see, it is important not to write a code that blocks the event loop,
    thus the Vert.x golden rule: don''t block the event loop.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，重要的是不要编写阻塞事件循环的代码，因此Vert.x的黄金规则是：不要阻塞事件循环。
- en: If not blocked, the event loop works very quickly and delivers a huge number
    of events in a short period of time. This is called the reactor pattern ([https://en.wikipedia.org/wiki/Reactor_pattern](https://en.wikipedia.org/wiki/Reactor_pattern)).
    Such an event-driven non-blocking programming model is a very good fit for reactive
    microservices. For certain types of code that are blocking by nature (JDBC calls
    and long computations are good examples) a worker verticle can be executed asynchronously
    (not by the event loop, but by a separate thread using the method `vertx.executeBlocking()`),
    which keeps the golden rule intact.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有阻塞，事件循环将非常快速地工作，并在短时间内传递大量事件。这称为反应器模式（[https://en.wikipedia.org/wiki/Reactor_pattern](https://en.wikipedia.org/wiki/Reactor_pattern)）。这种事件驱动的非阻塞编程模型非常适合响应式微服务。对于某些本质上是阻塞的代码类型（JDBC调用和长时间计算是很好的例子），可以异步执行工作verticle（不是由事件循环，而是使用`vertx.executeBlocking()`方法由单独的线程执行），这保持了黄金规则的完整性。
- en: 'Let''s look at a few examples. Here is a `Verticle` class that works as an
    HTTP server:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看几个例子。这是一个作为HTTP服务器工作的`Verticle`类：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the previous code, the server is created, and the stream of data from a
    possible request is wrapped into an `Observable`. We then subscribed to the data
    coming from the `Observable` and passed in a function (a request handler) that
    will process the request and generate a necessary response. We also told the server
    which port to listen. Using this `Verticle`, we can deploy several instances of
    an HTTP server listening on different ports. Here is an example:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码中，创建了服务器，并将可能的请求的数据流包装成“Observable”。然后，我们订阅了来自“Observable”的数据，并传入一个函数（请求处理程序），该函数将处理请求并生成必要的响应。我们还告诉服务器要监听哪个端口。使用这个“Verticle”，我们可以部署几个实例，监听不同的端口的HTTP服务器。这是一个例子：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If we run this application, the output would be as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行此应用程序，输出将如下所示：
- en: '![Building Microservices](img/04_01.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![构建微服务](img/04_01.jpg)'
- en: 'As you can see, the same thread is listening on both ports. If we now place
    a request to each of the running servers, we will get the response we have hardcoded:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，同一个线程同时监听两个端口。如果我们现在向每个正在运行的服务器发送请求，我们将得到我们已经硬编码的响应：
- en: '![Building Microservices](img/04_02.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![构建微服务](img/04_02.jpg)'
- en: 'We ran our examples from the `main()` method. A plugin `maven-shade-plugin`
    allows you to specify which verticle you would like to be the starting point of
    your application. Here is an example from [http://vertx.io/blog/my-first-vert-x-3-application](http://vertx.io/blog/my-first-vert-x-3-application):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`main()`方法运行示例。插件`maven-shade-plugin`允许您指定要作为应用程序起点的verticle。以下是来自[http://vertx.io/blog/my-first-vert-x-3-application](http://vertx.io/blog/my-first-vert-x-3-application)的示例：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, run the following command:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，运行以下命令：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It will generate a specified JAR file (called `target/my-first-app-1.0-SNAPSHOT-fat.jar`,
    in this example). It is called `fat` because it contains all the necessary dependencies.
    This file will also contain `MANIFEST.MF` with the following entries in it:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 它将生成一个指定的JAR文件（在本例中称为`target/my-first-app-1.0-SNAPSHOT-fat.jar`）。它被称为“fat”，因为它包含所有必要的依赖项。此文件还将包含`MANIFEST.MF`，其中包含以下条目：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can use any verticle instead of `io.vertx.blog.first.MyFirstVerticle`,
    used in this example, but `io.vertx.core.Starter` has to be there because that
    is the name of the `Vert.x` class that knows how to read the manifest and execute
    the method `start()` of the specified verticle. Now, you can run the following
    command:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用任何verticle来代替此示例中使用的`io.vertx.blog.first.MyFirstVerticle`，但必须有`io.vertx.core.Starter`，因为那是知道如何读取清单并执行指定verticle的`Vert.x`类的名称。现在，您可以运行以下命令：
- en: '[PRE9]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This command will execute the `start()` method of the `MyFirstVerticle` class
    the same way the `main()` method is executed in our example, which we will continue
    to use for the simplicity of demonstration.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将执行`MyFirstVerticle`类的`start()`方法，就像我们的示例中执行`main()`方法一样，我们将继续使用它来简化演示。
- en: 'To compliment the HTTP server, we can create an HTTP client too. However, first,
    we will modify the method `start()` in the `server` verticle to accept the parameter
    `name`:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了补充HTTP服务器，我们也可以创建一个HTTP客户端。但是，首先，我们将修改`server` verticle中的`start()`方法，以接受参数`name`：
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, we can create an HTTP `client` verticle that sends a request and prints
    out the response every second for 3 seconds, then stops:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以创建一个HTTP“客户端”verticle，每秒发送一个请求并打印出响应，持续3秒，然后停止：
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s assume we deploy both verticles as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们部署两个verticle如下：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output will be as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Building Microservices](img/04_03.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![构建微服务](img/04_03.jpg)'
- en: In this last example, we demonstrated how to create an HTTP client and periodic
    service. Now, let's add more functionality to our system. For example, let's add
    another verticle that will interact with the database and use it via the HTTP
    server we have already created.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个示例中，我们演示了如何创建HTTP客户端和周期性服务。现在，让我们为我们的系统添加更多功能。例如，让我们添加另一个verticle，它将与数据库交互，并通过我们已经创建的HTTP服务器使用它。
- en: 'First, we need to add this dependency:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要添加此依赖项：
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The newly added JAR file allows us to create an in-memory database and a handler
    to access it:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 新添加的JAR文件允许我们创建一个内存数据库和一个访问它的处理程序：
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Those familiar with RxJava can see that Vert.x code closely follows the style
    and naming convention of RxJava. Nevertheless, we encourage you to go through
    Vert.x documentation, because it has a very rich API that covers many more cases
    than just demonstrated. In the previous code, the operation `flatMap()` receives
    the function that runs the script and then closes the connection. The operation
    `doAfterTerminate()` in this case acts as if it was placed inside a finally block
    in a traditional code and closes the connection either in case of success or if
    an exception is generated. The `subscribe()` method has several overloaded versions.
    For our code, we have selected the one that takes two functions one is going to
    be executed in the case of success (we print a message about the table being created)
    and another in the case of an exception (we just print the stack trace then).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉RxJava的人可以看到，Vert.x代码紧密遵循RxJava的风格和命名约定。尽管如此，我们鼓励您阅读Vert.x文档，因为它具有非常丰富的API，涵盖了比我们演示的更多情况。在前面的代码中，`flatMap()`操作接收运行脚本然后关闭连接的函数。在这种情况下，`doAfterTerminate()`操作的作用就像是在传统代码中放置在finally块中并在成功或生成异常时关闭连接。`subscribe()`方法有几个重载版本。对于我们的代码，我们选择了一个在成功时执行一个函数（我们打印有关创建表的消息），在异常时执行另一个函数（我们只打印堆栈跟踪）。
- en: 'To use the created database, we can add to `DbHandler` methods `insert()`,
    `process()`, and `readProcessed()` that will allow us to demonstrate how to build
    a reactive system. The code for the method `insert()` can look like this:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用创建的数据库，我们可以向`DbHandler`添加`insert()`、`process()`和`readProcessed()`方法，这将允许我们演示如何构建一个响应式系统。`insert()`方法的代码可能如下所示：
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `insert()` method, as well as other methods we are going to write, takes
    full advantage of Java functional interfaces. It creates a record in the table
    `who_called` (using the passed in parameter `name`). Then, the operation `subscribe()`
    executes one of the two functions passed in by the code that calls this method.
    We use the method `printAction()` only for better traceability:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`insert()`方法以及我们将要编写的其他方法充分利用了Java函数接口。它在表`who_called`中创建一条记录（使用传入的参数`name`）。然后，`subscribe()`操作执行调用此方法的代码传递的两个函数中的一个。我们仅使用`printAction()`方法以获得更好的可追踪性。'
- en: '[PRE16]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The method `process()` also accepts two functions but does not need other parameters.
    It processes all the records from the table `who_called` that are not processed
    yet (not listed in the table `processed`):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`process()`方法还接受两个函数，但不需要其他参数。它处理表`who_called`中尚未处理的所有记录（未在`processed`表中列出）：'
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: If two threads are reading the table `who_called` for the purpose of selecting
    records not processed yet, the clause `for update` in the SQL query makes sure
    that only one gets each record, so they are not going to be processed twice. The
    significant advantage of the method `process()` code is its usage of the `rxQUeryStream()`
    operation that emits the found records one at a time so that they are processed
    independently of each other. In the case of a big number of not processed records,
    such a solution guarantees a smooth delivery of the results without the spiking
    of the resources consumption. The following `flatMap()` operation does processing
    using the function passed in. The only requirement for that function is that it
    must return one integer value (in `JsonArray`) that is going to be used as a parameter
    for the `SQL_INSERT_PROCESSED` statement. So, it is up to the code that calls
    this method to decide the nature of the processing. The rest of the code is similar
    to the method `insert()`. The code indentation helps to follow the nesting of
    the operations.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两个线程正在读取表`who_called`以选择尚未处理的记录，SQL查询中的`for update`子句确保只有一个线程获取每条记录，因此它们不会被处理两次。`process()`方法代码的显着优势在于其使用`rxQueryStream()`操作，该操作逐个发出找到的记录，以便它们独立地进行处理。在大量未处理记录的情况下，这样的解决方案保证了结果的平稳交付，而不会消耗资源。以下的`flatMap()`操作使用传递的函数进行处理。该函数的唯一要求是它必须返回一个整数值（在`JsonArray`中），该值将用作`SQL_INSERT_PROCESSED`语句的参数。因此，调用此方法的代码决定处理的性质。代码的其余部分类似于`insert()`方法。代码缩进有助于跟踪操作的嵌套。
- en: 'The method `readProcessed()` has code that looks very similar to the code of
    the method `insert()`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`readProcessed()`方法的代码看起来与`insert()`方法的代码非常相似：'
- en: '[PRE18]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The preceding code reads the specified number of the latest processed records.
    The difference from the method `process()` is that the method `readProcessed()`
    returns all the read records in one result set, so it is up to the user of this
    method to decide how to process the result in bulk or one at a time. We show all
    these possibilities just to demonstrate the variety of the possible options. With
    the `DbHandler` class in place, we are ready to use it and create the `DbServiceHttp`
    microservice, which allows a remote access to the `DbHandler` capabilities by
    wrapping around it an HTTP server. Here is the constructor of the new microservice:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码读取了指定数量的最新处理记录。与`process()`方法的不同之处在于，`readProcessed()`方法返回一个结果集中的所有读取记录，因此由使用此方法的用户决定如何批量处理结果或逐个处理。我们展示所有这些可能性只是为了展示可能的选择的多样性。有了`DbHandler`类，我们准备好使用它并创建`DbServiceHttp`微服务，它允许通过包装一个HTTP服务器来远程访问`DbHandler`的功能。这是新微服务的构造函数：
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the earlier mentioned code, you can see how the URL mapping is done in Vert.x.
    For each possible route, a corresponding `Verticle` method is assigned, each accepting
    the `RoutingContext` object that contains all the data of HTTP context, including
    the `HttpServerRequest` and `HttpServerResponse` objects. A variety of convenience
    methods allows us to easily access the URL parameters and other data necessary
    to process the request. Here is the method `insert()` referred in the `start()`
    method:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'All it does is extracts the parameter `name` from the request and constructs
    the two functions necessary to call method `insert()` of `DbHandler` we discussed
    earlier. The method `process()` looks similar to the previous method `insert()`:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The function `process` mentioned earlier defines what should be done with the
    records coming from the `SQL_SELECT_TO_PROCESS` statement inside the method `process()`
    in `DbHandler`. In our case, it calculates the length of the caller's name and
    passes it as a parameter along with the name itself (as a return value) to the
    next SQL statement that inserts the result into the table `processed`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the method `readProcessed()`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: That is where (in the previous code in the function `onSuccess()`) the result
    set from the query `SQL_READ_PROCESSED` is read and used to construct the response.
    Notice that we do it by creating an `Observable` first, then subscribing to it
    and passing the result of the subscription as the response into method `end()`.
    Otherwise, the response can be returned without waiting for the response to be
    constructed.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can launch our reactive system by deploying the `DbServiceHttp` verticle:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'If we do that, in the output we will see the following lines of code:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In another window, we can issue the command that generates an HTTP request:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '![Building Microservices](img/04_04.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
- en: 'If we read the processed records now, there should be none:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '![Building Microservices](img/04_05.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
- en: 'The log messages show the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![Building Microservices](img/4_06.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: 'Now, we can request processing of the existing records and then read the results
    again:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '![Building Microservices](img/04_07.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: In principle, it is enough already to build a reactive system. We can deploy
    many `DbServiceHttp` microservices on different ports or cluster them to increase
    processing capacity, resilience, and responsiveness. We can wrap other services
    inside an HTTP client or an HTTP server and let them talk to each other, processing
    the input and passing the results along the processing pipeline.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: However, Vert.x also has a feature that even better suits the message-driven
    architecture (without using HTTP). It is called an event bus. Any verticle has
    access to the event bus and can send any message to any address (which is just
    a string) using either method `send()` (`rxSend()` in the case of reactive programming)
    or method `publish()`. One or many verticles can register themselves as a consumer
    for a certain address.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: If many verticles are consumers for the same address, then the method `send()`
    (`rxSend()`) delivers the message only to one of them (using a round-robin algorithm
    to pick the next consumer). The method `publish()`, as you would expect, delivers
    the message to all consumers with the same address. Let's see an example, using
    the already familiar `DbHandler` as the main working horse.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'A microservice, based on an event bus, looks very similar to the one based
    on the HTTP protocol we discussed already:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We simplified the preceding code by skipping some sections (that are very similar
    to the `DbServiceHttp` class) and trying to highlight the code structure. For
    demo purposes, we will deploy two instances of this class and send three messages
    to each of the addresses `INSERT`, `PROCESS`, and `READ_PROCESSED`:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Notice the delay for 200 ms we inserted using the method `delayMs()`:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The delay is necessary to let the `DbServiceBus` verticle to be deployed and
    started (and the consumers registered with the address). Otherwise, an attempt
    to send a message may fail because the consumer is not registered with the address
    yet. The `PeriodicServiceBusSend()` verticle code is as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The previous code sends a message to an address every `delaySec` seconds as
    many times as the length of the array `caller[]`, and then undeploys the verticle
    (itself). If we run the demo, the beginning of the output will be as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '![Building Microservices](img/04_08.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
- en: 'As you can see, for each address, only `DbServiceBus(1)` was a receiver of
    the first message. The second message to the same address was received by `DbServiceBus(2)`.
    That was the round-robin algorithm (which we mentioned earlier) in action. The
    final section of the output looks like this:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '![Building Microservices](img/04_09.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
- en: 'We can deploy as many verticles of the same type as needed. For example, let''s
    deploy four verticles that send messages to the address `INSERT`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To see the results, we will also ask the reading Verticle to read the last
    eight records:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The result (the final section of the output) then will be as expected:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '![Building Microservices](img/04_10.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
- en: Four verticles have sent the same messages, so each name was sent four times
    and processed that is what we see in the previous output.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now return to one inserting periodic verticle but will change it from
    using the method `rxSend()` to the method `publish()`:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This change would mean that the message has to be sent to all verticles that
    are registered as the consumers at that address. Now, let''s run the following
    code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We have included another delay for 200 ms to give the publishing verticle time
    to send the message. The output (in the final section) now shows that each message
    was processed twice:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '![Building Microservices](img/04_11.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
- en: That is because two consumers `DbServiceBus(1)` and `DbServiceBus(2)` were deployed,
    and each received a message to the address `INSERT` and inserted it in the table
    `who_called`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: All the previous examples we have run in one JVM process. If necessary, Vert.x
    instances can be deployed in different JVM processes and clustered by adding the
    `-cluster` option to the run command. Therefore, they share the event bus and
    the addresses are visible to all Vert.x instances. This way, the resources can
    be added to each address as needed. For example, we can increase the number of
    processing microservices only and compensate the load's increase.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Other frameworks we mentioned earlier have similar capabilities. They make microservices
    creation easy and may encourage breaking the application into tiny single-method
    operations with an expectation of assembling a very resilient and responsive system.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: However, these are not the only criteria of good quality. System decomposition
    increases the complexity of its deployment. Also, if one development team is responsible
    for many microservices, the complexity of versioning so many pieces in different
    stages (development, test, integration test, certification, staging, production)
    may lead to confusion and a very challenging deployment process, which, in turn,
    may slow down the rate of changes necessary to keep the system in sync with the
    market requirements.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the developing of the microservices, many other aspects have
    to be addressed to support the reactive system:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: A monitoring system has to be designed to provide an insight into the state
    of the application, but it should not be so complex as to pull the development
    resources away from the main application.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alerts have to be installed to warn the team about possible and actual issues
    in a timely manner, so they can be addressed before affecting the business.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If possible, self-correcting automated processes have to be implemented. For
    example, the system should be able to add and release resources in accordance
    with the current load; the retry logic has to be implemented with a reasonable
    upper limit of a attempts before declaring the failure.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A layer of circuit breakers has to protect the system from the domino effect
    when failure of one component deprives other components of the necessary resources.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An embedded testing system should be able to introduce disruptions and simulate
    processing load to ensure that the application resilience and responsiveness do
    not degrade over time. For example, the Netflix team has introduced a **chaos
    monkey** a system that is able to shut down various parts of the production system
    to test the ability to recover. They use it even in production because a production
    environment has a specific configuration, and no test in another environment can
    guarantee that all possible issues are found.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the main considerations of a reactive system design is the selection
    of the deployment methodology that can be either container-less, self-contained,
    or in-container. We will look into the pros and cons of each of these approaches
    in the following sections of this lesson.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Container-Less Deployment
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: People use the term **container** to refer to very different things. In the
    original usage, a container was something that carried its content from one location
    to another without changing anything inside. However, when servers were introduced,
    only one aspect was emphasized the ability to hold an application to contain it.
    Also, another meaning was added to provide life-supportive infrastructure so that
    the container's content (an application) can not only survive but also be active
    and respond to the external requests. Such a redefined notion of a container was
    applied to web servers (servlet container), application servers (an application
    container with or without an EJB container), and other software facilities that
    provided the supportive environment for applications. Sometimes, even the JVM
    itself was called a container, but this association did not survive, probably,
    because the ability to actively engage (execute) the content does not align well
    with the original meaning of a container.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: That is why, later, when people started talking about container-less deployment,
    they typically meant the ability to deploy an application into a JVM directly,
    without first installing WebSphere, WebLogic, JBoss, or any other mediating software
    that provides the runtime environment for the application.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous sections, we described many frameworks that allow us to build
    and deploy an application (or rather a reactive system of microservices) without
    the need for any other container beyond the JVM itself. All you need to do is
    to build a fat JAR file that includes all the dependencies (except those that
    come from the JVM itself) and then run it as a standalone Java process:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Well, you also need to make sure that `MANIFEST.MF` in your JAR file has an
    entry `main` class that points to the fully qualified class name that has the
    `main()` method and will be run at the startup. We have described how to do it
    in the previous section, *Building Microservices*.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: That is the promised compile-once-run-everywhere of Java, everywhere meaning
    everywhere where JVM of a certain version or higher is installed. There are several
    advantages and disadvantages of this approach. We will discuss them not relative
    to the traditional deployment in a server container. The advantages of deployment
    without using the traditional containers are quite obvious, starting with much
    fewer (if any) licensing costs and ending up with much a lighter deployment and
    scalability process, not even mentioning much less consumption of resources. Instead,
    we will compare container-less deployment not with the traditional one, but with
    a self-contained and an in-container in a new generation of containers that have
    been developed a few years ago.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: They allow the ability not only to contain and execute the contained code, which
    the traditional containers did too, but also to move it to a different location
    without any change to the contained code. From now on, by a container, we are
    going to mean only the new ones.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'The advantages of container-less deployment are as follows:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: It is easy to add more Java processes either inside the same physical (or virtual
    or in the cloud) machine or on new hardware
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An isolation level between processes is high, which is especially important
    in the shared environment when you have no control over other co-deployed applications,
    and it is possible that a rogue application would try to penetrate the neighboring
    execution environment
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a small footprint since it does not include anything else beyond the
    application itself or a group of microservices
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The disadvantages of container-less deployment are as follows:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Each JAR file requires the JVM of a certain version or higher, which may force
    you to bring up a new physical or virtual machine just for this reason, to deploy
    one particular JAR file
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case of an environment you do not control, your code might be deployed
    with a wrong version of JVM, which could lead to unpredictable results
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processes in the same JVM compete for resources, which are especially hard to
    manage in the case of the environments shared by different teams or different
    companies
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When several microservices are bundled into the same JAR file, they might require
    different versions of a third-party library or even incompatible libraries
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microservices can be deployed one per JAR or bundled together by a team, by
    related services, by the unit of scale, or using another criterion. Not the least
    important consideration is the total number of such JAR files. As this number
    grows (Google today deals with hundreds of thousands of deployment units at a
    time), it may become impossible to handle deployment via simple bash script and
    require a complex process that allows account ability for possible incompatibilities.
    If that is the case, then it is reasonable to consider using virtual machines
    or containers (in their new incarnation, see the following section) for better
    isolation and management.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Self-Contained Microservices
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Self-contained microservices look much similar to container-less. The only difference
    is that the JVM (or JRE, actually) or any other external frameworks and servers
    necessary for the application to run are included in the fat JAR file too. There
    are many ways to build such an all-inclusive JAR file.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Spring Boot, for example, provides a convenient GUI with checkbox list that
    allows you to select which parts of your Spring Boot application and the external
    tools you would like to package. Similarly, WildFly Swarm allows you to choose
    which parts of the Java EE components you would like to bundle along with your
    application. Alternatively, you can do it yourself using the `javapackager` tool.
    It compiles and packages the application and JRE in the same JAR file (it can
    also be `.exe` or `.dmg`) for distribution. You can read about the tool on the
    Oracle website [https://docs.oracle.com/javase/9/tools/javapackager.htm](https://docs.oracle.com/javase/9/tools/javapackager.htm)
    or you can just run the command `javapackager` on a computer where JDK is installed
    (it comes with Java 8 too) you will get the list of tool options and their brief
    description.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Basically, to use the `javapackager` tool, all you need to do is to prepare
    a project with everything you would like to package together, including all the
    dependencies (packaged in JAR files), and run the `javapackager` command with
    the necessary options that allow you to specify the type of output you would like
    to have (`.exe` or `.dmg`, for example), the JRE location you would like to bundle
    together, the icon to use, the `main` class entry for `MANIFEST.MF`, and so on.
    There are also Maven plugins that make the packaging command simpler because much
    of the setup has to be configured in `pom.xml`.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'The advantages of self-contained deployment are as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: It is one file (with all the microservices that compose the reactive system
    or some part of it) to handle, which is simpler for a user and for a distributor
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no need to pre-install JRE and no risk of mismatching the required
    version
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The isolation level is high because your application has a dedicated JRE, so
    the risk of an intrusion from a co-deployed application is minimal
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have full control over the dependencies included in the bundle
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The disadvantages are as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: The size of the file is bigger, which might be an impediment if it has to be
    downloaded
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The configuration is more complex than in the case of a container-less JAR file
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The bundle has to be generated on a platform that matches the target one, which
    might lead to mismatch if you have no control over the installation process
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other processes deployed on the same hardware or virtual machine can hog the
    resources critical for your application needs, which are especially hard to manage
    if your application is downloaded and run not by the team that has developed it
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In-Container Deployment
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Those who are familiar with **Virtual Machine** (**VM**) and not familiar with
    modern containers (such as Docker, Rocket by CoreOS, VMware Photon, or similar)
    could get the impression that we were talking about VM while saying that a container
    could not only contain and execute the contained code, but also to move it to
    a different location without any change to the contained code. If so, that would
    be quite an apt assumption. VM does allow all of that, and a modern container
    can be considered a lightweight VM as it also allows the allocation of resources
    and provides the feeling of a separate machine. Yet, a container is not a full-blown
    isolated virtual computer.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: The key difference is that the bundle that can be passed around as a VM includes
    an entire operating system (with the application deployed). So, it is quite possible
    that a physical server running two VMs would have two different operating systems
    running on it. By contrast, a physical server (or a VM) running three containerized
    applications has only one operating system running, and the two containers share
    (read-only) the operating system kernel, each having its own access (mount) for
    writing to the resources they do not share. This means, for example, a much shorter
    start time, because starting a container does not require us to boot the operating
    system (as in the case of a VM).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: For an example, let's take a closer look at Docker the community leader in container.
    In 2015, an initiative called **Open Container Project** was announced, later
    renamed the **Open Container Initiative** (**OCI**), which was supported by Google,
    IBM, Amazon, Microsoft, Red Hat, Oracle, VMware, HP, Twitter, and many other companies.
    Its purpose was to develop industry standards for a container format and container
    runtime software for all platforms. Docker has donated about 5 percent of its
    code base to the project because its solution was chosen as the starting point.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'There is an extensive Docker documentation at: [https://docs.docker.com](https://docs.docker.com).
    Using Docker, one can include in the package all the Java EE Container and the
    application as a Docker image, achieving essentially the same result as with a
    self-contained deployment. Then, you can launch your application by starting the
    Docker image in the Docker engine using this command:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: It starts a process that looks like running an OS on a physical computer, although
    it can also be happening in a cloud inside a VM that is running on the physical
    Linux server shared by many different companies and individuals. That is why an
    isolation level (which, in the case of containers, is almost as high as in a VM)
    may be critical in choosing between different deployment models.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: A typical recommendation would be to put one microservice in each container,
    but nothing prevents you from putting several microservices in one Docker image
    (or any other container for that matter). However, there are already mature systems
    of container management (in the world of containers called **orchestration**)
    that can help you with deployment, so the complexity of having many containers,
    although a valid consideration, should not be a big obstacle if resilience and
    responsiveness are at stake. One of the popular orchestrations called **Kubernetes**
    supports microservice registry, discovery, and load balancing. Kubernetes can
    be used in any cloud or in a private infrastructure.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: Containers allow a fast, reliable, and consistent deployment in practically
    any of the current deployment environments, whether it is your own infrastructure
    or a cloud at Amazon, Google, or Microsoft. They also allow the easy movement
    of an application through the development, testing, and production stages. Such
    infrastructure independence allows you, if necessary, to use a public cloud for
    development and testing and your own computers for production.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Once a base operating image is created, each development team can then build
    their application on top, thus avoiding the complexities of environment configuration.
    The versions of a container can also be tracked in a version control system.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: 'The advantages of using containers are as follows:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: The level of isolation is the highest if compared with container-less and self-contained
    deployment. In addition, more efforts were put recently into adding security to
    containers.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each container is managed, distributed, deployed, started, and stopped by the
    same set of commands.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no need to pre-install JRE and risk of mismatching the required version.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have full control over the dependencies included in the container.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is straightforward to scale up/down each microservice by adding/removing
    container instances.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The disadvantages of using containers are as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: You and your team have to learn a whole new set of tools and become involved
    more heavily in the production stage. On the other hand, that seems to be the
    general tendency in recent years.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microservices is a new architectural and design solution for highly loaded processing
    systems that became popular after being successfully used in production by such
    giants as Amazon, Google, Twitter, Microsoft, IBM, and others. It does not mean
    though that you must adopt it too, but you can consider the new approach and see
    if some or any of it can help your applications to be more resilient and responsive.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Using microservices can provide a substantial value, but it is not free. It
    comes with increased complexity of the need to manage many more units through
    all the lifecycle from requirements and development through testing to production.
    Before committing to the full-scale microservice architecture, give it a shot
    by implementing just a few microservices and move them all the way to production.
    Then, let it run for some time and gauge the experience. It will be very specific
    to your organization. Any successful solution must not be blindly copied but adopted
    as fit for your particular needs and abilities.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Better performance and overall efficiency often can be achieved by gradual improvements
    of what is already in place than by radical redesign and re-architecture.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: In the next lesson, we will discuss and demonstrate new API that can improve
    your code by making it more readable and faster performing.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Assessments
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the _________ object, various verticles can be deployed, which talk to
    each other, receive an external request, and process and store data as any other
    Java application, thus forming a system of microservices.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is advantage of container-less deployment?
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each JAR file requires the JVM of a certain version or higher, which may force
    you to bring up a new physical or virtual machine just for this reason, to deploy
    one particular JAR file
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the case of an environment you do not control, your code might be deployed
    with a right version of JVM, which could lead to unpredictable results
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Processes in the same JVM compete for resources, which are especially hard to
    manage in the case of the environments shared by different teams or different
    companies
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It has a small footprint since it does not include anything else beyond the
    application itself or a group of microservices
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'State whether True or False: One way to support a transaction across several
    microservices is to create a service that would play the role of a Parallel Transaction
    Manager.'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following are the Java frameworks that are included in Java 9?
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Akka
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ninja
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Orange
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Selenium
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'State whether True or False: The level of isolation in a container is the highest
    if compared with container-less and self-contained deployment.'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
