- en: Deploying and Configuring Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After learning about Kubernetes internal components and how they interact with
    each other, it''s time to learn how to set them up. Installing a Kubernetes cluster
    manually can be a very painful and delicate process, but by going through the
    required steps, we can learn and understand better its internal components. After
    performing a manual install, we can also explore what other alternatives and tools
    we have available to automate this process. The following is a summary of what
    we will learn in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating our compute environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bootstrapping the control plane
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bootstrapping worker nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring cluster networking and DNS settings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of managed Kubernetes services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With each step, we will be closer to completing a full install of Kubernetes,
    and ready to test it in a development environment.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To deploy the infrastructure that will be running our Kubernetes cluster, we
    will be using Microsoft Azure. You can follow along by creating a free trial or
    using any other public cloud provider, or your own on-premise IT infrastructure.
    The steps will differ depending on what you choose, though.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Azure CLI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two ways of deploying resources in Azure when you are using Linux:
    you can do it either from the portal or via the Azure CLI. We will be using both,
    but for different scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin installing Azure CLI on our Linux workstation or on the Windows
    subsystem for Linux.
  prefs: []
  type: TYPE_NORMAL
- en: Note that all commands are assumed to be issued by an account with root privileges
    or the root account itself (but this is not recommended).
  prefs: []
  type: TYPE_NORMAL
- en: 'For RHEL/Centos-based distributions, you need to perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download and `import` the repository key, as shown in the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '2\. Create the repository config file, as shown in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '3\. Install `azure-cli` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '4\. Log in to your Azure subscription using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If you are not in a Desktop environment, you can use: az login --use-device-code, 
    because  the regular "az login" requires  a web browser to perform the login.
  prefs: []
  type: TYPE_NORMAL
- en: After installing Azure CLI, we still need to set up some defaults so we won't
    have to type the same flag options over and over again.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Azure CLI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Every resource on Azure lives in a resource group and a geographical location.
    Because all our resources will be living in the same resource group and location,
    let''s configure them as defaults. To do this, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For our example, we are using `east us` for the location, as this is the location
    closest to where we are based. The group name will depend on how you are going
    to name your resource group—in our case, `Kube_Deploy`.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the defaults configured, let''s move on to actually create the resource
    group that will contain our resources, using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: High-level design overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With our resource group created and our location selected, let''s take a high-level
    look at the design that we are going to create using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The important things that we need to note right now are the number of VMs, the
    network architecture, and firewall rules, because these are the elements that
    we will be configuring directly in our first steps.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at our network requirements before we start provisioning our
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the following requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following three sets of different, non-overlapping subnets:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VM subnet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pod subnet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service subnet
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Statically allocated IP addresses for the following resources:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Master nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Worker nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Management VM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Public IP for the load-balancer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DNS server
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For our VM subnet, we are going to use the following address space:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The service CIDR will be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'And finally, our POD CIDR will be a little bit bigger so that it can allocate
    more pods, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now let's start provisioning the network resources that we need to make this
    architecture possible.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning network resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we will create the virtual network that will contain our VM subnet.
    To do this, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The two key points in this command are the `address-prefix`flag and the `subnet-prefix` flag.
  prefs: []
  type: TYPE_NORMAL
- en: With the `address-prefix`flag, we will be specifying the address space that
    will define which subnets we can put on the VNET. For example, our VNET prefix
    is `192.16.0.0/16`. This means that we cannot put any address outside this CIDR;
    for example, `10.0.0.0/24` won’t work.
  prefs: []
  type: TYPE_NORMAL
- en: The subnet prefix will be the address space that will be provided to the VMs
    connected to our subnet. Now that we have created our VNET and the subnet, we
    require a static public IP address. In Azure and in any public cloud provider,
    public IPs are resources that are separate from the VM.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create our public IPs by running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Once created, we can take note of the IP by running the following query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'With our VNET, subnet, and public IP all allocated, we just need one final
    resource, a firewall, to provide security for our VMS. In Azure, firewalls are
    called **network security groups** (**NSGs**). The process of creating an NSG
    is fairly simple, as shown in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'After creating the NSG, we assign the NSG to our subnet using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Provisioning compute resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With our network all set up, we are ready to start creating some VMs. But before
    we create any VM, we need to create the SSH keys that we will use to access our
    VMs.
  prefs: []
  type: TYPE_NORMAL
- en: The first pair of keys that we will create is for our management VM. This VM
    will be the only one that will have SSH access from the outside world. We do not
    want to expose port `22` of any of our cluster nodes for security reasons. Any
    time when we want to access any of our nodes, we will be doing it from this VM.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the SSH keys, run `ssh-keygen` on your Linux workstation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s create the management VM using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Remember to replace the `<USERNAME>` field with the desired username.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is where we need to configure our first NSG rule. This rule will
    allow traffic from our own network to our management VM on port `22` so that we
    can SSH into it. Let''s set this up using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `source-address-prefixes` is your ISP provided public IP address, as this
    IPs can be dynamic, in the even that it changes, you can edit the IP on the Network
    Security Group rules in your Azure Portal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let''s connect to our VM to create SSH keys that will allow us to connect
    to our cluster VMs. To retrieve the public IP address of our management `vm`,
    run the following query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s SSH into our VM using our previously created private key, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: You will only need to specify the private key if you are logged in with a different
    user than the one with which you created the key pair.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are in the management VM, run `ssh-keygen` again and finally exit
    the VM.
  prefs: []
  type: TYPE_NORMAL
- en: To provide high availability in the case of a disaster in the Azure data centers,
    our master nodes will be on an availability set. Let’s create the availability
    set.
  prefs: []
  type: TYPE_NORMAL
- en: If you don't recall what an availability set is, you can go back to our Gluster
    chapters and revisit its functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the availability set, run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can go ahead and create our first control plane nodes. Let’s save our
    management’s VM public SSH key into a variable first to pass the key to the master
    nodes, as shown in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'To create the three controller nodes, run the following `for`loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The sizes that we are using on these VMs are small because this is only a test
    environment, and we will not really require a lot of compute resources. In a real
    environment, we would size the VMs based on the considerations that we explored
    in the [Chapter 8](ed5a52b9-ab7d-4db3-8c84-e295d7de9600.xhtml), *Architecting
    a Kubernetes Cluster*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Last but not least, we create our worker nodes using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Preparing the management VM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With our controller and worker nodes created, we can now log in to our management
    VM and start installing and configuring the tools that we will need to bootstrap
    our Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: From here on out, we will mostly be working on the management VM. Let's SSH
    to the VM and start installing our toolset.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will need to download the tools to create the certificates that our
    cluster’s services will be using to talk with one another.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will install dependencies first using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'With **Go lang** installed, you need to update your `PATH` variable and create
    a new one named `GOPATH`. Your TLS certificate-generating tool, CFFSL, will be
    installed in this path. To do this, you can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Then run the following to load the variables in your current shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'With the variables set, now we are ready to go and get our `cffsl` toolkit
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Both binaries will be saved under our `GOPATH` variable.
  prefs: []
  type: TYPE_NORMAL
- en: Generating certificates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the CFSSL binaries installed and loaded to our `PATH`, we can start generating
    our certificate files. We will be generating a lot of files in this part of the
    install, so it will be a good idea to create a directory structure to store them
    appropriately.
  prefs: []
  type: TYPE_NORMAL
- en: Certificate authority
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first files that we need to generate are the files for our certificate authority,
    which will be signing the rest of our component’s certificates.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be storing all of our certificates under the `~/certs/` directory,
    but first we need to create the directory. Let''s set this up using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the directory, let''s start by  using the following command
    to generate the CA configuration file, which will have information such as the
    expiration date of the certificates issued by our CA and what the CA is going
    to be used for:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: With our CA config, we can now start issuing certificate signing requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first CSR that we are going to generate is the one for our CA. Let''s set
    this up using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have both our `JSON` files, we can actually use `cffsl` and generate
    our certificates using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in the following command, three files will be generated, `ca.csr`,
    `ca.pem`, and `ca-key.pem`. The first one, `ca.csr`, is the certificate signing
    request. The other two are our public certificate and the private key respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This will be the case for any certificates that we generate from here on in.
  prefs: []
  type: TYPE_NORMAL
- en: Client certificates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that our CA is configured and its certificate files generated, we can start
    issuing certificates for our admin user and for the kubelet on each worker node.
  prefs: []
  type: TYPE_NORMAL
- en: The process and the files that we are going to create are very similar to the
    CA ones, but with slight differences in the commands that we use to generate them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create a directory for our `admin certs `using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: First, create the admin user certificate. This certificate is for our administrators
    to manage our cluster via `kubectl`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, we will generate the `json` for the `csr` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'With our JSON ready, let''s now sign and create the admin certificates using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: The process for creating the `kubelet` certificates is a little bit different
    compared to the admin and CA certs. The `kubelet` certificate requires us to have
    the hostname field filled up in the certificate, as this is how it will be identified.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the directory using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Then use the following command to create the `json` `csr`, in which not much
    has changed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'However, the process is a little bit different when it comes to generating
    the `certs`, as you can see from the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the hostname field will contain any IP or FQDN that the node
    will have. Now generate a cert for each worker node, filling in the information
    corresponding to the node that you are generating the cert for.
  prefs: []
  type: TYPE_NORMAL
- en: Control plane certificates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s start creating the certificate for our kube master components.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with the previous steps, create a directory that will contain the master
    node components’ certificates and generate the certificate files for each of them
    in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'For `kube-controller-manager`, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'For the `kube-proxy`, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'For the `kube-scheduler`, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to create the API server. You will notice that it is similar to
    the process we used with the `kubelets`, as this certificate requires the hostname
    parameter. But with the `kube-api` cert, we will not only provide the hostname
    and IP address of the individual nodes, we will also provide instead all of the
    possible hostnames and IPs that our API server will be using: the load-balancer
    public IP, the IP of each master node, and a special FQDN, `kubernetes.default`.
    All of them will be in a single cert.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a separate directory first using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s create a variable for the hostname using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Note that you should replace `<PUBLIC_IP>` with your public IP address.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create the certificate using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: At this point, only one certificate is missing—the service account certificate.
    This certificate is not for any normal user or Kubernetes component specifically.
    Service account certificates are used by the API server to sign tokens that are
    used for service accounts.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will be storing these key pairs in the same directory as the API certs,
    so we will just create the `json` and run the `cfssl` `gencert` command, as shown
    in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Sending our certificates home
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With all our certificates generated, it's time to move them to their corresponding
    nodes. Microsoft Azure can resolve internally via the VM name, so we can move
    the certificates easily.
  prefs: []
  type: TYPE_NORMAL
- en: 'To move the certificates to the `kubelets`, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Repeat for the rest of the nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'To move the certificates to the control plane, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Repeat for the last controllers.
  prefs: []
  type: TYPE_NORMAL
- en: Kubeconfigs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For you to be able to talk to Kubernetes, you need to know where your API is.
    You also need to tell the API who you are and what your credentials are. All of
    this information is provided with `kubeconfigs`. These configuration files contain
    all the information necessary for you to reach and authenticate against the cluster.
    Not only will users be using `kubeconfig` files to reach the cluster, they will
    also be using it to reach other services. That is why we will be generating multiple
    `kubeconfig` files for every component and user.
  prefs: []
  type: TYPE_NORMAL
- en: Installing kubectl
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To be able to create the `kubeconfig` files, we require `kubectl`. You will
    be installing `kubectl` in the management VM first to generate the config files,
    but later we will also use it to manage our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, add the repository from where we will be getting `kubectl`, as shown
    in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we install it using `yum`, as shown in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Control plane kubeconfigs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first kubeconfigs that we will be generating are for our control plane components.
  prefs: []
  type: TYPE_NORMAL
- en: 'To maintain order, we will keep organizing our files into directories. All
    our `kubeconfigs` will go in the same directory, though, as shown in the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: With our directory created, let's begin generating `kubeconfigs`!
  prefs: []
  type: TYPE_NORMAL
- en: Kube-controller-manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`kube-controller-manager` `kubeconfig`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Kube-scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`Kube-scheduler` `kubeconfig`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Kubelet configs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For our `kubelets`, we will require one `kubeconfig` for each node. To make
    things easier, we will just make a for loop to create a config for each node,
    as shown in the following command. Note that you need to replace  `<KUBE_API_PUBLIC_IP>`
    with your own public IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Finally, the last `kubeconfig` that our worker nodes will need is the `kube-proxy
    kubeconfig`. We will only be generating one as it does not contain any specific
    node configurations, and we can just copy the same config to all our nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Kube-proxy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`kube-proxy` `kubeconfig`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the control plane kubeconfigs and worker nodes, we will now
    create the `kubeconfig` for the administrator user, using the following command.
    This `kubeconfig` file is the one that we will be using to connect to the cluster
    and manage its API objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Moving configs around
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our kubeconfigs now need to be transferred to each of their corresponding VMs.
    To do this, we will follow the same procedure that we used to move the certificates.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s move kubeconfigs that go in the worker nodes using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Repeat for every node.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the kubeconfigs in place on the nodes, we can now move the `kube-api`
    server configs using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Repeat for every controller.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the control plane
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we will install the binaries required for our control plane.
  prefs: []
  type: TYPE_NORMAL
- en: ETCD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this design, we have decided to run `etcd` alongside our `kube-apiserver`.
    We will start downloading the binaries and configuring the `systemd` units for
    our database.
  prefs: []
  type: TYPE_NORMAL
- en: Installing etcd
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's time to start installing the `etcd` cluster in our controller nodes. To
    install `etcd`, we will SSH into each of the controllers from our management VM
    and run the following procedures.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by downloading and extracting the binaries using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'After we have extracted the binaries, we need to copy the kubernetes API and
    CA certificates to our `etcd` directory using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Before creating the `systemd` unit file, let’s set up some variables to make
    things a little easier.
  prefs: []
  type: TYPE_NORMAL
- en: 'These two first variables will be host-unique, as shown in the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The next and last variable will be the same across all the nodes; it will contain
    the hostname and IP of each of our `ectd` cluster members, as shown in the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the variables, let''s create the `systemd` unit file, as shown
    in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we reload, enable, and start the daemon using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have repeated this process for each of the nodes, you can check the
    status of the cluster by running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Encrypting etcd data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The API server can encrypt data stored in `etcd`. To do this, we will be using
    a flag called `--experimental-encryption-provider-config` when we create our `kube-apiserver
    systemd` unit file. But before we pass the flag, we need to create a YAML that
    will contain our encryption key.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will only create one YAML definition and copy it to every controller node.
    You should do this from the management VM so that you can easily transfer the
    file to all the controllers. Let''s set this up using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Input the YAML definition as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, move the key to every node as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Installing the Kubernetes controller binaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that `etcd` is in place, we can start installing `kube-apiserver`, `kube-controller-manager`,
    and `kube-scheduler`.
  prefs: []
  type: TYPE_NORMAL
- en: Kube-apiserver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s begin by SSHing into our first controller node and downloading the required
    binary using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Now move the binaries to `/usr/local/bin/` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will be creating and moving all the directories and certificates that
    are needed for our API server to work using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Before creating the `systemd` unit file, let''s declare some variables using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: Only the `I_IP` variable will be unique on each node, and it will depend on
    the IP of the node on which you are doing the procedure. The other three will
    be the same on all nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that the variables are set up, we can start creating the unit file, as
    shown in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Kube-controller-manager
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To install the `kube-controller-manager`, the steps will be very similar, except
    that at this point we will start using the kubeconfigs.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, download `kube-controller-manager` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Move the `kubeconfig` and create the unit file for the `kube-controller-manager` using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: Kube-scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final component to install in the control plane is `kube-scheduler`. With
    the scheduler, besides creating the `systemd` unit file we will also be creating
    a YAML file that contains the basic configuration of the scheduler.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s download the binaries. Use the following commands to download
    `kube-scheduler` and move it to `/usr/local/bin/`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'We move the `kubeconfig` file to the `kubernetes` folder using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '`kube-scheduler.yml` is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: '`kube-scheduler.service` is given as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: Repeat all the steps in the *Installing the control plane* section on each controller
    node before moving on to the next steps.
  prefs: []
  type: TYPE_NORMAL
- en: Starting the control plane
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After finishing the installation of each component on every controller node,
    we are ready to start and test the services.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, we will first enable and start all `systemd` units using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: Finally, to be able to use `kubectl` ourselves, we need to set the context of
    the cluster that we want to connect to and set up the `kubeconfig` admin as our
    default one. The `kubeconfig` admin that we have is currently set to point to
    `localhost` as the `kube-apiserver` endpoint. This will be OK for now, because
    we only want to test our components.
  prefs: []
  type: TYPE_NORMAL
- en: 'Enter the following command in your `kube-controller-1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'The output should look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: Setting RBAC permissions for kubelets.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our API server will require permissions to talk to the `kubelets` API. To accomplish
    this, we create cluster roles that we will bind to the Kubernetes user. We will
    do this on just one of the controller nodes because we will use `kubectl`, and
    the changes will be applied to the entire cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster role
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Create a cluster role that contains the permissions using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: Cluster role binding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now bind the role to the Kubernetes user using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: Load-balancer setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need to load-balance the request to all our kube-controller-nodes. Because
    we are running on the cloud, we can create a load-balancer object that will load-balance
    requests across all our nodes. Not only that, but we can configure health probes
    that will monitor the status of our controller nodes to see if they are available
    to receive requests.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the load-balancer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The load-balancer is what we have been saving the public IP for. The LB is going
    to be our point of access to our cluster from the outside. We will need to create
    rules to health-check port `80` and to redirect `kubectl` requests to `6443`.
  prefs: []
  type: TYPE_NORMAL
- en: Let's go through the following steps to achieve this.
  prefs: []
  type: TYPE_NORMAL
- en: Azure load-balancer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will have to go back to our workstation with the Azure CLI installed to go
    through the next set of steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the load-balancer in your workstation and assign it the public IP,
    run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have created our load-balancer, we still need to configure three
    more things:'
  prefs: []
  type: TYPE_NORMAL
- en: The backend pool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Health probes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load balancing rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The backend pool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far ,we have been doing everything related to Azure via the Azure CLI. Let''s
    go through the following steps via the Azure portal so you can familiarize yourself
    with the portal as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c8a39b26-0784-4a9b-aa82-9ce3e429b507.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To create the backend pool, navigate to your kube-lb object as shown in the
    following screenshots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/39e23280-0c2f-4e1a-a367-fe23bab0fb65.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When you are inside the load-balancer object, navigate to Backend Pools and
    click on Add, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/315ef824-ef98-4093-a4d4-ad9e97422f10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'When you click on Add, a menu will appear. Name your backend pool `kube-lb-backend`
    and make sure you select all the kube-controller-nodes and their respective IPs,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0fd2e97f-982e-4dbe-85ba-b52bb5428e03.png)'
  prefs: []
  type: TYPE_IMG
- en: Example
  prefs: []
  type: TYPE_NORMAL
- en: Click on Add to finish. We have successfully set up backend VMs.
  prefs: []
  type: TYPE_NORMAL
- en: Health probes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we can create load balancing rules, we need to create the health probes
    that will tell our LB which nodes are available to receive traffic. Because, at
    the time of writing this chapter, load-balancers in Azure do not support HTTPS
    health probes, we will need to expose the `/healthz` endpoint through HTTP. To
    do this, we will install Nginx in our controller nodes, and pass proxy requests
    coming to port `80` to port `6443`.
  prefs: []
  type: TYPE_NORMAL
- en: 'SSH back to your controller nodes and perform the following procedures in each
    one of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Once Nginx is installed, replace the `server` entry in `/etc/nginx/nginx.conf`
    with the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: Because we are running a RHEL-based distribution, SELINUX is enabled by default;
    therefore, it will be preventing Nginx from accessing the TCP socket on port `6443`.
    To permit this behavior, we need to run the following commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we install the required packages to manage SELINUX, as shown in the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the packages are installed, we run the following to allow connections
    to port `6443`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, we use the following command to start `nginx`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to test this, you can always run a `curl` on `localhost`, like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output will be generated if everything was correctly configured:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: Remember to repeat all these procedures for each of the controller nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Now that the health endpoints are exposed, we are ready to create health probe
    rules in the load-balancer.
  prefs: []
  type: TYPE_NORMAL
- en: Back in the `kube-lb` menu, under Settings—the same place where we configure
    backend pools—select health probes and click on Add.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the menu appears, fill in the fields as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de036edf-e4cc-4d3a-b71a-0f471cff5621.png)'
  prefs: []
  type: TYPE_IMG
- en: Load-balancing rules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have everything ready to create load-balancing rules and get our load-balancer
    ready for use.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process is the same one that we used with backend pools and health probes.
    Go to the Settings menu under kube-lb and select Load Balancing Rules. Click on
    Add and fill in the dialog that appears, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ab7bfe68-f15c-4c60-a5d0-46072476d4bf.png)'
  prefs: []
  type: TYPE_IMG
- en: Once what is ready, we just need to open our network security group to allow
    connections on port `6443`.
  prefs: []
  type: TYPE_NORMAL
- en: 'On your Azure CLI workstation, run the following command to create the rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: Give it a few minutes to take effect, and then navigate in your browser to `https://<LB_IP>:6443/version`.
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: This will indicate that you can access the API server through the LB.
  prefs: []
  type: TYPE_NORMAL
- en: Worker node setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's time to configure and install our worker nodes. In these, we will be installing
    `kubelet`, the kube proxy, the container runtime, and the container network interface
    plugins.
  prefs: []
  type: TYPE_NORMAL
- en: 'SSH into the first worker node from your management VM, as shown in the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: Downloading and preparing binaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before configuring any service, we need to download any dependencies and set
    up the required repositories. After this, we can start downloading the binaries
    and moving them to their respective locations.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the Kubernetes repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The repository that we need to configure is the Kubernetes repository. With
    this, we will be able to download `kubectl`. Let''s set this up using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Installing dependencies and kubectl
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the `repo` configured, we can start downloading `kubectl` and any required
    dependencies for the binaries that we will download. Let''s set this up using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: Downloading and storing worker binaries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have the dependencies ready, we can download our required worker
    binaries using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let''s create the folder structure for the recently downloaded binaries
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'We change the name to `runc` for ease of use and to conform to the convention,
    as shown in the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: 'We give executable permissions to the rest of our binaries using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'After giving them executable rights, we can move them to `/usr/local/bin/` using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'Some of the downloaded files are TAR archives, which we need to `untar` and
    store in their respective locations using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: Containerd setup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are ready now to start configuring each service. The first one is `containerd`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create the configuration directory using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we create the `toml` config file, which will tell `containerd` what container
    runtime to use. Let''s set this up using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let''s set up the `systemd` unit file using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: The kubelet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our main service in the worker nodes is the `kubelet`. Let's create its configuration
    files.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to move the `kubelet` certificates to their locations using
    the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we create the YAML config file that will contain things such as the DNS
    server IP address, the cluster domain, and the location of the certificate files.
    Let''s set this up using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we create the service unit file using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: kube-proxy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next service to create is `kube-proxy`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We move the previously created `kubeconfigs` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'As with `kubelet`, `kube-proxy` also requires a config `YAML` that has the
    cluster CIDR and the mode in which `kube-proxy` will operate. Let''s set this
    up using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we create a unit file for `kube-proxy` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: Starting services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Once you have completed these procedures on ALL kube-nodes, you can start the
    services on each node with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: Kubernetes networking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We still have a couple more things to do in our cluster: we need to install
    a network provider and configure the DNS.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting the nodes ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Our nodes will have to be able to forward packets in order for our pods to be
    able to talk to the outside world. Azure VMs do not have IP forwarding enabled
    out-of-the-box, so we will have to enable it manually.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, go to your Azure CLI workstation and run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: This will enable IP forwarding capabilities on the VM’s NIC.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have to enable the IP-forwarding kernel parameter on the worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'SSH into each worker node from the management VM and enable IPv4 forwarding
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: Configuring remote access
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, in order to run `kubectl` commands from your management VM, we need to
    create a `kubeconfig` that uses the admin certificate and the public IP address
    of our cluster. Let''s set this up using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: Installing Weave Net
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With remote access on our management VM configured, we can now run `kubectl`
    commands without having to log in to our controller nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install Weave Net, run the following `kubectl` command from the management
    VM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: With Weave Net installed, now our pods will have IP allocations.
  prefs: []
  type: TYPE_NORMAL
- en: DNS server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we will provision our DNS server, which will be provided by Core DNS, an
    open source DNS server based on plugins. Let''s set this up using the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the DNS pods with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'With the DNS server pods created, we have successfully finished the installation
    of our Kubernetes cluster. If you want, you can create the following deployment
    to test the cluster one more time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: Now that we have seen the steps needed to create a cluster from scratch, I want
    to talk a little bit about managed Kubernetes solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Managing Kubernetes on the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Installing and making a Kubernetes cluster usable and ready for production,
    as you saw in this chapter, is a very long and complex process. If any step goes
    wrong, your entire deployment might be useless. Because of this, many cloud providers
    are offering managed Kubernetes solutions—Kubernetes as a service, in a way. In
    this type of managed solution, the cloud provider or service provider will manage
    the master nodes of the cluster, which include all the Kubernetes controllers,
    the API server, and even the `etcd` database. This is a major advantage because
    using a managed service will mean that you don''t have to worry about the maintenance
    of the master nodes, and so you won''t have to worry about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Renewing SSL certificates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating/upgrading the `etcd` database
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating/upgrading each of the master node binaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Registering extra nodes to the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack of support if something goes wrong
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transparent integration with the cloud infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operating system patching and maintenance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By forgetting these, we can focus on what's important, such as provisioning
    pods and creating workloads on our cluster. With managed services, the learning
    curve decreases dramatically because our staff can focus mainly on the functionality
    of Kubernetes instead of how it works in order for them to maintain it.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the time of writing, some managed Kubernetes services worth mentioning are
    from the following three biggest cloud providers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Kubernetes Services** (**AKS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Amazon Web Services Elastic Container Service for Kubernetes** (**EKS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Google Kubernetes Engine** (**GKE**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Besides managed Kubernetes services, there are also several open-source projects
    and non-open-source projects that are Kubernetes-based. These projects are not
    entirely managed, but instead use Kubernetes in the backend to achieve their goals.
    The following are some more well-known projects:'
  prefs: []
  type: TYPE_NORMAL
- en: Okd (Red Hat's upstream community project for Red Hat OpenShift)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Red Hat OpenShift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SUSE **Container as a Service** (**Caas**)platform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mesosphere Kubernetes Engine
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned the basic steps of provisioning a Kubernetes cluster.
    We also learned about the Azure command-line interface and how to provision resources
    in Azure. We also tried different tools across the whole deployment, such as CFSSL
    and Nginx.
  prefs: []
  type: TYPE_NORMAL
- en: We learned about and provisioned `kubectl` configuration files that enabled
    us to access our cluster and deployed a dummy deployment to test our cluster.
    Finally, we looked at the benefits of running a managed cluster and the different
    types of managed service that we can find in the major public cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will explain what each component does. The reader will learn
    about the different components and their purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How do you install Kubernetes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a `kubeconfig`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we create SSL certificates?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is AKS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we use the Azure CLI?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we provision a resource group in Azure?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we install `etcd`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Mastering Kubernetes* by Packt Publishing: [https://prod.packtpub.com/in/application-development/mastering-kubernetes-second-edition](https://prod.packtpub.com/in/application-development/mastering-kubernetes-second-edition)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kubernetes for Developers* by Packt Publishing: [https://prod.packtpub.com/in/virtualization-and-cloud/kubernetes-developers](https://prod.packtpub.com/in/virtualization-and-cloud/kubernetes-developers)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hands-On Microservices with Kubernetes* by Packt Publishing: [https://prod.packtpub.com/in/virtualization-and-cloud/hands-microservices-kubernetes](https://prod.packtpub.com/in/virtualization-and-cloud/hands-microservices-kubernetes)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bibliography/sources:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Generating self-signed certificates:** [https://coreos.com/os/docs/latest/generate-self-signed-certificates.html](https://coreos.com/os/docs/latest/generate-self-signed-certificates.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CloudFlare''s PKI/TLS toolkit**: [https://github.com/cloudflare/cfssl](https://github.com/cloudflare/cfssl)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Go Programming Language**:[ ](https://golang.org/doc/install)[https://golang.org/doc/install](https://golang.org/doc/install)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
