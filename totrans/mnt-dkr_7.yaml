- en: Chapter 7. Collecting Application Logs from within the Container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most overlooked parts of monitoring are log files generated by the
    application or services such as NGINX, MySQL, Apache, and so on. So far we have
    looked at various ways of recording the CPU and RAM utilization of the processes
    within your containers are at a point in time, now its time to do the same for
    the log files.
  prefs: []
  type: TYPE_NORMAL
- en: If you are running your containers as Cattle or Chickens, then the way you deal
    with the issues to destroy and relaunch your container either manually or automatically
    is important. While this should fix the immediate problem, it does not help with
    tracking down the root cause of the issue and if you don't know that then how
    can you attempt to resolve it so that it does not reoccur.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at how we can get the content of the log files
    for the applications running within our containers to the central location so
    that they are available, even if you have to destroy and replace a container.
    We are going to cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: How to view container logs?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying an "ELK" stack using a Docker containers stack to ship the logs to
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing your logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What third party options are available?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viewing container logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like the `docker top` command, there is a very basic way of viewing logs. When
    you use the `docker logs` command, you are actually viewing the `STDOUT` and `STDERR`
    of the processes that are running within the container.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For more information on Standard Streams, please see [https://en.wikipedia.org/wiki/Standard_streams](https://en.wikipedia.org/wiki/Standard_streams).
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see from the following screenshot, the simplest thing you have to
    do is run `docker logs` followed by your container name:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Viewing container logs](../images/00059.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'To see this on your own host, let''s launch the WordPress installation from
    `chapter05` using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You can extend the `dockerlogs` command by adding the following flags before
    your container name:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-f` or `--follow` will stream the logs in real time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-t` or `--timestamps` will show a timestamp at the start of each line'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--tail="5"` will show the last *x* number of lines'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--since="5m00s"` will show only the entries for the last 5 minutes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using the WordPress installation that we have just launched, try running the
    following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show the last two lines of the logs, you can add timestamps using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in the following terminal output, you can also string commands
    together to form a very basic query language:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Viewing container logs](../images/00060.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The downside of using `docker logs` is exactly the same as using `docker top`,
    in that it is only available locally and the logs are only present for the time
    the container is around, you can view the logs of a stopped container, but once
    the container is removed, so are the logs.
  prefs: []
  type: TYPE_NORMAL
- en: ELK Stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to some of the technologies that we have covered in this book, an ELK
    stack really deserves a book by itself; in fact, there are books for each of the
    elements that make an ELK stack, these elements are:'
  prefs: []
  type: TYPE_NORMAL
- en: Elasticsearch is a powerful search server, which has been developed with modern
    workloads in mind
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logstash sits between your data source and Elasticsearch services; it transforms
    your data in real time to a format, which Elasticsearch can understand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kibana is in front of your Elasticsearch services and allows you to query your
    data in a feature-rich web-based dashboard.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a lot of moving parts with an ELK stack, so to simplify things, we
    will use a prebuilt stack for the purpose of testing; however, you probably don't
    want to use this stack in production.
  prefs: []
  type: TYPE_NORMAL
- en: Starting the stack
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s launch a fresh vagrant host on which to run the ELK stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we have a clean host that is up and running, we can start the stack by
    running the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As you may have noticed, it did more that just pull down some images; what
    happened was:'
  prefs: []
  type: TYPE_NORMAL
- en: An Elasticsearch container was launched using the official image from [https://hub.docker.com/_/elasticsearch/](https://hub.docker.com/_/elasticsearch/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Logstash container was launched using the official image from [https://hub.docker.com/_/logstash/](https://hub.docker.com/_/logstash/),
    it was also launched with our own configuration, which means that our installation
    listens for logs sent from Logspout (more about that in a minute).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A custom Kibana image was built using the official image from [https://hub.docker.com/_/kibana/](https://hub.docker.com/_/kibana/).
    All it did was add a small script to ensure that Kibana doesn't start until our
    Elasticsearch container is fully up and running. It was then launched with a custom
    configuration file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A custom Logspout container was built using the official image from [https://hub.docker.com/r/gliderlabs/logspout/](https://hub.docker.com/r/gliderlabs/logspout/)
    and then we added a custom module so that Logspout could talk to Logstash.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once `docker-compose` has finished building and launching the stack you should
    be able to see the following when running `docker-compose ps`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Starting the stack](../images/00061.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: We now have our ELK stack up and running, as you may have noticed, there is
    an additional container running and giving us an ELK-L stack, so what is Logspout?
  prefs: []
  type: TYPE_NORMAL
- en: Logspout
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we were to launch Elasticsearch, Logstash, and Kibana containers, we should
    have a functioning ELK stack but we will have a lot of configuration to do to
    get our container logs into Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since Docker 1.6, you have been able to configure logging drivers, this meant
    that it is possible to launch a container and have it send its `STDOUT` and `STDERR`
    to a Syslog Server, which will be Logstash in our case; however, this means that
    you will have to add something similar to the following options each time we launch
    a container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This is where Logspout comes in, it has been designed to collect all of the
    `STDOUT` and `STDERR` messages on a host machine by intercepting the messages
    that are being collected by the Docker process and then it routes them to our
    Logstash instance in a format that is understood by Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: Just as the log-driver, it supports Syslog out of the box; however, there is
    a third party module that transforms the output to JSON, which Logstash understands.
    As a part of our build we downloaded, compiled and configured the module.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find out more about Logspout and logging drivers at the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Official Logspout image: [https://hub.docker.com/r/gliderlabs/logspout/](https://hub.docker.com/r/gliderlabs/logspout/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Logspout Project page: [https://github.com/gliderlabs/logspout](https://github.com/gliderlabs/logspout)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Logspout Logstash module: [https://github.com/looplab/logspout-logstash](https://github.com/looplab/logspout-logstash)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docker 1.6 release notes: [https://blog.docker.com/2015/04/docker-release-1-6/](https://blog.docker.com/2015/04/docker-release-1-6/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docker Logging Drivers: [https://docs.docker.com/reference/logging/overview/](https://docs.docker.com/reference/logging/overview/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing the logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So now, we have our ELK running and a mechanism in place to stream all of the
    `STDOUT` and `STDERR` messages generated by our containers into Logstash, which
    in turn routes the data into Elasticsearch. Now its time to view the logs in Kibana.
    To access Kibana go to `http://192.168.33.10:8080/` in your browser; when you
    access the page, you will be asked to **Configure an index pattern**, the default
    index pattern will be fine for our needs so just click the **Create** button.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you do, you will see a list of the index patterns, these are taken directly
    from the Logspout output, and you should notice the following items in the index:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker.name`: The name of container'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker.id`: The full container ID'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker.image`: The name of the image used to launch the image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From here, if you were to click on **Discover** in the top menu you would see
    something similar to the following page:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Reviewing the logs](../images/00062.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'In the screenshot, you will see that I have recently launched the WordPress
    stack and we have been using it throughout the book, using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To give you an idea of what is being logged, here is the raw JSON taken from
    Elasticseach for running the WordPress installation script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: From here, you can start to use the free text search box and build up some quite
    complex queries to drill down into your container's `STDOUT` and `STDERR` logs.
  prefs: []
  type: TYPE_NORMAL
- en: What about production?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned at the top of this section, you probably don't want to run your
    production ELK stack using the `docker-compose` file, which accompanies this chapter.
    First of all, you will want your Elasticsearch data to be stored on a persistent
    volume and you more than likely want your Logstash service to be highly available.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are numerous guides on how to configure a highly available ELK stack,
    as well as, the hosted services from Elastic, which is the creator of Elasticsearch,
    and also Amazon Web Services, which offers an Elasticsearch service:'
  prefs: []
  type: TYPE_NORMAL
- en: 'ELK tutorial: [https://www.youtube.com/watch?v=ge8uHdmtb1M](https://www.youtube.com/watch?v=ge8uHdmtb1M)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Found from Elastic: [https://www.elastic.co/found](https://www.elastic.co/found)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Amazon Elasticsearch Service: [https://aws.amazon.com/elasticsearch-service/](https://aws.amazon.com/elasticsearch-service/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Looking at third party options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a few options when it comes to hosting central logging for your containers
    external to your own server instances. Some of these are:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Log Entries: [https://logentries.com/](https://logentries.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Loggly: [https://www.loggly.com/](https://www.loggly.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these services offer a free tier. Log Entries also offers a "Logentries
    DockerFree" account that you can find out more about at [https://logentries.com/docker/](https://logentries.com/docker/)
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As recommended in the *Exploring Third Party Options* chapter, it is best to
    use a cloud service when evaluating third party services. The remainder of this
    chapter assumes that you are running a cloud host.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at configuring the Log Entries on an external server, first of all
    you need to have signed up for an account at [https://logentries.com/](https://logentries.com/).
    Once you have signed up, you should be taken to a page in which your logs will
    eventually be displayed.
  prefs: []
  type: TYPE_NORMAL
- en: To start, click on the **Add new log** button in the top-right corner of the
    page and then click the Docker logo in the **Platforms** section.
  prefs: []
  type: TYPE_NORMAL
- en: 'You have to name your set of logs in the **Select set** section, so give a
    name to your log set. You now have the choice of building your own container locally
    using the Docker file from [https://github.com/logentries/docker-logentries](https://github.com/logentries/docker-logentries):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After running the preceding command, you will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Looking at third party options](../images/00063.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'Before you start your container, you will need to generate an access token
    for your log set by clicking on **Generate Log Token**. Once you have this, you
    can launch your locally built containers using the following command (replace
    the token with the one you have just generated):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You can download the image straight from the Docker hub by running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It's worth pointing out that the automatically generated instructions given
    by Log Entries launches the container in the foreground, rather than detaching
    from the container once it has been launched like the preceding instructions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have the `docker-logentries` container up and running, you should
    start to see logs from your container streamed in real-time to your dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Looking at third party options](../images/00064.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: From here, you will be able to query your logs, create dashboards, and create
    alerts depending on the account option you go for.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have covered how to query the `STDOUT` and `STDERR` output
    from your containers using the tool built into Docker, how to ship the messages
    to an external source, our ELK stack, and how to store the messages even after
    the container has been terminated. Finally, we have looked at a few of the third-party
    services who offer services to which you can stream your logs.
  prefs: []
  type: TYPE_NORMAL
- en: So why go to all of this effort? Monitoring isn't just about keeping and querying
    CPU, RAM, HDD, and Network utilization metrics; there is no point in knowing if
    there was a CPU spike an hour ago if you don't have access to the log files to
    see if any errors were being generated at that time.
  prefs: []
  type: TYPE_NORMAL
- en: The services we have covered in this chapter offer the quickest and most efficient
    insights into what can quickly become a complex dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at all of the services and concepts we have
    covered in the book and apply them to some real world scenarios.
  prefs: []
  type: TYPE_NORMAL
