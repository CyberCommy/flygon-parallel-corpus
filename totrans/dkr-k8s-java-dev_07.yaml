- en: Introduction to Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After reading [Chapter 6](text00108.html) , *Running Containers with Java Applications*
    , you now have a lot of knowledge about using Docker to package your Java applications.
    It''s now time to move even further and focus on what we are missing--the container
    management and orchestration. There are some suitable tools on the market, such
    as Nomad, Docker Swarm, Apache Mesos, or AZK, for example. In this chapter, we
    will focus on probably the most popular one, Kubernetes. Kubernetes (sometimes
    referred to as k8s) is an open source orchestration system for Docker containers,
    created by Google in 2015\. The first unified container management system developed
    at Google was the system, internally called, Borg; Kubernetes is its descendant.
    The list of topics covered in this chapter will be:'
  prefs: []
  type: TYPE_NORMAL
- en: Why and when we need container management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An introduction to Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basic Kubernetes concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's begin with answering the question, why do we even need Kubernetes? We
    will look at the reasoning behind container management and orchestration.
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need Kubernetes?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you already know, Docker containers provide great flexibility for running
    Java services packaged into small, independent pieces of software. Docker containers
    make components of your application portable--you can move individual services
    across different environments without needing to worry about the dependencies
    or the underlying operating system. As long as the operating system is able to
    run the Docker engine, your Java containers can run on this system.
  prefs: []
  type: TYPE_NORMAL
- en: Also, as you remember from [Chapter 1](text00022.html) , *Introduction to Docker*
    , the Docker concept of isolating containers is far from the traditional virtualization.
    The difference is that Docker containers utilize the resources of the host operating
    system--they are light, fast, and easy to spin up. It's all very nice, but there
    are some risks. Your application consists of multiple, independent microservices.
    The number of services can, and probably will, grow in time. Also, if your application
    starts to experience a higher load, it would be nice to increase the number of
    containers with the same service, just to distribute the load. It doesn't mean
    you only need to use your own server infrastructure--your containers can go to
    the cloud. Today we have a lot of cloud providers, such as Google or Amazon. By
    having the possibility to run your containers in the cloud, it gives you a lot
    of advantages. First, you don't need to manage your own servers. Second, in most
    clouds, you pay only for the real usage. If there's a peak in the load, the cost
    of the cloud service will increase, of course, as you will be using more computing
    power. But if there is no load, you will pay nothing. This is easy to say, but
    monitoring your server usage, especially with an application or applications running
    with a huge number of components, can be tricky. You will need to look at the
    bill from the cloud company carefully and make sure that you don't have a container
    sitting in the cloud spinning and doing nothing. If the specific service is not
    that important for your application and does not need to respond fast, you can
    move it to the cheapest machine. On the other hand, if another service experiences
    higher loads and it's critical, you will want to move it to a more powerful machine
    or spin up more instances of it. Best of all, by using Kubernetes, it can be automated.
    By having the right tool for managing Docker containers, this can be done on the
    fly. Your application can adapt itself in a very agile way--the end users will
    probably not even be aware of where an application they're using resides. Container
    management and monitoring software can greatly reduce the hardware costs by better
    utilizing the hardware you are paying for. Kubernetes handles scheduling onto
    nodes in a compute cluster and actively manages workloads to ensure that their
    state matches the user's declared intentions. Using the concepts of labels and
    Pods (which we are going to cover later in this chapter), Kubernetes groups the
    containers which make up an application into logical units for easy management
    and discovery.
  prefs: []
  type: TYPE_NORMAL
- en: Having your application in the form of a set of containers running in a managed
    environment also changes the perspective on software development. You can work
    on a new version of the service and when it's ready, you can do a rolling update
    on the fly. This also means focusing on the application over the machines it runs
    on and this, as a result, allows developer teams to operate in a much more flexible,
    smaller, and modular manner. It allows the software development to be truly agile,
    which is what we always wanted. Microservices are small and independent, and the
    build and deployment times are dramatically lower. Also, the risk of doing releases
    is smaller so you can release smaller changes more often, minimizing the possibility
    of a huge failure which may happen if you release everything in one go.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we begin with basic Kubernetes concepts, let''s summarize what Kubernetes
    gives us in a list:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploying applications quickly and predictably
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling on the fly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Releasing new features seamlessly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fail-proofing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limiting hardware usage only to required resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agile application development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Portability between operating systems, hosts, and cloud providers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is a list of features that cannot be easily beaten. To understand how this
    is being achieved, we need to understand the core Kubernetes concepts. So far,
    we know only one single concept coming from Docker--the container--which is a
    portable, independent unit of software. The container can contain anything we
    want, be it a database or a Java REST microservice. Let's get to know the remaining
    pieces.
  prefs: []
  type: TYPE_NORMAL
- en: Basic Kubernetes concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A cluster is a group of nodes; they can be physical servers or virtual machines
    that have the Kubernetes platform installed. The basic Kubernetes architecture
    is presented in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00080.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, the Kubernetes cluster consists of a Master node and a number
    of worker nodes with some components inside. While it may look scary and complicated
    at first glance, it will be easier to understand if we describe the concepts one
    by one, starting with the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Pods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Pod consists of one or more Docker containers. This is the basic unit of
    the Kubernetes platform and an elementary piece of execution that Kubernetes works
    with. A diagram of the Pod is presented as following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00081.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Containers running in the same Pod share the same common network namespace,
    disk, and security context. In fact, the communication over localhost is recommended
    between containers running on the same Pod. Each container can also communicate
    with any other Pod or service within the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: As you remember from [Chapter 2](text00037.html) , *Networking and Persistent
    Storage* , you can mount volumes within Docker containers. Kubernetes also supports
    the concept of a volume. Volumes that are attached to the Pod may be mounted inside
    of one or more containers running on this Pod. Kubernetes supports a lot of different
    volume types as a native support for mounting GitHub repositories, network disks,
    local hard drives, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'If your application needs a distributed storage and needs to handle large amounts
    of data, you are not limited only to local hard drives. Kubernetes also supports
    Volume Providers. Currently, the list of available Persistent Volume Providers
    includes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**GCE** : Which is a Google Cloud platform'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AWS** : Amazon Web Services'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GlusterFS** : A scalable network filesystem. Using GlusterFS, which is free
    and an open source software, you can use your existing storage hardware to create
    large, distributed storage solutions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenStack Cinder** : A block storage service for users of the OpenStack Nova
    compute platform'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CephRBD** : A **Reliable Autonomic Distributed Object Store** (**RADOS**
    ), which provides your applications with object, block, and file system storage
    in a single unified storage cluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: QuoByte
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kube-Aliyun
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Network namespace and volumes are not the only properties of the Pod. As you
    can see on the Pod''s diagram, a Pod can have labels and annotations attached.
    Labels are very important in Kubernetes. They are key/value pairs that are attached
    to objects, in this case to Pods. The idea behind labels is that they can be used
    to identify objects--labels are meaningful and relevant to users. An example of
    the label may be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Later on, we will be using label selectors to select objects (such as Pods)
    having the specified label. Via a label selector, which is the core grouping primitive
    in Kubernetes, the client or user can identify an object or a set of objects.
    A selector, similar to a label, is also a key-value expression to identify resources
    using matching labels. For example, the selector expression `app = my-rest-service`
    would select all Pods with the label `app = my-rest-service` . Annotations, on
    the other hand, are a kind of metadata you can attach to Pods. They are not intended
    to be identifying attributes; they are such properties that can be read by tools
    of libraries. There are no rules as to what an annotation should contain--it's
    up to you. The annotation can contain information such as the build or release
    version, a timestamp, Git branch name, Git `pull` request number, or just anything,
    as a mobile number.
  prefs: []
  type: TYPE_NORMAL
- en: Labels are intended for identifying information about Kubernetes objects such
    as Pods. Annotations are just metadata attached to an object.
  prefs: []
  type: TYPE_NORMAL
- en: We've said before that a Pod is a basic unit of execution in Kubernetes. It
    can contain multiple containers. A real-life example of having a Pod with more
    than one Docker container could be our Java REST microservice Pod. For example
    purposes in previous chapters, our microservice has been storing its database
    data in memory. In real life, the data should probably go to the real database.
    Our Pod would probably have a container with Java JRE and the Spring Boot application
    itself, together with the second container with a PostgreSQL database, which the
    microservice uses to store its data. Two of those containers makes a Pod--a single,
    decoupled unit of execution that contains everything our REST service needs to
    operate.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Pod''s definition is a JSON or YAML file called a `Pod` manifest. Take
    a look at a simple example with one container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The same `pod` manifest in a JSON file will look the same as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The container's `image` is a Docker image name. The `containerPort` exposes
    that port from the REST service container so we can connect to the service at
    the Pod's IP. By default, as you remember from [Chapter 1](text00022.html) , *Introduction
    to Docker* , the entry point defined in the `image` is what will run.
  prefs: []
  type: TYPE_NORMAL
- en: It's very important to be aware that a Pod's life is fragile. Because the Pods
    are treated as stateless, independent units, if one of them is unhealthy or is
    just being replaced with a newer version, the Kubernetes Master doesn't have mercy
    on it--it just kills it and disposes of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In fact, Pods have a strictly defined lifecycle. The following list describes
    the phases of a Pod''s life:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pending` : This phase means that the Pod has been accepted by the Kubernetes
    system, but one or more of the Docker container images has not been created. Pods
    can be in this phase for a while--if the image needs to be downloaded from the
    internet, for example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`running` : The Pod has been put onto a node and all of the Pod''s Docker containers
    have been created.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`succeeded` : All Docker containers in the Pod have been terminated with a
    success status.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`failed` : All Docker containers in the Pod have been terminated, but at least
    one container has terminated with a failure status or was terminated by the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`unknown` : This typically indicates a problem with communication to the host
    of the Pod; for some reason, the state of the Pod could not be retrieved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a Pod is being brought down, it's not only because it has failed. More
    often, if our application needs to handle an increased load, we need to have more
    Pods running. On the other hand, if the load decreases or there is no load at
    all, there's no point in having a lot of Pods running--we can dispose of them.
    Of course, we could start and stop Pods manually, but it's always better to automate.
    This brings us to the concept of ReplicaSets.
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'ReplicaSets is the concept used in scaling your application by using replication.
    What is Kubernetes replication useful for? Typically, you would want to replicate
    your containers (which are, in fact, your application) for several reasons, including:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scaling** : When load increases and becomes too heavy for the number of existing
    instances, Kubernetes enables you to easily scale up your application, creating
    additional instances as needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Load balancing** : We can easily distribute traffic to different instances
    to prevent overloading of a single instance or node. Load balancing comes out
    of the box because of Kubernetes'' architecture and it''s very convenient.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reliability and fault tolerance** : By having multiple versions of an application,
    you prevent problems if one or more fail. This is particularly true if the system
    replaces any containers that fail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replication is appropriate for numerous use cases, including microservice-based
    applications where multiple, independent small services provide very specific
    functionality, or cloud native applications that are based on the theory that
    any component can fail at any time. Replication is a perfect solution for implementing
    them, as multiple instances naturally fit into the architecture.
  prefs: []
  type: TYPE_NORMAL
- en: A ReplicaSet ensures that a specified number of Pod clones, known as replicas,
    are running at any given time. It there are too many, they will be shut down.
    If there is a need for more, for example some of them died because of an error
    or crash, or maybe there's a higher load, some more Pods will be brought to life.
    ReplicaSets are used by Deployments. Let's see what Deployments are.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Deployment is responsible for creating and updating instances of your application.
    Once the Deployment has been created, the Kubernetes Master schedules the application
    instances onto individual nodes in the cluster. A Deployment is a higher level
    of abstraction; it manages ReplicaSets when doing Pod orchestration, creation,
    deletion, and updates. A Deployment provides declarative updates for Pods and
    ReplicaSets. The Deployment allows for easy updating of a Replica Set as well
    as the ability to roll back to a previous deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'You just specify the number of replicas you need and the container to run within
    each Pod and the Deployment controller will spin them up. The example Deployment
    manifest definition in the YAML file looks the same as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the previous example, the Deployment Controller will create a ReplicaSet
    containing three Pods running our Java REST service.
  prefs: []
  type: TYPE_NORMAL
- en: The Deployment is a kind of control structure that takes care of the spinning
    up or down of Pods. A Deployment takes care of the state of a Pod or group of
    pods by creating or shutting down replicas. Deployments also manage updates to
    Pods. Deployments are a higher abstraction, which create ReplicaSets resources.
    ReplicaSets watch over the Pods and make sure the correct number of replicas are
    always running. When you want to update a Pod, you will need to modify the Deployment
    manifest. This modification will create a new ReplicaSet, which will be scaled
    up while the previous ReplicaSet will be scaled down, providing no down-time deployment
    of your application.
  prefs: []
  type: TYPE_NORMAL
- en: The main purpose of Deployments is to do rolling updates and rollbacks. A rolling
    update is the process of updating an application to a newer version, in a serial,
    one-by-one fashion. By updating one instance at a time, you are able to keep the
    application up and running. If you were to just update all instances at the same
    time, your application would likely experience downtime. In addition, performing
    a rolling update allows you to catch errors during the process so that you can
    roll back before it affects all of your users.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment also allows us to do an easy rollback. To do the rollback, we simply
    set the revision that we want to roll back to. Kubernetes will scale up the corresponding
    ReplicaSet and scale down the current one, and this will result in a rollback
    to a specified revision of our service. In fact, we will be using Deployments
    heavily in [Chapter 8](text00159.html) , *Using Kubernetes with Java* , to roll
    out an update of our service to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Replication is a large part of Kubernetes' features. As you can see, the life
    of a Pod is delicate and ephemeral. Because Pods and their clones come and go
    all the time, we need something permanent and tangible, something that will stay
    forever so our application's users (or other Pods as well) can discover and call.
    This brings us to the concept of Kubernetes services. Let's focus on them now.
  prefs: []
  type: TYPE_NORMAL
- en: Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes services group one or more Pods into an internal or external process
    that needs to be long-running and externally accessible, as our Java REST API
    endpoint or a database host, for example. This is where the labels we gave to
    our Pods become very important; a service finds Pods to group by looking for a
    specific label. We use label selectors to select Pods with particular labels and
    apply services or ReplicaSets to them. Other applications can find our service
    through Kubernetes service discovery.
  prefs: []
  type: TYPE_NORMAL
- en: 'A service is Kubernetes'' abstraction to provide a network connection to one
    or more Pods. While (as you remember from the chapter about Docker networking),
    by default, Docker uses host-private networking, containers can communicate with
    other containers only if they are on the same host machine. In Kubernetes, cluster
    Pods can communicate with other Pods, regardless of which host they land on. This
    is possible because of the services. Each service is given its own IP address
    and port which remains constant for the lifetime of the service. Services have
    an integrated load-balancer that will distribute network traffic to all Pods.
    While a Pod''s life can be fragile as they are being spun up or down depending
    on your application needs, the service is a more constant concept. Each Pod gets
    its own IP address, but when it dies and another one is being brought to life,
    the IP address can be different. This could potentially become a problem--if a
    set of Pods provides functionality to other Pods inside the Kubernetes cluster,
    one can lose track of the other one''s IP address. Services, by having a lifetime-assigned
    IP address, solves this issue. The Service abstraction enables decoupling. Let''s
    say we have our Java REST service running on top of the Spring Boot application.
    We need a way to route HTTP requests, such as `GET` or `POST` , from the internet
    to our Docker containers. We will do it by setting up a Kubernetes service that
    uses a load balancer to route requests coming from a public IP address to one
    of the containers. We will group the containers with the REST service into a Pod
    and name it, let''s say, Our little REST service. Then we will define a Kubernetes
    service that will serve port `8080` to any of the containers in the Our little
    REST service Pod. Kubernetes will then use a load balancer to divide the traffic
    between the specified containers. Let''s summarize the Kubernetes service features:'
  prefs: []
  type: TYPE_NORMAL
- en: Services are persistent and permanent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They provide discovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They offer load balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They expose a stable network IP address
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They find Pods to group by usage of labels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We have said that there is a service discovery mechanism built-in. Kubernetes
    supports two primary modes of finding a service: environment variables and DNS.
    Service discovery is the process of figuring out how to connect to a service.
    Kubernetes contains a built-in DNS server for that purpose: the kube-dns.'
  prefs: []
  type: TYPE_NORMAL
- en: kube-dns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes offers a DNS cluster add-on, started automatically each time the
    cluster is started up. The DNS service runs as a cluster service itself--its SkyDNS--a
    distributed service for announcement and discovery of services built on top of
    `etcd` (you will get to know what etcd is later in this chapter). It utilizes
    DNS queries to discover available services. It supports forward lookups (A records),
    service lookups (SRV records), and reverse IP address lookups (PTR records). Actually,
    the service is the only type of object to which Kubernetes assigns DNS names;
    Kubernetes generates an internal DNS entry that resolves to a service's IP address.
    Services are assigned a DNS A record for a name in the form `service-name.namespace-name.svc.cluster.local`
    . This resolves to the cluster IP of the service. For example, for a service named
    `my-rest-service` , the DNS add-on will make sure that the service will be available
    for other Pods (and other services) in the cluster via the `my-rest-service.default.svc.cluster.local`
    hostname. The DNS-based service discovery provides a flexible and generic way
    to connect to services across the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Note that when using the `hostNetwork=true` option, Kubernetes will use the
    host's DNS servers and will not use the cluster's DNS server.
  prefs: []
  type: TYPE_NORMAL
- en: There's one more concept that will appear from time to time during our Kubernetes
    journey--a namespace. Let's find out what it's for.
  prefs: []
  type: TYPE_NORMAL
- en: Namespace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A namespace functions as a grouping mechanism inside of Kubernetes. Pods, volumes,
    ReplicaSets, and services can easily cooperate within a namespace, but the namespace
    provides an isolation from the other parts of the cluster. What would be the possible
    use case for such isolation? Well, namespaces let you manage different environments
    within the same cluster. For example, you can have different test and staging
    environments in the same cluster of machines.
  prefs: []
  type: TYPE_NORMAL
- en: This could potentially save some resources in your infrastructure, but it can
    be dangerous; without namespaces, it would be risky to roll out a new version
    of your software to test the environment, having the pre-release version running
    on the same cluster. By having namespaces available, you can act on different
    environments in the same cluster without worrying about affecting other environments.
  prefs: []
  type: TYPE_NORMAL
- en: Because Kubernetes uses the `default` namespace, using namespaces is optional,
    but recommended.
  prefs: []
  type: TYPE_NORMAL
- en: We have all the Kubernetes abstractions explained--we know that there are Pods,
    ReplicaSets, Deployments, and services. Now it's time to move to the physical,
    execution layer of Kubernetes' architecture. All those little, fragile Pods need
    to live somewhere. They live in nodes, which we are going to learn about now.
  prefs: []
  type: TYPE_NORMAL
- en: Nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A node is a work horse in Kubernetes' architecture. It may be a virtual or physical
    machine, depending on your infrastructure. A worker node runs the tasks as instructed
    by the Master node, which we will explain very soon. Nodes (in the earlier Kubernetes
    life, they were called Minions) can run one or more Pods. They provide an application-specific
    virtual host in a containerized environment.
  prefs: []
  type: TYPE_NORMAL
- en: When a worker node dies, the Pods running on the node die as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the contents of a node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00082.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As you can see in the previous diagram, a node in Kubernetes has some processes
    running inside, and each is very important. Let's explain their purposes, one
    by one.
  prefs: []
  type: TYPE_NORMAL
- en: Kubelet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubelet is probably the most important controller in Kubernetes. It''s a process
    that responds to the commands coming from the Master node (we are going to explain
    what the Master node is in a second). Each node has this process listening. The
    Master calls it to manage Pods and their containers. The Kubelet runs Pods (which,
    as you already know, are collections of containers that share an IP and volumes).
    The Kubelet ([https://kubernetes.io/v1.0/docs/admin/kubelet/](https://kubernetes.io/v1.0/docs/admin/kubelet/)
    ) is responsible for what''s running on an individual machine and it has one job:
    given a set of containers to run, to make sure they are all running. To rephrase,
    a Kubelet is the name of the agent and a node is what we call the machine the
    agent runs on. It''s worth knowing that each Kubelet also has an internal `HTTP`
    server which listens for HTTP requests and responds to a simple API call to submit
    a new manifest.'
  prefs: []
  type: TYPE_NORMAL
- en: Proxy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A proxy is a network proxy that creates a virtual IP address which clients can
    access. The network calls will be transparently proxied to the Pods in a Kubernetes
    service. A service, as you already know, provides a way to group Pods into kind
    of a single business process, which can be reached under a common access policy.
    By having a proxy run on a node, we can call the service IP address. Technically,
    a node's proxy is a `kube-proxy` ([https://kubernetes.io/docs/admin/kube-proxy/](https://kubernetes.io/docs/admin/kube-proxy/)
    ) process which programs `iptables` rules to trap access to the service IP address.
    The Kubernetes network proxy runs on each node. Without it, we would not be able
    to access the service.
  prefs: []
  type: TYPE_NORMAL
- en: '`kube-proxy` knows only UDP and TCP, does not understand HTTP, provides load
    balancing, and is just used to reach services.'
  prefs: []
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, each node needs something to run. It will be a Docker container runtime,
    which is responsible for pulling the images and running containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'All those nodes, as any other group of workers in the real world, need a manager.
    In Kubernetes, the role of the node manager is being performed by one special
    node: the Master node.'
  prefs: []
  type: TYPE_NORMAL
- en: The Master node
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Master node does not run any containers--it just handles and manages the
    cluster. The Master is the central control point that provides a unified view
    of the cluster. There is a single Master node that controls multiple worker nodes,
    which actually run our containers. The Master automatically handles the scheduling
    of the Pods across the worker nodes in the cluster -by taking into account the
    available resources on each node. The structure of the Master node is presented
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Image00083.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Let's dissect the Master node piece by piece, starting with `etcd` .
  prefs: []
  type: TYPE_NORMAL
- en: etcd
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes stores all of its cluster state in [`etcd`](https://github.com/coreos/etcd)
    , a distributed data store with a strong consistency model. `etcd` is a distributed,
    reliable key-value store for the most critical data of a distributed system, with
    a focus on being:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Simple** : Well-defined, user-facing API'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secure** : Automatic TLS with optional client cert authentication'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fast** : Benchmarked for 10,000 writes/sec'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reliable** : Properly distributed using Raft'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This state includes what nodes exist in the cluster, what Pods should be running,
    which nodes they are running on, and a whole lot more. The whole cluster state
    is stored in an instance of `etcd` . This provides a way to store configuration
    data reliably. Another crucial component running on the Master node is the API
    server.
  prefs: []
  type: TYPE_NORMAL
- en: The API server
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the main components residing on the Master node is the API server. It's
    so important that sometimes, you may find out that the Master node is being referred
    to as the API server in general. Technically, it's a process named `kube-apiserver`
    which accepts and responds to `HTTP` `REST` requests using JSON. It's main purpose
    is to validate and configure data for the API objects which are Pods, services,
    ReplicaSets, and others. The API server provides the frontend to the cluster's
    shared state through which all other components interact. The API server is the
    central management entity and is the only Kubernetes component that connects to
    etcd. All the other components must go through the API server to work with the
    cluster state. We will cover the Kubernetes API in detail in [Chapter 9](text00180.html)
    , *Working With Kubernetes API* .
  prefs: []
  type: TYPE_NORMAL
- en: The Master node does not run any containers--it just handles and manages the
    whole cluster. The nodes that actually run the containers are the worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: The scheduler
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have said before, if you create a Deployment, the Master will schedule
    the distribution of application instances onto individual nodes in the cluster.
    Once the application instances are up and running, the Deployment Controller will
    be continuously monitoring those instances. This is kind of a self-healing mechanism--if
    a node goes down or is deleted, the Deployment Controller replaces it.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know what the Kubernetes specific components are that form it's
    architecture, let's look what tools are available for us.
  prefs: []
  type: TYPE_NORMAL
- en: Available tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are a couple of tools we will be using throughout the rest of the book.
    Let''s start with the most important one: `kubectl` .'
  prefs: []
  type: TYPE_NORMAL
- en: kubectl
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`kubectl` is a command-line interface for running commands against Kubernetes
    clusters. In fact, this is the command used most often when working with Kubernetes.
    In [Chapter 8](text00159.html) , *Using Kubernetes with Java* , we will go through
    the command''s syntax and possible usages. Using `kubectl` , you will be interacting
    with your cluster. Of course, having the API exposed by the Master node and the
    API server, we could do it using an `HTTP` client of our choice, but using `kubectl`
    is a lot faster and more convenient. `kubectl` provides a lot of functionalities,
    such as listing resources, showing detailed information about the resources, prints
    log, managing cluster, and executing commands on a container in a Pod.'
  prefs: []
  type: TYPE_NORMAL
- en: Dashboard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes Dashboard is a nice, clean web-based UI for Kubernetes clusters.
    Using the Dashboard, you can manage and troubleshoot the cluster itself as well
    as the applications running in it. You could say it's the Kubernetes user interface.
    For those who prefer to use the graphical UI, the Dashboard can be a handy tool
    for deploying containerized applications and getting an overview of applications
    running on your cluster, as well as for creating or modifying individual resources
    such as Deployments, Pods, and services. For example, you can scale a Deployment,
    initiate a rolling update, restart a Pod, or deploy new applications using a deploy
    wizard. We will also use the Dashboard in [Chapter 8](text00159.html) , *Using
    Kubernetes with Java* .
  prefs: []
  type: TYPE_NORMAL
- en: Minikube
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running a cluster seems to be a complicated process that needs a lot of setup.
    This is not necessarily the truth. Actually, it's quite easy to have the Kubernetes
    cluster up and running on the local machine, for learning, testing, and development
    purposes. The `minikube` tool, available at GitHub at [https://github.com/kubernetes/minikube](https://github.com/kubernetes/minikube)
    , allows you to set up the local cluster on your own machine. It's available for
    all major platforms, which includes Linux, macOS, and Windows. The cluster started
    will of course be a single node cluster, but it's more than enough to start doing
    real-life Kubernetes examples. In fact, in [Chapter 8](text00159.html) , *Using
    Kubernetes with Java* , before we start deploying our `REST` service into the
    cluster, we are going to run Kubernetes locally.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from those mentioned previously, you may find a lot of other tools and
    utilities that work very well with Kubernetes on the internet.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter introduced a lot of new concepts. Let's briefly summarize what
    we have learned about the Kubernetes architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes (k8s) is an open source platform for automating container operations
    such as deployment, scheduling, and scalability across a cluster of nodes. Using
    Kubernetes, you can:'
  prefs: []
  type: TYPE_NORMAL
- en: Automate the deployment and replication of containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scale up and down containers on the fly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Organize containers in groups and provide load balancing between them
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easily roll out new versions of application containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide fault tolerance mechanisms to your application--if a container dies
    it gets replaced
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes consists of:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A Cluster** : A group of nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Nodes** : Physical or virtual machines that act as workers. Each node runs
    the kubelet, proxy, and a Docker engine process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Master node** : Provides a unified view into the cluster. It delivers
    the Kubernetes API server. The API server provides a `REST` endpoint that can
    be used to interact with the cluster. The Master also includes the controllers
    used to create and replicate Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pods** : Scheduled to nodes. Each Pod runs a single container or a group
    of containers and volumes. Containers in the same Pod share the same network namespace
    and volumes and can communicate with each other using localhost. Their life is
    fragile; they will be born and die all the time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Labels** : Pods have labels, with key/value pairs attached. Labels are used
    to precisely select Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Services** : An abstraction that defines a set of Pods and a policy to access
    them. Services find their group of Pods by using label selectors. Because the
    IP of the single Pod can change, the service provides a permanent IP address for
    its client to use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That was a piece of theory that may be a bit overwhelming. Don't worry, in [Chapter
    8](text00159.html) , *Using Kubernetes with Java* , we are going to run the local
    Kubernetes cluster. Our plan will consist of creating a local Kubernetes cluster
    using `minikube` . We will then deploy and manage Docker containers with our Java
    REST microservice. By doing some practical, hands-on actions, the Kubernetes architecture
    will be a lot more clear. Running a local Kubernetes is not the only thing we
    are going to do. Later on, in [Chapter 10](text00205.html) , *Deploying Java on
    Kubernetes in the Cloud* , we will put our application in the real cloud--a place
    where Kubernetes really shines.
  prefs: []
  type: TYPE_NORMAL
