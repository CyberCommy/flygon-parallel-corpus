- en: Deploying Your Serverless Stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we created a fully-functional serverless data API using
    the API Gateway, Lambda, and DynamoDB with an IAM role, and tested it once it
    was deployed. However, most of the code and configuration was deployed manually;
    a process that is prone to error, not repeatable, and not scalable.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to show you how to deploy all that infrastructure
    using only code and configuration. The topics covered are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: An overview of serverless-stack build and deploy options
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a profile, an S3 bucket, IAM policies, and IAM roles resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building and deploying with API Gateway, Lambda, and DynamoDB
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An overview of serverless stack build and deploy options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will discuss the challenges in manually provisioning infrastructure,
    infrastructure as code, building and deploying using the serverless application
    model, and building and deploying using the alternative options.
  prefs: []
  type: TYPE_NORMAL
- en: Manually provisioning infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The challenge of provisioning infrastructure is that it used to be a very manual
    process. For example, administrators would follow the steps described in a manual
    by clicking items on a user interface, running a set of commands, or logging into
    the servers and editing configuration files. This became more and more challenging
    with the growth of cloud computing and web frameworks that started to scale out.
    This could just be done with a monolithic architecture and their shared web servers
    or application servers. However, with the microservices architecture, there are
    different web servers and databases developed using different languages, and thousands
    of services running that need to be tested, built, and deployed independently.
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of efforts in deploying services manually in terms of cost,
    and also in terms of the ability to maintain such configurations at scale. The
    deployment of services has become slower to scale up and also to recover from
    any errors, as you would have the administrator, for example, remotely connecting
    via SSH onto your box, rebooting the machine, or trying to understand what the
    issues were and actually changing the configuration many times for many machines.
    It's also very difficult to test and make any process repeatable. Any configuration
    changes, done either by using a user interface or editing configuration files
    on one server, were not very repeatable and also prone to human error or misconfiguration.
    For example, we were using the AWS Management Console in the previous chapters.
    Had you made some errors in any of the configuration, you would have to go back,
    diagnose the issue, and fix it, which is very time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will talk about infrastructure as code and how it helps
    to resolve the issues we have with manually provisioning infrastructure or deploying
    services.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure as code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Infrastructure as code is basically the process of managing and provisioning
    your resources through definition files or code. It provides a centralized way
    to manage configuration in terms of implementation and version control. Suddenly,
    the resource management and provisioning becomes much more like the agile process
    in the systems-development life cycle in software. All changes are validated,
    tested, and provisioned as part of a release process and using standard deployment
    pipelines. This also provides the ability to copy configuration used to deploy
    infrastructure in one region to another.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, let''s say you deployed infrastructure in the North Virginia region
    using code and configuration, you could easily modify it to make it work in the
    Ireland region too. This allows you to scale out very quickly in terms of your
    configuration around the infrastructure and this led to the development of the
    term DevOps. This is where developers get much more involved in the configuration,
    especially around the infrastructure, and the ops team (or operations teams) gets
    much more involved in the development process. The following diagram shows the
    different benefits of infrastructure as code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9baf9c90-8f05-41e9-a1ed-ce1d4e83c094.png)'
  prefs: []
  type: TYPE_IMG
- en: There are many benefits in using infrastructure as code. The first one is cost
    reduction, as you expend a lot less effort on simple and repetitive tasks. You
    can also reduce cost when scaling or deploying similar infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: When building any system, I usually like to build it so that it works with two
    environments. Once it works for two, it will work for many. For example, if you
    build code with a naming convention as a prefix or variable for each environment,
    such as **dev** for **development** and **stg** for **staging**, and substitute
    it when deploying it, then we can easily later add a **prd** prefix for **production**.
    Using a standard naming convention is always highly recommended. Another example
    could be to always have three characters as a convention or rule, so that you
    will not get into the situation of having multiple prefixes, such prod or production,
    that can introduce unexpected errors. In a config file, the environment variable
    that would get substituted could look like `${env}`.
  prefs: []
  type: TYPE_NORMAL
- en: The other point is the speed of execution; that is, your administrators or DevOps
    team can actually release infrastructure and services a lot faster than they would
    have done before. In addition, there's a reduction in the risk of errors that
    can be introduced, for example, through manual configuration or user-interface
    changes. Also, having traceability, validation, and testing at each step helps
    reduce the number of errors and issues. Overall, this helps reduce risks and improves
    security. Since you have this traceability, you can understand what was deployed
    and find out whether it was successful, or whether it's causing an issue and should
    be rolled back.
  prefs: []
  type: TYPE_NORMAL
- en: Building and deploying using the Serverless Application Model (SAM)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A tool that's emerged recently is the SAM ([https://github.com/awslabs/serverless-application-model](https://github.com/awslabs/serverless-application-model)),
    which is maintained by AWS. It allows you to build and deploy your serverless
    stack. It provides a simplified way to define and deploy any serverless resources
    or applications. At its base, it employs a cloud formation, but using fewer lines
    of source code than if you used the AWS command line. The basic concept of using
    a SAM template file is that it can be either a JSON or YAML file that contains
    all the serverless configuration, and its mascot is SAM the squirrel.
  prefs: []
  type: TYPE_NORMAL
- en: Building and deploying using alternate options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are alternative options to deploying your AWS serverless stack. The first
    one is the AWS **Command-Line Interface** (**CLI**). The AWS CLI is an option
    when, for example, your organization does not want to use cloud formation stacks
    for everything or for parts of your serverless stack. The AWS CLI is also usually
    ahead of SAM in terms of feature releases. So, in this book, I use some commands
    to complement what is not built into SAM yet.
  prefs: []
  type: TYPE_NORMAL
- en: Serverless Framework, initially called JAWS, is built using Node.js technology.
    It was ahead of its time when it was first released, but now with the AWS SAM,
    it's an additional layer on top of AWS that's maintained by a third party. However,
    it does allow you to use other functions from other cloud providers, such as Google
    and Azure, which is a great feature, but I personally question the reuse of your
    function code across cloud providers as the event source, security, and data shape
    are different anyway.
  prefs: []
  type: TYPE_NORMAL
- en: Chalice and Zappa are Python-based frameworks for AWS and are similar to Python
    Flask and Bottle micro web frameworks, but again, they are another abstraction
    on top of AWS. You need to wait for any improvements to cascade through.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, there's also the risk of having a dependency on those frameworks
    when AWS features are deprecated. You will need to keep in sync with them or rely
    on those other frameworks' open source committers to actually make changes or
    contribute directly. If I had to go for one, I would choose SAM, but I do accept
    that some people prefer serverless.
  prefs: []
  type: TYPE_NORMAL
- en: SAM needs an S3 bucket for package deployment, and the Lambda needs IAM policies
    and IAM roles. So let's look at that next.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a profile, an S3 bucket, IAM policies, and IAM roles resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will first set up an S3 bucket that will hold the source code for the Lambda
    deployment package. IAM policies and roles allow API Gateway to invoke Lambda,
    and Lambda to access DynamoDB. We set them up using the AWS Management Console;
    here, we will use the AWS CLI and SAM.
  prefs: []
  type: TYPE_NORMAL
- en: The code, shell scripts, and configuration files used in this chapter are available
    under the `./serverless-microservice-data-api/` folder.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an AWS credentials profile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Follow these steps to create an AWS credentials profile:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an AWS profile called `demo`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Re-enter the same AWS `aws_access_key_id` and `aws_secret_access_key` details
    as in [Chapter 1](669eac03-68f5-4097-83fb-0f0ecce5ef42.xhtml), *Serverless Microservices
    Architectures and Patterns*, for `newuser`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, you can copy the `[default]` profile by copying `[default]`
    and creating a new entry for `[demo]`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The code provided with this book needs a profile name (here, `demo`) to make
    use of the right keys; please change this in each shell script, `common-variables.sh`,
    for each project if you use another profile name.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an S3 bucket
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To deploy the Lambda source code, you will need to use an existing S3 bucket
    or create a new one—use the following code to create one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Ensure that `<your-bucket-name>` can be addressable—it must follow DNS naming
    conventions. To choose your AWS Region, refer to AWS Regions and Endpoints ([https://docs.aws.amazon.com/general/latest/gr/rande.html](https://docs.aws.amazon.com/general/latest/gr/rande.html)).
    Generally, those in the USA can use `us-east-1` and those in Europe can use `eu-west-1`.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the configuration files for your AWS account
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I''ve created a configuration file called `common-variables.sh` for each serverless
    project under `./bash/`, which creates environment variables that are used by
    the AWS CLI and SAM. You will need to modify them with your AWS account details.
    This is done to lay the groundwork to support multiple AWS accounts in more than
    one region. Here is an example of `common-variables.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s try to understand the code:'
  prefs: []
  type: TYPE_NORMAL
- en: Update `<your-aws-region>` with your AWS region, such as `us-east-1`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I'm dynamically determining the `aws_account_id`, but you can also hardcode
    it as shown in the comments, in which case uncomment the line and update `<your-aws-accountid>`
    with your AWS account ID. If you do not know it, you can find your account number
    in the AWS Management Console | Support | Support Center screen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`template` is the name of the SAM template that we will be using.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bucket` and `prefix` define the location of the deployed Lambda package.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Updating the polices and assuming roles files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You will need to change the AWS `aws_account_id` (currently set to `000000000000`)
    in the IAM policy documents stored under the `./IAM` folder. In addition, the
    region currently set to `eu-west-1` will have to be changed.
  prefs: []
  type: TYPE_NORMAL
- en: 'To replace your `aws_account_id` (assuming that your AWS `aws_account_id` is
    `111111111111`), you can do it manually or you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Creating the IAM roles and policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We created the IAM policies and roles manually in the AWS Management Console.
    We will now look at how we can create these using the AWS CLI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a JSON policy, `dynamo-readonly-user-visits.json`, that we have created
    under the `./IAM/` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: To summarize the policy, it says that we have `Query` and `Scan` access to two
    DynamoDB tables called `user-visits` that we created manually or in Python, and
    `user-visits-sam` that we are going to create in this chapter using SAM.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a policy that allows the Lambda function to write the logs to CloudWatch
    logs. Create a `lambda-cloud-write.json` file with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'When creating an IAM role, you also need specify the type of IAM role it can
    assume. We have created an `assume-role-lambda.json` file, which is known as a
    trusted entity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Having the preceding defined as JSON code allows us to version-control the security
    and permissions in AWS. In addition, if someone deleted them by mistake, we can
    simply recreate them in AWS.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now created a shell script called `create-role.sh`, under the `./bash`
    folder, to create a Lambda IAM role and three IAM policies, and attach them to
    the IAM role:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Execute the script using `./create-role.sh`. It will create one IAM role and
    three IAM policies, and attach them to the IAM role. Notice that here code is
    idempotent on purpose, as policy changes need to be managed carefully as they
    could impact others.
  prefs: []
  type: TYPE_NORMAL
- en: Note that there is also the ability to create IAM roles in a SAM template, but
    using the AWS CLI means that the roles and policies can be reused rather than
    deleted when the serverless stack is deleted. This adds version control if you
    check them into the Git standard naming convention and helps the support team
    by centralizing the creation.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the IAM roles and policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The AWS CLI gives you feedback on the creation of the IAM role and policies,
    but you can also check in the AWS Management Console:'
  prefs: []
  type: TYPE_NORMAL
- en: Sign in to the AWS Management Console and open the IAM console at [https://console.aws.amazon.com/iam/](https://console.aws.amazon.com/iam/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the IAM navigation pane, choose Roles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose `lambda-dynamo-data-api` from the list of roles.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose Show more under Permissions policies on the Permissions tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should see the following three attached policies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/67b3fe80-4e4b-475e-aece-57205716093b.png)'
  prefs: []
  type: TYPE_IMG
- en: Building and deploying with API Gateway, Lambda, and DynamoDB
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are three steps involved in deploying a serverless stack:'
  prefs: []
  type: TYPE_NORMAL
- en: Build Lambda as a ZIP package
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Package your serverless stack using SAM and CloudFormation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy your serverless stack using SAM and CloudFormation
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Building the Lambda as a ZIP package
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Install ZIP if it is not installed already. For Ubuntu/Debian, you can use
    `sudo apt-get install zip -y`. Create a file called `create-lambda-package.sh`
    with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This will create a ZIP file of the Lambda code only if the source code has changed.
    This is what will be deployed to AWS and there are advantages in separating these
    commands when we need to package third-party libraries.
  prefs: []
  type: TYPE_NORMAL
- en: SAM YAML template
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will use a SAM template to create the serverless stack. SAM uses YAML or
    JSON, and allows you to define the Lambda function and API Gateway settings, as
    well as create a DynamoDB table. The template looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: From top to bottom, we first specify the template type, a description, and pass
    in a string parameter, `AccountId`. We then specify the Lambda details, such as
    `Handler`, which is the entry point, location of the ZIP code, and give the function
    a name and description. We then choose 128 MB RAM as this is a proof of concept
    and we won't need more memory; we specify `3` for the timeout. After this, the
    Lambda will terminate even if it is still running; this limits costs and is reasonable,
    since we expect a synchronous response. We then have the IAM Lambda execution
    role with the `${AccountId}` parameter that gets passed in when we deploy the
    serverless stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'We saw how to add the environment variable that will be available in the Lambda
    function. The variable is `environment: dev`.'
  prefs: []
  type: TYPE_NORMAL
- en: We then have the trigger or event source for the Lambda function. Here, we create
    an API Gateway with a resource in the `/visits/{resourceId}` path with the `GET`
    method that will invoke a Lambda function with `resourceId`, which will be the
    `EventId`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we create a DynamoDB table with an `EventId` hash of the data type
    `string` and an `EventDay` range of data type `number` using Python. To keep costs
    down (or free), I've put the read and write capacities to `1`.
  prefs: []
  type: TYPE_NORMAL
- en: So in one SAM YAML file, we have configured the Lambda, API Gateway with its
    Lambda integration, and created a new DynamoDB table.
  prefs: []
  type: TYPE_NORMAL
- en: For DynamoDB, I strongly recommend that you append `sam` at the end when it
    is a resource created by SAM, so you know the origin. I also recommend that if
    a DynamoDB table is shared between services, you create it using Boto3 or the
    AWS CLI. This is because the deletion of one serverless stack could mean the table
    is deleted for all services.
  prefs: []
  type: TYPE_NORMAL
- en: Packaging and deploying your serverless stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once the IAM role with policies, the ZIP package with the Lambda code, and SAM
    template are all created, you just need to run two CloudFormation commands to
    package and deploy your serverless stack.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first command packages the Lambda code with the SAM template and pushes
    it to S3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The second command deploys it to AWS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: One of the great features in SAM is the ability to use parameters. Here, this
    is done when we deploy the stack with `--parameter-overrides AccountId=${aws_account_id}`.
    The benefit is that we can reuse the same SAM template for multiple environments,
    such as AWS Accounts and Regions, and any other parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check that the stack has been deployed to AWS correctly by checking
    the AWS Management Console:'
  prefs: []
  type: TYPE_NORMAL
- en: Sign into the AWS Management Console at [https://console.aws.amazon.com/cloudformation/](https://console.aws.amazon.com/cloudformation/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose Management & Governance | CloudFormation or search for CloudFormation
    under Find services.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the CloudFormation pane, choose lambda-dynamo-data-api.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose Events. This shows the different events and is very useful for diagnosing
    any issues you get when deploying a stack. Usually, it will be a naming conflict
    (for example, a DynamoDB table with the same name exists) or an IAM-related issue
    (for example, a role does not exist).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Choose Resources. This shows the resources that are managed by this CloudFormation
    stack:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/31906f76-725d-4686-b076-afb5dab963e7.png)'
  prefs: []
  type: TYPE_IMG
- en: You can also check the AWS Management Console directly if the API Gateway, Lambda
    function, and DynamoDB table have been created correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, here is the same Lambda we created using Python, but deployed
    and managed by SAM. Unless you are doing a proof of concept, it is recommended
    that any further changes are managed by configuration changes rather than changes
    in the AWS Management Console, as this would break the infrastructure as code
    and automation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d50d164-b37e-440d-8c4f-89cd41154572.png)'
  prefs: []
  type: TYPE_IMG
- en: Putting it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we deployed a fully-working serverless stack without the need
    to use the AWS Management Console to configure any settings using the user interface.
    This is the recommended way to deploy infrastructure and code as it's much more
    repeatable, scalable, and less prone to errors. It also allows you to do things
    such as revert configurations when everything is version-controlled in Git.
  prefs: []
  type: TYPE_NORMAL
- en: 'The shell scripts available under the `./serverless-microservice-data-api/bash`
    folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '`common-variables.sh`: Environment variables used by other scripts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`create-role.sh`: Lambda IAM role created with the three policies attached'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`lambda-dynamo-data-api.yaml`: Defines the SAM YAML template'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`create-lambda-package.sh`: Creates the Lambda ZIP package'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`build-package-deploy-lambda-dynamo-data-api.sh`: Orchestrates the building
    of the Lambda ZIP, packaging, and deployment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are the contents of `build-package-deploy-lambda-dynamo-data-api.sh`,
    which you can run when you modify your Lambda code or other SAM configuration
    settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Manually testing the serverless microservice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The steps for testing are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Sign in to the AWS Management Console and open the API Gateway console at [https://console.aws.amazon.com/apigateway/](https://console.aws.amazon.com/apigateway/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Amazon API Gateway navigation pane, choose APIs | lambda-dynamo-data-api
    | Stages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select GET under `Prod/visits/{resourceId}/GET` to get the invoke URL, which should
    look like `https://{restapi_id}.execute-api.{region}.amazonaws.com/Prod/visits/{resourceId}`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open a new browser tab and enter the `https://{restapi_id}.execute-api.{region}.amazonaws.com/Prod/visits/{resourceId}` URL.
    You will get the `{"message":"resource_id not a number"}` response body. This
    is because we validated `resource_id` in the `parse_parameters()` URL function
    before querying DynamoDB to make sure that it is a number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open a new browser tab and enter the `https://{restapi_id}.execute-api.{region}.amazonaws.com/Prod/visits/324` URL.
    As we have used the correct `resourceId`, you should see [ ] in your browser tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are we getting no data?
  prefs: []
  type: TYPE_NORMAL
- en: Well, no data has been loaded into the `user-visits-sam` DynamoDB table, that
    is why!
  prefs: []
  type: TYPE_NORMAL
- en: Run `python3 ./aws_dynamo/dynamo_modify_items.py` to load some records into
    the `user-visits-sam` DynamoDB table.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the contents of `dynamo_modify_items.py`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now go to the same endpoint in the browser, and you should get the following
    data back:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Open a new browser tab and enter the `https://{restapi_id}.execute-api.{region}.amazonaws.com/Prod/visits/324?startDate=20171002` URL.
    As we have added the `startDate=20171002` parameter, you should see the following
    in your browser tab:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Making code and configuration changes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Code rarely stays static, as new requirements and business requests arise. To
    illustrate how well changes are supported, assume we made some changes to the
    Lambda function Python code and now want to use Python 3.7, instead of Python
    3.6.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can update the code, configuration, and stack in three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Change the `lambda_return_dynamo_records.py` Python code to make it compliant
    with Python 3.7.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Change the `lambda-dynamo-data-api.yaml` SAM template as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Run `./build-package-deploy-lambda-dynamo-data-api.sh`. This will rebuild the
    Lambda ZIP package, as the code has changed. Package and deploy the code and SAM
    configuration, and then CloudFormation will manage and deploy the changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deleting the serverless stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you no longer need your serverless stack, you can delete it in the AWS
    Management Console under CloudFormation:'
  prefs: []
  type: TYPE_NORMAL
- en: Sign in to the AWS Management Console and open the CloudFormation console at
    [https://console.aws.amazon.com/cloudformation/](https://console.aws.amazon.com/cloudformation/).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: From the list, select lambda-dynamo-data-api.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose Actions and then Delete Stack.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose Yes, Delete when prompted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, you can run the following shell script with `./delete-stack.sh`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You now have a much deeper understanding and some practical experience of manually
    deploying your serverless stack in a repeatable and consistent way using infrastructure-as-code
    principles. You can adapt these for your organization's serverless microservice
    needs. You know the service deployment options and you used the AWS CLI to create
    a bucket, IAM roles, and IAM policies, as well as the AWS SAM to deploy the API
    Gateway, Lambda, and DynamoDB. You also saw how you can easily modify the SAM
    template file to propagate changes throughout the stack. The full Python source
    code, IAM policies, roles, Linux, and shell scripts are provided with this book
    so you can adapt it for your needs. You can now take advantage of them without
    having to use the AWS management console GUI manually, and only need to modify
    the scripts when deploying other serverless microservices.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have shown you how to deploy the stacks, it's really important that
    you know the code is functioning and performing as expected, especially as the
    code base grows and will be used in a production environment. We have not yet
    covered the mechanism for automated deployment and testing. So, in the next chapter,
    we are going to discuss and walk through the different types of testing you should
    use on your serverless microservice.
  prefs: []
  type: TYPE_NORMAL
