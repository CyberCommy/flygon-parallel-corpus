- en: Scraping with Concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you begin to add more and more target websites into your scraping requirements,
    you will eventually hit a point where you wish you could make more calls, faster.
    In a single program, the crawl delay might add extra time to your scraper, adding
    unnecessary time to process the other sites. Do you see the problem in the following
    diagram?
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/49cfec0e-bab5-4c02-ae06-151795e343f5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If these two sites could be run in parallel, there would not be any interference.
    Maybe the time to access and parse a page is longer than the crawl delay for this
    website, and launching a second request before the processing of the first response
    completes could save you time as well. Look how the situation is improved in the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/29436d6c-1b52-402c-b32b-0b8dff8dfb14.png)'
  prefs: []
  type: TYPE_IMG
- en: In any of these cases, you will need to introduce concurrency into your web
    scraper.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What is concurrency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concurrency pitfalls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Go concurrency model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: sync package helpers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Instructions in a program are run by a **central processing unit** (**CPU**).
    This CPU can run multiple threads, which can process instructions for separate
    tasks, together. This is achieved by switching between the two tasks and executing
    the instructions in an alternating fashion, like pulling together two sides of
    a zipper. This overlapping execution of tasks is called concurrency. For the sake
    of simplicity, we will describe it as performing multiple tasks at the same time.
    The following diagram shows how it may appear:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4a8fe2d3-f970-4f80-ae76-2acedbf7a915.png)'
  prefs: []
  type: TYPE_IMG
- en: Concurrency should not be confused with parallelism, where two things or instructions
    can literally be executed at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: By introducing a concurrent architecture to your web scraper, you will be able
    to make multiple web requests to different sites without waiting for one site
    to respond. In this way, a slow site or bad connection to one server will only
    affect the task of scraping that specific site and not the others. As the majority
    of the time spent in web scraping is communication over a network, this is a very
    good solution to your problem.
  prefs: []
  type: TYPE_NORMAL
- en: Building a program with a concurrent architecture can sometimes be a daunting
    task, as it opens up a new set of issues that need to be taken into consideration.
    When multiple threads are running, they will typically need some mechanism for
    communication and must be very careful about trying to modify the same objects
    at the same time. Without a well-thought-out approach, your scraper is bound to
    encounter a variety of problems that can be very difficult to detect and fix.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency pitfalls
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The source of most issues with concurrency is figuring out how to share information
    safely, and provide access to that information, between multiple threads. The
    simplest solution would seem to be to have an object that both threads can have
    access to, and modify, in order to communicate with the other thread. This seemingly
    innocent strategy is easier suggested than done. Let's look at this example, where
    two threads are sharing the same stack of web pages to scrape. They will need
    to know which web pages have been completed, and which web pages the other thread
    is currently working on.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use a simple map for this example, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `"READY"` status indicates that the site has not yet been scraped.
  prefs: []
  type: TYPE_NORMAL
- en: Race conditions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From the start, this strategy has a major issue. If both threads look at the
    map at the same time, they will see that `page1.html` is ready to be scraped.
    They would then both update the value for `page1.html` to `"WORKING"`, and go
    on to scrape the same site at the same time! This would not only be a duplicated
    effort, but it would also create an extra load on the [example.com](http://example.com)
    server. An even worse situation is if one thread is updating the status to `"WORKING"`
    while the other thread is attempting to read the status. Then, your scraper will
    crash. Concurrent read and/or write operations are not allowed in Go.
  prefs: []
  type: TYPE_NORMAL
- en: This situation is known as a race condition and is one of the most common issues
    you will run into as you build concurrent programs. In order to prevent race conditions
    from happening, there needs to be a mechanism where one thread can block access
    to the map for all other threads. The Go standard library provides the `sync`
    package to hold many helpful tools for building concurrent applications. In our
    specific situation, a `sync.Mutex` would be a very helpful tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also use the `"-race"` flag with many of the Go commands (such as:
    `go run` and `go test`) to help detect race conditions and provide helpful information.
    See more in their blog post at [https://blog.golang.org/race-detector](https://blog.golang.org/race-detector).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sync.Mutex` is a lockable object that acts as a barrier for other objects,
    much like the lock on a door. In order to enter the room, you first check if the
    door is locked. If it is locked, you must wait for someone to unlock it before
    you can proceed. The following code is a sample of how you would use a `sync.Mutex`
    in Go to protect concurrent reads and writes to our map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: When a thread calls `mtx.Lock()`, it first checks if there is an existing lock
    being held by any other thread. If there is already an existing lock being held,
    your thread will wait until the existing lock is released. Only one thread can
    hold a lock at any given time, just like the door mentioned before.
  prefs: []
  type: TYPE_NORMAL
- en: 'When access to an object allows for concurrent reads, but must protect the
    object when a write is in process, the `sync` package provides the `sync.RWMutex`
    struct. This works similarly to the `sync.Mutex`, except that it separates locking
    into two separate methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Lock()` / `Unlock()`: A lock used specifically when a write operation is in
    progress'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RLock()` / `RUnlock()`: A lock used specifically when a read operation is
    in progress'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Multiple threads can obtain read locks without blocking access to the object,
    except for threads attempting to obtain a write lock. Along the same lines, a
    read lock cannot be obtained if the write lock exists. Using the `RWMutex`, the
    preceding example would look like the following one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The thread obtains a read lock before checking the map, to ensure that no writes
    are being made. Then it releases the read lock, regardless of whether the `if` a
    statement is `true` or `false`, and obtains a write lock before updating the map.
    Using these two type of mutexes will help protect your scraper from race conditions.
    However, it can also add another common concurrency pitfall.
  prefs: []
  type: TYPE_NORMAL
- en: Deadlocks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When adding locks and unlocking code to a concurrent application, at some point
    you may see that your application has completely stopped, but not crashed. After
    much time spent digging through the code, adding extra print statements, and stepping
    through a debugger, you finally see it; a lock was not released! This situation
    is what is known as a deadlock.
  prefs: []
  type: TYPE_NORMAL
- en: The Go standard library does not have any tools to help detect and overcome
    deadlocks. However, there is support in the open source community. One such package
    being `go-deadlock` by GitHub user `sacha-s`. The `go-deadlock` package provides
    a drop-in replacement for the `sync.Mutex` and the `sync.RWMutex`, that monitors
    how long a lock on an object has been held. By default, when it detects a deadlock,
    it will exit the program.
  prefs: []
  type: TYPE_NORMAL
- en: 'The deadlock timeout duration and the action to take are both configurable
    through the `deadlock.Opts` object, as shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using mutexes and deadlock detections are some of the standard ways of ensuring
    that concurrent threads can operate without getting in each other's way. These
    traditional methods are offered through the Go programming language. However,
    they provide a different perspective on how concurrent threads should communicate
    with one another.
  prefs: []
  type: TYPE_NORMAL
- en: The Go concurrency model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you have seen, many of the problems with concurrent programs stem from sharing
    memory resources between multiple threads. This shared memory is used to communicate
    state and can be very fragile, with great care needed to ensure that everything
    stays up and running. In Go, concurrency is approached with the mantra:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Do not communicate by sharing memory; instead, share memory by communicating.*'
  prefs: []
  type: TYPE_NORMAL
- en: When you use mutexes and locks around a common object, you are communicating
    by sharing memory. Multiple threads look to the same memory location to alert
    and to provide information for the other threads to use. Instead of doing this,
    Go provides tools to help share memory by communicating.
  prefs: []
  type: TYPE_NORMAL
- en: Goroutines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Up until this point, we have been referring to concurrent paths of execution
    as threads. In Go, the synonymous tool for accomplishing this is called a **goroutine**.
    Goroutines are described as a:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Lightweight thread of execution*.'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike traditional threads found in C and Java, goroutines are managed by the
    Go runtime and not the OS thread scheduler. This allows the Go runtime scheduler
    to be hyper-focused on only tasks in the Go program. It also leverages OS threads
    as needed, providing more granular units of operation. OS threads suffer from
    a large amount of overhead required to create each thread and a relatively slow
    ability to determine which thread a task should be run on. The Go runtime chooses
    much smaller footprints when creating separations of goroutines, allowing more
    of them to run simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating goroutines is, by design, a very simple task in Go. By prefixing any
    function call with the word `go`, it will run the function in a new goroutine.
    The following example is a simple program that runs a small goroutine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: When you run this code, you can see that the numbers from `startTicker()` are
    printed, even though the main goroutine sleeps for 10 seconds. If you modify this
    code, changing the Go `startTicker()` with just `startTicker()`, this code will
    run forever, printing each second until the process is killed forcefully.
  prefs: []
  type: TYPE_NORMAL
- en: When multiple goroutines need to communicate with each other, Go provides a
    simple tool for them to use.
  prefs: []
  type: TYPE_NORMAL
- en: Channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Channels are conduits through which goroutines can send and receive information.
    This sits at the core of the Go''s concurrency model for sharing memory through
    communicating. Channels allow for goroutines to each other rather than trying
    to access the same information. Channels are also unidirectional, meaning that
    data can only flow in one direction, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c585b8d7-d38f-48d1-9999-f75436f8a483.png)'
  prefs: []
  type: TYPE_IMG
- en: If communication is needed in both directions, two channels will need to be
    used.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our previous example using mutexes, multiple threads attempted to access
    the map containing the status of each website by creating a release lock. We can
    use channels as a safer approach by launching the scraper threads as separate
    goroutines and having them communicate their status back to the main goroutine
    through a channel. This is shown in the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the main function for this program, the `updatesChan` is created to act as
    the means through which goroutines can provide their status back to the main goroutine.
    These goroutines are started in the first `for` loop by calling Go `scrapeSite`,
    which takes the URL of the website to be scraped, and a reference to the `updatesChan`.
    The main goroutine then enters a second `for` loop where it listens for data to
    come through `updatesChan`, providing a new status update for any of the URLs.
    As each site provides an update, the number of completed sites is incremented
    until all of the sites have completed. At this point, the main goroutine closes
    the channel.
  prefs: []
  type: TYPE_NORMAL
- en: Closing a channel prevents the sending and receiving of any more data through
    that channel. As far as for-range operations are concerned, this marks the end
    of the stream, exiting to loop.
  prefs: []
  type: TYPE_NORMAL
- en: By converting the method of communication to use channels, there is only one
    owner of the shared data and the responsibility of updating the map falls back
    on a single goroutine. This allows each worker of goroutine to provide status
    updates safely, without the need for locks, or sharing memory.
  prefs: []
  type: TYPE_NORMAL
- en: sync package helpers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Goroutines and channels, being the core constructs of concurrent programming
    in Go, will provide most of the utility that you will need. However, there are
    many helpful objects that the Go standard library provides that are also useful
    to know. We have already seen how `sync.Mutex` and `sync.RWMutex` work, but let's
    take a look at some of the other objects offered.
  prefs: []
  type: TYPE_NORMAL
- en: Conditions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you are able to launch scraper tasks into multiple threads, some controls
    will need to be put into place so things don't get too out of hand. It is very
    simple in Go to launch 1,000 goroutines to scrape 1,000 pages simultaneously from
    a single program. However, your machine most likely cannot handle the same load.
    The `sync` package provides a few utilities to help maintain order in your web
    scraper.
  prefs: []
  type: TYPE_NORMAL
- en: One common control that you will want to put into place is the number of active
    concurrent scraping threads. Before you launch a new goroutine, you will need
    to satisfy a certain condition, being that the number of active threads is less
    than some value. If this condition fails the check, your new goroutine will have
    to wait, until it is signaled that the condition passes. This scenario is solved
    using the `sync.Cond` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `sync.Cond` object provides a mechanism to tell goroutines to wait until
    a signal is received, based on any defined condition. A `sync.Cond` struct wraps
    a `sync.Locker` (usually a `sync.Mutex` or `sync.RWMutex`) to control access to
    the condition itself. There follows an example of how you might use a `sync.Cond`
    to control the number of active scraper threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The main focus of this code is inside the `scrapeSite()` function. In this part
    of the code, the program first checks if it has reached the maximum number of
    concurrent threads. If this condition is true, it will wait. This pauses the goroutine
    until a `Signal()` or a `Broadcast()` is called from the `sync.Cond`. We use `Signal()`
    in our case to notify a single goroutine that the condition has passed, and that
    it can proceed. If `Broadcast()` was used here, it would release all of the goroutines
    which are currently waiting on the condition. A good use case for that could be
    pausing the entire system to make some configuration change on the `fly`, then
    resuming all paused goroutines.
  prefs: []
  type: TYPE_NORMAL
- en: Atomic counters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous example, we surrounded any increment or decrement of `activeThreads`
    with a `Lock()` / `Unlock()`. This can become quite verbose if it needs to be
    done multiple times, as in our case. The `sync` package offers a subpackage called
    atomic that provides methods for updating objects without the need for locks.
    This is done by creating a new variable each time a change is made, while preventing
    multiple writes from occurring at the same time. The following example shows some
    of the changes necessary to use `activeThreads` as an `atomic` counter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed many topics surrounding concurrency in web scraping.
    We looked at what concurrency is and how we can benefit from it. We reviewed some
    of the common issues that must be avoided when building concurrent programs. We
    also learned about the Go concurrency model and how to use its primitive objects
    to build concurrent Go applications. Finally, we looked at a few of the niceties
    Go has included in its `sync` package. In our final chapter, we will look at taking
    our scraper to the highest level.
  prefs: []
  type: TYPE_NORMAL
