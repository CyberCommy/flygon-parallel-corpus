- en: Chapter 6. Assessing Web Applications with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Web application assessments, or web application penetration tests, are a different
    animal compared to infrastructure assessments. This is dependent on the goals
    of the assessment as well. Web application assessments, like mobile application
    assessments, are all too often approached in the wrong manner. Network or infrastructure
    penetration tests have matured, and clients are becoming wiser in what to expect
    for results. This is not always true for web application or mobile application
    assessments. There are a variety of tools that can be used to analyze applications
    for vulnerabilities, including Metasploit, Nexpose, Nessus, Core Impact, WebInspect,
    AppScan, Acunetix, and many more. Some are far better than others for web application
    vulnerability assessments, but they all have a few things in common. One of these
    things is that they are not a replacement for penetration tests.
  prefs: []
  type: TYPE_NORMAL
- en: These tools have their place, but depending on the scoping of the engagement
    and what weaknesses are trying to be identified, they often fall short. Specific
    products such as WebInspect, AppScan, and Acunetix are appropriate for identifying
    potential vulnerabilities, especially during the **System Development Life Cycle**
    (**SDLC**), but they will report false positives and miss complex multistage exploits.
    Every tool has its place, but even when using tools such as these, relevant risks
    can be missed.
  prefs: []
  type: TYPE_NORMAL
- en: Now there is a flip side to this coin; a penetration test will not find every
    vulnerability in a web application, but it is not meant to do so anyway. Web application
    penetration tests are focused on identifying systematic developmental problems,
    processes, and critical risks. So, the identified vulnerabilities can be quickly
    remediated, but the specific weaknesses point to larger security practices that
    should be addressed in the overall SDLC.
  prefs: []
  type: TYPE_NORMAL
- en: 'The focus of most application penetration tests should involve at least some
    components out of the following, if not all:'
  prefs: []
  type: TYPE_NORMAL
- en: Analysis of the current **Open Web Application Security Project** (**OWASP**)
    top 10 vulnerabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identification of application areas that leak data or leave residual data traces
    in some locations, which includes undocumented or unlinked pages or directories.
    This is also known as data permanency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manners in which a malicious actor could move laterally from one account type
    to another or escalate privileges.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Areas in which the application could provide an attacker with the means to inject
    or manipulate data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ways in which the application could create **Denial of Service** (**DoS**) situations,
    but this is typically accomplished without exploitation or explicit validation
    to prevent any impact on business operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, how an attacker could penetrate the internal network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider all of these components and you will see that the use of an application
    scanning tool will not identify all of them. Additionally, a penetration test
    should have specific objectives and goals to identify indicators and issues with
    relevant proof of concepts. Otherwise, if an assessor attempts to identify all
    the vulnerabilities in the application depending on complexity, it could take
    an extensive period of time.
  prefs: []
  type: TYPE_NORMAL
- en: These recommendations and the application code should be reviewed by the client.
    The client should remediate all the specified locations highlighted by the assessor
    and then follow through and identify other weaknesses the assessor may not have
    identified during the time period. Once completed the SDLC should be updated so
    that future weaknesses are remediated in development. Finally, the more complex
    the application, the more the developers involved; so as you test it, be aware
    of vulnerability heat mapping.
  prefs: []
  type: TYPE_NORMAL
- en: Just like penetration testers, developers can have varied levels of skills,
    and if the organization's SDLC is not very mature, the grade of vulnerability
    in the application areas can vary for each development team. We call this vulnerability
    heat mapping, where some places in an application we will have more vulnerabilities
    than others. This typically means that the developer, or developers, did not have
    the necessary skills to deliver the product at the same level as the other teams.
    Areas where there are more vulnerabilities may also indicate that there are more
    critical vulnerabilities. So, if you notice that a specific area of an application
    is lighting up like a Christmas tree with weaknesses, elevate the type of attack
    vectors you are looking at.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the scope of the engagement, start focusing on vulnerabilities
    that will crack the security perimeter, such as **Structured Query Language injection**
    (**SQLi**), **Remote** or **Local File Inclusion** (**RFI**/**LFI**), nonvalidated
    redirects and forwards, unrestricted file uploads, and finally insecure direct
    object references. Each of these vulnerabilities are related to the manipulation
    of the request-and-response model of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Applications typically work on a request-and-response model, with tracking of
    specific user session data with cookies. Therefore, when you write your scripts,
    you have to build them in a method to handle sending data, receiving it, and parsing
    the results for what was expected or not expected. Then, you can create follow-on
    requests to move further ahead.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying live applications versus open ports
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When assessing large environments to include **Content Delivery Networks**
    (**CDN**), you will find that you will be identifying hundreds of open web ports.
    Most of these web ports have no active web applications deployed on those ports,
    so you need to either visit each page or request the web page header. This can
    simply be done by executing a `HEAD` request to both the `http://` and `https://`
    versions of the site. A Python script that uses `urllib2` can execute this very
    easily. This script simply takes a file of the host **Internet Protocol** (**IP**)
    addresses, which then builds the strings that create the relevant **Uniform Resource
    Locator** (**URL**). As each site is requested, if it receives a successful request,
    the data is written to a file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the output of this script on the screen as it
    is run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying live applications versus open ports](img/B04315_06_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The full version of this script can be found at [https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/headrequest.py](https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/headrequest.py).
    This script can easily be modified so as to execute follow-on tasks, if desired.
    There are already tools such as `PeppingTom` and `EyeWitness` available that accomplish
    this activity better than this script, but understanding how to build this basic
    script will allow you to include additional analysis as necessary.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying hidden files and directories with Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When we visit the site of the identified IP address, we see that it is the
    **Damn Vulnerable Web Application** (**DVWA**). We also see that it has appended
    the details of the default landing page to our initial request. This means that
    we start from the `http://192.168.195.145/dvwa/login.php` site as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying hidden files and directories with Python](img/B04315_06_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We now have a starting location to test from, and using these details, we can
    look for hidden directories and files. Let's modify our last script to automatically
    look for hidden files or directories.
  prefs: []
  type: TYPE_NORMAL
- en: 'The best way to do this is to start within the base directory of the site we
    are in. You can go up levels, but in environments where multiple websites are
    housed, you may end up jumping out of the scope. So, know your environment before
    proceeding to attack in that manner. As you can see, the script runs through a
    file of directories and filenames, which appends them to the target site. We are
    then reported whether they were valid or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Knowing this, we can load up four of the most common hidden or unlinked locations
    that websites house. These are `admin`, `dashboard`, `robots.txt`, and `config`.
    Using this data, when we run the script, we identify two viable locations, as
    shown in the following screenshot. `Robots.txt` is good, but `config` usually
    means we can find usernames and passwords if the permissions are incorrect or
    if the file is not in use by the web server.
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying hidden files and directories with Python](img/B04315_06_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'As you can see here, we get a listing of the directory''s contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying hidden files and directories with Python](img/B04315_06_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Unfortunately, when you open the `config.inc.php` file, as shown in this screenshot,
    nothing is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying hidden files and directories with Python](img/B04315_06_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Administrators and support personnel do not always understand the impact of
    some of their actions. When backups are made from `config` files, if they are
    not actively being used, or if the permissions are not correctly set, you can
    often read them through a browser. A backup file on a Linux system is denoted
    by a trailing `~`. We know that it is a Linux system because of the previous `HEAD`
    request, which showed that it was an Ubuntu host.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember that headers can be manipulated by administrators and security tools,
    so they should not be trusted as definitive sources of information.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in the following screenshot, the request opens up a `config`
    file that provides us the details required to access a database server, from which
    we can extract critical data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying hidden files and directories with Python](img/B04315_06_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: As a penetration tester, you have to be efficient with your time as mentioned
    previously it is one of the obstacles of a successful penetration test. This means
    that when we research the contents of a database, we can also set up some automated
    tools. A simple test would be to use Burp Suite using Intruder.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The full version of the `dirtester.py` script can be found at [https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/dirtester.py](https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/dirtester.py).
  prefs: []
  type: TYPE_NORMAL
- en: Credential attacks with Burp Suite
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Download the Burp Suite free edition from [http://portswigger.net/burp/download.html](http://portswigger.net/burp/download.html)
    and then run it. Make sure you use a browser that will not interfere with the
    assessing of your application testing. Most current browsers will mitigate much
    of your testing automatically, and most of these protective measures cannot be
    turned off, to complete unhindered testing. Firefox has these protection capabilities,
    but they can be turned off for development and security analysis. Additionally,
    the plugin support that Firefox has allows you to assess applications better.
    Many an assessor who has just started has not been able to understand why some
    new **Cross-site Scripting** (**XSS**) attack that they just executed was blocked.
    Often, it is some built-in browser protection in Chrome or Internet Explorer that
    says it is off, but really, it is not.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, from Firefox, turn on the local proxy support by entering `127.0.0.1`
    and `port 8080` in the manual proxy configuration, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Credential attacks with Burp Suite](img/B04315_06_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'While assessing web applications, you would want to restrict your scope to
    only the system you want to test. Make sure that you set this and then filter
    all other targets to clean up your output and prevent yourself from attacking
    other hosts by mistake. This can be done by either right clicking on the host
    in the **Site map** window or clicking on the **Scope** tab and adding it manually,
    as shown in this screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Credential attacks with Burp Suite](img/B04315_06_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now that Burp has been set up, we can start assessing the DVWA site, which has
    a simple login page that requires a username and a password. When each of these
    web pages are loaded, you have to either disable the **Intercept** mode or click
    on **Forward** to go to the next page. We are going to need the intercept capabilities
    in a few minutes, so we are going to leave that enabled. Basically, Burp Suite—as
    mentioned previously—is a transparent proxy that has all of the specified traffic
    sent between the website and the browser. This allows you to manipulate data and
    traffic in real time, which means that you can have the application perform differently
    than intended.
  prefs: []
  type: TYPE_NORMAL
- en: To start this analysis, we have to see how the login page formats its request
    as it is sent to the server so that it can be manipulated. So, we provide a bad
    username and password in the login prompt—the letter `a` for both—and capture
    the request in the proxy. The following image shows the raw capture from the erroneous
    login that was captured by Burp Intruder.
  prefs: []
  type: TYPE_NORMAL
- en: '![Credential attacks with Burp Suite](img/B04315_06_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Then, right-click on it, select Send to Intruder, and turn off Intercept in
    the proxy. This allows us to repeatedly manipulate the request sent to the server
    to see whether we can get different responses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following this pattern, we can configure the attack to run through a list of
    usernames and passwords, and this may grant us access. The click on the **Intruder**
    major tab and the **Position** minor tab. Select the two positions for the originally
    supplied username and password and then select **Cluster Bomb** from the drop-down,
    as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are multiple types of intruder attack, and cluster bomb will be the most
    commonly used type in your assessments. More details about intruder attacks can
    be found at [https://support.portswigger.net/customer/portal/articles/1783129-configuring-a-burp-intruder-attack](https://support.portswigger.net/customer/portal/articles/1783129-configuring-a-burp-intruder-attack).
  prefs: []
  type: TYPE_NORMAL
- en: '![Credential attacks with Burp Suite](img/B04315_06_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Then create two lists; payload set 1 is for the usernames, and payload set 2
    is for the passwords.
  prefs: []
  type: TYPE_NORMAL
- en: '![Credential attacks with Burp Suite](img/B04315_06_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Next, select **Always** for following redirections, as logins often create website
    transitions.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The benefit of setting a hard scope for the entire assessment and then using
    intruder to ignore the scope, for instance, is that you know you are not creeping
    into unexpected territory throughout the engagement.
  prefs: []
  type: TYPE_NORMAL
- en: '![Credential attacks with Burp Suite](img/B04315_06_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Then click on the **Intruder** menu item and select **Start**, which will show
    a new popup. You can identify the viable account by the change in size compared
    to the other results.
  prefs: []
  type: TYPE_NORMAL
- en: '![Credential attacks with Burp Suite](img/B04315_06_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Now you can gain direct access to the web application, which allows you to move
    through the application.
  prefs: []
  type: TYPE_NORMAL
- en: Using twill to walk through the source
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python has a library that allows you to browse and interact with web applications
    at the source level. After installing the library, you either import the library
    or use the `twill` shell, called `twill-sh`.
  prefs: []
  type: TYPE_NORMAL
- en: '![Using twill to walk through the source](img/B04315_06_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'You can then load the target website and review the page''s source with the
    following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This simply shows the source code of the site, which allows you to further interact
    with the site.
  prefs: []
  type: TYPE_NORMAL
- en: '![Using twill to walk through the source](img/B04315_06_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This allows you to interact directly with the components of the site and identify
    what needs to be submitted. The `twill-sh` library has help support when run in
    interactive mode, but it is a limited tool. What twill is good for is interacting
    with the source and identifying potentially interesting areas of a site. It is
    not good for sites that have significant dynamic content or extensive pages. As
    an example, I ran the `info` command to try and identify anything particular about
    the site, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using twill to walk through the source](img/B04315_06_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'At this basic level, you can understand the content types, data formats and
    other details that can be manipulated within the application, but there are better
    libraries in Python that can be used to achieve the same results as described
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding when to use Python for web assessments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python has several libraries that are very useful for executing web application
    assessments, but there are limitations. Python is best used for small automation
    components of web applications that cannot be simulated manually through a transparent
    proxy, such as Burp. What this means is that specific work streams that you find
    in applications may be generated on the fly and cannot be replicated easily through
    a transparent proxy. This is especially true if there are timing concerns. So,
    if you need to interact with the backend server using multiple request and response
    mechanisms, then Python may fit the bill.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding when to use specific libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are mainly five libraries that you are going to use while working with
    web applications. Historically, I have used the `urllib2` library the most, and
    this is because of the great features and easy means to prototype code, but the
    library is old. You will find that it is missing some major capabilities and more
    advanced methods of interacting with new age web applications are considered broken,
    this is in comparison to newer libraries as described following. The `httplib2`
    Python library provides robust capabilities when you are interacting with websites,
    but it is significantly more difficult to work with than `urllib2`, `mechanize`,
    `request`, and `twill`. That said, if you are dealing with tricky detection capabilities
    related to proxies, this may be your best option as the header data sent can be
    completely manipulated to perfectly simulate standard browser traffic. This should
    be fully tested in simulated environments before it is used against real applications.
    Often, the library provides erroneous responses simply because of the way the
    client requests were crafted.
  prefs: []
  type: TYPE_NORMAL
- en: If you come from the Perl world, you might instantly gravitate to `mechanize`
    as your go-to library, but it does not work well with dynamic websites and, in
    some situations, it cannot work with them at all. So what is today's answer? The
    `request` library. It is very clean and provides the necessary capabilities to
    quickly meet today's challenges of complex web engagements. To highlight the differences
    between the two and the prototype code, I have created application credential
    attack scripts using `httplib2` and `request`. The aim of these scripts is to
    identify live credential sets and capture the relevant cookie. Once this is done,
    additional features can be added to either script. Additionally, these two scripts
    highlight the differences between the library sets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first example is the `httplib2` version, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding when to use specific libraries](img/B04315_06_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'The second is the `request` library version, which can be seen in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Understanding when to use specific libraries](img/B04315_06_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The request-based script can be found at [https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/request_brute.py](https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/request_brute.py),
    and the `httplib2` script can be found at [https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/httplib2_brute.py](https://raw.githubusercontent.com/funkandwagnalls/pythonpentest/master/httplib2_brute.py).
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, they are nearly identical in length, but the crafting of the
    statements in the request makes the simulation of web traffic simpler.
  prefs: []
  type: TYPE_NORMAL
- en: Being efficient during web assessments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The benefit of using scripts like these or Burp would be to analyze parameters
    that could be manipulated, injected, and or brute-forced. Specifically, you are
    able to interact with code features that are not readily apparent through a web
    browser at a speed beyond human interaction. Examples of this include the building
    of exploitation lists for common SQLi or XSS attacks. Build lists of common SQLi
    attacks or XSS attacks. Then load them into the relevant parameters on the websites
    to identify the vulnerabilities. You will have to modify the aforementioned scripts
    to hit the target parameter, but this will significantly speed up the process
    of identifying potential vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some of the best SQLi lists for common injection types for each database instance
    can be found at [http://pentestmonkey.net/category/cheat-sheet/sql-injection](http://pentestmonkey.net/category/cheat-sheet/sql-injection).
    Equally good XSS lists are available at [https://www.owasp.org/index.php/XSS_Filter_Evasion_Cheat_Sheet](https://www.owasp.org/index.php/XSS_Filter_Evasion_Cheat_Sheet).
    Some of these details are also built into Burp Suite, as highlighted at [https://support.portswigger.net/customer/portal/articles/1783128-Intruder_Common%20Uses.html](https://support.portswigger.net/customer/portal/articles/1783128-Intruder_Common%20Uses.html).
  prefs: []
  type: TYPE_NORMAL
- en: Today, we have to contend with **Web Application Firewalls** (**WAFs**) and
    protection tools that can be bypassed, but you need to know how these protections
    are set up and what character encoding can bypass them. Remember if there are
    white or black lists they are keyed on specific character sets and/or encoding,
    which may block your exploitation attempts. By automating the testing, we can
    identify the items that key on captures that prevent the exploitation the web
    applications, and from that we can tailor our injections to bypass the protections
    put in place.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Character encoding for web application assessments is completely different from
    generating payloads. So, you should understand that these statements are not contradictory.
    The majority of WAFs do not smartly detect and decode data prior to comparing
    it with their white lists and/or black lists. So, you can bypass these protection
    mechanisms by changing the character format into something that an application
    can understand but the WAF cannot.
  prefs: []
  type: TYPE_NORMAL
- en: This is important for tools such as `sqlmap`, which is fantastic for verifying
    SQLi, but it should have its request tailored. It should be used only after you
    have confirmed that there is a plausible injection vulnerability. Then it should
    be used to build a proof of concept, extract data, or compromise systems. Loading
    up `sqlmap` to hit every parameter just to look for SQLi is a very time-consuming
    process. It can provide potential false positives and break systems.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Remember that if you do not customize your parameters and the request passed
    to `sqlmap`, it will likely turn non-blind injection attacks into blind injection
    attacks, which will significantly impact the time it takes to finish its task.
    The tool is probably the best in the market for what it does, but without a smart
    user, it will sometimes get lost.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed what the difference between web application assessments
    and normal network assessments is. The method of identifying live web pages versus
    open ports was highlighted, and we demonstrated how to identify unlinked or hidden
    content and execute credential attacks with Burp. Additionally, this chapter demonstrated
    how to walk through websites with twill, extract data, and then create scripts
    that will allow request-response trains to be built using different libraries.
    The wrap-up for this chapter highlighted how to be efficient by using scripts
    and open source tools to examine sites for specific vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will see how we can use techniques such as these and
    other weaknesses to crack the perimeter of an organization.
  prefs: []
  type: TYPE_NORMAL
