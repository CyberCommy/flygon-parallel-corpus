- en: 5\. The Philosophers' Dinner – Threads and Concurrency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Learning Objectives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By the end of this chapter, you will be able to:'
  prefs: []
  type: TYPE_NORMAL
- en: Create synchronous and asynchronous multithreaded applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply synchronization to handle data hazards and race conditions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Develop efficient multithreaded code with C++ thread library primitives
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create threads using move semantics for multithreading closures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement thread communication with futures, promises, and async
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will clarify the difference between basic terms in multithreaded
    programming, learn how to write multi-threaded code, find out which resources
    are provided by the C++ Standard Library for data access synchronization, learn
    how to prevent our code from encountering race conditions and deadlocks.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, we covered different types of dependencies and coupling
    in C++. We looked at how common API design patterns and idioms can be implemented
    in C++ and what data structures are provided by Standard Libraries, as well as
    their efficacy. We also learned how to work with functional objects, lambdas,
    and captures. This knowledge will help us learn how to write clear and efficient
    multithreaded programs.
  prefs: []
  type: TYPE_NORMAL
- en: The heading of this chapter contains the name of the most significant synchronization
    issue in concurrent programming – The Philosopher's Dinner. In a few words, this
    definition is as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Three philosophers are sitting at a round dining table with bowls of sushi.
    Chopsticks are placed between each adjacent philosopher. Only one philosopher
    at a time can eat their sushi with two chopsticks. Perhaps each philosopher will
    take one chopstick and then wait until someone gives up another chopstick. Philosophers
    are an analogy for three working processes and chopsticks for shared resources.
    "Who will grab the two chopsticks first"symbolizes the **race condition**. When
    each philosopher holds a chopstick and waits until another chopstick is available,
    it leads to a **deadlock**. This analogy explains what problems occur during multithreading.
  prefs: []
  type: TYPE_NORMAL
- en: We will start our chapter with a brief introduction to the main multithreaded
    concepts. We will consider the difference between synchronous, asynchronous, and
    threaded execution. Using clear and simple examples, we will start with synchronization,
    data hazards, and race conditions. We will find out why they appear in our code
    and how we can manage them. The next part of this chapter is devoted to the C++
    Standard Library for threaded execution. Using examples, we will learn how and
    when to use thread library primitives, and how does the **move semantic** interact
    with threads. We will also practice with **futures**, **promises**, and **async**
    to receive results from threads.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will be concluded with a challenging activity in which we'll create
    an Art Gallery simulator that works by simulating visitors and gallery staff.
    We will develop a multithreaded generator that will simultaneously create and
    remove visitors from the art gallery. Next, we will create a multithreaded class
    that is responsible for moving visitors through the gallery. They will interact
    with each other using synchronization techniques. Finally, we will create thread-safe
    storage, instances of which will be accessed from the different threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next section, we will clarify a nuanced distinction between the concepts
    of concurrent programming: **synchronous**, **asynchronous**, and **threaded**
    execution.'
  prefs: []
  type: TYPE_NORMAL
- en: Synchronous, Asynchronous, and Threaded Execution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is a nuanced distinction between the concepts of concurrent programming:
    `synchronous`, `asynchronous`, and `threaded execution`. To clarify it, we will
    start from the very beginning, with the concept of concurrent and parallel programs.'
  prefs: []
  type: TYPE_NORMAL
- en: Concurrency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The idea of `concurrency` is more than one task being executed simultaneously.
    `Concurrency` doesn''t specify how the simultaneity will be achieved. It only
    indicates that more than one task will be completed in a given period. Tasks can
    be `dependent`, `parallel`, `synchronous`, or `asynchronous`. The following diagram
    shows the concept of concurrent work:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1: The abstraction of the concurrency - a few people working on
    the same computer'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.1: The abstraction of the concurrency - a few people working on the
    same computer'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the preceding diagram, three people are working at the same time on one computer.
    We aren't interested in the way they do that, it's doesn't matter for this level
    of the abstraction.
  prefs: []
  type: TYPE_NORMAL
- en: Parallelism
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Parallelism** occurs when several tasks are performed simultaneously. The
    tasks work in parallel due to hardware capabilities. The best example of parallelism
    is a multi-core processor. For parallel execution, the tasks are divided into
    completely independent subtasks that are performed in different processors'' cores.
    After that, the result of the execution can be combined. Look at the following
    diagram to understand the concept of parallelism:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C14583_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.2: The abstraction of the parallelism - all of the tasks are executed
    by different people; they don''t interact with each other'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the preceding diagram, there are three people working at the same time on
    their own computers – well, they're working in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`Concurrency` and `parallelism` are not the same thing. `Parallelism` supplements
    concurrency. It tells us how tasks are performed: they are independent of each
    other and run in different computational units, that is, processors or cores.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will smoothly move toward a threaded execution concept. When we talk
    about threads, we mean the thread of execution. This is an abstraction of the
    operating system, which allows us to perform several tasks simultaneously. Remember
    that the entire program executes in a separate process. The operating system allocates
    the `main()` function. We can create a new thread for execution and assign a beginning
    function that will be the starting point of this thread.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The address space and registers of the processor are called **Thread Context**.
    When the OS interrupts the thread's work, it must store the context of the current
    thread and load the context of the next one.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider the creation of a new thread in the following example. To create
    a new thread, we must include a `<thread>` header file. It contains classes and
    functions for managing threads. Actually, there are a few possible ways to create
    an `std::thread` object and thread of execution, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an `std::thread` object without explicit initialization. Remember, the
    thread needs a start function to run its job. We didn''t point out which function
    is the main one for this thread. This means that the thread of execution was not
    created. Let''s look at the following code sample, where we create an empty `std::thread`
    object:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an `std::thread` object and pass a pointer to a function as a constructor
    argument. Now, the thread of execution will be created and will start its job
    from the function that we passed in the constructor. Let''s look at the following
    code sample:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here, we created an `std::thread` object and initialized it with the function
    pointer. This is a simple function that returns `void` and doesn't take any parameters.
    Then, we tell the main thread to wait until the new thread finishes using the
    `join()` function. We always have to `join()` or `detach()` a thread until the
    end of the scope of the `std::thread` object. If we don't do that, our application
    will be terminated by the OS using an `std::terminate`() function that is called
    in the `std::thread` destructor. Instead of a function pointer, we can also pass
    any callable object, such as `lambda`, `std::function`, or a class with an overloaded
    `operator()`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The thread of execution can finish its job before the destruction of the `std::thread`
    object. It also can be destructed before the thread of execution finishes its
    job. Always `join()` or `detach()` an `std::thread` object before its destruction.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know about the main syntax for creating a thread, we can proceed
    to the next important concepts. Let's find out what synchronous, asynchronous,
    and multithreaded execution mean.
  prefs: []
  type: TYPE_NORMAL
- en: Synchronous Execution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The term synchronous execution means that each subtask will be performed sequentially,
    one by one. In other words, this means that if we have a few tasks to execute,
    each of them can only start its work after the previous one has finished its work.
    This term does not specify a way to perform tasks, or whether they will be performed
    in a single or several threads. It only tells us about the execution order. Let's
    go back to the philosophers' dinner example. In a single-threaded world, the philosophers
    will eat one after the other.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first philosopher takes two chopsticks and eats their sushi. Then, the
    second philosopher takes two chopsticks and eats their sushi. They take turns
    until all of them have finished their sushi. Take a look at the following diagram,
    which represents the synchronous execution of four tasks in a single thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3: Synchronous execution in a single thread'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.3: Synchronous execution in a single thread'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here, each of the tasks waits for the previous task to finish. Tasks can also
    be performed synchronously in multiple threads. Consider the following diagram,
    which represents the synchronous execution of four tasks in multiple threads.
    Again, each of the tasks waits for the previous task to finish:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C14583_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.4: Synchronous execution in multiple threads'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this case, each task is launched in a separate thread, but only after the
    previous thread has completed its work. In a multithreaded world, the philosophers
    will still eat one after the other, but with a small difference. Now, each of
    them has their own chopsticks, but can only eat in a strict order.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`Synchronous execution` means that the finishing time of each task is synchronized.
    The order of the execution of tasks is the main point here.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider synchronous execution on the following code sample. When we
    run tasks in a single thread, we just call the usual functions. For example, we
    implemented four functions that print a message to the terminal. We ran them in
    a synchronous, single-threaded way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we call all the functions one by one, and every next function runs after
    the execution of the previous function. Now, let''s run them in the different
    threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code sample, we created four threads and immediately joined
    them. Thus, every thread finishes its job before the one can be run. As you can
    see, nothing changes for the tasks – they are still executed in a strict order.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous Execution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is where a few tasks can be executed simultaneously without blocking any
    thread execution. Usually, the main thread initiates an asynchronous operation
    and continues execution. After execution is finished, the results are sent to
    the main thread. Often, performing an asynchronous operation is not related to
    creating a separate thread for it. The task can be performed by someone else,
    such as another computing device, a remote web server, or an external device.
    Let's go back to the philosophers' dinner example.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of `asynchronous execution`, all of the philosophers will have their
    own chopsticks and will eat independently from each other. When the sushi is ready
    and the waiter serves it, they all start to eat and can finish in their own time.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In `asynchronous execution`, as all the tasks work independently of each other,
    it's not important to know the finish time of each task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following diagram, which represents the asynchronous execution
    of four tasks in multiple threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5: Asynchronous execution in multiple threads'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.5: Asynchronous execution in multiple threads'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Each of them was started and finished at a different time. Let''s consider
    this asynchronous execution with a code sample. For example, we implemented four
    functions that print a message to the terminal. We ran them in different threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Let's see what happens here. We used four functions from the previous examples,
    but they were changed a little bit. We added the print of the thread's unique
    ID by using the `std::this_thread::get_id()` function. This function returns the
    `std::thread::id` object, which represents the unique ID of the thread. This class
    has overloaded operators for the output and comparison, so we can use it in a
    different manner. For example, we can check the thread ID and if it is the ID
    of the main thread, we can execute a special job. In our example, we can print
    the thread ID to the terminal. Next, we created four threads and detached them.
    This means that no thread will wait for the other to finish working. From this
    moment, they become **daemon threads**.
  prefs: []
  type: TYPE_NORMAL
- en: 'They will continue their job, but nobody knows about that. Then, we used the
    `std::this_thread::sleep_for(2s)` function to make the main thread wait for two
    seconds. We did that because when the main thread finishes its job, the application
    will stop, and we won''t be able to view the output of the detached threads in
    the terminal. The following screenshot is an example of the output to the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6: The result of an example execution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.6: The result of an example execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In your IDE, the output can change as the order of execution is undefined. A
    real-world example of asynchronous execution can be an internet browser wherein
    you can open multiple tabs. When a new tab is opened, the application starts a
    new thread and detaches them. Although the threads work independently, they can
    share some resources, such as a file handler, to write logs or do something else.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`std::thread` has a member function called `get_id()` that returns the unique
    ID of the `std::thread` instance. If the `std::thread` instance wasn''t initialized
    or was joined or detached, `get_id()` returns a default `std::thread::id` object.
    This means that no thread of execution is associated with the current `std::thread`
    instance.'
  prefs: []
  type: TYPE_NORMAL
- en: Let's use some pseudocode to show an example where computations are done by
    another computational unit. For example, let's say we develop an application that
    performs calculations with currency exchange. The user inputs an amount in one
    currency, chooses another currency to exchange, and the application shows them
    the amount in that currency. The application, in the background, sends a request
    to a remote server that holds all the currency exchange rates.
  prefs: []
  type: TYPE_NORMAL
- en: 'The remote server calculates the amount of the given currency and sends the
    result back. Your application shows a progress bar at that time and allows the
    user to perform other operations. When it receives the results, it displays them
    on the window. Let''s take a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Let's see what happens here. In the `main()` function, we created a thread called
    `messageLoop` that executes the `runMessageLoop()` function. Some code that checks
    if there are any new results from the server can be placed in this function. If
    a new result is received, it creates a new thread, `procRes`, that will display
    the results in a window. We also created another thread, `userInput`, in the `main()`
    function that gets currencies and the amount from the user and creates a new thread,
    `request`, that will send a request to the remote server. After sending the request,
    it creates a new thread, `progress`, that will display a progress bar until the
    results are received. Since all the threads were detached, they were able to work
    independently. Sure, this is just pseudocode, but the main idea is clear – our
    application sends a request to the remote server, which performs calculations
    for our application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s revise what we have learned about concurrency concepts using an example
    from daily life. Here is a background wherein you''ve to write an application
    and provide all the documentation and architectural concepts related to it:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Single-threaded work: You write it yourself.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Multi-threaded work: You invite your friends and write a project together.
    Somebody writes an architectural concept, somebody takes care of documentation
    work, and you focus on the coding part. All participants communicate with each
    other to clarify any questions and share documentation, such as questions about
    specifications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Parallel work: The tasks are divided. Someone writes the documentation for
    the project, someone designs the diagrams, someone writes the test cases, and
    you work independently. Participants don''t communicate at all.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Synchronized work: In this case, each of you are unable to understand what
    they are supposed to do. Thus, you all decide to work one after the other. When
    the architectural work is finished, the developer starts to write the code. Then,
    when the development work is finished, someone starts to write the documentation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Asynchronous work: In this case, you hire an outsource company to complete
    the project. While they are developing the project, you''ll be engaged in some
    other task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's apply our knowledge in practice and solve an exercise to see how
    all it works.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1: Creating Threads in a Different Way'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we'll write a simple application that creates four threads;
    two of them will work in a synchronized way and two of them will work asynchronously.
    All of them will print some symbols to the terminal, so that we can see how the
    operating system switches thread execution.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Add the pthread linker flag in your project settings to let the compiler know
    that you will use threading libraries. For Eclipse IDE you can do this following
    this path: `Eclipse Version: 3.8.1`, it may vary in different versions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Include some headers for threading support, namely `<thread>`, streaming support,
    namely `<iostream>`, and functional objects support, namely `<functional>`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a free function, `printNumbers()`, that prints numbers from 0 to
    100 in a `for` loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a callable object, that is, a `Printer` class with an overloaded
    `operator()` that prints a "*" symbol from 0 to 100000 in a `for` loop. For every
    `200` iterations, print a new line symbol for more readable output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Enter the `main()` function and then create a lambda object called `printRevers`
    that prints the numbers from 100 to 0 in a `for` loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement an `std::function` object called `printOther` that prints the "^"
    symbol from `0` to `100000` in a `for` loop. For every `200` iterations, print
    a new line symbol for more readable output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the first thread, `thr1`, and pass the `printNumbers` free function
    to its constructor. Join it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a second thread, `thr2`, and pass the `printRevers` lambda object to
    its constructor. Join it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Create an instance of the `Printer` class called `print`. Create a third thread,
    `thr3`, and initialize it with the `print` object. Detach it using the `detach()`
    method:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the last thread, `thr4`, and initialize it with the `printOther` object.
    Detach it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the `std::getchar()` function call before the exit of the `main()` function.
    This avoids closing the application. We''ll have the possibility to see how detached
    threads work:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Run this code in your editor. You will see that `thr1` starts execution and
    the program waits. After `thr1` has finished, `thr2` starts execution and the
    program waits. This is an example of synchronous execution. After `thr2` has finished
    its work, threads `thr3` and `thr4` start execution. They are detached, so the
    program can proceed with the execution. In the following output, you will see
    that the symbols are mixed. This happens because the operating system performs
    interruptions and the threads work at the same time.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Your output will be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C14583_05_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.7: The result of the exercise''s execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In this exercise, we implemented four different ways we can initialize threads:
    with a free function, with a lambda object, with a callable object, and with an
    `std::function` object. There are a few more ways to initialize the thread, but
    we''ll consider them in the next section. We''ve also reviewed how we can implement
    a synchronous program in multiple threads. We also tried to implement the asynchronous
    program and saw that threads really work at the same time and independently. In
    the next section, we''ll learn about data hazards and race conditions and how
    we can avoid them by using synchronization techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: Review Synchronization, Data Hazards, and Race Conditions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The key challenge of multithreaded programming is knowing how the threads work
    with **shared data**. Shared data, also known as resources, are not only variables,
    but also file descriptors and environment variables, and even Windows registries.
    For example, if the threads just read the data, then there are no problems and
    no synchronization is required. However, if at least one of the threads edits
    the data, **race conditions** could arise. Usually, the operations on the data
    are not atomic, that is, they require several steps. Even the simplest increment
    operation of a numeric variable is performed in the following three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Read the value of the variable.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increment it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the new value.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Due to the OSes interruptions, the thread can be stopped before it completes
    the operation. For example, we have threads A and B and have a variable that is
    equal to 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thread A starts the increment:'
  prefs: []
  type: TYPE_NORMAL
- en: Reads the value of the variable (var = 0).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increments it (tmp = 1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Gets interrupted by the OS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Thread B starts the increment:'
  prefs: []
  type: TYPE_NORMAL
- en: Reads the value of the variable (var = 0).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increments it (tmp = 1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Writes the new value (var = 1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Gets interrupted by the OS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Thread A continues the increment:'
  prefs: []
  type: TYPE_NORMAL
- en: Writes the new value (var = 1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Thus, we expect the variable to be equal to 2 after the completion of the work,
    but in fact, it is equal to 1\. Have a look at the following diagram to get a
    better understanding of this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8: Two threads increment the same shared variable'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.8: Two threads increment the same shared variable'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let's go back to the philosophers' dinner analogy. The original issue was that
    one philosopher had only one chopstick. If all of them are hungry, then they will
    hurry to grab two chopsticks. The first philosopher who grabs two chopsticks will
    be the first to eat, and the others must wait. They will race for the sticks.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's apply our knowledge to practice and write some code to see how the
    race conditions can appear in our code and can damage our data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 2: Writing an Example of Race Conditions'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will write a simple application that will demonstrate race
    conditions in action. We will create a classic example of a "check then act" race
    condition. We will create a thread, which performs the division of two numbers.
    We will pass these numbers by reference. After a check, if a dividend is equal
    to 0, we will set a small timeout. At this time in the main thread, we will set
    the dividend to 0\. When the child thread wakes up, it will perform a division
    to 0\. That will lead to an application crash. We will also add some logs to see
    the execution flow.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: By default, all the variables are copied when they are passed to the thread.
    To pass the variable as a reference, use the `std::ref()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we implement the code without a race condition and ensure that it works
    as expected. Perform the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Include headers for threading support, namely `<thread>`, streaming support,
    namely `<iostream>`, and functional objects support, namely `<functional>`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a `divide()` function, which performs a division of two integers.
    Pass the `divisor` and `dividend` variables by reference. Check whether a dividend
    is equal to 0\. Then, add the logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Enter the `main()` function, create two integers called `divisor` and `dividend`,
    and initialize them with any non-zero values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the `thr1` thread, pass the `divide` function, use `divisor` and `dividend`
    by reference, and then detach the thread:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the `std::this_thread` namespace there is a function called `sleep_for` that
    blocks threads for a given period of time. As a parameter, it takes `std::chrono::duration`
    – a template class to represent a time interval.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run this code in your editor. You will see that the `divide()` function works
    correctly in `thr1`. The output looks as follows:![Figure 5.9: The result of the
    correct exercise execution'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/C14583_05_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.9: The result of the correct exercise execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now, we will continue and make changes that will demonstrate race conditions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Go back to the function and set the sleeping time in `2s` for the child thread
    after the `if` condition. Add the logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Go back to the `main()` function and set the sleeping time in `1s` for the
    main thread. After that, set the `dividend` variable to `0`. Add the logs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The `std::chrono_literals` namespace contains literals for time representations:
    ``h`` for `hours`, ``min`` for `minutes`, ``s`` for `seconds`, ``ms`` for `milliseconds`,
    ``us`` for `microseconds`, and ``ns`` for `nanoseconds`. To use them, you should
    just add them to the end of the number, for example, 1s, 1min, 1h, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the `std::getchar()` function call before the exit of the `main()` function.
    This avoids us closing the application and we will have the possibility to see
    how detached threads work:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Run this code in your editor. You will see that the main thread goes to sleep
    for `1s`. Then, the child thread enters the `if` condition and goes to sleep for
    `2s`, which means that it validates a `dividend` and it is not equal to `0`. Then,
    the main thread wakes up and sets a `dividend` variable to 0\. Then, the child
    thread wakes up and performs the division. But because the `dividend` is equal
    to `0` now, the application crashes. If you run this example in Debug mode, you
    will see a `SIGFPE exception` with a message: "Arithmetic exception". You will
    get the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.10: The result of the exercise’s execution with race conditions'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.10: The result of the exercise''s execution with race conditions'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In this exercise, we considered "check then act" kinds of race conditions.
    We''ve set periods of sleep for threads to emulate the OS interruption, but in
    real-world programs, this situation may well happen but may not. It all depends
    on the OS and its scheduler. This makes it enormously difficult to debug and fix
    race conditions. To avoid race conditions in this example, we can act in a few
    ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Pass copies of variables to the threaded function instead of passing references.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synchronize access to the shared variables between threads using Standard Library
    primitives.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join child thread before the main thread changes a `dividend` value to 0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's look at a few more ways to fix this race condition. All of them depend
    on a task that you try to implement. In the next section, we will consider synchronization
    primitives that are provided by the C++ Standard Library.
  prefs: []
  type: TYPE_NORMAL
- en: Data Hazards
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Previously, we considered the most harmless example, but sometimes, there are
    situations where the data is damaged, and this leads to undefined program behavior
    or abnormal termination. Such damage to data, as a result of race conditions or
    simply wrong design, are known as **data hazards**. In general, this term implies
    that the final result of a piece of work depends on the order of the thread''s
    execution. If different threads work with shared data or global variables, it
    may happen that, due to an incorrect order of task execution by different threads,
    the result will vary from time to time. This happens due to the dependencies between
    the data being multi-threaded. Such dependency issues are conditionally divided
    into three groups:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A **true dependency**: **Read After Writing** (RAW)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An **anti-dependency**: **Write After Reading** (WAR)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An **output dependency**: **Write After Writing** (WAW)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RAW Dependency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A RAW dependency occurs when one thread calculates the value that is used by
    another thread. For example, `Thread A` should do its job and write the results
    to a variable. `Thread B` must read the value of this variable and do its job.
    In pseudocode, this looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Difficulties will arise if `Thread B` executes first. It will lead to `Thread
    B` reads an invalid value. The order of the execution of threads should be strictly
    guaranteed. `Thread B` must read the value of the variable, but only after `Thread
    A` has written it. Otherwise, it will lead to undefined behavior. The following
    diagram will help you clarify the RAW data dependency that leads to data hazards:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.11: RAW data dependency between two threads'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.11: RAW data dependency between two threads'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: WAR Dependency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A `Thread A` must read the value of a variable and do its job. After that,
    `Thread B` should do its job and write the results to a variable. In pseudocode,
    this looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Difficulties will arise if `Thread B` executes first. It will lead to `Thread
    B` changing the value before `Thread A` reads it. The order of the execution of
    threads should be strictly guaranteed. `Thread B` should write the new value to
    a variable only after `Thread A` reads its value. The following diagram will help
    you clarify the RAW data dependency that leads to data hazards:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.12: WAR data dependency between two threads'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.12: WAR data dependency between two threads'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: WAW Dependency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A `Thread A` executes its job and writes the results to a variable. `Thread
    B` reads the value of the variable and executes its job. `Thread C` executes its
    job and writes the results to the same variable. In pseudocode, this looks as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Difficulties will arise if `Thread C` executes before threads A and B. This
    leads to `Thread B` reads the value that it is not expected to be read. The order
    of the execution of threads should be strictly guaranteed. `Thread C` must write
    a new value to a variable, but only after `Thread A` has written its value and
    `Thread B` has read it. The following diagram will help you clarify the WAW data
    dependency that leads to data hazards:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.13: WAW data dependency between two threads'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.13: WAW data dependency between two threads'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Resource Synchronization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To prevent races and data hazards, there is a shared data locking mechanism
    where one of the streams intends to change or read these data. This mechanism
    is called `critical sections`. Synchronization consists of blocking critical sections
    when one of the threads enters it. Other threads that also intend to execute the
    code of this critical section will be blocked. When the thread executing the critical
    section leaves it, the lock is released. Then, the story will repeat with the
    next thread.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the previous example with an increment, but now with synchronized access.
    Remember that we have threads A and B and have a variable that is equal to 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thread A starts the increment:'
  prefs: []
  type: TYPE_NORMAL
- en: Enters the critical section and locks it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reads the value of the variable (var = 0).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increments it (tmp = 1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Gets interrupted by the OS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Thread B starts the increment:'
  prefs: []
  type: TYPE_NORMAL
- en: Tries to enter the critical section; it's locked, so the thread is waiting.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Thread A continues the increment:'
  prefs: []
  type: TYPE_NORMAL
- en: Writes the new value (var = 1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Thread B continues the increment:'
  prefs: []
  type: TYPE_NORMAL
- en: Enters the critical section and locks it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reads the value of the variable (var = 1).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increments it (tmp = 2).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Writes the new value (var = 2).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After the completion of both threads, the variable contains the correct result.
    Thus, synchronization ensures that shared data will not be damaged. Have a look
    at the following diagram, to get a better understanding of this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.14: Two threads increment the same shared variable in a synchronized
    way'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.14: Two threads increment the same shared variable in a synchronized
    way'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Highlighting critical sections and anticipating the possible consequences of
    non-synchronized access is a very difficult task. Because excessive synchronization
    negates the very essence of multithreaded work. If two or three threads work on
    one critical section rather quickly, however, there can be dozens of threads in
    the program where all of them will be blocked in the critical section. This will
    greatly slow down the program.
  prefs: []
  type: TYPE_NORMAL
- en: Event Synchronization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There is another mechanism for synchronizing the work of threads – `Thread
    A`, which receives a message from another process. It writes the message to the
    queue and waits for new messages. There is another thread, `Thread B`, that processes
    these messages. It reads messages from the queue and performs some actions on
    them. When there are no messages, `Thread B` is sleeping. When `Thread A` receives
    a new message, it wakes up `Thread B` and processes it. The following diagram
    provides a clear understanding of the event synchronization of two threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15: Event synchronization of two threads'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.15: Event synchronization of two threads'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'However, even in synchronized code can appear another reason for a race conditions
    – a flawed interface of a class. To get an understanding of what this is, let''s
    consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we have a class called `Messages` that has a dynamically allocated array
    of strings. In the constructor, it takes the size of the array and creates an
    array of the given size. It has a function, `full()`, that returns `true` if the
    array is full and `false` otherwise. It also has an `empty()` function that returns
    true if the array is empty and false otherwise. It is the user''s responsibility
    to check if the array is full before pushing a new value and checking if the array
    is empty, and before popping a new value from the array. This is an example of
    a poor interface of the class that leads to race conditions. Even if we protect
    the `push()` and `pop()` functions with locks, race conditions will not disappear.
    Let''s look at the following example of using the `Messages` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Here, we created a `msgs` variable and then created the first thread, which
    pushes value to the `msgs`. Then, we created the second thread, which pops values
    from the array and detaches them. Even if we protect all the functions by using
    a locking mechanism, one of the threads can check the array's size and can be
    interrupted by the OS. At this time, another thread can change the array. When
    the first thread continues its work, it can try to push to the full array or pop
    from the empty array. So, synchronization is only effective in a pair with a good
    design.
  prefs: []
  type: TYPE_NORMAL
- en: Deadlock
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There is one more synchronization issue. Let''s go back to the philosophers''
    dinner example. The original issue was that one philosopher has only one chopstick.
    So, they can eat their sushi one by one by sharing chopsticks with each other.
    Although it will take a long time for them to finish their sushi, all of them
    will be well-fed. But if each of them grabs a chopstick at the same time and doesn''t
    want to share the second chopstick, they won''t be able to eat their sushi as
    each of them will be waiting for the second chopstick forever. This leads to a
    **deadlock**. This happens when two threads are waiting for another thread to
    continue its job. One of the causes of deadlocks is when one thread joins another
    thread, but another thread joins the first thread. So, when both threads are joined
    to each other, none of them can continue their job. Let''s consider the following
    example of a deadlock:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In the main function, we have two threads, `t1` and `t2`. We initialized the
    `t1` thread with the `someStuff()` function, which does some useful work. We also
    initialized the `t2` thread with the `someAnotherStuff()` function, which does
    some more useful work. We have global pointers to these threads and a join pointer
    to the `t1` thread in the function that's executed by `t2`. We also join a pointer
    to the `t2` thread into the function, which is executed by `t1`. By doing this,
    they joined each other. This causes a deadlock.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will consider C++ thread library primitives for synchronization
    and another cause of deadlocks.
  prefs: []
  type: TYPE_NORMAL
- en: Move Semantics for Multithreading Closures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `std::thread` class cannot be copied, but what if we want to store a few
    threads, or maybe 10 or 20? Sure, we can create the number of threads, and then
    we can join or detach them like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'But it''s more convenient to store a bunch of threads in an **STL container**,
    for example, the vector of threads:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'STL containers cannot be used with objects that don''t support `std::move()`
    function. To initialize the threads in the container, we can do something like
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can join or detach all of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Move semantics can also be useful when we store an `std::thread` object as
    a class member. In this case, we should design our class carefully, delete the
    copy constructor and assignment operator, and implement a new move constructor
    and move assignment operator. Let''s consider the following code example of such
    a class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: In the move assignment operator, we first check if the thread is joinable. If
    so, we join it and only after that do we perform assignment operation.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We should never assign one thread object to another without using `join()` or
    `detach()` on them. This will lead to an `std::terminate()` function call.
  prefs: []
  type: TYPE_NORMAL
- en: It's also possible to use the `std::move()` function to move objects into a
    thread function. It can be helpful for copying big objects, which is not advisable.
    Let's execute an exercise to ensure that the objects can be moved into thread
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 3: Moving Objects to a Thread Function'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this exercise, we will write a simple application that demonstrates how
    `std::move()` works for `std::thread` classes. We will create a class that has
    both a copy constructor and a move constructor to see which one will be called
    when we move the object of this class into the `std::thread` function. Perform
    the following steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Include headers for threading support, namely `<thread>`, and streaming support,
    namely `<iostream>`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `Handler` clas, which has the default constructor, destructor,
    copy constructor, assignment operator, move constructor, and move assignment operator.
    They will do nothing except print a log:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `doSomeJob()` function, which actually does nothing here and
    just prints a log message:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Enter the `main()` function and create a `handler` variable of the `Handler`
    type. Create `thr1`, pass the `doSomeJob()` function, and move the handler variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Detach the `thr1` thread and add a small sleep for the main thread to avoid
    closing the application. We will be able to see the output from the detached thread:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Run this code in your editor. In the terminal log, from the default constructor,
    you will see two logs from the move operator, one log from a destructor, a message
    from the `doSomeJob()` function, and, finally, two other log messages from the
    destructor. We can see that the move constructor is called twice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C14583_05_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.16: The result of the exercise''s execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, the `Handler` object was moved into the thread function. Despite
    that, all the parameters, that were passed without the `std::ref()` function,
    were copied to the thread's memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s consider one interesting issue. As you may remember, when we initialize
    `std::thread`, all of the constructor arguments are copied into thread memory,
    including a callable object – a lambda, a function, or an std::function. But what
    if our callable object doesn''t support copy semantics? For example, we created
    a class that has only a move constructor and a move assignment operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'How can we pass it to the thread constructor? If we pass it as it is, we will
    get a compiler error; for example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'You will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/C14583_05_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.17: Example of a compilation error'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'There are lots of strange errors here. To fix this issue, we can use the `std::move()`
    function to move the callable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Now, everything is ok – the code is compiled and does exactly what we want it
    to do.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s consider one more interesting example. For example, you have a
    lambda function that needs to capture a non-copiable object, for example, a `unique_ptr`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Starting from C++ 14, we can use `std::move()` to capture movable objects.
    So, to capture a unique pointer, we can use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, it's pretty useful to capture value in a lambda by using `std::move`.
    This can be also useful when we do not want to copy some objects because they
    might take a long time to copy.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's put our knowledge to practice and write an application example that
    demonstrates how we can use `std::move` with threads.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 4: Creating and Working with an STL Container of Threads'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will write a simple application where we will use `std::move()`
    with threads. First of all, we will implement a class that is move constructible.
    This class will convert lowercase text into uppercase text. Then, we will create
    a vector of instances of this class. Next, we will create a vector of `std::thread`
    objects. Finally, we will initialize the threads with an object from the first
    vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Include headers for threading support, namely `<thread>`, streaming support,
    namely `<iostream>`, and `<vector>`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement the `Converter` class, which has the `m_bufferIn` private member
    of the `const` `std::vector<std::string>&` type. This is a reference to the original
    vector of strings in lowercase. It also has a user constructor, which takes the
    `bufferIn` variable. Then, we delete the copy constructor and assignment operators.
    Finally, we define the overloaded `operator()`, where we convert all lowercase
    symbols into uppercase. After conversion, we write the result to the result buffer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Enter the `main()` function, create a constant value called `numberOfTasks`,
    and set it to `5`. Then, create a vector of a `Converter` object and reserve its
    size with `numberOfTasks`. Then, create a vector of `std::thread` objects and
    reserve its size with `numberOfTasks`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the vector of strings, `textArr`, and push five different big strings
    to be converted:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a `for` loop where we push `Converter` objects into the functions
    vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a result vector of strings and push five empty strings. Then, create
    a variable that will be an index of the array element:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement another `for` loop where we push `std::thread` objects into the threads
    vector:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a third `for` loop where we detach `std::threads`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Add a small sleep for the main thread to avoid closing the application. Now,
    we can see how detached threads work:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally print the result into the terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Run this code in your editor. In the terminal, you can see that all strings
    are in uppercase, which means that all threads were moved and run successfully.
    You will get the following output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.18: The result of the exercise’s execution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.18: The result of the exercise''s execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this exercise, we practiced how to create an STL container of move-only objects.
    We also considered how to pass non-copiable objects to a thread constructor. This
    knowledge will help us in the next section when we learn how to get the result
    from the thread.
  prefs: []
  type: TYPE_NORMAL
- en: Futures, Promises, and Async
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we learned almost all that we need to work with threads.
    But we still have something interesting to consider, that is, synchronizing threads
    using future results. When we considered condition variables, we didn't cover
    the second type of synchronization with future results. Now, it's time to learn
    about that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose there is a situation wherein we run some thread and continue with other
    work. When we need a result, we stop and check if it is ready. This situation
    describes the actual work with future results. In C++, we have a header file called
    `<future>` that contains two template classes which represent future results:
    `std::future<>` and `std::shared_future<>`. We use `std::future<>` when we need
    a single future result and use `std::shared_future<>` when we need multiple valid
    copies. We can compare them with `std::unique_ptr` and `std::shared_ptr`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To work with future results, we need a special mechanism to run the task in
    the background and to receive the result later: the `std::async()` template function.
    It takes a callable as a parameter and the launch mode – deferred or async and,
    sure, parameters for the callable. The launch modes `std::launch::async` and `std::launch::deferred`
    indicate how to execute task. When we pass `std::launch::async`, we expect that
    function to be executed in a separate thread. When we pass `std::launch::deferred`,
    the function call will be deferred until we ask for the results. We can also pass
    both of them, for example, `std::launch::deferred|std::launch::async`. This means
    that the run mode will depend on the implementation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s consider an example of usage `std::future` with `std::async`. We
    have a `toUppercase()` function, that converts the given string into uppercase:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, in the `main()` function, we create an `std::future` variable with a
    name `result` and initialize it using the `std::async()` return value. Then, we
    fetch the result by using the `get()` function of the result object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Actually, here, we created a future object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, we didn''t pass the launch mode to the `std::async()` function,
    which means that the default mode will be used: `std::launch::deferred | std::launch::async`.
    You can do this explicitly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are waiting for the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: If our task takes a long time, the thread will wait here until the end.
  prefs: []
  type: TYPE_NORMAL
- en: In general, we can use the `std::async()` function in the same way as we use
    the `std::thread` constructor. We can pass any callable object. All of the arguments
    are copied by default, and we can either move variables and callables or can pass
    them by reference.
  prefs: []
  type: TYPE_NORMAL
- en: The `std::future` object is not protected by race conditions. So, to access
    it from different threads and protect from damage, we should use mutexes. But
    if we need to share a future object, it's better to use `std::shared_future`.
    Shared future results are not thread-safe either. To avoid race conditions, we
    have to use mutexes or store the threads' own copy of `std::shared_future` in
    every thread.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Race conditions for `std::future` objects are very tricky. When the thread calls
    `get()` function, the future object becomes invalid.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a shared future by moving future to a constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we created an `std::shared_future` variable from `std::future`
    and copied it. Both shared future objects are referring to the same result.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also create the shared future object using the `share()` member function
    of the `sdt::future` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Pay attention that, in both cases, the `std::future` object becomes invalid.
  prefs: []
  type: TYPE_NORMAL
- en: Another way we can get a future result from a separate thread is by using the
    `std::packaged_task<>` template class. How do we work with them?
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a new `std::packaged_task` and declare the callable function signature:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we store the future result in the `std::future` variable:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we run this task in a separate thread or call it as a function:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we wait until the future results are ready:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`std::packaged_task` is non-copyable. So, to run it in the separate thread,
    use the `std::move()` function.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one more important thing to take note of. If you don''t want any results
    from the thread and would prefer to wait until the thread finishes its work, you
    can use `std::future<void>`. Now, when you call `future.get()`, your current thread
    will wait at this point. Let''s consider an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, by waiting for another thread, we are making use of several
    techniques such as condition variables, future results, and promises.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s move on to the next important feature in the Standard Library –
    the `std::promise<>` template class. With this class, we can set the value of
    the type that we want to receive and then get it using `std::future`. How do we
    work with them? For that, we need to implement a function that takes an `std::promise`
    parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'When the work is done, we need to initialize a new value with `std::promise`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'For creating `std::promise` in the place where we''ll be using it, we need
    to write the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'Once this is done, we must create `std::future` and get it from the promise:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'We need to run this function in the separate thread:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we need to wait until the future is set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The complete example of getting the result using promises is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: So, we covered almost everything that's required to write multithreaded applications,
    except one important thing – what would happen if an exception is thrown in the
    separate thread? For example, you pass a function in the thread and it throws
    an exception. In this case, `std::terminate()` will be called for this thread.
    Other threads will continue their job. Let's consider a simple example.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a `getException()` function that generates a message with a thread
    ID and throws `std::runtime_error`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'We also have the `toUppercase()` function. Which converts the given string
    into uppercase and calls the `getException()` function, which throws an exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the `main()` function, where we create a new thread, `thr`, in the
    `try-catch` block. We catch an exception and print the message to the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run this code in your IDE, you will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.19: The result of an example’s execution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.19: The result of an example''s execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can see that `std::terminate()` was called after throwing an exception. When
    you have lots of threads in your program, it's very hard to find the right place
    where the thread was terminated. Fortunately, we have a few mechanisms for catching
    an exception from another thread. Let's consider them all.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `std::exception_ptr` in the future result and sets the ready flag. Then,
    when you call `get()`, `std::exception_ptr` stored and rethrows the exception.
    All we need to do is place a `get()` call in the `try-catch` block. Let''s consider
    an example. We will use two helper functions from the previous example, that is,
    `getException()` and `toUppercase()`. They will stay the same. In the `main()`
    function, we create an `std::future` object called `result` and run the `toUppercase()`
    function using the `std::async()` function. Then, we call the `get()` function
    of the result object in the `try-catch` block and catch an exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run the preceding code in your IDE, you will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.20: The result of the example’s execution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.20: The result of the example''s execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As you can see, we caught an exception and now we can handle it in some way.
    The `std::packaged_task<>` class handles exceptions in the same way – it stores
    `std::exception_ptr` in the future result, sets the ready flag, and then `std::future`
    rethrows an exception in the `get()` call. Let''s consider a small example. We
    will use two helper functions from the previous example - `getException()` and
    `toUppercase()`. They will stay the same. In the `main()` function, we create
    an `std::packaged_task` object called `task`. By using the type of our `toUppercase()`
    function, it returns an integer and takes two integers as parameters. We pass
    the `toUppercase()` function to the `task` object. Then, we create an `std::future`
    object called `result` and get the result from the task object using the `get_future()`
    function. Finally, we run the task object in the new thread, `thr`, and in the
    `try-catch` block call the `get()` function of the `result` variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'If you run this code in your IDE, you will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.21: The result of this example’s execution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.21: The result of this example''s execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The `std::promise<>` class handles exceptions in another way. It allows us
    to store an exception manually using the `set_exception()` or `set_exception_at_thread_exit()`
    function. To set an exception in `std::promise`, we have to catch it. If we do
    not catch an exception, an error will be set in the destructor of `std::promise`
    as `std::future_errc::broken_promise` in future result. When you call the `get()`
    function, an exception will be rethrown. Let''s consider an example. We will use
    a helper function from the previous example – `getException()`. It''s staying
    the same. However, we will change the `toUppercase()` function and add the third
    parameter, `std::promise`. Now, we will call the `getException()` function in
    the `try` block, catch an exception, and set it to the `std::promise` value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are a few ways to set an exception to the promise. First of all, we can
    catch `std::exception` and convert it into `std::exception_ptr` using the `std::make_exception_ptr()`
    function. You can also use the `std::current_exception()` function, which returns
    the `std::exception_ptr` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `main()` function, we create a promise of the integer type called `upperResult`.
    We create a future result called `futureRes` and set it from the `upperResult`
    promise value. Next, we create a new thread, `thr`, pass the `toUppercase()` function
    to it, and move the `upperResult` promise. Then, we call the `wait()` function
    of the `futureRes` object, which makes the calling thread wait until the result
    becomes available. Then, in the `try-catch` block, we call the `get()` function
    of the `futureRes` object and it rethrows an exception:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When we create an `std::promise<>` object, we promise that we will obligatorily
    set the value or the exception. If we do not do any that, the destructor of `std::promise`
    will throw an exception, that is, `std::future_error – std::future_errc::broken_promise`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run this code in your IDE, you will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.22: The result of this example’s execution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.22: The result of this example''s execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: That's all for handling exceptions in a multithreaded application. As you can
    see, it's very similar to what we do in a single thread. Now, let's put our knowledge
    to practice and write a simple application example that demonstrates how we can
    use different future results for synchronization.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 5: Synchronization with Future Results'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this exercise, we will write a simple application to demonstrate how we can
    use future results to receive values from the separate threads. We will run the
    `ToUppercase()` callable object three times. We will execute the first task using
    the `std::async()` function, the second task using the `std::packaged_task<>`
    template class, and the last task using `std::thread` and `std::promise`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Include the headers for threading support, namely `<thread>`, streaming support,
    namely `<iostream>`, and `<future>` for future results support:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Implement a `ToUppercase` class that will convert the given string into uppercase.
    It has two overloaded operators, `()`. The first `operator()` takes the string
    to be converted and returns the result value in uppercase. The second `operator()`
    takes the string to be converted and an `std::promise` and stores the return value
    in a promise:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create a `ToUppercase` object, namely `ptConverter`, and create an `std::packaged_task`,
    namely `upperCaseResult1`, which takes the `ptConverter` object as a parameter.
    Create an `std::future` value and set it from `upperCaseResult1`. Run this task
    in a separate thread:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, create a second `ToUppercase` object, namely `fConverter`. Create an `std::future`
    object called `futureUpperResult2` and set it from `std::async()`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'Now. create a third `ToUppercase` object. namely `pConverter`. Create an `std::promise`
    value called `promiseResult`. Then, create an `std::future` value called `futureUpperResult3`
    and set it from `promiseResult`. Now, run the `pConverter` task in the separate
    thread and pass `promiseResult` as an argument:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, to receive the results from all the threads, wait for `futureUpperResult3`
    to be ready and then get all three results and print them:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: Run this code in your editor. You will see the converted strings from all three
    threads.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.23: The result of this exercise’s execution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.23: The result of this exercise''s execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: So, what have we done here? We split big calculations into smaller parts and
    ran them in separate threads. For long calculations, this will increase performance.
    In this exercise, we learned how to receive results from threads. In this section,
    we also learned how to pass an exception that was thrown in a separate thread
    to the calling thread. We also learned how to synchronize the work of a few threads
    by an event, not only with condition variables but also with future results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1: Creating a Simulator to Model the Work of the Art Gallery'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this activity, we are going to create a simulator to model the working of
    an Art Gallery. We have set a limit of visitors to the Gallery – only 50 people
    can be inside. To implement this simulation, we need to create a `Person` class
    that will represent people in the Art Gallery. Also, we need a `Persons` class,
    which is a thread-safe container for people. We also need a `Watchman` class that
    controls how many people are inside it. If the limit exceeds the Watchman, we
    put all the newcomers into a waiting list. Finally, we need a `Generator` class
    that has two threads – one for creating new visitors and another for notifying
    us that somebody has to leave the Gallery. Thus, we will cover working with threads,
    mutexes, condition variables, lock_guards, and unique_locks. This simulator will
    allow us to utilize the techniques that we've covered in this chapter. Thus, before
    attempting this activity, ensure that you have completed all the previous exercises
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement this application, we need to describe our classes. We have the
    following classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.24: Description of the classes that are used in this activity'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.24: Description of the classes that are used in this activity'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s create the class diagram before starting the implementation. All of
    the aforementioned classes with relationships are shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.25: The class diagram'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.25: The class diagram'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Follow these steps to implement this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Define and implement the Person class, which does nothing except print logs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create some thread-safe storage for Persons that wraps the std::vector class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement the PersonGenerator class, that, in an infinite loop in different
    threads, creates and removes visitors and notifies the Watchman class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the Watchman class that, in an infinite loop in separate threads, moves
    visitors from the queue to another queue on notification from the PersonGenerator
    class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Declare the corresponding objects in the main() function to simulate the Art
    Gallery and how it works.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After implementing these steps, you should get the following output, where
    you can see the logs from all the implemented classes. Ensure that the simulation
    flows as expected. The expected output should look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.26: The result of the application’s execution'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/C14583_05_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5.26: The result of the application''s execution'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The solution for this activity can be found on page 681.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we learned about working with threads that are supported by
    the C++ Standard Library. This is fundamental if we want to write robust, fast,
    and clear multithreaded applications.
  prefs: []
  type: TYPE_NORMAL
- en: We started by looking at general concepts regarding concurrency – what parallel,
    concurrent, synchronous, asynchronous, and threaded execution is. Having a clear
    understanding of these concepts allowed us to understand the architectural design
    of the multithreaded application.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we looked at the different issues that we faced while developing multithreaded
    applications, such as data hazards, race conditions, and deadlocks. Understanding
    these issues helped us build a clear synchronized architecture for our projects.
    We considered the synchronization concept on some real-life examples, which gave
    us a good understanding of the challenges that we may face while programming threaded
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we tried to work with different Standard Library primitives for synchronization.
    We tried to figure out how to handle race conditions and implemented examples
    of synchronization by events and synchronization by data. Next, we considered
    how the move semantics apply to multithreading. We learned which classes from
    threading support libraries are non-copiable but movable. We also considered how
    the move semantics work in multithreaded closures. Finally, we learned how to
    receive results from separate threads and how to synchronize threads using futures,
    promises, and async.
  prefs: []
  type: TYPE_NORMAL
- en: We put all of these new skills into practice by building an Art Gallery simulator.
    We built a multithreaded application with one main thread and four child threads.
    We implemented communication between them by using condition variables. We protected
    them using shared data by mutexes. In all, we employed everything we learned about
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we're going to be taking a closer look at I/O operations
    and classes in C++. We will start by looking at the I/O support of the Standard
    Library. Then, we will move on to working with streams and asynchronous I/O operations.
    Next, we will learn about the interaction of threads and I/O. We will write an
    activity that will allow us to master our skills in I/O work in C++.
  prefs: []
  type: TYPE_NORMAL
