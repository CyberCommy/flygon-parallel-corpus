- en: 3\. Application deployment on AKS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will deploy two applications on **Azure Kubernetes Service**
    (**AKS**). An application consists of multiple parts, and you will build the applications
    one step at a time while the conceptual model behind them is explained. You will
    be able to easily adapt the steps in this chapter to deploy any other application
    on AKS.
  prefs: []
  type: TYPE_NORMAL
- en: To deploy the applications and make changes to them, you will be using YAML
    files. YAML is the acronym for **YAML Ain't Markup Language**. YAML is a language
    that is used to create configuration files to deploy to Kubernetes. Although you
    can use either JSON or YAML files to deploy applications to Kubernetes, YAML is
    the most commonly used language to do so. YAML became popular because it is easier
    for a human to read when compared to JSON or XML. You will see multiple examples
    of YAML files throughout this chapter and throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'During the deployment of the sample guestbook application, you will see Kubernetes
    concepts in action. You will see how a **deployment** is linked to a **ReplicaSet**,
    and how that is linked to the **Pods** that are deployed. A Deployment is an object
    in Kubernetes that is used to define the desired state of an application. A deployment
    will create a ReplicaSet. A ReplicaSet is an object in Kubernetes that guarantees
    that a certain number of Pods will always be available. Hence, a ReplicaSet will
    create one or more Pods. A Pod is an object in Kubernetes that is a group of one
    or more containers. Let''s revisit the relationship between Deployment, ReplicaSet,
    and Pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The image describes how Deployments, ReplicaSets, and Pods are linked to
    each other.](image/Figure_3.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: Relationship between a Deployment, a ReplicaSet, and Pods'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: While deploying the sample applications, you will use the **service object**
    to connect to the application. A service in Kubernetes is an object that is used
    to provide a static IP address and DNS name to an application. Since a Pod can
    be killed and moved to different nodes in the cluster, a service ensures you can
    connect to a static endpoint for your application.
  prefs: []
  type: TYPE_NORMAL
- en: You will also edit the sample applications to provide configuration details
    using a **ConfigMap**. A ConfigMap is an object that is used to provide configuration
    details to Pods. It allows you to keep configuration settings outside of the actual
    container. You can then provide these configuration details to your application
    by connecting the ConfigMap to your deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you will be introduced to Helm. Helm is a package manager for Kubernetes
    that helps to streamline the deployment process. You will deploy a WordPress site
    using Helm and gain an understanding of the value Helm brings to Kubernetes. WordPress
    installation makes use of persistent storage in Kubernetes. You will learn how
    persistent storage in AKS is set up.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the sample guestbook application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Full deployment of the sample guestbook application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Helm to install complex Kubernetes applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll begin with the sample guestbook application.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the sample guestbook application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you will deploy the classic guestbook sample Kubernetes application.
    You will be mostly following the steps from [https://Kubernetes.io/docs/tutorials/stateless-application/guestbook/](https://Kubernetes.io/docs/tutorials/stateless-application/guestbook/)
    with some modifications. You will employ these modifications to show additional
    concepts, such as ConfigMaps, that are not present in the original sample.
  prefs: []
  type: TYPE_NORMAL
- en: The sample guestbook application is a simple, multi-tier web application. The
    different tiers in this application will have multiple instances. This is beneficial
    for both high availability and for scale. The guestbook's front end is a stateless
    application because the front end doesn't store any state. The Redis cluster in
    the back end is stateful as it stores all the guestbook entries.
  prefs: []
  type: TYPE_NORMAL
- en: You will be using this application as the basis for testing out the scaling
    of the back end and the front end, independently, in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get started, let's consider the application that we'll be deploying.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The application stores and displays guestbook entries. You can use it to record
    the opinion of all the people who visit your hotel or restaurant, for example.
    Along the way, we will explain Kubernetes concepts such as deployments and ReplicaSets.
  prefs: []
  type: TYPE_NORMAL
- en: The application uses PHP as a front end. The front end will be deployed using
    multiple replicas. The application uses Redis for its data storage. Redis is an
    in-memory key-value database. Redis is most often used as a cache. It's among
    the most popular container images according to [https://www.datadoghq.com/docker-adoption/](https://www.datadoghq.com/docker-adoption/).
  prefs: []
  type: TYPE_NORMAL
- en: '![Overview of the guestbook application. A user connects to the frontend. The
    frontend then connects to either the Redis master or one of the Redis slaves.](image/Figure_3.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2: High-level overview of the guestbook application'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We will begin deploying this application by deploying the Redis master.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Redis master
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, you are going to deploy the Redis master. You will learn about
    the YAML syntax that is required for this deployment. In the next section, you
    will make changes to this YAML. Before making changes, let's start by deploying
    the Redis master.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the task:'
  prefs: []
  type: TYPE_NORMAL
- en: Open your friendly Cloud Shell, as highlighted in *Figure 3.3*:![To open the
    Cloud Shell, click on the icon that is on the right side of the search bar.](image/Figure_3.3.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 3.3: Opening the Cloud Shell'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If you have not cloned the github repository for this book, please do so now
    by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Enter the following command to deploy the master:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'It will take some time for the application to download and start running. While
    you wait, let''s understand the command you just typed and executed. Let''s start
    by exploring the content of the YAML file that was used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s dive deeper into the code to understand the provided parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Line 2**: This states that we are creating a `Deployment`. As explained in
    *Chapter 1*, *Introduction to Docker and Kubernetes*, a deployment is a wrapper
    around Pods that makes it easy to update and scale Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 4-6**: Here, the `Deployment` is given a name, which is `redis-master`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 7-12**: These lines let us specify the containers that this `Deployment`
    will manage. In this example, the `Deployment` will select and manage all containers
    for which labels match (`app: redis`, `role: master`, and `tier: backend`). The
    preceding label exactly matches the labels provided in lines 14-19.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 13**: Tells Kubernetes that we need exactly one copy of the running
    Redis master. This is a key aspect of the declarative nature of Kubernetes. You
    provide a description of the containers your applications need to run (in this
    case, only one replica of the Redis master), and Kubernetes takes care of it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 14-19**: Adds labels to the running instance so that it can be grouped
    and connected to other containers. We will discuss them later to see how they
    are used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 22**: Gives this container a name, which is `master`. In the case of
    a multi-container Pod, each container in a Pod requires a unique name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 23**: This line indicates the Docker image that will be run. In this
    case, it is the `redis` image tagged with `e2e` (the latest Redis image that successfully
    passed its end-to-end [`e2e`] tests).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 28-29**: These two lines indicate that the container is going to listen
    on port `6379`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 24-27**: Sets the `cpu/memory` resources requested for the container.
    In this case, the request is 0.1 CPU, which is equal to `100m` and is also often
    referred to as 100 millicores. The memory requested is `100Mi`, or 104857600 bytes,
    which is equal to ~105MB ([https://Kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/](https://Kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/)).
    You can also set CPU and memory limits in a similar way. Limits are caps on what
    a container can use. If your Pod hits the CPU limit, it''ll get throttled, whereas
    if it hits the memory limits, it''ll get restarted. Setting requests and limits
    is best practice in Kubernetes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Kubernetes YAML definition is similar to the arguments given to Docker
    to run a particular container image. If you had to run this manually, you would
    define this example in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '`# Run a container named master, listening on port 6379, with 100M memory and
    100m CPU using the redis:e2e image.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker run --name master -p 6379:6379 -m 100M -c 100m -d k8s.gcr.io/redis:e2e`'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you have deployed the Redis master and learned about the syntax
    of the YAML file that was used to create this deployment. In the next section,
    you will examine the deployment and learn about the different elements that were
    created.
  prefs: []
  type: TYPE_NORMAL
- en: '**Examining the deployment**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `redis-master` deployment should be complete by now. Continue in the Azure
    Cloud Shell that you opened in the previous section and type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get the output displayed in *Figure 3.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the kubectl get all command, you will see that objects such as Pod,
    service, Deployment, and ReplicaSet are created.](image/Figure_3.4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.4: Output displaying the objects that were created by your deployment'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can see that we have a deployment named `redis-master`. It controls a ReplicaSet
    of `redis-master-<random id>`. On further examination, you will also find that
    the ReplicaSet is controlling a Pod, `redis- master-<replica set random id>-<random
    id>`. *Figure 3.1* has a graphical representation of this relationship.
  prefs: []
  type: TYPE_NORMAL
- en: 'More details can be obtained by executing the `kubectl describe <object> <instance-name>`
    command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate an output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![By using the kubectl describe deployment/redis-master command, you will see
    more details of the deployment.](image/Figure_3.5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.5: Output of describing the deployment'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You have now launched a Redis master with the default configuration. Typically,
    you would launch an application with an environment-specific configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next section, we will introduce a new concept called ConfigMaps and
    then recreate the Redis master. So, before proceeding, we need to clean up the
    current version, and we can do so by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing this command will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: In this section, you examined the Redis master deployment you created. You saw
    how a deployment relates to a ReplicaSet and how a ReplicaSet relates to Pods.
    In the following section, you will recreate this Redis master with an environment-specific
    configuration provided via a ConfigMap.
  prefs: []
  type: TYPE_NORMAL
- en: Redis master with a ConfigMap
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There was nothing wrong with the previous deployment. In practical use cases,
    it would be rare that you would launch an application without some configuration
    settings. In this case, we are going to set the configuration settings for `redis-master`
    using a ConfigMap.
  prefs: []
  type: TYPE_NORMAL
- en: A ConfigMap is a portable way of configuring containers without having specialized
    images for each configuration. It has a key-value pair for data that needs to
    be set on a container. A ConfigMap is used for non-secret configuration. Kubernetes
    has a separate object called a **Secret**. A Secret is used for configurations
    that contain critical data such as passwords. This will be explored in detail
    in *Chapter 10*, *Securing your AKS cluster* of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we are going to create a ConfigMap. In this ConfigMap, we
    will configure `redis-config` as the key and the value will be:'
  prefs: []
  type: TYPE_NORMAL
- en: '`maxmemory 2mb`'
  prefs: []
  type: TYPE_NORMAL
- en: '`maxmemory-policy allkeys-lru`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create this ConfigMap. There are two ways to create a ConfigMap:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a ConfigMap from a file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a ConfigMap from a YAML file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will explore each one in detail.
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating a ConfigMap from a file**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help us create a ConfigMap from a file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the Azure Cloud Shell code editor by typing `code redis-config` in the
    terminal. Copy and paste the following two lines and save it as `redis-config`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can create the ConfigMap using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use the same command to describe this ConfigMap:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The output will be as shown in *Figure 3.6*:![Using the kubectl describe configmap/example-redis-configcommand,
    output will be generated that provides details such as Name, Namespace, Labels,
    Annotations, Data, redis-config, memory, and events.](image/Figure_3.6.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 3.6: Output of describing the ConfigMap'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this example, you created the ConfigMap by referring to a file on disk. A
    different way to deploy ConfigMaps is by creating them from a YAML file. Let's
    have a look at how this can be done in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating a ConfigMap from a YAML file**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, you will recreate the ConfigMap from the previous section
    using a YAML file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, delete the previously created ConfigMap:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Copy and paste the following lines into a file named `example-redis-config.yaml`,
    and then save the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You can now recreate your ConfigMap via the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get an output as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This command returns the same output as the previous one:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, using a YAML file, you were able to create the same ConfigMap.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`kubectl get` has the useful option `-o`, which can be used to get the output
    of an object in either YAML or JSON. This is very useful in cases where you have
    made manual changes to a system and want to see the resulting object in YAML format.
    You can get the current ConfigMap in YAML using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl get -o yaml configmap/example-redis-config`'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have the ConfigMap defined, let's use it.
  prefs: []
  type: TYPE_NORMAL
- en: '**Using a ConfigMap to read in configuration data**'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, you will reconfigure the `redis-master` deployment to read
    configuration from the ConfgMap:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, modify `redis-master-deployment.yaml` to use the ConfigMap as follows.
    The changes you need to make will be explained after the source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you downloaded the source code accompanying this book, there is a file in
    *Chapter 3*, *Application deployment on AKS*, called `redis-master-deployment_Modified.yaml`,
    which has the necessary changes applied to it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s dive deeper into the code to understand the different sections:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lines 24-26**: These lines introduce a command that will be executed when
    your Pod starts. In this case, this will start the `redis-server` pointing to
    a specific configuration file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 27-29**: Shows how to pass configuration data to your running container.
    This method uses environment variables. In Docker form, this would be equivalent
    to `docker run -e "MASTER=true". --name master -p 6379:6379 -m 100M -c 100m -d
    Kubernetes /redis:v1`. This sets the environment variable `MASTER` to `true`.
    Your application can read the environment variable settings for its configuration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 30-32**: These lines mount the volume called `config` (this volume
    is defined in lines 39-45) on the `/redis-master` path on the running container.
    It will hide whatever exists on `/redis-master` on the original container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Docker terms, it would be equivalent to `docker run -v config:/redis-master.
    -e "MASTER=TRUE" --name master -p 6379:6379 -m 100M -c 100m -d Kubernetes /redis:v1`.
  prefs: []
  type: TYPE_NORMAL
- en: '**Line 40**: Gives the volume the name `config`. This name will be used within
    the context of this Pod.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 41-42**: Declare that this volume should be loaded from the `example-redis-config`
    ConfigMap. This ConfigMap should already exist in the system. You have already
    defined this, so you are good.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 43-45**: Here, you are loading the value of the `redis-config` key
    (the two-line `maxmemory` settings) as a `redis.conf` file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s create this updated deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'This should output the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now make sure that the configuration was successfully applied. First,
    get the Pod''s name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Then `exec` into the Pod and verify that the settings were applied:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: To summarize, you have just performed an important and tricky part of configuring
    cloud-native applications. You will have also noticed that the apps have to be
    configured to read config dynamically. After you set up your app with configuration,
    you accessed a running container to verify the running configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Connecting to a running container is useful for troubleshooting and doing diagnostics.
    Due to the ephemeral nature of containers, you should never connect to a container
    to do additional configuration or installation. This should either be part of
    your container image or configuration you provide via Kubernetes (as we just did).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you configured the Redis Master to load configuration data
    from a ConfigMap. In the next section, we will deploy the end-to-end application.
  prefs: []
  type: TYPE_NORMAL
- en: Complete deployment of the sample guestbook application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having taken a detour to understand the dynamic configuration of applications
    using a ConfigMap, we will now return to the deployment of the rest of the guestbook
    application. You will once again come across the concepts of deployment, ReplicaSets,
    and Pods for the back end and front end. Apart from this, you will also be introduced
    to another key concept, called a service.
  prefs: []
  type: TYPE_NORMAL
- en: To start the complete deployment, we are going to create a service to expose
    the Redis master service.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing the Redis master service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When exposing a port in plain Docker, the exposed port is constrained to the
    host it is running on. With Kubernetes networking, there is network connectivity
    between different Pods in the cluster. However, Pods themselves are ephemeral
    in nature, meaning they can be shut down, restarted, or even moved to other hosts
    without maintaining their IP address. If you were to connect to the IP of a Pod
    directly, you might lose connectivity if that Pod was moved to a new host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes provides the `service` object, which handles this exact problem.
    Using label-matching selectors, it proxies traffic to the right Pods and does
    load balancing. In this case, the master has only one Pod, so it just ensures
    that the traffic is directed to the Pod independent of the node the Pod runs on.
    To create the Service, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The Redis master Service has the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now see what you have created using the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lines 1-8**: These lines tell Kubernetes that we want a service called `redis-master`,
    which has the same labels as our `redis-master` server Pod.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 10-12:** These lines indicate that the service should handle traffic
    arriving at port `6379` and forward it to port `6379` of the Pods that match the
    selector defined between lines 13 and 16\.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 13-16**: These lines are used to find the Pods to which the incoming
    traffic needs to be proxied. So, any Pod with labels matching (`app: redis`, `role:
    master` and `tier: backend`) is expected to handle port `6379` traffic. If you
    look back at the previous example, those are the exact labels we applied to that
    deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can check the properties of the service by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give you an output as shown in *Figure 3.7*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![With the help of kubectl get service command, you will see details such as
    Name, Type, Cluster-IP, External-IP, Port(s), and the age of each service.](image/Figure_3.7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.7: Output of the service that was created'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You see that a new service, named `redis-master`, has been created. It has a
    cluster-wide IP of `10.0.227.250` (in your case, the IP will likely be different).
    Note that this IP will work only within the cluster (hence the `ClusterIP` type).
  prefs: []
  type: TYPE_NORMAL
- en: 'A service also introduces a **Domain Name Server** (**DNS**) name for that
    service. The DNS name is of the form `<service-name>.<namespace>.svc.cluster.local`;
    in our case, that would be `redis-master.default.svc.cluster.local`. To see this
    in action, we''ll do a name resolution on our `redis-master` VM. The default image
    doesn''t have `nslookup` installed, so we''ll bypass that by running a `ping`
    command. Don''t worry if that traffic doesn''t return; this is because you didn''t
    expose `ping` on your service, only the `redis` port. Let''s have a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This should output the resulting name resolution, showing you the **Fully Qualified
    Domain Name** (**FQDN**) of your service and the IP address that showed up earlier.
    You can exit out of the Pod via the `exit` command, as shown in *Figure 3.8*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The output displays the FQDN of the service along with the IP address.](image/Figure_3.8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.8: Using a ping command to view the FQDN of your service'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this section, you exposed the Redis master using a service. In the next section,
    you will deploy the Redis slaves.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Redis slaves
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Running a single back end on the cloud is not recommended. You can configure
    Redis in a master-slave setup. This means that you can have a master that will
    serve write traffic and multiple slaves that can handle read traffic. It is useful
    for handling increased read traffic and high availability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s set this up:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the deployment by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check all the resources that have been created now:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The output would be as shown in *Figure 3.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the kubectl get all command, you see new objects such as Pod, Deployment,
    and ReplicaSet.](image/Figure_3.9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9: Deploying the Redis slaves creates a number of new objects'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Based on the preceding output, you can see that you created two replicas of
    the `redis-slave` Pods. This can be confirmed by examining the `redis-slave- deployment.yaml`
    file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Everything is the same except for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Line 13:** The number of replicas is `2`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 23:** You are now using a specific slave image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 29-30**: Setting `GET_HOSTS_FROM` to `dns`. As you saw in the previous
    example, DNS resolves in the cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Like the master service, you need to expose the slave service by running the
    following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The only difference between this service and the `redis-master` service is that
    this service proxies traffic to Pods that have the `role:slave` label.
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the `redis-slave` service by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This should give you the output shown in *Figure 3.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When you execute the kubectl get service command, the output screen will
    display a redis-master and a redis-slave.](image/Figure_3.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.10: Output displaying both a redis-master and a redis-slave service'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You now have a Redis cluster up and running, with a single master and two replicas.
    In the next section, you will deploy and expose the front end.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and exposing the front end
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Up to now, you have focused on the Redis back end. Now you are ready to deploy
    the front end. This will add a graphical web page to your application that you'll
    be able to interact with.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create the front end using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'To verify the deployment, run this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'This will display the output shown in *Figure 3.11*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When you execute the kubectl get pods command, the output screen displays
    a total of 6 Pods in the Running state.](image/Figure_3.11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.11: Output displaying the additional Pods running the front end'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You will notice that this deployment specifies `3` replicas. The deployment
    has the usual aspects with minor changes, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see these changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Line 11**: The replica count is set to `3`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 8-10 and 14-16:** The labels are set to `app: guestbook` and `tier:
    frontend`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 20:** `gb-frontend:v4` is used as the image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have now created the front-end deployment. You now need to expose it as
    a service.
  prefs: []
  type: TYPE_NORMAL
- en: '**Exposing the front-end service**'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are multiple ways to define a Kubernetes service. The two Redis services
    we created were of the type `ClusterIP`. This means they are exposed on an IP
    that is reachable only from the cluster, as shown in *Figure 3.12*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A service of type clusterIP is an IP that spans the whole cluster and connects
    to pods on each node. A ClusterIP is only available inside the cluster.](image/Figure_3.12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.12: Kubernetes service of type ClusterIP'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Another type of service is the type `NodePort`. This service would be exposed
    on a static port on each node as shown in *Figure 3.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A Service of type NodePort will open a port on each node that will connect
    to the pods on each node. External users can use that port to connect to pods
    from outside the cluster.](image/Figure_3.13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.13: Kubernetes service of type NodePort'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'A final type – which we will use in our example – is the `LoadBalancer` type.
    This will create an **Azure load balancer** that will get a public IP that we
    can use to connect to, as shown in *Figure 3.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A Service of type LoadBalancer will create an external load balancer that
    will connect to the Pods on each node. External users can use that load balancer
    to connect to the pods from outside the cluster.](image/Figure_3.14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.14: Kubernetes service of type LoadBalancer'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The following code will help us to understand how a front-end service is exposed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that you have seen how a front-end service is exposed, let''s make the
    guestbook application ready for use with the following steps:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To create the service, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This step takes some time to execute when you run it for the first time. In
    the background, Azure must perform a couple of actions to make it seamless. It
    has to create an Azure load balancer and a public IP and set the port-forwarding
    rules to forward traffic on port `80` to internal ports of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following until there is a value in the `EXTERNAL-IP` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'This should display the output shown in *Figure 3.15*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When the kubectl get service command is executed, it generates an output
    wherein the frontend, kubernetes, redis-master, and redis-slave all have a Cluster
    IP. However, here only the frontend has an External IP.](image/Figure_3.15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.15: Output displaying a value for External IP after a while'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the Azure portal, if you click on **All Resources** and filter on **Load
    balancer**, you will see a **kubernetes Load balancer**. Clicking on it shows
    you something similar to *Figure 3.16*. The highlighted sections show you that
    there is a load balancing rule accepting traffic on port `80` and you have 2 public
    IP addresses:![Upon opening the Kubernetes load balancer in the Azure portal,
    you will see a load balancing rule and twopublic IP addresses that appear towards
    the rightside of the screen.](image/Figure_3.16.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 3.16: Displaying the Kubernetes load balancer in the Azure portal'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you click through on the two public IP addresses, you'll see both IP addresses
    linked to your cluster. One of those will be the IP address of your actual service;
    the other one is used by AKS to make outbound connections.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Azure has two types of load balancers: basic and standard.'
  prefs: []
  type: TYPE_NORMAL
- en: Virtual machines behind a basic load balancer can make outbound connections
    without any specific configuration. Virtual machines behind a standard load balancer
    (which is the default for AKS now) need a specific configuration to make outbound
    connections. This is why you see a second IP address configured.
  prefs: []
  type: TYPE_NORMAL
- en: We're finally ready to put our guestbook app into action!
  prefs: []
  type: TYPE_NORMAL
- en: The guestbook application in action
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Type the public IP of the service in your favorite browser. You should get
    the output shown in *Figure 3.17*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When you type in the IP address in your browser, you will see a white screen
    displaying the word Guestbook. This indicates that the Guestbook application is
    running.](image/Figure_3.17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.17: The guestbook application in action'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Go ahead and record your messages. They will be saved. Open another browser
    and type the same IP; you will see all the messages you typed.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations – you have completed your first fully deployed, multi-tier,
    cloud-native Kubernetes application!
  prefs: []
  type: TYPE_NORMAL
- en: 'To conserve resources on your free-trial virtual machines, it is better to
    delete the created deployments to run the next round of the deployments by using
    the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Over the course of the preceding sections, you have deployed a Redis cluster
    and deployed a publicly accessible web application. You have learned how deployments,
    ReplicaSets, and Pods are linked, and you have learned how Kubernetes uses the
    `service` object to route network traffic. In the next section of this chapter,
    you will use Helm to deploy a more complex application on top of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Installing complex Kubernetes applications using Helm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, we used static YAML files to deploy our application.
    When deploying more complicated applications, across multiple environments (such
    as dev/test/prod), it can become cumbersome to manually edit YAML files for each
    environment. This is where the Helm tool comes in.
  prefs: []
  type: TYPE_NORMAL
- en: Helm is the package manager for Kubernetes. Helm helps you deploy, update, and
    manage Kubernetes applications at scale. For this, you write something called
    Helm Charts.
  prefs: []
  type: TYPE_NORMAL
- en: You can think of Helm Charts as parameterized Kubernetes YAML files. If you
    think about the Kubernetes YAML files we wrote in the previous section, those
    files were static. You would need to go into the files and edit them to make changes.
  prefs: []
  type: TYPE_NORMAL
- en: Helm charts allow you to write YAML files with certain parameters in them, which
    you can dynamically set. This setting of the parameters can be done through a
    values file or as a command-line variable when you deploy the chart.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, with Helm, you don't necessarily have to write Helm Charts yourself;
    you can also use a rich library of pre-written Helm Charts and install popular
    software in your cluster through a simple command such as `helm install --name
    my-release stable/mysql`.
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly what you are going to do in the next section. You will install
    WordPress on your cluster by issuing only two commands. In the next chapters,
    you'll also dive into custom Helm Charts that you'll edit.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: On November 13, 2019 the first stable release of Helm v3 was released. We will
    be using Helm v3 in the following examples. The biggest difference between Helm
    v2 and Helm v3 is that Helm v3 is a fully client-side tool that no longer requires
    the server-side tool called `tiller`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want a more thorough introduction to writing your own Helm Charts, you
    can refer to the following blog post by one of the authors of this book: [https://blog.nillsf.com/index.php/2019/11/23/writing-a-helm-v3-chart/](https://blog.nillsf.com/index.php/2019/11/23/writing-a-helm-v3-chart/).'
  prefs: []
  type: TYPE_NORMAL
- en: Let's start by installing WordPress on your cluster using Helm. In this section,
    you'll also learn about persistent storage in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Installing WordPress using Helm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As mentioned in the introduction, Helm has a rich library of pre-written Helm
    charts. To access this library, you''ll have to add a repo to your Helm client:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the repo that contains the stable Helm Charts using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'To install WordPress, we will run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This execution will cause Helm to install the chart detailed at [https://github.com/helm/charts/tree/master/stable/wordpress](https://github.com/helm/charts/tree/master/stable/wordpress).
  prefs: []
  type: TYPE_NORMAL
- en: It takes some time for Helm to install and the site to come up. Let's look at
    a key concept, PersistentVolumeClaims, while the site is loading. After covering
    this, we'll go back and look at our site that got created.
  prefs: []
  type: TYPE_NORMAL
- en: '**PersistentVolumeClaims**'
  prefs: []
  type: TYPE_NORMAL
- en: A process requires compute, memory, network, and storage. In the guestbook example,
    we saw how Kubernetes helps us abstract the compute, memory, and network. The
    same YAML files work across all cloud providers, including a cloud-specific setup
    of public-facing load balancers. The WordPress example shows how the last piece,
    namely storage, is abstracted from the underlying cloud provider.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the WordPress Helm Chart depends on the MariaDB helm chart ([https://github.com/helm/charts/tree/master/stable/mariadb](https://github.com/helm/charts/tree/master/stable/mariadb))
    for its database installation.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike stateless applications, such as our front ends, MariaDB requires careful
    handling of storage. To make Kubernetes handle stateful workloads, it has a specific
    object called a StatefulSet. A StatefulSet ([https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/))
    is like a deployment with the additional capability of ordering, and the uniqueness
    of the Pods. This means that Kubernetes will ensure that the Pod and its storage
    are kept together. Another way that StatefulSets help is with the consistent naming
    of Pods in a StatefulSet. The Pods are named `<pod-name>-#`, where `#` starts
    from `0` for the first Pod, and `1` for the second Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the following command, you can see that MariaDB has a predictable number
    attached to it, whereas the WordPress deployment has a random number attached
    to the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the output shown in *Figure 3.18*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When the kubectl get pods command is executed, you will see a predictable
    name for the MariaDB Pod and a random alpha-numeric name for the WordPress Pod.](image/Figure_3.18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.18: Output displaying a predictable number for the MariaDB Pod, whereas
    a random name for the WordPress Pod'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The numbering reinforces the ephemeral nature of the deployment Pods versus
    the StatefulSet Pods.
  prefs: []
  type: TYPE_NORMAL
- en: Another difference is how pod deletion is handled. When a deployment pod is
    deleted, Kubernetes will launch it again anywhere it can, whereas when a StatefulSet
    pod is deleted, Kubernetes will relaunch it only on the node it was running on.
    It will relocate the pod only if the node is removed from the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Often, you will want to attach storage to a StatefulSet. To achieve this, a
    StatefulSet requires a persistent volume. This volume can be backed by many mechanisms
    (including blocks, such as Azure Blob, EBS, and iSCSI, and network filesystems,
    such as AFS, NFS, and GlusterFS). Please refer to https://Kubernetes.io/docs/concepts/storage/volumes/#persistentvolumeclaim
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: 'StatefulSets require either a pre-provisioned volume or a dynamically provisioned
    volume handled by a **PersistentVolumeClaim** (**PVC**). In our example, we are
    using a PVC. A PVC provides an abstraction over the underlying storage mechanism.
    Let''s look at what the MariaDB Helm Chart did for us by running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show us something similar to *Figure 3.19*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Upon executing the kubectl get statefulsets command, the output screen will
    show you a MariaDB Pod inthe 1/1 Ready state.](image/Figure_3.19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.19: Output displaying the StatefulSet that created the MariaDB Pods'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let''s have a more in-depth look by exporting the YAML definition of our StatefulSet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s look at the most relevant parts of that YAML file. The code has been
    truncated to only show the most relevant parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Most of the elements of the preceding code have been covered earlier in the
    deployment. In the following block, we will highlight the key differences, to
    take a look at just the PVC:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: PVC can be used by any Pod, not just StatefulSet Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s discuss the different elements of the preceding code in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Line 4**: This line indicates the `StatefulSet` declaration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 106-108**: Mount the volume defined as `data` and mount it under the
    `/bitnami/mariadb` path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lines 128-143**: Declare the PVC. Note specifically:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 136**: This line gives it the name `data`, which is reused at line 108.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 139**: Gives the access mode `ReadWriteOnce`, which will create block
    storage, which on Azure is a disk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 142**: Defines the size of the disk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Based on the preceding information, Kubernetes dynamically requests and binds
    an 8Gi volume to this Pod. In this case, the default dynamic-storage provisioner
    backed by the Azure disk is used. The dynamic provisioner was set up by Azure
    when we created the cluster. To see the storage classes available on your cluster,
    you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show you an output similar to *Figure 3.20*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![The kubectl get storageclass command generates an output where you will see
    two storage classes, the default and managed premium. Both are of the provisioner
    type azure-disktype.](image/Figure_3.20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.20: Output displaying the different storage classes in your cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can get more details about the PVC by running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'The output generated is displayed in *Figure 3.21*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When you execute the kubectl get pvc command, your output screen will display
    the Name, Status, Volume, Capacity, Access mode, Storageclass, and the age of
    each PVC.](image/Figure_3.21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.21: Different PVCs in the cluster'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When we asked for storage in the StatefulSet description (lines 128-143), Kubernetes
    performed Azure-disk-specific operations to get the Azure disk with 8 GiB of storage.
    If you copy the name of the PVC and paste that in the Azure search bar, you should
    find the disk that was created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When you paste the PVC name that was generated from the previous command
    in the bar, you will see that a disk is created inthe Resources column.](image/Figure_3.22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.22: Getting the disk linked to a PVC'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The concept of a PVC abstracts cloud provider storage specifics. This allows
    the same Helm template to work across Azure, AWS, or GCP. On AWS, it will be backed
    by **Elastic Block Store** (**EBS**), and on GCP it will be backed by Persistent
    Disk.
  prefs: []
  type: TYPE_NORMAL
- en: Also, note that PVCs can be deployed without using Helm.
  prefs: []
  type: TYPE_NORMAL
- en: '**Checking the WordPress deployment**'
  prefs: []
  type: TYPE_NORMAL
- en: 'After our analysis of the PVCs, let''s check back in with our Helm deployment.
    We can check the status of the deployment using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'This should return the output shown in *Figure 3.23*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![On executing the helm ls command, the output screen will display the status
    of the deployment as deployed.](image/Figure_3.23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.23: Helm shows that our WordPress application has been deployed'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can get more info from our deployment in Helm using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return the output shown in *Figure 3.24*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the helm status handsonakswp command, you can obtain more details about
    the application.](image/Figure_3.24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.24: Getting more details about the application'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This shows us that our chart was successfully deployed. It also shows more
    info on how we can connect to our site. We won''t be using these steps for now;
    we will revisit these steps in *Chapter 5*, *Handling common failures in AKS*,
    in the section where we cover fixing storage mount issues. For now, we are going
    to look into everything that Helm created for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate an output similar to *Figure 3.25*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Executing the kubectl get all command generates an output screen that displays
    objects created by Helm such as Pod, Service, Deployment, ReplicaSet, and the
    StatefulSet, along with information about each of them. You will also get the
    external-ip of the WordPress service.](image/Figure_3.25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.25: Output displaying all the objects created by Helm'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you don't have an external IP yet, wait for a couple of minutes and retry
    the command.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can then go ahead and connect to your external IP and access your WordPress
    site. The following screenshot is the resulting output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![When you connect an external IP to the WordPress site, you will see a screen
    that displays Hello World! andencourages you to start writing a blog post.](image/Figure_3.26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.26: WordPress site being displayed on connection with the external
    IP'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To make sure we don''t run into issues in the following chapters, let''s delete
    the WordPress site. This can be done in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'By design, our PVCs won''t be deleted. This ensures persistent data is kept.
    As we don''t have any persistent data, we can safely delete those as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Be very careful when executing `kubectl delete <object> --all` as it will delete
    all the objects in a namespace. This is not recommended on a production cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you have deployed a full WordPress site using Helm. You also
    learned how Kubernetes handles persistent storage using PVCs.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we deployed two applications. We started the chapter by deploying
    the guestbook application. During that deployment, we looked into the details
    of Pods, ReplicaSets, and deployments. We also used dynamic configuration using
    ConfigMaps. Finally, we looked into how services are used to route traffic to
    the deployed applications.
  prefs: []
  type: TYPE_NORMAL
- en: The second application we deployed was a WordPress application. We deployed
    it via the Helm package manager. As part of this deployment, PVCs were used, and
    we explored how these were used in the system.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look into scaling applications and the cluster
    itself. We will first look at the manual and automatic scaling of the application,
    and afterward, we'll look at the manual and automatic scaling of the cluster itself.
    Finally, we will explain different ways in which applications can be updated on
    Kubernetes.
  prefs: []
  type: TYPE_NORMAL
