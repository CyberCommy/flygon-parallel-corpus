- en: Matplotlib and Advanced Probability Concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After going through some of the simpler concepts of statistics and probability
    in the previous chapter, we're now going to turn our attention to some more advanced
    topics that you'll need to be familiar with to get the most out of the remainder
    of this book. Don't worry, they're not too complicated. First of all, let's have
    some fun and look at some of the amazing graphing capabilities of the `matplotlib`
    library.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll be covering the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the `matplotlib` package to plot graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding covariance and correlation to determine the relationship between
    data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding conditional probability with examples
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Bayes' theorem and its importance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A crash course in Matplotlib
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Your data is only as good as you can present it to other people, really, so
    let's talk about plotting and graphing your data and how to present it to others
    and make your graphs look pretty. We're going to introduce Matplotlib more thoroughly
    and put it through its paces.
  prefs: []
  type: TYPE_NORMAL
- en: I'll show you a few tricks on how to make your graphs as pretty as you can.
    Let's have some fun with graphs. It's always good to make pretty pictures out
    of your work. This will give you some more tools in your tool chest for visualizing
    different types of data using different types of graphs and making it look pretty.
    We'll use different colors, different line styles, different axes, things like
    that. It's not only important to use graphs and data visualization to try to find
    interesting patterns in your data, but it's also interesting to present your findings
    well to a non-technical audience. Without further ado, let's dive in to Matplotlib.
  prefs: []
  type: TYPE_NORMAL
- en: Go ahead and open up the `MatPlotLib.ipynb` file and you can play around with
    this stuff along with me. We'll start by just drawing a simple line graph.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: So in this example, I import `matplotlib.pyplot` as `plt`, and with this, we
    can refer to it as `plt` from now on in this notebook. Then, I use `np.arange(-3,
    3, 0.001)` to create an x-axis filled with values between `-3` and `3` at increments
    of 0.001, and use `pyplot`'s `plot()` function to plot `x`. The y function will
    be `norm.pdf(x)`. So I'm going to create a probability density function with a
    normal distribution based on the `x` values, and I'm using the `scipy.stats norm`
    package to do that.
  prefs: []
  type: TYPE_NORMAL
- en: 'So tying it back into last chapter''s look at probability density functions,
    here we are plotting a normal probability density function using `matplotlib`.
    So we just call `pyplot`''s `plot()` method to set up our plot, and then we display
    it using `plt.show()`. When we run the previous code, we get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac909c54-d8e6-4437-bcbe-49aaace13bb8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'That''s what we get: a pretty little graph with all the default formatting.'
  prefs: []
  type: TYPE_NORMAL
- en: Generating multiple plots on one graph
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s say I want to plot more than one thing at a time. You can actually call
    plot multiple times before calling show to actually add more than one function
    to your graph. Let''s look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: In this example, I'm calling my original function of just a normal distribution,
    but I'm going to render another normal distribution here as well, with a mean
    around `1.0` and a standard deviation of `0.5`. Then, I'm going to show those
    two together so you can see how they compare to each other.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/86bcf451-c546-482c-81f0-7d32400aebff.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that by default, `matplotlib` chooses different colors for each
    graph automatically for you, which is very nice and handy of it.
  prefs: []
  type: TYPE_NORMAL
- en: Saving graphs as images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If I want to save this graph to a file, maybe I want to include it in a document
    or something, I can do something like the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Instead of just calling `plt.show()`, I can call `plt.savefig()` with a path
    to where I want to save this file and what format I want it in.
  prefs: []
  type: TYPE_NORMAL
- en: You'll want to change that to an actual path that exists on your machine if
    you're following along. You probably don't have a `Users\Frank` folder on your
    system. Remember too that if you're on Linux or macOS, instead of a backslash
    you're going to use forward slashes, and you're not going to have a drive letter.
    With all of these Python Notebooks, whenever you see a path like this, make sure
    that you change it to an actual path that works on your system. I am on Windows
    here, and I do have a `Users\Frank` folder, so I can go ahead and run that. If
    I check my file system under `Users\Frank`, I have a `MyPlot.png` file that I
    can open up and look at, and I can use that in whatever document I want.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/74064b37-2c98-42e6-af09-84e624a65d80.png)'
  prefs: []
  type: TYPE_IMG
- en: That's pretty cool. One other quick thing to note is that depending on your
    setup, you may have permissions issues when you come to save the file. You'll
    just need to find the folder that works for you. On Windows, your `Users\Name`
    folder is usually a safe bet. Alright, let's move on.
  prefs: []
  type: TYPE_NORMAL
- en: Adjusting the axes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s say that I don''t like the default choices of the axes of this value
    in the previous graph. It''s automatically fitting it to the tightest set of the
    axis values that you can find, which is usually a good thing to do, but sometimes
    you want things on an absolute scale. Look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: In this example, first I get the axes using `plt.axes`. Once I have these axes
    objects, I can adjust them. By calling `set_xlim`, I can set the x range from
    -5 to 5 and with set `set_ylim`, I set the y range from 0 to 1\. You can see in
    the below output, that my x values are ranging from `-5` to `5`, and y goes from
    0 to 1\. I can also have explicit control over where the tick marks on the axes
    are. So in the previous code, I'm saying I want the x ticks to be at `-5`, `-4`,
    `- 3`, etc., and y ticks from 0 to 1 at 0.1 increments using the `set_xticks()`
    and `set_yticks()` functions. Now I could use the `arange` function to do that
    more compactly, but the point is you have explicit control over where exactly
    those tick marks happen, and you can also skip some. You can have them at whatever
    increments you want or whatever distribution you want. Beyond that, it's the same
    thing.
  prefs: []
  type: TYPE_NORMAL
- en: Once I've adjusted my axes, I just called `plot()` with the functions that I
    want to plot and called `show()` to display it. Sure enough, there you have the
    result.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5f1b0b4c-ae5e-4f7b-8e82-91a816a80f2f.png)'
  prefs: []
  type: TYPE_IMG
- en: Adding a grid
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What if I want grid lines in my graphs? Well, same idea. All I do is call `grid()`
    on the axes that I get back from `plt.axes()`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: By executing the above code, I get nice little grid lines. That makes it a little
    bit easier to see where a specific point is, although it clutters things up a
    little bit. It's a little bit of a stylistic choice there.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cbcc6628-6b51-448c-a8f7-1adadc53cef2.png)'
  prefs: []
  type: TYPE_IMG
- en: Changing line types and colors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What if I want to play games with the line types and colors? You can do that
    too.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: So you see in the preceding code, there's actually an extra parameter on the
    `plot()` functions at the end where I can pass a little string that describes
    the style of a line. In this first example, what `b-` indicates is I want a blue,
    solid line. The `b` stands for blue, and the dash means a solid line. For my second
    `plot()` function, I'm going to plot it in red, that's what the `r` means, and
    the colon means I'm going to plot it with a dotted line.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ff115f9e-aafa-40cf-8c34-140780516fa6.png)'
  prefs: []
  type: TYPE_IMG
- en: If I run that, you can see in the above graph what it does, and you can change
    different types of line styles.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, you can do a double dash (`--`).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code gives you dashed red line as a line style as shown in the
    following graph image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5bd95715-c102-46e5-ae16-2732ec4c9640.png)'
  prefs: []
  type: TYPE_IMG
- en: I can also do a dash dot combination (`-.`).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You get an output that looks like the following graph image:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/252eb00e-7eed-40b8-8355-57fabd4e13bf.png)'
  prefs: []
  type: TYPE_IMG
- en: So, those are the different choices there. I could even make it green with vertical
    slashes (`g:`).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'I''ll get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98bce130-eb7a-4833-b107-388a6d8c09aa.png)'
  prefs: []
  type: TYPE_IMG
- en: Have some fun with that if you want, experiment with different values, and you
    can get different line styles.
  prefs: []
  type: TYPE_NORMAL
- en: Labeling axes and adding a legend
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Something you''ll do more often is labeling your axes. You never want to present
    data in a vacuum. You definitely want to tell people what it represents. To do
    that, you can use the `xlabel()` and `ylabel()` functions on `plt` to actually
    put labels on your axes. I''ll label the x axis Greebles and the y axis Probability.
    You can also add a legend inset. Normally, this would be the same thing, but just
    to show that it''s set independently, I''m also setting up a legend in the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Into the legend, you pass in basically a list of what you want to name each
    graph. So, my first graph is going to be called Sneetches, and my second graph
    is going to be called Gacks, and the `loc` parameter indicates what location you
    want it at, where `4` represents the lower right-hand corner. Let''s go ahead
    and run the code, and you should see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/987087bc-64bd-4573-85e6-763adff5de35.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that I'm plotting Greebles versus Probability for both Sneetches
    and Gacks. A little Dr. Seuss reference for you there. So that's how you set axes
    labels and legends.
  prefs: []
  type: TYPE_NORMAL
- en: A fun example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A little fun example here. If you're familiar with the webcomic XKCD, there's
    a little bit of an Easter egg in Matplotlib, where you can actually plot things
    in XKCD style. The following code shows how you can do that.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, you call `plt.xkcd()`, which puts Matplotlib in XKCD mode.
    After you do that, things will just have a style with kind of a comic book font
    and squiggly lines automatically. This little simple example will show a funny
    little graph where we are plotting your health versus time, where your health
    takes a steep decline once you realize you can cook bacon whenever you want to.
    All we''re doing there is using the `xkcd()` method to go into that mode. You
    can see the results below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/72e7f5b8-3152-47a4-abf1-c47f038380f8.png)'
  prefs: []
  type: TYPE_IMG
- en: There's a little bit of interesting Python here in how we're actually putting
    this graph together. We're starting out by making a data line that is nothing
    but the value 1 across 100 data points. Then we use the old Python list slicing
    operator to take everything after the value of 70, and we subtract off from that
    sub-list of 30 items, the range of 0 through 30\. So that has the effect of subtracting
    off a larger value linearly as you get past 70, which results in that line heading
    downward down to 0 beyond the point 70.
  prefs: []
  type: TYPE_NORMAL
- en: So, it's a little example of some Python list slicing in action there, and a
    little creative use of the `arange` function to modify your data.
  prefs: []
  type: TYPE_NORMAL
- en: Generating pie charts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, to go back to the real world, we can remove XKCD mode by calling `rcdefaults()`
    on Matplotlib, and we can get back to normal mode here.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want a pie chart, all you have to do is call `plt.pie` and give it an
    array of your values, colors, labels, and whether or not you want items exploded,
    and if so, by how much. Here''s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see in this code that I''m creating a pie chart with the values `12`,
    `55`, `4`, `32`, and `14`. I''m assigning explicit colors to each one of those
    values, and explicit labels to each one of those values. I''m exploding out the
    Russian segment of the pie by 20%, and giving this plot a title of Student Locations
    and showing it. The following is the output you should see:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46c057a3-e9a6-40da-8748-ff1b8107251e.png)'
  prefs: []
  type: TYPE_IMG
- en: That's all there is to it.
  prefs: []
  type: TYPE_NORMAL
- en: Generating bar charts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If I want to generate a bar chart, that is also very simple. It's a kind of
    a similar idea to the pie chart. Let's look at the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'I''ve defined an array of values and an array of colors, and just plot the
    data. The above code plots from the range of 0 to 5, using the y values from the
    `values` array and using the explicit list of colors listed in the `colors` array.
    Go ahead and show that, and there you have your bar chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bb70ed4a-96b3-4742-9d20-9f97247d41ed.png)'
  prefs: []
  type: TYPE_IMG
- en: Generating scatter plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A scatter plot is something we'll see pretty often in this book. So, say you
    have a couple of different attributes you want to plot for the same set of people
    or things. For example, maybe we're plotting ages against incomes for each person,
    where each dot represents a person and the axes represent different attributes
    of those people.
  prefs: []
  type: TYPE_NORMAL
- en: The way you do that with a scatter plot is you call `plt.scatter()` using the
    two axes that you want to define, that is, the two attributes that contain data
    that you want to plot against each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say I have a random distribution in `X` and `Y` and I scatter those
    on the scatter plot, and I show it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You get the following scatter plot as output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/216c10dd-6394-43a9-ac6b-f761a26acd83.png)'
  prefs: []
  type: TYPE_IMG
- en: This is what it looks like, pretty cool. You can see the sort of a concentration
    in the center here, because of the normal distribution that's being used in both
    axes, but since it is random, there's no real correlation between those two.
  prefs: []
  type: TYPE_NORMAL
- en: Generating histograms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Finally, we''ll remind ourselves how a histogram works. We''ve already seen
    this plenty of times in the book. Let''s look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: In this example, I call a normal distribution centered on 27,000, with a standard
    deviation of 15,000 with 10,000 data points. Then, I just call `pyplot`'s histogram
    function, that is, `hist()`, and specify the input data and the number of buckets
    that we want to group things into in our histogram. Then I call `show()` and the
    rest is magic.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fdd1e7b6-d46c-4ff0-99d5-3c9390efc143.png)'
  prefs: []
  type: TYPE_IMG
- en: Generating box-and-whisker plots
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, let's look at box-and-whisker plots. Remember in the previous chapter,
    when we talked about percentiles I touched on this a little bit.
  prefs: []
  type: TYPE_NORMAL
- en: Again, with a box-and-whisker plot, the box represents the two inner quartiles
    where 50% of your data resides. Conversely, another 25% resides on either side
    of that box; the whiskers (dotted lines in our example) represent the range of
    the data except for outliers.
  prefs: []
  type: TYPE_NORMAL
- en: We define outliers in a box-and-whisker plot as anything beyond 1.5 times the
    interquartile range, or the size of the box. So, we take the size of the box times
    1.5, and up to that point on the dotted whiskers, we call those parts outer quartiles.
    But anything outside of the outer quartiles is considered an outlier, and that's
    what the lines beyond the outer quartiles represent. That's where we are defining
    outliers based on our definition with the box-and-whisker plot.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some points to remember about box-and-whisker plots:'
  prefs: []
  type: TYPE_NORMAL
- en: They are useful for visualizing the spread and skew of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The line in the middle of the box represents the median of the data, and the
    box represents the bounds of the 1st and 3rd quartiles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Half of the data exists within the box
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The "whiskers" indicate the range of the data-except for outliers, which are
    plotted outside the whiskers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outliers are 1.5 times or more the interquartile range.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, just to give you an example here, we have created a fake dataset. The
    following example creates uniformly distributed random numbers between -40 and
    60, plus a few outliers above `100` and below `-100`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In the code, we have a uniform random distribution of data (`uniformSkewed`).
    Then we added a few outliers on the high end (`high_outliers`) and a few negative
    outliers (`low_outliers`) as well. Then we concatenated these lists together and
    created a single dataset from these three different sets that we created using
    NumPy. We then took that combined dataset of uniform data and a few outliers and
    we plotted using `plt.boxplot()`, and that's how you get a box-and-whisker plot.
    Call `show()` to visualize it, and there you go.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/77d95176-b924-4737-b914-454a2ebca453.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that the graph is showing the box that represents the inner 50%
    of all data, and then we have these outlier lines where we can see little crosses
    (they may be circles in your version) for each individual outlier that lies in
    that range.
  prefs: []
  type: TYPE_NORMAL
- en: Try it yourself
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alright, that's your crash course in Matplotlib. Time to get your hands on it,
    and actually do some exercises here.
  prefs: []
  type: TYPE_NORMAL
- en: As your challenge, I want you to create a scatter plot that represents random
    data that you fabricate on age versus time spent watching TV, and you can make
    anything you want, really. If you have a different fictional data set in your
    head that you like to play with, have some fun with it. Create a scatter plot
    that plots two random sets of data against each other and label your axes. Make
    it look pretty, play around with it, have fun with it. Everything you need for
    reference and for examples should be in this IPython Notebook. It's kind of a
    cheat sheet, if you will, for different things you might need to do for generating
    different kinds of graphs and different styles of graphs. I hope it proves useful.
    Now it's time to get back to the statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Covariance and correlation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, we're going to talk about covariance and correlation. Let's say I have
    two different attributes of something and I want to see if they're actually related
    to each other or not. This section will give you the mathematical tools you need
    to do so, and we'll dive into some examples and actually figure out covariance
    and correlation using Python. These are ways of measuring whether two different
    attributes are related to each other in a set of data, which can be a very useful
    thing to find out.
  prefs: []
  type: TYPE_NORMAL
- en: Defining the concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine we have a scatter plot, and each one of the data points represents a
    person that we measured, and we're plotting their age on one axis versus their
    income on another. Each one of these dots would represent a person, for example
    their x value represents their age and the y value represents their income. I'm
    totally making this up, this is fake data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d09e1804-b7c3-4f94-ad47-af0d6695da76.png)'
  prefs: []
  type: TYPE_IMG
- en: Now if I had a scatter plot that looks like the left one in the preceding image,
    you see that these values tend to lie all over the place, and this would tell
    you that there's no real correlation between age and income based on this data.
    For any given age, there can be a huge range of incomes and they tend to be clustered
    around the middle, but we're not really seeing a very clear relationship between
    these two different attributes of age and income. Now in contrast, in the scatter
    plot on the right you can see there's a very clear linear relationship between
    age and income.
  prefs: []
  type: TYPE_NORMAL
- en: So, covariance and correlation give us a means of measuring just how tight these
    things are correlated. I would expect a very low correlation or covariance for
    the data in the left scatter plot, but a very high covariance and correlation
    for the data in the right scatter plot. So that's the concept of covariance and
    correlation. It measures how much these two attributes that I'm measuring seem
    to depend on each other.
  prefs: []
  type: TYPE_NORMAL
- en: Measuring covariance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Measuring covariance mathematically is a little bit hard, but I''ll try to
    explain it. These are the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Think of the data sets for the two variables as high-dimensional vectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convert these to vectors of variances from the mean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take the dot product (cosine of the angle between them) of the two vectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Divide by the sample size
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's really more important that you understand how to use it and what it means.
    To actually derive it, think of the attributes of the data as high dimensional
    vectors. What we're going to do on each attribute for each data point is compute
    the variance from the mean at each point. So now I have these high dimensional
    vectors where each data point, each person, if you will, corresponds to a different
    dimension.
  prefs: []
  type: TYPE_NORMAL
- en: I have one vector in this high dimensional space that represents all the variances
    from the mean for, let's say, age for one attribute. Then I have another vector
    that represents all the variances from the mean for some other attribute, like
    income. What I do then is I take these vectors that measure the variances from
    the mean for each attribute, and I take the dot product between the two. Mathematically,
    that's a way of measuring the angle between these high dimensional vectors. So
    if they end up being very close to each other, that tells me that these variances
    are pretty much moving in lockstep with each other across these different attributes.
    If I take that final dot product and divide it by the sample size, that's how
    I end up with the covariance amount.
  prefs: []
  type: TYPE_NORMAL
- en: Now you're never going to have to actually compute this yourself the hard way.
    We'll see how to do this the easy way in Python, but conceptually, that's how
    it works.
  prefs: []
  type: TYPE_NORMAL
- en: Now the problem with covariance is that it can be hard to interpret. If I have
    a covariance that's close to zero, well, I know that's telling me there's not
    much correlation between these variables at all, but a large covariance implies
    there is a relationship. But how large is large? Depending on the units I'm using,
    there might be very different ways of interpreting that data. That's a problem
    that correlation solves.
  prefs: []
  type: TYPE_NORMAL
- en: Correlation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Correlation normalizes everything by the standard deviation of each attribute
    (just divide the covariance by the standard deviations of both variables and that
    normalizes things). By doing so, I can say very clearly that a correlation of
    -1 means there's a perfect inverse correlation, so as one value increases, the
    other decreases, and vice versa. A correlation of 0 means there's no correlation
    at all between these two sets of attributes. A correlation of 1 would imply perfect
    correlation, where these two attributes are moving in exactly the same way as
    you look at different data points.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, correlation does not imply causation. Just because you find a very
    high correlation value does not mean that one of these attributes causes the other.
    It just means there's a relationship between the two, and that relationship could
    be caused by something completely different. The only way to really determine
    causation is through a controlled experiment, which we'll talk about more later.
  prefs: []
  type: TYPE_NORMAL
- en: Computing covariance and correlation in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alright, let's get our hands dirty with covariance and correlation here with
    some actual Python code. So again, you can think conceptually of covariance as
    taking these multi-dimensional vectors of variances from the mean for each attribute
    and computing the angle between them as a measure of the covariance. The math
    for doing that is a lot simpler than it sounds. We're talking about high dimensional
    vectors. It sounds like Stephen Hawking stuff, but really, from a mathematical
    standpoint it's pretty straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: Computing correlation – The hard way
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I''m going to start by doing this the hard way. NumPy does have a method to
    just compute the covariance for you, and we''ll talk about that later, but for
    now I want to show that you can actually do this from first principles:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Covariance, again, is defined as the dot product, which is a measure of the
    angle between two vectors, of a vector of the deviations from the mean for a given
    set of data and the deviations from the mean for another given set of data for
    the same data's data points. We then divide that by n - 1 in this case, because
    we're actually dealing with a sample.
  prefs: []
  type: TYPE_NORMAL
- en: So `de_mean()`, our deviation from the mean function is taking in a set of data,
    `x`, actually a list, and it's computing the mean of that set of data. The `return`
    line contains a little bit of Python trickery for you. The syntax is saying, I'm
    going to create a new list, and go through every element in `x`, call it `xi`,
    and then return the difference between `xi` and the mean, `xmean`, for that entire
    dataset. This function returns a new list of data that represents the deviations
    from the mean for each data point.
  prefs: []
  type: TYPE_NORMAL
- en: My `covariance()` function will do that for both sets of data coming in, divided
    by the number of data points minus 1\. Remember that thing about sample versus
    population in the previous chapter? Well, that's coming into play here. Then we
    can just use those functions and see what happens.
  prefs: []
  type: TYPE_NORMAL
- en: To expand this example, I'm going to fabricate some data that is going to try
    to find a relationship between page speeds, that, is how quickly a page renders
    on a website, and how much people spend. For example, at Amazon we were very concerned
    about the relationship between how quickly pages render and how much money people
    spend after that experience. We wanted to know if there is an actual relationship
    between how fast the website is and how much money people actually spend on the
    website. This is one way you might go about figuring that out. Let's just generate
    some normally distributed random data for both page speeds and purchase amounts,
    and since it's random, there's not going to be a real correlation between them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'So just as a sanity check here we''ll start off by scatter plotting this stuff:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e91f9ab7-f787-4d99-a8bd-20be4560b14b.png)'
  prefs: []
  type: TYPE_IMG
- en: You'll see that it tends to cluster around the middle because of the normal
    distribution on each attribute, but there's no real relationship between the two.
    For any given page speed is a wide variety of amount spent, and for any given
    amount spent there's a wide variety of page speeds, so no real correlation there
    except for ones that are coming out the randomness or through the nature of the
    normal distribution. Sure enough, if we compute the covariance in these two sets
    of attributes, we end up with a very small value, -0.07\. So that's a very small
    covariance value, close to zero. That implies there's no real relationship between
    these two things.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's make life a little bit more interesting. Let's actually make the purchase
    amount a real function of page speed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we are keeping things a little bit random, but we are creating a real
    relationship between these two sets of values. For a given user, there''s a real
    relationship between the page speeds they encounter and the amount that they spend.
    If we plot that out, we can see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a59c51cf-ff2b-457e-bf18-2bb1340e9fa4.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that there's actually this little curve where things tend to be
    tightly aligned. Things get a little bit wonky near the bottom, just because of
    how random things work out. If we compute the covariance, we end up with a much
    larger value, -8, and it's the magnitude of that number that matters. The sign,
    positive or negative, just implies a positive or negative correlation, but that
    value of 8 says that's a much higher value than zero. So there's something going
    on there, but again it's hard to interpret what 8 actually means.
  prefs: []
  type: TYPE_NORMAL
- en: 'That''s where the correlation comes in, where we normalize everything by the
    standard deviations as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, doing that from first principles, we can take the correlation between
    two sets of attributes, compute the standard deviation of each, then compute the
    covariance between these two things, and divide by the standard deviations of
    each dataset. That gives us the correlation value, which is normalized to -1 to
    1\. We end up with a value of -0.4, which tells us there is some correlation between
    these two things in the negative direction:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/68d23ab2-f88b-4e59-9a50-ca99032fe2da.png)'
  prefs: []
  type: TYPE_IMG
- en: It's not a perfect line, that would be -1, but there's something interesting
    going on there.
  prefs: []
  type: TYPE_NORMAL
- en: A -1 correlation coefficient means perfect negative correlation, 0 means no
    correlation, and 1 means perfect positive correlation.
  prefs: []
  type: TYPE_NORMAL
- en: Computing correlation – The NumPy way
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, NumPy can actually compute correlation for you using the `corrcoef()`
    function. Let''s look at the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'This single line gives the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'So, if we wanted to do this the easy way, we could just use `np.corrcoef(pageSpeeds,
    purchaseAmount)`, and what that gives you back is an array that gives you the
    correlation between every possible combination of the sets of data that you pass
    in. The way to read the output is: the 1 implies there is a perfect correlation
    between comparing `pageSpeeds` to itself and `purchaseAmount` to itself, which
    is expected. But when you start comparing `pageSpeeds` to `purchaseAmount` or
    `purchaseAmount` to the `pageSpeeds`, you end up with the -0.4672 value, which
    is roughly what we got when we did it the hard way. There''s going to be little
    precision errors, but it''s not really important.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we could force a perfect correlation by fabricating a totally linear relationship,
    so let''s take a look at an example of that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'And again, here we would expect the correlation to come out to -1 for a perfect
    negative correlation, and in fact, that''s what we end up with:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b671a29a-545d-4ae6-9a91-6f3c80106b6f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Again, a reminder: Correlation does not imply causality. Just because people
    might spend more if they have faster page speeds, maybe that just means that they
    can afford a better Internet connection. Maybe that doesn''t mean that there''s
    actually a causation between how fast your pages render and how much people spend,
    but it tells you there''s an interesting relationship that''s worth investigating
    more. You cannot say anything about causality without running an experiment, but
    correlation can tell you what experiments you might want to run.'
  prefs: []
  type: TYPE_NORMAL
- en: Correlation activity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So get your hands dirty, roll up your sleeves, I want you to use the `numpy.cov()`
    function. That's actually a way to get NumPy to compute covariance for you. We
    saw how to compute correlation using the `corrcoef()` function. So go back and
    rerun these examples just using the `numpy.cov()` function and see if you get
    the same results or not. It should be pretty darn close, so instead of doing it
    the hard way with the covariance function that I wrote from scratch, just use
    NumPy and see if you can get the same results. Again, the point of this exercise
    is to get you familiar with using NumPy and applying it to actual data. So have
    at it, see where you get.
  prefs: []
  type: TYPE_NORMAL
- en: And there you have it, covariance and correlation both in theory and in practice.
    A very useful technique to have, so definitely remember this section. Let's move
    on.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, we're going to talk about conditional probability. It's a very simple
    concept. It's trying to figure out the probability of something happening given
    that something else occurred. Although it sounds simple, it can be actually very
    difficult to wrap your head around some of the nuances of it. So get an extra
    cup of coffee, make sure your thinking cap's on, and if you're ready for some
    more challenging concepts here. Let's do this.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional probability is a way to measure the relationship between two things
    happening to each other. Let's say I want to find the probability of an event
    happening given that another event already happened. Conditional probability gives
    you the tools to figure that out.
  prefs: []
  type: TYPE_NORMAL
- en: What I'm trying to find out with conditional probability is if I have two events
    that depend on each other. That is, what's the probability that both will occur?
  prefs: []
  type: TYPE_NORMAL
- en: In mathematical notation, the way we indicate things here is that *P(A,B)* represents
    the probability of both A and B occurring independent of each other. That is,
    what's the probability of both of these things happening irrespective of everything
    else.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whereas this notation, *P(B|A)*, is read as the probability of B given A. So,
    what is the probability of B given that event A has already occurred? It''s a
    little bit different, and these things are related like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/37e81c3a-f563-41db-b0ec-13cdf30b6947.png)'
  prefs: []
  type: TYPE_IMG
- en: The probability of B given A is equal to the probability of A and B occurring
    over the probability of A alone occurring, so this teases out the probability
    of B being dependent on the probability of A.
  prefs: []
  type: TYPE_NORMAL
- en: It'll make more sense with an example here, so bear with me.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say that I give you, my readers, two tests, and 60% of you pass both tests.
    Now the first test was easier, 80% of you passed that one. I can use this information
    to figure out what percentage of readers who passed the first test also passed
    the second. So here's a real example of the difference between the probability
    of B given A and the probability of A and B.
  prefs: []
  type: TYPE_NORMAL
- en: I'm going to represent A as the probability of passing the first test, and B
    as the probability of passing the second test. What I'm looking for is the probability
    of passing the second test given that you passed the first, that is, *P (B|A)*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e4de6cdd-edda-437a-8e02-a49b596bf779.png)'
  prefs: []
  type: TYPE_IMG
- en: So the probability of passing the second test given that you passed the first
    is equal to the probability of passing both tests, *P(A,B)* (I know that 60% of
    you passed both tests irrespective of each other), divided by the probability
    of passing the first test, *P(A)*, which is 80%. It's worked out to 60% passed
    both tests, 80% passed the first test, therefore the probability of passing the
    second given that you passed the first works out to 75%.
  prefs: []
  type: TYPE_NORMAL
- en: OK, it's a little bit tough to wrap your head around this concept. It took me
    a little while to really internalize the difference between the probability of
    something given something and the probability of two things happening irrespective
    of each other. Make sure you internalize this example and how it's really working
    before you move on.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional probability exercises in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Alright, let's move on and do another more complicated example using some real
    Python code. We can then see how we might actually implement these ideas using
    Python.
  prefs: []
  type: TYPE_NORMAL
- en: Let's put conditional probability into action here and use some of the ideas
    to figure out if there's a relationship between age and buying stuff using some
    fabricated data. Go ahead and open up the `ConditionalProbabilityExercise.ipynb`
    here and follow along with me if you like.
  prefs: []
  type: TYPE_NORMAL
- en: 'What I''m going to do is write a little bit of Python code that creates some
    fake data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: What I'm going to do is take 100,000 virtual people and randomly assign them
    to an age bracket. They can be in their 20s, their 30s, their 40s, their 50s,
    their 60s, or their 70s. I'm also going to assign them a number of things that
    they bought during some period of time, and I'm going to weight the probability
    of purchasing something based on their age.
  prefs: []
  type: TYPE_NORMAL
- en: 'What this code ends up doing is randomly assigning each person to an age group
    using the `random.choice()` function from NumPy. Then I''m going to assign a probability
    of purchasing something, and I have weighted it such that younger people are less
    likely to buy stuff than older people. I''m going to go through 100,000 people
    and add everything up as I go, and what I end up with are two Python dictionaries:
    one that gives me the total number of people in each age group, and another that
    gives me the total number of things bought within each age group. I''m also going
    to keep track of the total number of things bought overall. Let''s go ahead and
    run that code.'
  prefs: []
  type: TYPE_NORMAL
- en: If you want to take a second to kind of work through that code in your head
    and figure out how it works, you've got the IPython Notebook. You can go back
    into that later too. Let's take a look what we ended up with.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb97b2f4-ffbe-47d4-b107-2562141edf4b.png)'
  prefs: []
  type: TYPE_IMG
- en: Our `totals` dictionary is telling us how many people are in each age bracket,
    and it's pretty evenly distributed, just like we expected. The amount purchased
    by each age group is in fact increasing by age, so 20-year-olds only bought about
    3,000 things and 70-year-olds bought about 11,000 things, and overall the entire
    population bought about 45,000 things.
  prefs: []
  type: TYPE_NORMAL
- en: Let's use this data to play around with the ideas of conditional probability.
    Let's first figure out what's the probability of buying something given that you're
    in your 30s. The notation for that will be *P(E|F)* if we're calling purchase
    E, and F as the event that you're in your 30s.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have this fancy equation that gave you a way of computing *P(E|F)* given
    *P(E,F)*, and *P(E)*, but we don't need that. You don't just blindly apply equations
    whenever you see something. You have to think about your data intuitively. What
    is it telling us? I want to figure out the probability of purchasing something
    given that you're in your 30s. Well I have all the data I need to compute that
    directly.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'I have how much stuff 30-year-olds purchased in the purchases[30] bucket, and
    I know how many 30-year-olds there are. So I can just divide those two numbers
    to get the ratio of 30-year-old purchases over the number of 30-year-olds. I can
    then output that using the print command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'I end up with a probability of purchasing something given that you''re in your
    30s of being about 30%:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that if you''re using Python 2, the print command doesn''t have the surrounding
    brackets, so it would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'If I want to find *P(F)*, that''s just the probability of being 30 overall,
    I can take the total number of 30-year-olds divided by the number of people in
    my dataset, which is 100,000:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, remove those brackets around the print statement if you''re using Python
    2\. That should give the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: I know the probability of being in your `30s` is about 16%.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll now find out *P(E)*, which just represents the overall probability of
    buying something irrespective of your age:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: That works out to be, in this example, about 45%. I can just take the total
    number of things purchased by everybody regardless of age and divide it by the
    total number of people to get the overall probability of purchase.
  prefs: []
  type: TYPE_NORMAL
- en: Alright, so what do I have here? I have the probability of purchasing something
    given that you're in your 30s being about 30%, and then I have the probability
    of purchasing something overall at about 45%.
  prefs: []
  type: TYPE_NORMAL
- en: Now if E and F were independent, if age didn't matter, then I would expect the
    *P(E|F)* to be about the same as *P(E)*. I would expect the probability of buying
    something given that you're in your 30s to be about the same as the overall probability
    of buying something, but they're not, right? And because they're different, that
    tells me that they are in fact dependent, somehow. So that's a little way of using
    conditional probability to tease out these dependencies in the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do some more notation stuff here. If you see something like *P(E)P(F)*
    together, that means multiply these probabilities together. I can just take the
    overall probability of purchase multiplied by the overall probability of being
    in your `30s`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: That worked out to about 7.5%.
  prefs: []
  type: TYPE_NORMAL
- en: Just from the way probabilities work, I know that if I want to get the probability
    of two things happening together, that would be the same thing as multiplying
    their individual probabilities. So it turns out that *P(E,F)* happening, is the
    same thing as *P(E)P(F)*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Now because of the random distribution of data, it doesn't work out to be exactly
    the same thing. We're talking about probabilities here, remember, but they're
    in the same ballpark, so that makes sense, about 5% versus 7%, close enough.
  prefs: []
  type: TYPE_NORMAL
- en: Now that is different again from *P(E|F)*, so the probability of both being
    in your `30s` and buying something is different than the probability of buying
    something given that you're in your `30s`.
  prefs: []
  type: TYPE_NORMAL
- en: Now let's just do a little sanity check here. We can check our equation that
    we saw in the Conditional Probability section earlier, that said that the probability
    of buying something given that you're in your `30s` is the same as the probability
    of being in your `30s` and buying something over the probability of buying something.
    That is, we check if *P(E|F)=P(E,F)/P(F)*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Sure enough, it does work out. If I take the probability of buying something
    given that you're in your `30s` over the overall probability, we end up with about
    30%, which is pretty much what we came up with originally for *P(E|F)*. So the
    equation works, yay!
  prefs: []
  type: TYPE_NORMAL
- en: Alright, it's tough to wrap your head around some of this stuff. It's a little
    bit confusing, I know, but if you need to, go through this again, study it, and
    make sure you understand what's going on here. I've tried to put in enough examples
    here to illustrate different combinations of thinking about this stuff. Once you've
    got it internalized, I'm going to challenge you to actually do a little bit of
    work yourself here.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional probability assignment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What I want you to do is modify the following Python code which was used in
    the preceding section.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Modify it to actually not have a dependency between purchases and age. Make
    that an evenly distributed chance as well. See what that does to your results.
    Do you end up with a very different conditional probability of being in your `30s`
    and purchasing something versus the overall probability of purchasing something?
    What does that tell you about your data and the relationship between those two
    different attributes? Go ahead and try that, and make sure you can actually get
    some results from this data and understand what's going on, and I'll run through
    my own solution to that exercise in just a minute.
  prefs: []
  type: TYPE_NORMAL
- en: So that's conditional probability, both in theory and in practice. You can see
    there's a lot of little nuances to it and a lot of confusing notation. Go back
    and go through this section again if you need to wrap your head around it. I gave
    you a homework assignment, so go off and do that now, see if you can actually
    modify my code in that IPython Notebook to produce a constant probability of purchase
    for those different age groups. Come back and we'll take a look at how I solved
    that problem and what my results were.
  prefs: []
  type: TYPE_NORMAL
- en: My assignment solution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Did you do your homework? I hope so. Let's take a look at my solution to the
    problem of seeing how conditional probability tells us about whether there's a
    relationship between age and purchase probability in a fake dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'To remind you, what we were trying to do was remove the dependency between
    age and probability of purchasing and see if we could actually reflect that in
    our conditional probability values. Here''s what I''ve got:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: What I've done here is I've taken the original snippet of code for creating
    our dictionary of age groups and how much was purchased by each age group for
    a set of 100,000 random people. Instead of making purchase probability dependent
    on age, I've made it a constant probability of 40%. Now we just have people randomly
    being assigned to an age group, and they all have the same probability of buying
    something. Let's go ahead and run that.
  prefs: []
  type: TYPE_NORMAL
- en: Now this time, if I compute the *P(E|F)*, that is, the probability of buying
    something given that you're in your `30s`, I come up with about 40%.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: If I compare that to the overall probability of purchasing, that too is about
    40%.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: I can see here that the probability of purchasing something given that you're
    in your `30s` is about the same as the probability of purchasing something irrespective
    of your age (that is, *P(E|F)* is pretty close to *P(E)*). That suggests that
    there's no real relationship between those two things, and in fact, I know there
    isn't from this data.
  prefs: []
  type: TYPE_NORMAL
- en: Now in practice, you could just be seeing random chance, so you'd want to look
    at more than one age group. You'd want to look at more than one data point to
    see if there really is a relationship or not, but this is an indication that there's
    no relationship between age and probability of purchase in this sample data that
    we modified.
  prefs: []
  type: TYPE_NORMAL
- en: So, that's conditional probability in action. Hopefully your solution was fairly
    close and had similar results. If not, go back and study my solution. It's right
    there in the data files for this book, ConditionalProbabilitySolution.ipynb, if
    you need to open it up and study it and play around with it. Obviously, the random
    nature of the data will make your results a little bit different and will depend
    on what choice you made for the overall purchase probability, but that's the idea.
  prefs: []
  type: TYPE_NORMAL
- en: And with that behind us, let's move on to Bayes' theorem.
  prefs: []
  type: TYPE_NORMAL
- en: Bayes' theorem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you understand conditional probability, you can understand how to apply
    Bayes' theorem, which is based on conditional probability. It's a very important
    concept, especially if you're going into the medical field, but it is broadly
    applicable too, and you'll see why in a minute.
  prefs: []
  type: TYPE_NORMAL
- en: You'll hear about this a lot, but not many people really understand what it
    means or its significance. It can tell you very quantitatively sometimes when
    people are misleading you with statistics, so let's see how that works.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s talk about Bayes'' theorem at a high level. Bayes'' theorem is
    simply this: the probability of A given B is equal to the probability of A times
    the probability of B given A over the probability of B. So you can substitute
    A and B with whatever you want.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/46d5e844-cd07-49ac-98ce-04f0cb662906.png)'
  prefs: []
  type: TYPE_IMG
- en: The key insight is that the probability of something that depends on B depends
    very much on the base probability of B and A. People ignore this all the time.
  prefs: []
  type: TYPE_NORMAL
- en: One common example is drug testing. We might say, what's the probability of
    being an actual user of a drug given that you tested positive for it. The reason
    Bayes' theorem is important is that it calls out that this very much depends on
    both the probability of A and the probability of B. The probability of being a
    drug user given that you tested positive depends very much on the base overall
    probability of being a drug user and the overall probability of testing positive.
    The probability of a drug test being accurate depends a lot on the overall probability
    of being a drug user in the population, not just the accuracy of the test.
  prefs: []
  type: TYPE_NORMAL
- en: It also means that the probability of B given A is not the same thing as the
    probability of A given B. That is, the probability of being a drug user given
    that you tested positive can be very different from the probability of testing
    positive given that you're a drug user. You can see where this is going. That
    is a very real problem where diagnostic tests in medicine or drug tests yield
    a lot of false positives. You can still say that the probability of a test detecting
    a user can be very high, but it doesn't necessarily mean that the probability
    of being a user given that you tested positive is high. Those are two different
    things, and Bayes' theorem allows you to quantify that difference.
  prefs: []
  type: TYPE_NORMAL
- en: Let's nail that example home a little bit more.
  prefs: []
  type: TYPE_NORMAL
- en: Again, a drug test can be a common example of applying Bayes' theorem to prove
    a point. Even a highly accurate drug test can produce more false positives than
    true positives. So in our example here, we're going to come up with a drug test
    that can accurately identify users of a drug 99% of the time and accurately has
    a negative result for 99% of non-users, but only 0.3% of the overall population
    actually uses the drug in question. So we have a very small probability of actually
    being a user of a drug. What seems like a very high accuracy of 99% isn't actually
    high enough, right?
  prefs: []
  type: TYPE_NORMAL
- en: 'We can work out the math as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Event A = is a user of the drug
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Event B = tested positively for the drug
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So let event A mean that you're a user of some drug, and event B the event that
    you tested positively for the drug using this drug test.
  prefs: []
  type: TYPE_NORMAL
- en: We need to work out the probability of testing positively overall. We can work
    that out by taking the sum of probability of testing positive if you are a user
    and the probability of testing positive if you're not a user. So, P(B) works out
    to 1.3% (0.99*0.003+0.01*0.997) in this example. So we have a probability of B,
    the probability of testing positively for the drug overall without knowing anything
    else about you.
  prefs: []
  type: TYPE_NORMAL
- en: Let's do the math and calculate the probability of being a user of the drug
    given that you tested positively.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dc189173-51c2-4167-9314-8c8d5e278215.png)'
  prefs: []
  type: TYPE_IMG
- en: So the probability of a positive test result given that you're actually a drug
    user works out as the probability of being a user of the drug overall *(P(A))*,
    which is 3% (you know that 3% of the population is a drug user) multiplied by
    *P(B|A)* that is the probability of testing positively given that you're a user
    divided by the probability of testing positively overall which is 1.3%. Again,
    this test has what sounds like a very high accuracy of 99%. We have 0.3% of the
    population which uses a drug multiplied by the accuracy of 99% divided by the
    probability of testing positively overall, which is 1.3%. So the probability of
    being an actual user of this drug given that you tested positive for it is only
    22.8%. So even though this drug test is accurate 99% of the time, it's still providing
    a false result in most of the cases where you're testing positive.
  prefs: []
  type: TYPE_NORMAL
- en: Even though *P(B|A)* is high (99%), it doesn't mean *P(A|B)* is high.
  prefs: []
  type: TYPE_NORMAL
- en: People overlook this all the time, so if there's one lesson to be learned from
    Bayes' theorem, it is to always take these sorts of things with a grain of salt.
    Apply Bayes' theorem to these actual problems and you'll often find that what
    sounds like a high accuracy rate can actually be yielding very misleading results
    if you're dealing with a low overall incidence of a given problem. We see the
    same thing in cancer screening and other sorts of medical screening as well. That's
    a very real problem; there's a lot of people getting very, very real and very
    unnecessary surgery as a result of not understanding Bayes' theorem. If you're
    going into the medical profession with big data, please, please, please remember
    this theorem.
  prefs: []
  type: TYPE_NORMAL
- en: So that's Bayes' theorem. Always remember that the probability of something
    given something else is not the same thing as the other way around, and it actually
    depends a lot on the base probabilities of both of those two things that you're
    measuring. It's a very important thing to keep in mind, and always look at your
    results with that in mind. Bayes' theorem gives you the tools to quantify that
    effect. I hope it proves useful.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we talked about plotting and graphing your data and how to
    make your graphs look pretty using the `matplotlib` library in Python. We also
    walked through the concepts of covariance and correlation. We looked at some examples
    and figured out covariance and correlation using Python. We analyzed the concept
    of conditional probability and saw some examples to understand it better. Finally,
    we saw Bayes' theorem and its importance, especially in the medical field.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we'll talk about predictive models.
  prefs: []
  type: TYPE_NORMAL
