- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Memory Management
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存管理
- en: After reading the previous chapters, it should no longer come as a surprise
    that the way we handle memory can have a huge impact on performance. The CPU spends
    a lot of time shuffling data between the CPU registers and the main memory (loading
    and storing data to and from the main memory). As shown in *Chapter 4*, *Data
    Structures*, the CPU uses memory caches to speed up access to memory, and programs
    need to be cache-friendly in order to run quickly.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读了前面的章节之后，应该不会再感到惊讶，我们处理内存的方式对性能有很大影响。CPU花费大量时间在CPU寄存器和主内存之间传输数据（加载和存储数据到主内存和从主内存中读取数据）。正如在*第4章*，*数据结构*中所示，CPU使用内存缓存来加速对内存的访问，程序需要对缓存友好才能运行得快。
- en: 'This chapter will reveal more aspects of how computers work with memory so
    that you know which things must be considered when tuning memory usage. In addition,
    this chapter covers:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将揭示更多关于计算机如何处理内存的方面，以便您知道在调整内存使用时必须考虑哪些事项。此外，本章还涵盖了：
- en: Automatic memory allocation and dynamic memory management.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动内存分配和动态内存管理。
- en: The life cycle of a C++ object and how to manage object ownership.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C++对象的生命周期以及如何管理对象所有权。
- en: Efficient memory management. Sometimes, there are hard memory limits that force
    us to keep our data representation compact, and sometimes, we have plenty of memory
    available but need the program to go faster by making memory management more efficient.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高效的内存管理。有时，存在严格的内存限制，迫使我们保持数据表示紧凑，有时我们有大量的可用内存，但需要通过使内存管理更高效来加快程序运行速度。
- en: How to minimize dynamic memory allocations. Allocating and deallocating dynamic
    memory is relatively expensive and, at times, we need to avoid unnecessary allocations
    to make the program run faster.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何最小化动态内存分配。分配和释放动态内存相对昂贵，有时我们需要避免不必要的分配以使程序运行更快。
- en: We will start this chapter by explaining some concepts that you need to understand
    before we dig deeper into C++ memory management. This introduction will explain
    virtual memory and virtual address spaces, stack memory versus heap memory, paging,
    and swap space.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从解释一些概念开始这一章，这些概念在我们深入研究C++内存管理之前需要理解。这个介绍将解释虚拟内存和虚拟地址空间，堆内存与栈内存，分页和交换空间。
- en: Computer memory
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机内存
- en: The physical memory of a computer is shared among all the processes running
    on a system. If one process uses a lot of memory, the other processes will most
    likely be affected. But from a programmer's perspective, we usually don't have
    to bother about the memory that is being used by other processes. This isolation
    of memory is due to the fact that most operating systems today are **virtual memory**
    operating systems, which provide the illusion that a process has all the memory
    for itself. Each process has its own **virtual address space**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机的物理内存是所有运行在系统上的进程共享的。如果一个进程使用了大量内存，其他进程很可能会受到影响。但从程序员的角度来看，我们通常不必担心其他进程正在使用的内存。这种内存的隔离是因为今天的大多数操作系统都是**虚拟内存**操作系统，它们提供了一个假象，即一个进程拥有了所有的内存。每个进程都有自己的**虚拟地址空间**。
- en: The virtual address space
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 虚拟地址空间
- en: Addresses in the virtual address space that programmers see are mapped to physical
    addresses by the operating system and the **memory management unit** (**MMU**),
    which is a part of the processor. This mapping or translation happens each time
    we access a memory address.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 程序员看到的虚拟地址空间中的地址由操作系统和处理器的**内存管理单元**（**MMU**）映射到物理地址。每次访问内存地址时都会发生这种映射或转换。
- en: This extra layer of indirection makes it possible for the operating system to
    use physical memory for the parts of a process that are currently being used,
    and back up the rest of the virtual memory on disk. In this sense, we can look
    at the physical main memory as a cache for the virtual memory space, which resides
    on secondary storage. The areas of the secondary storage that are used for backing
    up memory pages are usually called **swap space**, **swap file**, or simply **pagefile**,
    depending on the operating system.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这种额外的间接层使操作系统能够使用物理内存来存储进程当前正在使用的部分，并将其余的虚拟内存备份到磁盘上。在这个意义上，我们可以把物理主内存看作是虚拟内存空间的缓存，而虚拟内存空间位于辅助存储上。通常用于备份内存页面的辅助存储区域通常称为**交换空间**、**交换文件**或简单地称为**页面文件**，具体取决于操作系统。
- en: Virtual memory makes it possible for processes to have a virtual address space
    bigger than the physical address space, since virtual memory that is not in use
    does not have to occupy physical memory.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟内存使进程能够拥有比物理地址空间更大的虚拟地址空间，因为未使用的虚拟内存不需要占用物理内存。
- en: Memory pages
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存页面
- en: The most common way to implement virtual memory today is to divide the address
    space into fixed-size blocks called **memory pages**. When a process accesses
    memory at a virtual address, the operating system checks whether the memory page
    is backed by physical memory (a page frame). If the memory page is not mapped
    in the main memory, a hardware exception occurs, and the page is loaded from disk
    into memory. This type of hardware exception is called a **page fault**. This
    is not an error but a necessary interrupt in order to load data from disk to memory.
    As you may have guessed, though, this is very slow compared to reading data that
    is already resident in memory.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 实现虚拟内存的最常见方式是将地址空间划分为称为**内存页面**的固定大小块。当一个进程访问虚拟地址处的内存时，操作系统会检查内存页面是否由物理内存（页面帧）支持。如果内存页面没有映射到主内存中，将会发生硬件异常，并且页面将从磁盘加载到内存中。这种硬件异常称为**页面错误**。这不是错误，而是为了从磁盘加载数据到内存而必要的中断。不过，正如你可能已经猜到的那样，这与读取已经驻留在内存中的数据相比非常慢。
- en: When there are no more available page frames in the main memory, a page frame
    has to be evicted. If the page to be evicted is dirty, that is, it has been modified
    since it was last loaded from disk, it needs to be written to disk before it can
    be replaced. This mechanism is called **paging**. If the memory page has not been
    modified, the memory page is simply evicted.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Not all operating systems that support virtual memory support paging. iOS, for
    example, does have virtual memory but dirty pages are never stored on disk; only
    clean pages can be evicted from memory. If the main memory is full, iOS will start
    terminating processes until there is enough free memory again. Android uses a
    similar strategy. One reason for not writing memory pages back to the flash storage
    of the mobile devices is that it drains the battery, and it also shortens the
    lifespan of the flash storage itself.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows two running processes. They both have their own
    virtual memory space. Some of the pages are mapped to the physical memory, while
    some are not. If process 1 needs to use memory in the memory page that starts
    at address 0x1000, a page fault will occur. The memory page will then be mapped
    to a vacant memory frame. Also, note that the virtual memory addresses are not
    the same as the physical addresses. The first memory page of process 1, which
    starts at the virtual address 0x0000, is mapped to a memory frame that starts
    at the physical address 0x4000:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15619_07_01.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.1: Virtual memory pages, mapped to memory frames in physical memory.
    Virtual memory pages that are not in use do not have to occupy physical memory.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Thrashing
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Thrashing** can happen when a system runs low on physical memory and is,
    therefore, constantly paging. Whenever a process gets time scheduled on the CPU,
    it tries to access memory that has been paged out. Loading new memory pages means
    that the other pages first have to be stored on disk. Moving data back and forth
    between disk and memory is usually very slow; in some cases, this more or less
    stalls the computer since the system spends all its time paging. Looking at the
    system''s page fault frequency is a good way to determine whether the program
    has started thrashing.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Knowing the basics of how memory is being handled by the hardware and the OS
    is important when optimizing performance. Next, we will see how memory is handled
    during the execution of a C++ program.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Process memory
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The stack and the heap are the two most important memory segments in a C++ program.
    There is also static storage and thread local storage, but we will talk more about
    that later. Actually, to be formally correct, C++ doesn't talk about stack and
    heap; instead, it talks about the free store, storage classes, and the storage
    duration of objects. However, since the concepts of stack and heap are widely
    used in the C++ community, and all the implementations of C++ that we are aware
    of use a stack to implement function calls and manage the automatic storage of
    local variables, it is important to understand what stack and heap are.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: In this book, I will also use the terms *stack* and *heap* rather than the storage
    duration of objects. I will use the terms *heap* and *free store* interchangeably
    and will not make any distinction between them.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: 'Both the stack and the heap reside in the process'' virtual memory space. The
    stack is a place where all the local variables reside; this also includes arguments
    to functions. The stack grows each time a function is called and contracts when
    a function returns. Each thread has its own stack and, hence, stack memory can
    be considered thread-safe. The heap, on the other hand, is a global memory area
    that is shared among all the threads in a running process. The heap grows when
    we allocate memory with `new` (or the C library functions `malloc()` and `calloc()`)
    and contracts when we free the memory with `delete` (or `free()`). Usually, the
    heap starts at a low address and grows in an upward direction, whereas the stack
    starts at a high address and grows in a downward direction. *Figure 7.2* shows
    how the stack and heap grow in opposite directions in a virtual address space:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15619_07_02.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.2: An address space of a process. The stack and the heap grow in opposite
    directions.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: The next sections will provide more details about the stack and the heap, and
    also explain when we are using each of these memory areas in the C++ programs
    we write.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Stack memory
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The stack differs in many ways compared to the heap. Here are some of the unique
    properties of the stack:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: The stack is a contiguous memory block.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It has a fixed maximum size. If a program exceeds the maximum stack size, the
    program will crash. This condition is called stack overflow.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The stack memory never becomes fragmented.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allocating memory from the stack is (almost) always fast. Page faults are possible
    but rare.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each thread in a program has its own stack.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code examples that follow in this section will examine some of these properties.
    Let's start with allocations and deallocations to get a feel for how the stack
    is used in a program.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: 'We can easily find out in which direction the stack grows by inspecting the
    address of the stack-allocated data. The following example code demonstrates how
    the stack grows and contracts when entering and leaving functions:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A possible output when running the program could look like this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: By printing the address of the stack allocated integer, we can determine how
    much and in which direction the stack grows on my platform. The stack grows by
    24 bytes each time we enter either `func1()` or `func2()`. The integer `i`, which
    will be allocated on the stack, is 4 bytes long. The remaining 20 bytes contain
    data needed when the function ends, such as the return address, and perhaps some
    padding for alignment.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates how the stack grows and contracts during
    the execution of the program. The first box illustrates how the memory looks when
    the program has just entered the `main()` function. The second box shows how the
    stack has increased when we execute `func1()`, and so on:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15619_07_03.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.3: The stack grows and contracts when functions are entered'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: The total memory allocated for the stack is a fixed-size contiguous memory block
    created at thread startup. So, how big is the stack and what happens when we reach
    the limit of the stack?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, the stack grows each time the program enters a function
    and contracts when the function returns. The stack also grows whenever we create
    a new stack variable within the same function and contracts when such a variable
    goes out of scope. The most common reason for the stack to overflow is by deep
    recursive calls and/or by using large, automatic variables on the stack. The maximum
    size of the stack differs among platforms and can also be configured for individual
    processes and threads.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see if we can write a program to see how big the stack is by default
    on my system. We will begin by writing a function, `func()`, which will recurse
    infinitely. At the beginning of each function, we''ll allocate a 1-kilobyte variable,
    which will be placed onto the stack every time we enter `func()`. Every time `func()`
    is executed, we print the current size of the stack:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看是否可以编写一个程序来查看默认情况下系统的堆栈有多大。我们将首先编写一个名为`func()`的函数，该函数将无限递归。在每个函数的开始，我们将分配一个1千字节的变量，每次进入`func()`时都会将其放入堆栈。每次执行`func()`时，我们打印堆栈的当前大小：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The size of the stack is only an estimate. We compute it by subtracting the
    address of the first local variable in `main()` from the first local variable
    defined in `func()`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 堆栈的大小只是一个估计值。我们通过从`main()`中定义的第一个局部变量的地址减去`func()`中定义的第一个局部变量的地址来计算它。
- en: 'When I compiled the code with Clang, I got a warning that `func()` will never
    return. Normally, this is a warning that we should not ignore, but this time,
    this is exactly the result we want, so we ignore the warning and run the program
    anyway. The program crashes after a short while when the stack has reached its
    limit. Before the program crashes, it manages to print out thousands of lines
    with the current size of the stack. The last lines of the output look like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当我用Clang编译代码时，我收到一个警告，即`func()`永远不会返回。通常，这是一个我们不应该忽略的警告，但这次，这正是我们想要的结果，所以我们忽略了警告并运行了程序。程序在堆栈达到其限制后不久崩溃。在程序崩溃之前，它设法打印出数千行堆栈的当前大小。输出的最后几行看起来像这样：
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Since we are subtracting `std::byte` pointers, the size is in bytes, so it
    looks like the maximum size of the stack is around 8 MB on my system. On Unix-like
    systems, it is possible to set and get the stack size for processes by using the
    `ulimit` command with the option `-s`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在减去`std::byte`指针，所以大小以字节为单位，因此在我的系统上，堆栈的最大大小似乎约为8 MB。在类Unix系统上，可以使用`ulimit`命令和选项`-s`来设置和获取进程的堆栈大小：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`ulimit` (short for user limit) returns the current setting for the maximum
    stack size in kilobytes. The output of `ulimit` confirms the results from our
    experiment: the stack is about 8 MB on my Mac if I don''t configure it explicitly.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`ulimit`（用户限制的缩写）返回以千字节为单位的最大堆栈大小的当前设置。`ulimit`的输出证实了我们实验的结果：如果我没有显式配置，我的Mac上的堆栈大约为8
    MB。'
- en: On Windows, the default stack size is usually set to 1 MB. A program running
    fine on macOS might crash due to a stack overflow on Windows if the stack size
    is not correctly configured.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上，默认的堆栈大小通常设置为1 MB。如果堆栈大小没有正确配置，那么在Windows上运行良好的程序在macOS上可能会因堆栈溢出而崩溃。
- en: With this example, we can also conclude that we don't want to run out of stack
    memory since the program will crash when that happens. Later in this chapter,
    we will see how to implement a rudimentary memory allocator to handle fixed-size
    allocations. We will then understand that the stack is just another type of memory
    allocator that can be implemented very efficiently because the usage pattern is
    always sequential. We always request and release memory at the top of the stack
    (the end of the contiguous memory). This ensures that the stack memory will never
    become fragmented and that we can allocate and deallocate memory by only moving
    a stack pointer.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个例子，我们还可以得出结论，我们不希望用尽堆栈内存，因为当发生这种情况时，程序将崩溃。在本章的后面，我们将看到如何实现一个基本的内存分配器来处理固定大小的分配。然后我们将了解到，堆栈只是另一种类型的内存分配器，可以非常高效地实现，因为使用模式总是顺序的。我们总是在堆栈的顶部（连续内存的末尾）请求和释放内存。这确保了堆栈内存永远不会变得碎片化，并且我们可以通过仅移动堆栈指针来分配和释放内存。
- en: Heap memory
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 堆内存
- en: The heap (or the free store, which is a more correct term in C++) is where data
    with dynamic storage lives. As mentioned earlier, the heap is shared among multiple
    threads, which means that memory management for the heap needs to take concurrency
    into account. This makes memory allocations in the heap more complicated than
    stack allocations, which are local per thread.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 堆（或者更正确的术语是自由存储区，在C++中）是动态存储数据的地方。如前所述，堆在多个线程之间共享，这意味着堆的内存管理需要考虑并发性。这使得堆中的内存分配比堆栈分配更复杂，因为堆中的内存分配是每个线程的本地分配。
- en: The allocation and deallocation pattern for stack memory is sequential, in the
    sense that memory is always deallocated in the reverse order to that in which
    it was allocated. On the other hand, for dynamic memory, the allocations and deallocations
    can happen arbitrarily. The dynamic lifetime of objects and the variable sizes
    of memory allocations increase the risk of **fragmented memory**.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 堆栈内存的分配和释放模式是顺序的，即内存总是按照分配的相反顺序进行释放。另一方面，对于动态内存，分配和释放可以任意发生。对象的动态生命周期和内存分配的变量大小增加了**内存碎片**的风险。
- en: 'An easy way to understand the issue with memory fragmentation is to go through
    an example of how fragmented memory can occur. Suppose that we have a small contiguous
    memory block of 16 KB that we are allocating memory from. We are allocating objects
    of two types: type **A**, which is 1 KB, and type **B**, which is 2 KB. We first
    allocate an object of type **A**, followed by an object of type **B**. This repeats
    until the memory looks like the following image:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 理解内存碎片问题的简单方法是通过一个示例来说明内存如何发生碎片化。假设我们有一个小的连续内存块，大小为16 KB，我们正在从中分配内存。我们正在分配两种类型的对象：类型**A**，大小为1
    KB，和类型**B**，大小为2 KB。我们首先分配一个类型**A**的对象，然后是一个类型**B**的对象。这样重复，直到内存看起来像下面的图像：
- en: '![](img/B15619_07_04.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15619_07_04.png)'
- en: 'Figure 7.4: The memory after allocating objects of type A and B'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4：分配类型A和B对象后的内存
- en: 'Next, all objects of type **A** are no longer needed, so they can be deallocated.
    The memory now looks like this:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，所有类型**A**的对象都不再需要，因此它们可以被释放。内存现在看起来像这样：
- en: '![](img/B15619_07_05.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15619_07_05.png)'
- en: 'Figure 7.5: The memory after objects of type A are deallocated'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5：释放类型A对象后的内存
- en: There is now 10 KB of memory in use and 6 KB is available. Now, suppose we want
    to allocate a new object of type **B**, which is 2 KB. Although there is 6 KB
    of free memory, there is nowhere we can find a 2 KB memory block because the memory
    has become fragmented.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有10KB的内存正在使用，还有6KB可用。现在，假设我们想要分配一个类型为**B**的新对象，它占用2KB。尽管有6KB的空闲内存，但我们找不到2KB的内存块，因为内存已经变得碎片化。
- en: Now that you have a good understanding of how computer memory is structured
    and used in a running process, it's time to explore how C++ objects live in memory.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经对计算机内存在运行过程中的结构和使用有了很好的理解，现在是时候探索C++对象在内存中的生存方式了。
- en: Objects in memory
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存中的对象
- en: All the objects we use in a C++ program reside in memory. Here, we will explore
    how objects are created and deleted from memory, and also describe how objects
    are laid out in memory.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在C++程序中使用的所有对象都驻留在内存中。在这里，我们将探讨如何在内存中创建和删除对象，并描述对象在内存中的布局方式。
- en: Creating and deleting objects
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建和删除对象
- en: 'In this section, we will dig into the details of using `new` and `delete`.
    Consider the following way of using `new` to create an object on the free store
    and then deleting it using `delete`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入探讨使用`new`和`delete`的细节。考虑以下使用`new`在自由存储器上创建对象，然后使用`delete`删除它的方式：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'I don''t recommend that you call `new` and `delete` explicitly in this manner,
    but let''s ignore that for now. Let''s get to the point; as the comments suggest,
    `new` actually does two things, namely:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我不建议以这种方式显式调用`new`和`delete`，但现在让我们忽略这一点。让我们来重点讨论一下；正如注释所建议的那样，`new`实际上做了两件事，即：
- en: Allocates memory to hold a new object of the `User` type
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配内存以容纳`User`类型的新对象
- en: Constructs a new `User` object in the allocated memory space by calling the
    constructor of the `User` class
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过调用`User`类的构造函数在分配的内存空间中构造一个新的`User`对象
- en: 'The same thing goes with `delete`, it:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的事情也适用于`delete`，它：
- en: Destructs the `User` object by calling its destructor
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过调用其析构函数来销毁`User`对象
- en: Deallocates/frees the memory that the `User` object was placed in
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 释放`User`对象所在的内存
- en: It is actually possible to separate these two actions (memory allocation and
    object construction) in C++. This is rarely used but has some important and legitimate
    use cases when writing library components.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在C++中可以将这两个操作（内存分配和对象构造）分开。这很少使用，但在编写库组件时有一些重要和合法的用例。
- en: Placement new
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 放置new
- en: 'C++ allows us to separate memory allocation from object construction. We could,
    for example, allocate a byte array with `malloc()` and construct a new `User`
    object in that region of memory. Have a look at the following code snippet:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: C++允许我们将内存分配与对象构造分开。例如，我们可以使用`malloc()`分配一个字节数组，并在该内存区域中构造一个新的`User`对象。看一下以下代码片段：
- en: '[PRE6]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The perhaps unfamiliar syntax that's using `::new (memory)` is called **placement
    new**. It is a non-allocating form of `new`, which only constructs an object.
    The double colon (`::`) in front of `new` ensures that the resolution occurs from
    the global namespace to avoid picking up an overloaded version of `operator new`.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`::new (memory)`的可能不熟悉的语法称为**放置new**。这是`new`的一种非分配形式，它只构造一个对象。`::`前面的双冒号确保了从全局命名空间进行解析，以避免选择`operator
    new`的重载版本。
- en: In the preceding example, placement new constructs the `User` object and places
    it at the specified memory location. Since we are allocating the memory with `std::malloc()`
    for a single object, it is guaranteed to be correctly aligned (unless the class
    `User` has been declared to be overaligned). Later on, we will explore cases where
    we have to take alignment into account when using placement new.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，放置new构造了`User`对象，并将其放置在指定的内存位置。由于我们使用`std::malloc()`为单个对象分配内存，所以它保证了正确的对齐（除非`User`类已声明为过对齐）。稍后，我们将探讨在使用放置new时必须考虑对齐的情况。
- en: 'There is no placement delete, so in order to destruct the object and free the
    memory, we need to call the destructor explicitly and then free the memory:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 没有放置删除，因此为了销毁对象并释放内存，我们需要显式调用析构函数，然后释放内存：
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This is the only time you should call a destructor explicitly. Never call a
    destructor like this unless you have created an object with placement new.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这是您应该显式调用析构函数的唯一时机。除非您使用放置new创建了一个对象，否则永远不要这样调用析构函数。
- en: C++17 introduces a set of utility functions in `<memory>` for constructing and
    destroying objects without allocating or deallocating memory. So, instead of calling
    placement new, it is now possible to use some of the functions from `<memory>`
    whose names begin with `std::uninitialized_` for constructing, copying, and moving
    objects to an uninitialized memory area. And instead of calling the destructor
    explicitly, we can now use `std::destroy_at()` to destruct an object at a specific
    memory address without deallocating the memory.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: C++17在`<memory>`中引入了一组实用函数，用于在不分配或释放内存的情况下构造和销毁对象。因此，现在可以使用一些以`std::uninitialized_`开头的函数来构造、复制和移动对象到未初始化的内存区域，而不是调用放置new。而且，现在可以使用`std::destroy_at()`在特定内存地址上销毁对象，而无需释放内存。
- en: 'The previous example could be rewritten using these new functions. Here is
    how it would look:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的示例可以使用这些新函数重写。下面是它的样子：
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'C++20 also introduces `std::construct_at()`, which makes it possible to replace
    the `std::uninitialized_fill_n()` call with:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: C++20还引入了`std::construct_at()`，它使得可以用它来替换`std::uninitialized_fill_n()`的调用：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Please keep in mind that we are showing these naked low-level memory facilities
    to get a better understanding of memory management in C++. Using `reinterpret_cast`
    and the memory utilities demonstrated here should be kept to an absolute minimum
    in a C++ code base.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，我们展示这些裸露的低级内存设施是为了更好地理解C++中的内存管理。在C++代码库中，使用`reinterpret_cast`和这里演示的内存实用程序应该保持绝对最低限度。
- en: Next, you will see what operators are called when we use the `new` and `delete`
    expressions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将看到当我们使用`new`和`delete`表达式时调用了哪些操作符。
- en: The new and delete operators
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: new和delete操作符
- en: The function `operator new` is responsible for allocating memory when a new
    expression is invoked. The `new` operator can be either a globally defined function
    or a static member function of a class. It is possible to overload the global
    operators `new` and `delete`. Later in this chapter, we will see that this can
    be useful when analyzing memory usage.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `operator new` 负责在调用 `new` 表达式时分配内存。`new` 运算符可以是全局定义的函数，也可以是类的静态成员函数。可以重载全局运算符
    `new` 和 `delete`。在本章后面，我们将看到在分析内存使用情况时，这可能是有用的。
- en: 'Here is how to do it:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何做到这一点：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can verify that our overloaded operators are actually being used when creating
    and deleting a `char` object:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以验证我们重载的运算符在创建和删除 `char` 对象时是否真的被使用：
- en: '[PRE11]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'When creating and deleting an array of objects using the `new[]` and `delete[]`
    expressions, there is another pair of operators that are being used, namely `operator
    new[]` and `operator delete[]`. We can overload these operators in the same way:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `new[]` 和 `delete[]` 表达式创建和删除对象数组时，还使用了另一对运算符，即 `operator new[]` 和 `operator
    delete[]`。我们可以以相同的方式重载这些运算符：
- en: '[PRE12]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Keep in mind that if you overload `operator new`, you should also overload `operator
    delete`. Functions for allocating and deallocating memory come in pairs. Memory
    should be deallocated by the allocator that the memory was allocated by. For example,
    memory allocated with `std::malloc()` should always be freed using `std::free()`,
    while memory allocated with `operator new[]` should be deallocated using `operator
    delete[]`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，如果重载了 `operator new`，还应该重载 `operator delete`。分配和释放内存的函数是成对出现的。内存应该由分配该内存的分配器释放。例如，使用
    `std::malloc()` 分配的内存应始终使用 `std::free()` 释放，而使用 `operator new[]` 分配的内存应使用 `operator
    delete[]` 释放。
- en: It is also possible to override a class-specific `operator new` or `operator
    delete`. This is probably more useful than overloading the global operators, since
    it is more likely that we need a custom dynamic memory allocator for a specific
    class.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以覆盖特定于类的 `operator new` 或 `operator delete`。这可能比重载全局运算符更有用，因为更有可能需要为特定类使用自定义动态内存分配器。
- en: 'Here, we are overloading `operator new` and `operator delete` for the `Document`
    class:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在为 `Document` 类重载 `operator new` 和 `operator delete`：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The class-specific version of `new` will be used when we create new dynamically
    allocated `Document` objects:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建新的动态分配的 `Document` 对象时，将使用特定于类的 `new` 版本：
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If we instead want to use global `new` and `delete`, it is still possible by
    using the global scope (`::`):'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望使用全局 `new` 和 `delete`，仍然可以通过使用全局作用域 (`::`) 来实现：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We will discuss memory allocators later in this chapter and we will then see
    the overloaded `new` and `delete` operators in use.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章后面讨论内存分配器，然后我们将看到重载的 `new` 和 `delete` 运算符的使用。
- en: 'To summarize what we have seen so far, a `new` expression involves two things:
    allocation and construction. `operator new` allocates memory and you can overload
    it globally or per class to customize dynamic memory management. Placement new
    can be used to construct an object in an already allocated memory area.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，总结一下，`new`表达式涉及两个方面：分配和构造。`operator new`分配内存，您可以全局或按类重载它以自定义动态内存管理。放置 new
    可用于在已分配的内存区域中构造对象。
- en: Another important, but rather low-level, topic that we need to understand in
    order to use memory efficiently is the **alignment** of memory.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要但相当低级的主题是我们需要了解以有效使用内存的**内存对齐**。
- en: Memory alignment
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存对齐
- en: The CPU reads memory into its registers one word at a time. The word size is
    64 bits on a 64-bit architecture, 32 bits on a 32-bit architecture, and so forth.
    For the CPU to work efficiently when working with different data types, it has
    restrictions on the addresses where objects of different types are located. Every
    type in C++ has an alignment requirement that defines the addresses at which an
    object of a certain type should be located in memory.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 每次从内存中读取一个字时，将其读入寄存器。64 位架构上的字大小为 64 位，32 位架构上为 32 位，依此类推。为了使 CPU 在处理不同数据类型时能够高效工作，它对不同类型的对象所在的地址有限制。C++
    中的每种类型都有一个对齐要求，定义了内存中应该位于某种类型对象的地址。
- en: 'If the alignment of a type is 1, it means that the objects of that type can
    be located at any byte address. If the alignment of a type is 2, it means that
    the number of bytes between successive allowed addresses is 2\. Or to quote the
    C++ standard:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果类型的对齐方式为 1，则表示该类型的对象可以位于任何字节地址。如果类型的对齐方式为 2，则表示允许地址之间的字节数为 2。或者引用 C++ 标准的说法：
- en: '"An alignment is an implementation-defined integer value representing the number
    of bytes between successive addresses at which a given object can be allocated."'
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '"对齐是一个实现定义的整数值，表示给定对象可以分配的连续地址之间的字节数。"'
- en: 'We can use `alignof` to find out the alignment of a type:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `alignof` 来查找类型的对齐方式：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: When I run this code, it outputs `4`, which means that the alignment requirement
    of the type `int` is 4 bytes on my platform.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 当我运行此代码时，输出为 `4`，这意味着在我的平台上，类型 `int` 的对齐要求为 4 字节。
- en: 'The following figure shows two examples of memory from a system with 64-bit
    words. The upper row contains three 4-byte integers, which are located on addresses
    that are 4 bytes aligned. The CPU can load these integers into registers in an
    efficient way and never need to read multiple words when accessing one of the
    `int` members. Compare this with the second row, which contains two `int` members,
    which are located at unaligned addresses. The second `int` even spans over two-word
    boundaries. In the best case, this is just inefficient, but on some platforms,
    the program will crash:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示显示了来自具有 64 位字的系统的内存的两个示例。上排包含三个 4 字节整数，它们位于 4 字节对齐的地址上。CPU 可以以高效的方式将这些整数加载到寄存器中，并且在访问其中一个
    `int` 成员时永远不需要读取多个字。将其与第二排进行比较，其中包含两个 `int` 成员，它们位于不对齐的地址上。第二个 `int` 甚至跨越了两个字的边界。在最好的情况下，这只是低效，但在某些平台上，程序将崩溃：
- en: '![](img/B15619_07_06.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15619_07_06.png)'
- en: 'Figure 7.6: Two examples of memory that contain ints at aligned and unaligned
    memory addresses'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Let's say that we have a type with an alignment requirement of 2\. The C++ standard
    doesn't say whether the valid addresses are 1, 3, 5, 7... or 0, 2, 4, 6.... All
    platforms that we are aware of start counting addresses at 0, so, in practice
    we could check if an object is correctly aligned by checking if its address is
    a multiple of the alignment using the modulo operator (`%`).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if we want to write fully portable C++ code, we need to use `std::align()`
    and not modulo to check the alignment of an object. `std::align()` is a function
    from `<memory>` that will adjust a pointer according to an alignment that we pass
    as an argument. If the memory address we pass to it is already aligned, the pointer
    will not be adjusted. Therefore, we can use `std::align()` to implement a small
    utility function called `is_aligned()`, as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: At first, we make sure that the `ptr` argument isn't null and that `alignment`
    is a power of 2, which is stated as a requirement in the C++ standard. We are
    using C++20 `std::has_single_bit()` from the `<bit>` header to check this. Next,
    we are calling `std::align()`. The typical use case for `std::align()` is when
    we have a memory buffer of some size in which we want to store an object with
    some alignment requirement. In this case, we don't have a buffer, and we don't
    care about the size of the objects, so we say that the object is of size 1 and
    the buffer is the maximum value of a `std::size_t`. Then, we can compare the original
    `ptr` and the adjusted `aligned_ptr` to see if the original pointer was already
    aligned. We will have use for this utility in the examples to come.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 'When allocating memory with `new` or `std::malloc()`, the memory we get back
    should be correctly aligned for the type we specify. The following code shows
    that the memory allocated for `int` is at least 4 bytes aligned on my platform:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In fact, `new` and `malloc()` are guaranteed to always return memory suitably
    aligned for any scalar type (if it manages to return memory at all). The `<cstddef>`
    header provides us with a type called `std::max_align_t`, whose alignment requirement
    is at least as strict as all the scalar types. Later on, we will see that this
    type is useful when writing custom memory allocators. So, even if we only request
    memory for `char` on the free store, it will be aligned suitably for `std::max_align_t`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code shows that the memory returned from `new` is correctly aligned
    for `std::max_align_t` and also for any scalar type:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Let''s allocate `char` two times in a row with `new`:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then, the memory may look something like this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15619_07_07.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.7: Memory layout after two separate allocations of one char each'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: The space between `p1` and `p2` depends on the alignment requirements of `std::max_align_t`.
    On my system, it was `16` bytes and, therefore, there are 15 bytes between each
    `char` instance, even though the alignment of a `char` is only 1.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'It is possible to specify custom alignment requirements that are stricter than
    the default alignment when declaring a variable using the `alignas` specifier.
    Let''s say we have a cache line size of 64 bytes and that we, for some reason,
    want to ensure that two variables are placed on separate cache lines. We could
    do the following:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It''s also possible to specify a custom alignment when defining a type. The
    following is a struct that will occupy exactly one cache line when being used:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, if we were to create a stack variable of the type `CacheLine`, it would
    be aligned according to the custom alignment of 64 bytes:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The stricter alignment requirements are also satisfied when allocating objects
    on the heap. In order to support dynamic allocation of types with non-default
    alignment requirements, C++17 introduced new overloads of `operator new()` and
    `operator delete()` which accept an alignment argument of type `std::align_val_t`.
    There is also an `aligned_alloc()` function defined in `<cstdlib>` which can be
    used to manually allocate aligned heap memory.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在堆上分配对象时，也满足了更严格的对齐要求。为了支持具有非默认对齐要求的类型的动态分配，C++17引入了`operator new()`和`operator
    delete()`的新重载，它们接受`std::align_val_t`类型的对齐参数。在`<cstdlib>`中还定义了一个`aligned_alloc()`函数，可以用于手动分配对齐的堆内存。
- en: 'As follows is an example in which we allocate a block of heap memory that should
    occupy exactly one memory page. In this case, the alignment-aware versions of
    `operator new()` and `operator delete()` will be invoked when using `new` and
    `delete`:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例，我们在其中分配一个应该占用一个内存页面的堆内存块。在这种情况下，使用`new`和`delete`时将调用对齐感知版本的`operator
    new()`和`operator delete()`：
- en: '[PRE24]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Memory pages are not part of the C++ abstract machine, so there is no portable
    way to programmatically get hold of the page size of the currently running system.
    However, you could use `boost::mapped_region::get_page_size()` or a platform-specific
    system call, such as `getpagesize()`, on Unix systems.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 内存页面不是C++抽象机器的一部分，因此没有可移植的方法来以编程方式获取当前运行系统的页面大小。但是，您可以在Unix系统上使用`boost::mapped_region::get_page_size()`或特定于平台的系统调用，如`getpagesize()`。
- en: A final caveat to be aware of is that the supported set of alignments are defined
    by the implementation of the standard library you are using, and not the C++ standard.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要注意的最后一个警告是，支持的对齐集由您使用的标准库的实现定义，而不是C++标准。
- en: Padding
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 填充
- en: The compiler sometimes needs to add extra bytes, **padding**, to our user-defined
    types. When we define data members in a class or struct, the compiler is forced
    to place the members in the same order as we define them.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 编译器有时需要为我们定义的用户定义类型添加额外的字节，**填充**。当我们在类或结构中定义数据成员时，编译器被迫按照我们定义它们的顺序放置成员。
- en: 'However, the compiler also has to ensure that the data members inside the class
    have the correct alignment; hence, it needs to add padding between data members
    if necessary. For example, let''s assume we have a class defined as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，编译器还必须确保类内的数据成员具有正确的对齐方式；因此，如果需要，它需要在数据成员之间添加填充。例如，假设我们有一个如下所示的类：
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The reason for the possible output being 24 is that the compiler inserts padding
    after `bool` and `int`, to fulfill the alignment requirements of the individual
    data members and the entire class. The compiler converts the `Document` class
    into something like this:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 可能输出为24的原因是，编译器在`bool`和`int`之后插入填充，以满足各个数据成员和整个类的对齐要求。编译器将`Document`类转换为类似于这样的形式：
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The first padding between `bool` and `double` is 7 bytes, since the `rank_`
    data member of the `double` type has an alignment of 8 bytes. The second padding
    that is added after `int` is 4 bytes. This is needed in order to fulfill the alignment
    requirements of the `Document` class itself. The member with the largest alignment
    requirement also determines the alignment requirement for the entire data structure.
    In our example, this means that the total size of the `Document` class must be
    a multiple of 8, since it contains a `double` value that is 8-byte aligned.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`bool`和`double`之间的第一个填充为7字节，因为`double`类型的`rank_`数据成员具有8字节的对齐。在`int`之后添加的第二个填充为4字节。这是为了满足`Document`类本身的对齐要求。具有最大对齐要求的成员也决定了整个数据结构的对齐要求。在我们的示例中，这意味着`Document`类的总大小必须是8的倍数，因为它包含一个8字节对齐的`double`值。'
- en: 'We now realize that we can rearrange the order of the data members in the `Document`
    class in a way that minimizes the padding inserted by the compiler, by starting
    with types with the biggest alignment requirements. Let''s create a new version
    of the `Document` class:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在意识到，我们可以重新排列`Document`类中数据成员的顺序，以最小化编译器插入的填充，方法是从具有最大对齐要求的类型开始。让我们创建`Document`类的新版本：
- en: '[PRE27]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'With the rearrangement of the members, the compiler now only needs to pad after
    the `is_cached_` data member to adjust for the alignment of `Document`. This is
    how the class will look after padding:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 通过重新排列成员，编译器现在只需要在`is_cached_`数据成员之后填充，以调整`Document`的对齐方式。这是填充后类的样子：
- en: '[PRE28]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The size of the new `Document` class is now only 16 bytes, compared to the
    first version, which was 24 bytes. The insight here should be that the size of
    an object can change just by changing the order in which its members are declared.
    We can also verify this by using the `sizeof` operator again on our updated version
    of `Document`:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 新的`Document`类的大小现在只有16字节，而第一个版本为24字节。这里的见解应该是，对象的大小可以通过更改成员声明的顺序而改变。我们还可以通过在我们更新的`Document`版本上再次使用`sizeof`运算符来验证这一点：
- en: '[PRE29]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The following image shows the memory layout of version 1 and version 2 of the
    `Document` class:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片显示了`Document`类版本1和版本2的内存布局：
- en: '![](img/B15619_07_08.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15619_07_08.png)'
- en: 'Figure 7.8: Memory layouts of the two versions of the Document class. The size
    of an object can change just by changing the order in which its members are declared.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8：`Document`类的两个版本的内存布局。对象的大小可以通过更改成员声明的顺序而改变。
- en: As a general rule, you can place the biggest data members at the beginning and
    the smallest members at the end. In this way, you can minimize the memory overhead
    caused by padding. Later on, we will see that we need to think about alignment
    when placing objects in memory regions that we have allocated, before we know
    the alignment of the objects that we are creating.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 一般规则是，将最大的数据成员放在开头，最小的成员放在末尾。这样，您可以最小化填充引起的内存开销。稍后，我们将看到，在将对象放置在我们已分配的内存区域时，我们需要考虑对齐，然后才能知道我们正在创建的对象的对齐方式。
- en: From a performance perspective, there can also be cases where you want to align
    objects to cache lines to minimize the number of cache lines an object spans over.
    While we are on the subject of cache friendliness, it should also be mentioned
    that it can be beneficial to place multiple data members that are frequently used
    together next to each other.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Keeping your data structures compact is important for performance. Many applications
    are bound by memory access time. Another important aspect of memory management
    is to never leak or waste memory for objects that are no longer needed. We can
    effectively avoid all sorts of resource leaks by being clear and explicit about
    the ownership of resources. This is the topic of the following section.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Memory ownership
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ownership of resources is a fundamental aspect to consider when programming.
    An owner of a resource is responsible for freeing the resource when it is no longer
    needed. A resource is typically a block of memory but could also be a database
    connection, a file handle, and so on. Ownership is important, regardless of which
    programming language you are using. However, it is more apparent in languages
    such as C and C++, since dynamic memory is not garbage-collected by default. Whenever
    we allocate dynamic memory in C++, we have to think about the ownership of that
    memory. Fortunately, there is now very good support in the language for expressing
    various types of ownership by using smart pointers, which we will cover later
    in this section.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'The smart pointers from the standard library help us specify the ownership
    of dynamic variables. Other types of variables already have a defined ownership.
    For example, local variables are owned by the current scope. When the scope ends,
    the objects that have been created inside the scope will be automatically destroyed:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Static and global variables are owned by the program and will be destroyed
    when the program terminates:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Data members are owned by the instances of the class that they belong to:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'It is only dynamic variables that do not have a default owner, and it is up
    to the programmer to make sure that all the dynamically allocated variables have
    an owner to control the lifetime of the variables:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: With modern C++, we can write most of our code without explicit calls to `new`
    and `delete`, which is a great thing. Manually keeping track of calls to `new`
    and `delete` can very easily become an issue with memory leaks, double deletes,
    and other nasty bugs as a result. Raw pointers do not express any ownership, which
    makes ownership hard to track if we are only using raw pointers to refer to dynamic
    memory.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: I recommend that you make ownership clear and explicit, but do strive to minimize
    manual memory management. By following a few fairly simple rules for dealing with
    the ownership of memory, you will increase the likelihood of getting your code
    clean and correct without leaking resources. The coming sections will guide you
    through some best practices for that purpose.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Handling resources implicitly
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, make your objects implicitly handle the allocation/deallocation of dynamic
    memory:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In the preceding example, we are using both stack and dynamic memory, but we
    don't have to explicitly call `new` and `delete`. The `std::vector` object we
    create is an automatic object that will live on the stack. Since it is owned by
    the scope, it will be automatically destroyed when the function returns. The `std::vector`
    object itself uses dynamic memory to store the integer elements. When `v` goes
    out of scope, its destructor can safely free the dynamic memory. This pattern
    of letting destructors free dynamic memory makes it fairly easy to avoid memory
    leaks.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'While we are on the subject of freeing resources, I think it makes sense to
    mention RAII. **RAII** is a well-known C++ technique, short for **Resource Acquisition
    Is Initialization**, where the lifetime of a resource is controlled by the lifetime
    of an object. The pattern is simple but extremely useful for handling resources
    (memory included). But let''s say, for a change, that the resource we need is
    some sort of connection for sending requests. Whenever we are done using the connection,
    we (the owners) must remember to close it. Here is an example of how it looks
    when we open and close the connection manually to send a request:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'As you can see, we have to remember to close the connection after we have used
    it, or the connection will stay open (leak). In this example, it seems hard to
    forget, but once the code gets more complicated after inserting proper error handling
    and multiple exit paths, it will be hard to guarantee that the connection will
    always be closed. RAII solves this by relying on the fact that the lifetime of
    automatic variables is handled for us in a predictable way. What we need is an
    object that will have the same lifetime as the connection we get from the `open_connection()`
    call. We can create a class for this, called `RAIIConnection`:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The `Connection` object is now wrapped in a class that controls the lifetime
    of the connection (the resource). Instead of manually closing the connection,
    we can now let `RAIIConnection` handle this for us:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: RAII makes our code safer. Even if `send_request()` would throw an exception
    here, the connection object would still be destructed and close the connection.
    We can use RAII for many types of resources, not just memory, file handles, and
    connections. Another example is `std::scoped_lock` from the C++ standard library.
    It tries to acquire a lock (mutex) on creation and then releases the lock on destruction.
    You can read more about `std::scoped_lock` in *Chapter 11*, *Concurrency*.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will explore more ways to make memory ownership explicit in C++.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Containers
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can use standard containers to handle a collection of objects. The container
    you use will own the dynamic memory it needs to store the objects you add to it.
    This is a very effective way of minimizing manual `new` and `delete` expressions
    in your code.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: It's also possible to use `std::optional` to handle the lifetime of an object
    that might or might not exist. `std::optional` can be seen as a container with
    a maximum size of 1.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: We won't talk more about the containers here, since they have already been covered
    in *Chapter 4*, *Data Structures*.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Smart pointers
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The smart pointers from the standard library wrap a raw pointer and make the
    ownership of the object it points to explicit. When used correctly, there is no
    doubt about who is responsible for deleting a dynamic object. The three smart
    pointer types are: `std::unique_ptr`, `std::shared_ptr`, and `std::weak_ptr`.
    As their names suggest, they represent three types of ownership of an object:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Unique ownership expresses that I, and only I, own the object. When I'm done
    using it, I will delete it.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shared ownership expresses that I own the object along with others. When no
    one needs the object anymore, it will be deleted.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weak ownership expresses that I'll use the object if it exists, but don't keep
    it alive just for me.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll deal with each of these types, respectively, in the following sections.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Unique pointer
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The safest and least complicated ownership is unique ownership and should be
    the first thing that pops into your mind when thinking about smart pointers. Unique
    pointers represent unique ownership; that is, a resource is owned by exactly one
    entity. Unique ownership can be transferred to someone else, but it cannot be
    copied, since that would break its uniqueness. Here is how to use a `std::unique_ptr`:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Unique pointers are also very efficient since they add very little performance
    overhead compared to ordinary raw pointers. The slight overhead is incurred by
    the fact that `std::unique_ptr` has a non-trivial destructor, which means that
    (unlike a raw pointer) it cannot be passed in a CPU register when being passed
    to a function. This makes them slower than raw pointers.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Shared pointer
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Shared ownership means that an object can have multiple owners. When the last
    owner ceases to exist, the object will be deleted. This is a very useful pointer
    type but is also more complicated than the unique pointer.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: The `std::shared_ptr` object uses reference counting to keep track of the number
    of owners an object has. When the counter reaches 0, the object will be deleted.
    The counter needs to be stored somewhere, so it does have some memory overhead
    compared to the unique pointer. Also, `std::shared_ptr` is internally thread-safe,
    so the counter needs to be updated atomically to prevent race conditions.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'The recommended way of creating objects owned by shared pointers is to use
    `std::make_shared<T>()`. It is both safer (from an exception-safety point of view)
    and more efficient than creating the object manually with `new` and then passing
    it to a `std::shared_ptr` constructor. By overloading `operator new()` and `operator
    delete()` again to track allocations, we can conduct an experiment to find out
    why using `std::make_shared<T>()` is more efficient:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now, let''s try the recommended way first, using `std::make_shared()`:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output when running the program is as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, let''s allocate the `int` value explicitly by using `new` and then pass
    it to the `std::shared_ptr` constructor:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The program will generate the following output:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We can conclude that the second version needs two allocations, one for the `double` and
    one for the `std::shared_ptr`, whereas the first version only needed one allocation.
    This also means that, by using `std::make_shared()`, our code will be more cache-friendly,
    thanks to spatial locality.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Weak pointer
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Weak ownership doesn't keep any objects alive; it only allows us to use an object
    if someone else owns it. Why would you want such a fuzzy ownership as weak ownership?
    One common reason for using a weak pointer is to break a reference cycle. A reference
    cycle occurs when two or more objects refer to each other using shared pointers.
    Even if all external `std::shared_ptr` constructors are gone, the objects are
    kept alive by referring to themselves.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'Why not just use a raw pointer? Isn''t the weak pointer exactly what a raw
    pointer already is? Not at all. A weak pointer is safe to use since we cannot
    reference the object unless it actually exists, which is not the case with a dangling
    raw pointer. An example will clarify this:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Whenever we try to use the weak pointer, we need to convert it into a shared
    pointer first using the member function `lock()`. If the object hasn't expired,
    the shared pointer will be a valid pointer to that object; otherwise, we will
    get an empty `std::shared_ptr` back. This way, we can avoid dangling pointers
    when using `std::weak_ptr` instead of raw pointers.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: This will end our section about objects in memory. C++ offers excellent support
    for dealing with memory, both regarding low-level concepts such as alignment and
    padding and high-level concepts such as object ownership.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Having a sound understanding of ownership, RAII, and reference counting are
    very important when working with C++. Programmers that are new to C++ and haven't
    been exposed to these concepts earlier might need some time to fully grasp this.
    At the same time, these concepts are not unique to C++. In most languages, they
    are more diffused, but in others, they are even more prominent (Rust is an example
    of the latter). So, once mastered, it will improve your programming skills in
    other languages as well. Thinking about object ownership will have a positive
    impact of the design and architecture of the programs you write.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will move on to an optimization technique that will reduce the usage
    of dynamic memory allocations and instead use the stack whenever possible.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Small object optimization
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the great things about containers such as `std::vector` is that they
    automatically allocate dynamic memory when needed. Sometimes, though, the use
    of dynamic memory for container objects that only contain a few small elements
    can hurt performance. It would be more efficient to keep the elements in the container
    itself and only use stack memory, instead of allocating small regions of memory
    on the heap. Most modern implementations of `std::string` will take advantage
    of the fact that a lot of strings in a normal program are short, and that short
    strings are more efficient to handle without the use of heap memory.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: One alternative is to keep a small separate buffer in the string class itself,
    which can be used when the string's content is short. This would increase the
    size of the string class, even when the short buffer is not used.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: So, a more memory-efficient solution is to use a union, which can hold a short
    buffer when the string is in short mode and, otherwise, hold the data members
    it needs to handle a dynamically allocated buffer. The technique for optimizing
    a container for handling small data is usually referred to as small string optimization
    for strings, or small object optimization and small buffer optimization for other
    types. We have many names for the things we love.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'A short code example will demonstrate how `std::string` from libc++ from LLVM
    behaves on my 64-bit system:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The code starts by overloading global `operator new` and `operator delete`
    for the purpose of tracking dynamic memory allocations. We can now start testing
    different sizes of the string `s` to see how `std::string` behaves. When building
    and running the preceding example in release mode on my system, it generates the
    following output:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This output tells us that `std::string` occupies 24 bytes on the stack and
    that it has a capacity of 22 chars without using any heap memory. Let''s verify
    that this is actually true by replacing the empty string with a string of 22 chars:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The program still produces the same output and verifies that no dynamic memory
    has been allocated. But what happens when we increase the string to hold 23 characters
    instead?
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Running the program now produces the following output:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The `std::string` class has now been forced to use the heap to store the string.
    It allocates 32 bytes and reports that the capacity is 31\. This is because libc++
    always stores a null-terminated string internally and, therefore, needs an extra
    byte at the end for the null character. It is still quite remarkable that the
    string class can be only 24 bytes and can hold strings of 22 characters in length
    without allocating any memory. How does it do this? As mentioned earlier, it is
    common to save memory by using a union with two different layouts: one for the
    short mode and one for the long mode. There is a lot of cleverness in the real
    libc++ implementation to make the maximum use of the 24 bytes that are available.
    The code here is simplified for the purpose of demonstrating this concept. The
    layout for the long mode looks like this:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Each member in the long layout is 8 bytes, so the total size is 24 bytes. The
    `char` pointer `data_` is a pointer to the dynamically allocated memory that will
    hold long strings. The layout of the short mode looks something like this:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: In the short mode, there is no need to use a variable for the capacity, since
    it is a compile-time constant. It is also possible to use a smaller type for the
    `size_` data member in this layout, since we know that the length of the string
    can only range from 0 to 22 if it is a short string.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: 'Both layouts are combined using a union:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'There is one piece missing, though: how can the string class know whether it
    is currently storing a short string or a long string? A flag is needed to indicate
    this, but where is it stored? It turns out that libc++ uses the least significant
    bit on the `capacity_` data member in the long mode, and the least significant
    bit on the `size_` data member in the short mode. For the long mode, this bit
    is redundant anyway since the string always allocates memory sizes that are multiples
    of 2\. In the short mode, it is possible to use only 7 bits for storing the size
    so that one bit can be used for the flag. It becomes even more complicated when
    writing this code to handle big endian byte order, since the bit needs to be placed
    in memory at the same location, regardless of whether we are using the short struct
    or the long struct of the union. You can look up the details in the libc++ implementation
    at [https://github.com/llvm/llvm-project/tree/master/libcxx](https://github.com/llvm/llvm-project/tree/master/libcxx).'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7.9* summarizes our simplified (but still rather complicated) memory
    layout of the union used by an efficient implementation of the small string optimization:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15619_07_09.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.9: The union of the two different layouts used for handling short
    strings and long strings, respectively'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: Clever tricks like this are the reason that you should strive to use the efficient
    and well-tested classes provided by the standard library before you try to roll
    out your own. Nevertheless, knowing about these optimizations and how they work
    is important and useful, even if you never need to write one yourself.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: Custom memory management
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have come a long way in this chapter now. We have covered the basics of virtual
    memory, the stack and the heap, the `new` and `delete` expressions, memory ownership,
    and alignment and padding. But before we close this chapter, we are going to show
    how to customize memory management in C++. We will see how the parts that we went
    through earlier in this chapter will come in handy when writing a custom memory
    allocator.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: But first, what is a custom memory manager and why do we need one?
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: 'When using `new` or `malloc()` to allocate memory, we use the built-in memory
    management system in C++. Most implementations of `operator new` use `malloc()`,
    which is a general-purpose memory allocator. Designing and building a general-purpose
    memory manager is a complicated task, and there are many people who have already
    spent a lot of time researching this topic. Still, there are several reasons why
    you might want to write a custom memory manager. Here are some examples:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '**Debugging and diagnostics**: We have already done this a couple of times
    in this chapter by overloading `operator new` and `operator delete`, just to print
    out some debugging information.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sandboxing**: A custom memory manager can provide a sandbox for code that
    isn''t allowed to allocate unrestricted memory. The sandbox can also track memory
    allocations and release memory when the sandboxed code finishes executing.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Performance**: If we need dynamic memory and can''t avoid allocations, we
    may have to write a custom memory manager that performs better for our specific
    needs. Later on, we will cover some of the circumstances that we could utilize
    to outperform `malloc()`.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that said, many experienced C++ programmers have never faced a problem
    that actually required them to customize the standard memory manager that comes
    with the system. This is a good indication of how good the general-purpose memory
    managers actually are today, despite all the requirements they have to fulfill
    without any knowledge about our specific use cases. The more we know about the
    memory usage patterns in our application, the better the chances are that we can
    actually write something more efficient than `malloc()`. Remember the stack, for
    example? Allocating and deallocating memory from the stack is very fast compared
    to the heap, thanks to the fact that it doesn't need to handle multiple threads
    and that deallocations are guaranteed to always happen in reverse order.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: Building a custom memory manager usually starts with analyzing the exact memory
    usage patterns and then implementing an arena.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Building an arena
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Two frequently used terms when working with memory allocators are **arena**
    and **memory pool**. We will not distinguish between these terms in this book.
    By arena, I mean a block of contiguous memory, including a strategy for handing
    out parts of that memory and reclaiming it later on.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: An arena could technically also be called a *memory resource* or an *allocator*,
    but those terms will be used to refer to abstractions from the standard library.
    The custom allocator we will develop later will be implemented using the arena
    we create here.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some general strategies that can be used when designing an arena
    that will make allocations and deallocations likely to perform better than `malloc()`
    and `free()`:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '**Single-threaded**: If we know that an arena will only be used from one thread,
    there is no need to protect data with synchronization primitives, such as locks
    or atomics. There is no risk that the client using the arena may be blocked by
    some other thread, which is important in real-time contexts.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fixed-size allocations**: If the arena only hands out memory blocks of a
    fixed size, it is relatively easy to reclaim memory efficiently without memory
    fragmentation by using a free list.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Limited lifetime**: If you know that objects allocated from an arena only
    need to live during a limited and well-defined lifetime, the arena can postpone
    reclamation and free the memory all at once. An example could be objects created
    while handling a request in a server application. When the request has finished,
    all the memory that was handed out during the request can be reclaimed in one
    step. Of course, the arena needs to be big enough to handle all the allocations
    during the request without reclaiming memory continually; otherwise, this strategy
    will not work.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I will not go into further details about these strategies, but it is good to
    be aware of the possibilities when looking for ways to improve memory management
    in your program. As is often the case with optimizing software, the key is to
    understand the circumstances under which your program will run and to analyze
    the specific memory usage patterns. We do this to find ways to improve a custom
    memory manager compared to a general-purpose one.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will have a look at a simple arena class template, which can be used
    for small or few objects that need dynamic storage duration, but where the memory
    it needs usually is so small that it can be placed on the stack. This code is
    based on Howard Hinnant's `short_alloc`, published at [https://howardhinnant.github.io/stack_alloc.html](https://howardhinnant.github.io/stack_alloc.html).
    This is a great place to start if you want to dig deeper into custom memory management.
    I think it is a good example for demonstration purposes because it can handle
    multiple sizes of objects, which require proper handling of alignment.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 'But again, keep in mind that this is a simplified version for demonstrating
    the concept rather than providing you with production-ready code:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The arena contains an `std::byte` buffer, whose size is determined at compile
    time. This makes it possible to create an arena object on the stack or as a variable
    with a static or thread local storage duration. The alignment might be allocated
    on the stack; hence, there is no guarantee that it will be aligned for types other
    than `char` unless we apply the `alignas` specifier to the array. The helper `align_up()`
    function may look complicated if you are not used to bitwise operations. However,
    it basically just rounds up to the alignment requirement that we use. The memory
    that this version will hand out will be the same as when using `malloc()` as it's
    suitable for any type. This is a bit wasteful if we use the arena for small types
    with smaller alignment requirements, but we'll ignore this here.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: When reclaiming memory, we need to know whether the pointer we are asked to
    reclaim actually belongs to our arena. The `pointer_in_buffer()` function checks
    this by comparing a pointer address with the address range of the arena. As a
    side note, relationally comparing raw pointers to disjoint objects is undefined
    behavior; this might be used by an optimizing compiler and result in surprising
    effects. To avoid this, we are casting the pointers to `std::uintptr_t` before
    comparing the addresses. If you are curious about the details behind this, you
    can find a thorough explanation in the article *How to check if a pointer is in
    range of memory* by Raymond Chen at [https://devblogs.microsoft.com/oldnewthing/20170927-00/?p=97095](https://devblogs.microsoft.com/oldnewthing/20170927-00/?p=97095).
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need the implementation of allocate and deallocate:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The `allocate()` function returns a pointer to a correctly aligned memory with
    the specified size, `n`. If there is no available space in the buffer for the
    requested size, it will fall back to using `operator new` instead.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `deallocate()` function first checks whether the pointer to the
    memory to be deallocated is from the buffer, or has been allocated with `operator
    new`. If it is not from the buffer, we simply delete it with `operator delete`.
    Otherwise, we check whether the memory to be deallocated is the last memory we
    handed out from the buffer and, then, reclaim it by moving the current `ptr_`,
    just as a stack would do. We simply ignore other attempts to reclaim the memory:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'That''s about it; our arena is now ready to be used. Let''s use it when allocating
    `User` objects:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: The `User` objects created in this example will all reside in the buffer of
    the `user_area` object. That is, no dynamic memory is allocated when we call `new`
    or `make_unique()` here. But there are other ways to create `User` objects in
    C++ that this example doesn't show. We will cover them in the next section.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: A custom memory allocator
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When trying out our custom memory manager with a specific type, it worked great!
    There is a problem, though. It turns out that the class-specific `operator new`
    is not called on all the occasions that we might have expected. Consider the following
    code:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: What happens when we want to have a `std::vector` of 10 users?
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: In neither of the two cases is our custom memory manager being used. Why? Starting
    with the shared pointer, we have to go back to the example earlier where we saw
    that `std::make_shared()` actually allocates memory for both reference counting
    data and the object it should point to. There is no way that `std::make_shared()`
    can use an expression such as `new User()` to create the user object and the counter
    with only one allocation. Instead, it allocates memory and constructs the user
    object using placement new.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: The `std::vector` object is similar. It doesn't construct 10 objects by default
    in an array when we call `reserve()`. This would have required a default constructor
    for all the classes to be used with the vector. Instead, it allocates memory that
    can be used for holding 10 user objects when they are being added. Again, placement
    new is the tool for making this possible.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, we can provide a custom memory allocator to both `std::vector`
    and `std::shared_ptr` in order to have them use our custom memory manager. This
    is true for the rest of the containers in the standard library as well. If we
    don't supply a custom allocator, the containers will use the default `std::allocator<T>`
    class. So, what we need in order to use our arena is to write an allocator that
    can be used by the containers.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: Custom allocators have been a hotly debated topic for a long time in the C++
    community. Many custom containers have been implemented to control how memory
    is managed instead of using the standard containers with custom allocators, probably
    for good reasons.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: However, the support and requirements for writing a custom allocator were improved
    in C++11, and are now a lot better. Here, we will only focus on allocators from
    C++11 and beyond.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'A minimal allocator in C++11 now looks like this:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: It's really not that much code anymore, thanks to the improvements in C++11\.
    The container that uses the allocator actually uses `std::allocator_traits`, which
    provides reasonable defaults if the allocator omits them. I recommend you have
    a look at the `std::allocator_traits` to see what traits can be configured and
    what the defaults are.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: 'By using `malloc()` and `free()`, we could quite easily implement a minimal
    custom allocator. Here, we will show the old and famous `Mallocator`, first published
    in a blog post by Stephan T. Lavavej, to demonstrate how to write a minimal custom
    allocator using `malloc()` and `free()`. Since then, it has been updated for C++11
    to make it even slimmer. Here is how it looks:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '`Mallocator` is a **stateless allocator**, which means that the allocator instance
    itself doesn''t have any mutable state; instead, it uses global functions for
    allocation and deallocation, namely `malloc()` and `free()`. A stateless allocator
    should always compare equal to the allocators of the same type. It indicates that
    memory allocated with `Mallocator` should also be deallocated with `Mallocator`,
    regardless of the `Mallocator` instance. A stateless allocator is the least complicated
    allocator to write, but it is also limited, since it depends on the global state.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: To use our arena as a stack-allocated object, we will need a **stateful allocator**
    that can reference the arena instance. Here, the arena class that we implemented
    really starts to make sense. Say, for example, that we want to use one of the
    standard containers in a function to do some processing. We know that, most of
    the time, we are dealing with very small amounts of data that will fit on the
    stack. But once we use the containers from the standard library, they will allocate
    memory from the heap, which, in this case, will hurt our performance.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: What are the alternatives to using the stack to manage data and avoid unnecessary
    heap allocations? One alternative is to build a custom container that uses a variation
    of the small object optimization we looked at for `std::string`.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also possible to use a container from Boost, such as `boost::container::small_vector`,
    which is based on LLVM''s small vector. We advise you to check it out if you haven''t
    already: [http://www.boost.org/doc/libs/1_74_0/doc/html/container/non_standard_containers.html](http://www.boost.org/doc/libs/1_74_0/doc/html/container/non_standard_containers.html).'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: Yet another alternative, though, is to use a custom allocator, which we will
    explore next. Since we already have an arena template class ready, we could simply
    create the instance of an arena on the stack and have a custom allocator use it
    for the allocations. What we then need to do is implement a stateful allocator,
    which could hold a reference to the stack-allocated arena object.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, this custom allocator that we will implement is a simplified version
    of Howard Hinnant''s `short_alloc`:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: The allocator holds a reference to the arena. This is the only state the allocator
    has. The functions `allocate()` and `deallocate()` simply forward their requests
    to the arena. The compare operators ensure that two instances of the `ShortAlloc`
    type are using the same arena.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, the allocator and arena we implemented can be used with a standard container
    to avoid dynamic memory allocations. When we are using small data, we can handle
    all allocations using the stack instead. Let''s see an example using `std::set`:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The program reads integers from standard input until the end-of-file is reached
    (Ctrl + D on Unix-like systems and Ctrl + Z on Windows). It then prints the unique
    numbers in ascending order. Depending on how many numbers are read from `stdin`,
    the program will use stack memory or dynamic memory by using our `ShortAlloc`
    allocator.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Using polymorphic memory allocators
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you have followed this chapter, you now know how to implement a custom allocator
    that can be used with arbitrary containers, including those from the standard
    library. Suppose we want to use our new allocator for some code we find in our
    code base that is processing buffers of the type `std::vector<int>`, like this:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'We are eager to try out our new allocator, which is utilizing stack memory,
    and try to inject it like this:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'When compiling, we come to the painful realization that `process()` is a function
    that expects `std::vector<int>`, and our `vec` variable is now of another type.
    GCC gives us the following error:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: The reason for the type mismatch is that the custom allocator, `MyAlloc`, that
    we want to use is passed to `std::vector` as a template parameter and therefore
    becomes part of the type we instantiate. As a result, `std::vector<int>` and `std::vector<int,
    MyAlloc>` cannot be interchanged.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: This may or may not be a problem for the use cases you are working on, and you
    could solve it by making the `process()` function accept a `std::span` or make
    it a generic function working with ranges instead of requiring a `std::vector`.
    Regardless, it's important to realize that the allocator actually becomes a part
    of the type when using allocator-aware template classes from the standard library.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: 'What allocator is `std::vector<int>` using then? The answer is that `std::vector<int>`
    uses the default template argument which is `std::allocator`. So, writing `std::vector<int>`
    is equivalent to `std::vector<int, std::allocator<int>>`. The template class `std::allocator`
    is an empty class that uses global `new` and global `delete` when it fulfills
    allocation and deallocation requests from the container. This also means that
    the size of a container using an empty allocator is smaller than that of a container
    using our custom allocator:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Checking the implementation of `std::vector` from libc++, we can see that it
    is using a nifty type called **compressed pair**, which, in turn, is based on
    the *empty base-class optimization* to get rid of the unnecessary storage usually
    occupied by a member of an empty class. We will not cover the details here, but
    if you are interested, you could have a look at the boost version of `compressed_pair`,
    which is documented at [https://www.boost.org/doc/libs/1_74_0/libs/utility/doc/html/compressed_pair.html](https://www.boost.org/doc/libs/1_74_0/libs/utility/doc/html/compressed_pair.html).
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: This problem of ending up with different types when using different allocators
    was addressed in C++17 by introducing an extra layer of indirection; all standard
    containers under the namespace `std::pmr` use the same allocator, namely `std::pmr::polymorphic_allocator`,
    which dispatches all allocation/deallocation requests to a **memory resource**
    class. So, instead of writing new custom memory allocators, we could use the general
    polymorphic memory allocator named `std::pmr::polymorphic_allocator` and instead
    write new custom memory resources that will be handed to the polymorphic allocator
    during construction. The memory resource is analogous to our `Arena` class, and
    the `polymorphic_allocator` is the extra layer of indirection that contains a
    pointer to the resource.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the control flow as the vector delegates to its
    allocator instance and the allocator, in turn, delegates to the memory resource
    to which it points:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15619_07_10.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.10: Allocating memory using a polymorphic_allocator'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: 'To start using the polymorphic allocator, we need to change the namespace from
    `std` to `std::pmr`:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Writing a custom memory resource is relatively straightforward, especially
    with knowledge about memory allocators and arenas. But we might not even have
    to write a custom memory resource in order to achieve what we want. C++ already
    provides us with a few useful implementations that we should consider before writing
    our own. All memory resources derive from the base class `std::pmr::memory_resource`.
    The following memory resources live in the `<memory_resource>` header:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '`std::pmr::monotonic_buffer_resource`: This is quite similar to our `Arena`
    class. This class is preferable in scenarios when we''re creating many objects
    with a short lifetime. Memory is freed only when the `monotonic_buffer_resource`
    instance is destructed, which makes allocations very fast.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::pmr::unsynchronized_pool_resource`: This uses memory pools (also known
    as "slabs") containing fixed-size memory blocks, which avoids fragmentation within
    each pool. Each pool hands out memory for objects of a certain size. If you are
    creating many objects of a few different sizes, this class can be beneficial to
    use. This memory resource is not thread-safe and cannot be used from multiple
    threads unless you provide external synchronization.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::pmr::synchronized_pool_resource`: This is a thread-safe version of `unsynchronized_pool_resource`.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Memory resources can be chained. When creating an instance of a memory resource,
    we can provide it with an **upstream memory resource**. This will be used if the
    current resource cannot handle the request (similar to what we did in `ShortAlloc`
    by using `malloc()` once our small buffer was full), or when the resource itself
    needs to allocate memory (such as when `monotonic_buffer_resource` needs to allocate
    its next buffer). The `<memory_resource>` header provides us with free functions
    that return pointers to global resource objects that are useful when specifying
    upstream resources:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: '`std::pmr::new_delete_resource()`: Uses the global `operator new` and `operator
    delete`.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::pmr::null_memory_resource()`: A resource that always throws `std::bad_alloc`
    whenever it is asked to allocate memory.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`std::pmr::get_default_resource()`: Returns a globally default memory resource
    that can be set at runtime by `set_default_resource()`. The initial default resource
    is `new_delete_resource()`.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s see how we could rewrite our example from the last section, but this
    time using a `std::pmr::set`:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: We are passing a stack-allocated buffer to the memory resource, and then providing
    it with the object returned from `new_delete_resource()` as an upstream resource
    to be used if the buffer becomes full. If we would have omitted the upstream resource,
    it would have used the default memory resource, which, in this case, would have
    been the same since our code does not change the default memory resource.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a custom memory resource
  id: totrans-343
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Implementing a custom memory resource is fairly simple. We need to publicly
    inherit from `std::pmr::``memory_resource` and then implement three pure virtual
    functions that will be invoked by the base class (`std::pmr::memory_resource`).
    Let''s implement a simple memory resource that prints allocations and deallocations
    and then forwards the request to the default memory resource:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Note that we are saving the default resource in the constructor rather than
    calling `get_default_resource()` directly from `do_allocate()` and `do_deallocate()`.
    The reason for this is that someone could potentially change the default resource
    by calling `set_default_resource()` in the time between an allocation and a deallocation.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use a custom memory resource to track allocations made by a `std::pmr`
    container. Here is an example of using a `std::pmr::vector`:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'A possible output when running the program is:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Something to be very careful about when using polymorphic allocators is that
    we are passing around raw non-owning pointers to memory resources. This is not
    specific to polymorphic allocators; we actually had the same problem with our
    `Arena` class and `ShortAlloc` as well, but this might be even easier to forget
    when using containers from `std::pmr` since these containers are using the same
    allocator type. Consider the following example:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Since the resource is destroyed when it goes out if scope at the end of `create_vec()`,
    our newly created `std::pmr::vector` is useless and will most likely crash when
    used.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: This concludes our section on custom memory management. It is a complicated
    subject and if you feel tempted to use custom memory allocators to gain performance,
    I encourage you to carefully measure and analyze the memory access patterns in
    your application before you use and/or implement custom allocators. Typically,
    there are only a small set of classes or objects in an application that really
    need to be tweaked using custom allocators. At the same time, reducing the number
    of dynamic memory allocations in an application or grouping objects together,
    in certain regions of memory, can have a dramatic effect on performance.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-355
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter has covered a lot of ground, starting with the basics of virtual
    memory and finally implementing a custom allocator that can be used by containers
    from the standard library. A good understanding of how your program uses memory
    is important. Overuse of dynamic memory can be a performance bottleneck that you
    might need to optimize away.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: Before you start implementing your own containers or custom memory allocators,
    bear in mind that many people before you have probably had very similar memory
    issues to the ones you may face. So, there is a good chance that the right tool
    for you is already out there in a library. Building custom memory managers that
    are fast, safe, and robust is a challenge.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn how to benefit from the newly introduced
    feature of C++ concepts, and how we can use template metaprogramming to have the
    compiler generate code for us.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
