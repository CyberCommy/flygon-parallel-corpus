- en: Writing Testable Code
  prefs: []
  type: TYPE_NORMAL
- en: The ability to test code is the most important quality of any software product.
    Without proper testing, it is prohibitively expensive to refactor the code or
    to improve any other part of it, such as its security, scalability, or performance.
    In this chapter, we'll learn how to design and manage automated tests and how
    to correctly use fakes and mocks when it is necessary to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Why do you test code?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing testing frameworks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding mocks and fakes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test-driven class design
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating tests for continuous integration/continuous deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The sample code for this chapter can be found at [https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter08](https://github.com/PacktPublishing/Software-Architecture-with-Cpp/tree/master/Chapter08).
  prefs: []
  type: TYPE_NORMAL
- en: 'The software that we will be using in this chapter''s examples is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: GTest 1.10+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Catch2 2.10+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CppUnit 1.14+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doctest 2.3+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serverspec 2.41+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testinfra 3.2+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goss 0.3+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CMake 3.15+
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoconf
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automake
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Libtool
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why do you test code?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Software engineering and software architecture is a very complex matter, and
    the natural way to deal with uncertainties is to insure yourself against potential
    risks. We do it all the time with life insurance, health insurance, and car insurance.
    Yet when it comes to software development, we tend to forget about all the safety
    precautions and just hope for an optimistic outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing that things not only may but *will* go wrong, it is unbelievable that
    the topic of testing software is still a controversial one. Whether it's from
    having a lack of skill or from a lack of budget, there are still projects that
    lack even some of the most basic tests. And when the client decides to change
    the requirements, a simple correction may result in endless reworks and firefights.
  prefs: []
  type: TYPE_NORMAL
- en: The time that's saved from not implementing proper testing is lost when the
    first rework happens. If you think this rework will not happen very soon, you
    are most probably very mistaken. In the agile environment we live in nowadays,
    reworks are a part of our daily life. Our knowledge about the world and our customers'
    changes means that the requirements change, and with that comes making changes
    to our code.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, testing's main purpose is to protect your precious time later in
    the project. Sure, it's an investment early on when you have to implement various
    tests instead of focusing solely on the features, but it's an investment you won't
    regret. Like an insurance policy, testing takes a little from your budget when
    things go according to plan, but when things go bad, you'll get a generous payout.
  prefs: []
  type: TYPE_NORMAL
- en: The testing pyramid
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are different types of testing you may encounter when designing or implementing
    a software system. Each of the classes serves a slightly different purpose. They
    can be categorized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unit testing: Code'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Integration testing: Design'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'System testing: Requirements'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Acceptance testing (**end-to-end** or **E2E**): Client needs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This distinction is arbitrary and you may often see other layers of the pyramid,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Unit testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: UI testing (**end-to-end** or **E2E**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here, unit testing refers to the same layer as in the previous example. Service
    testing refers to a combination of integration testing and system testing. On
    the other hand, UI testing refers to acceptance testing. The following diagram
    shows the testing pyramid:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/38151759-9e75-4e63-a745-4364c71a9eaf.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Testing pyramid
  prefs: []
  type: TYPE_NORMAL
- en: It's worth noting that unit tests are not only the cheapest to build but that
    they also execute pretty quickly and can often run in parallel. This means they
    make for a great continuous integration gating mechanism. Not only that, but they
    also often provide the best feedback about the health of your system. Higher-level
    tests are not only harder to write properly, but they also may be less robust.
    This can lead to flickering test results, with one in every few test runs failing.
    If the failure in the higher-level test is not correlated with any failure at
    the unit test level, chances are that the problem may be with the test itself
    and not in the system under test.
  prefs: []
  type: TYPE_NORMAL
- en: We don't want to say that the higher-level tests are entirely useless and that
    you should only focus on writing unit tests. That's not the case. The pyramid
    has its shape because there should be a solid base covered by unit tests. On that
    base, however, you should also have all the higher-level tests in an appropriate
    proportion. After all, it is not very hard to imagine a system where all the unit
    tests are passing, but the system itself doesn't provide any value to the customer.
    An extreme example would be a perfectly working backend without any user interface
    (be it graphical or in the form of an API) present. Sure, it passes all the unit
    tests, but that's no excuse!
  prefs: []
  type: TYPE_NORMAL
- en: As you may imagine, the opposite of the testing pyramid is known as an ice cone,
    and it is an antipattern. Violating the testing pyramid often leads to fragile
    code and hard to trace bugs. This makes debugging much more expensive and doesn't
    introduce savings in test development either.
  prefs: []
  type: TYPE_NORMAL
- en: Non-functional testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'What we''ve already covered are so-called functional tests. Their aim is to
    check whether the system under test fulfills the functional requirements. But
    there are also other types of requirements besides functional ones that we may
    want to control. Some of them are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance**: Your application may behave according to requirements in terms
    of functionality but still be unusable for end users due to weak performance.
    We will focus more on improving performance in [Chapter 11](9d4b9eb1-c0cc-4fdb-b0e2-db0a401405ac.xhtml),
    *Performance.*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Endurance**: Even if your system can be really performant, it doesn''t mean
    it can survive a continuously high workload. And when it does, can it survive
    some of the malfunctionings of the components? When we embrace the idea that every
    piece of software is vulnerable and may break at any given moment, we start designing
    systems that can be failure-resistant. This is a concept that the Erlang ecosystem
    embraces, but the concept itself is not limited to that environment alone. In
    [Chapter 13](ccc9ef2c-747a-4b56-9009-21382c7838d5.xhtml), *Designing Microservices,*
    and [Chapter 15](27377621-3532-4513-8045-caa00285fdda.xhtml), *Cloud-Native Design*,
    we will mention a bit more about designing systems that are fault-tolerant and
    the role of chaos engineering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: Nowadays, there should be no need to repeat that security is
    crucial. But since it still isn''t treated with all the seriousness the matter
    requires, we will bore you with saying this yet again. Every system that is connected
    to the network can – and most probably will – be broken. Performing security tests
    early on during development gives the same benefits as other kinds of tests: you
    can catch problems before they are too expensive to fix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Availability**: Whereas poor performance may discourage your end users from
    using your product, poor availability may prevent them from even accessing said
    product. While availability problems may arise due to performance overload, there
    are also other causes of lost availability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integrity**: Your customers'' data should not only be safe from outside attackers.
    It should also be safe from any alterations or losses due to software malfunction.
    Protection against bit rot, snapshotting, and backups are ways to prevent integrity
    loss. By comparing the current version with previously recorded snapshots, you
    can make sure if the difference resulted only from the action that was taken or
    whether it was caused by errors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Usability**: Even a product that ticks all of the previous boxes may still
    be unsatisfactory for the users if it has a clunky interface and unintuitive interaction.
    Usability tests are mostly performed manually. It''s important to perform a usability
    assessment each time the UI or the workflow of the system changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regression tests are usually end-to-end tests that should prevent you from making
    the same mistake twice. When you (or your QA team or customers) discover a bug
    in a production system, it is not sufficient to apply a hotfix and forget all
    about it.
  prefs: []
  type: TYPE_NORMAL
- en: One of the things you need to do is write a regression test that should prevent
    the same error from ever entering the production system again. Good regression
    tests can even prevent the same *class* of errors from entering production. After
    all, once you know what you did wrong, you can imagine other ways to mess things
    up. Another thing you can do is perform root cause analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Root cause analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Root cause analysis is a process that helps you uncover what the original source
    of the problem was, not only its manifestation. The most common way to perform
    root cause analysis is to use the method of *5 Whys*, which was made famous by
    the Toyota company. This method consists of peeling off all the superficial layers
    of the problem's manifestation to uncover the root cause hidden underneath. You
    do this by asking "why" at each layer until you find the root cause you are looking
    for.
  prefs: []
  type: TYPE_NORMAL
- en: Let's look at an example of this method in action.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem: We didn''t get payments for some of the transactions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Why?* The system didn''t send the appropriate emails to the customers.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Why?* The email sending system doesn''t support special characters in customers''
    names.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Why?* The email sending system wasn''t tested properly.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Why?* There was no time for proper testing due to a need to develop new features.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Why?* Our time estimates for the features were incorrect.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this example, the problem with time estimates may be the root cause of the
    bug that was found in the production system. But it may as well be another layer
    to peel. The framework gives you a heuristic that should work most of the time,
    but if you don't feel entirely sure that what you got is what you are looking
    for, you can keep on peeling additional layers until you find what caused all
    the trouble.
  prefs: []
  type: TYPE_NORMAL
- en: Given that many bugs result from the exact same and often repeatable root causes,
    finding the root cause is extremely beneficial because you can protect yourself
    from making the same mistake in the future *on several different levels*. This
    is the principle of defense in depth when it's applied to software testing and
    problem-solving.
  prefs: []
  type: TYPE_NORMAL
- en: The groundwork for further improvement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having your code tested protects you from making accidental errors. But it also
    opens up different possibilities. When your code is covered by test cases, you
    don't have to fear refactoring. Refactoring is the process of transforming code
    that does its job into code that is functionally similar, except it has better
    internal organization. You may be wondering why you need to change the code's
    organization. There are several reasons for this.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, your code may no longer be readable, which means every modification
    takes too much time. Second, fixing a bug you are about to fix will make some
    other features behave incorrectly as the code gathered too many workarounds and
    special cases over time. Both of those reasons can be summed up as productivity
    improvements. They will make maintenance cheaper in the long run.
  prefs: []
  type: TYPE_NORMAL
- en: But apart from productivity, you may also want to improve performance. This
    can mean either runtime performance (how the application behaves in production)
    or compile-time performance (which is basically another form of productivity improvement).
  prefs: []
  type: TYPE_NORMAL
- en: You can refactor for runtime performance by replacing the current suboptimal
    algorithms with more efficient ones or by changing the data structures that are
    used through the module you are refactoring.
  prefs: []
  type: TYPE_NORMAL
- en: Refactoring for compile-time performance usually consists of moving parts of
    code to different compilation units, reorganizing headers, or reducing dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: No matter what your end goal is, refactoring is generally a risky business.
    You take something that mostly works correctly and can end up either with a better
    version or a worse one. How would you know which case is yours? Here, testing
    comes to the rescue.
  prefs: []
  type: TYPE_NORMAL
- en: If the current feature set is thoroughly covered and you want to fix the recently
    uncovered bug, all you need to do is add another test case that will fail at that
    time. The moment your entire test suite starts passing again means your refactoring
    efforts were successful.
  prefs: []
  type: TYPE_NORMAL
- en: The worst-case scenario is that you have to abort the refactoring process in
    case you cannot satisfy all the test cases in a specified timeframe. You would
    undertake a similar procedure if you wanted to improve performance, but instead
    of unit tests (or end-to-end tests), you would focus on performance testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'With the recent rise of automated tools that aid in refactoring (such as ReSharper
    C++: [https://www.jetbrains.com/resharper-cpp/features/ReSharper C++:](https://www.jetbrains.com/resharper-cpp/features/)
    ) and code maintenance, you can even go as far as outsourcing a part of coding
    solely to the external software services. Services such as Renovate ([https://renovatebot.com/](https://renovatebot.com/)),
    Dependabot ([https://dependabot.com](https://dependabot.com)), and Greenkeeper
    ([https://greenkeeper.io/](https://greenkeeper.io/)) may soon support C++ dependencies.
    Having solid test coverage will let you use them without the fear of breaking
    your application during dependency updates.'
  prefs: []
  type: TYPE_NORMAL
- en: Since keeping your dependencies up to date in terms of security vulnerabilities
    is something you should always consider, such services can reduce the burden significantly.
    Therefore, testing not only protects you from making mistakes, but it reduces
    the effort necessary to introduce new features. It can also help you improve your
    code base and keep it stable and secure!
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the need for testing, we want to start writing our own
    tests. It is possible to write tests without any external dependencies. However,
    we'd like to focus just on the testing logic. We're not interested in the details
    of managing test results and reporting. Therefore, we will select a testing framework
    to handle this tedious job for us. In the next section, we will introduce some
    of the most popular testing frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing testing frameworks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As for the frameworks, the current de facto standard is Google's GTest. Together
    with its counterpart GMock, they form a small suite of tools that allow you to
    follow the best practices of testing in C++.
  prefs: []
  type: TYPE_NORMAL
- en: Other popular alternatives to GTest/GMock duo are Catch2, CppUnit, and Doctest.
    CppUnit has been available for a long time, but its lack of recent releases means
    we don't recommend it for fresh projects. Both Catch2 and Doctest support the
    modern C++ standards – in particular, C++14, C++17, and C++20.
  prefs: []
  type: TYPE_NORMAL
- en: To compare these testing frameworks, we will use the same codebase that we want
    to test. Using it as a basis, we will then implement tests in each of the frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: GTest examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is an example test for our customer library written in GTest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Most of the tasks that are commonly done during testing have been abstracted.
    We're mostly focused on providing the action we want to test (`prepare_response`)
    and the desired behavior (both `ASSERT_EQ` lines).
  prefs: []
  type: TYPE_NORMAL
- en: Catch2 examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is an example test for our customer library written in Catch2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: It looks pretty similar to the previous one. Some keywords differ (`TEST` and
    `TEST_CASE`) and there's a slightly different way to check the results (`REQUIRE(a
    == b)` instead of `ASSERT_EQ(a,b)`). Both are pretty compact and readable anyway.
  prefs: []
  type: TYPE_NORMAL
- en: CppUnit examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here is an example test for our customer library written in CppUnit. We will
    split it into several snippets.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block prepares us to use the constructs from the CppUnit
    library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we must define the test class and implement the method that will execute
    our test case. After that, we must register the class so that we can use it in
    our test runner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we must provide the behavior of our test runner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Compared to the previous two examples, there's a lot of boilerplate in here.
    The test itself, however, looks pretty similar to the previous example.
  prefs: []
  type: TYPE_NORMAL
- en: Doctest examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here is an example test for our customer library written in Doctest:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Once again, it's quite clean and easy to understand. The main selling point
    of Doctest is that it's the fastest both at compile-time and at runtime compared
    to the other similarly-featured alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: Testing compile-time code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Template metaprogramming allows us to write C++ code that is executed during
    compile-time as opposed to the usual execution time. The `constexpr` keyword,
    which was added in C++11, allows us to use even more compile-time code, and `consteval`
    keyword from C++20 aims to give us greater control over the way the code is evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: One of the problems with compile-time programming is that there is no easy way
    to test it. While unit testing frameworks for execution time code are abundant
    (as we just saw), there are not that many resources regarding compile-time programming.
    Part of this may stem from the fact that compile-time programming is still considered
    complicated and only aimed at experts.
  prefs: []
  type: TYPE_NORMAL
- en: Just because something isn't easy doesn't mean it is impossible, though. Just
    like execution time tests rely on assertions being checked during runtime, you
    can check your compile-time code for correct behavior using `static_assert`, which
    was introduced alongside `constexpr` in C++11.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a simple example of using `static_assert`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Since we can compute each value tested here during compile time, we can effectively
    use the compiler as our testing framework.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding mocks and fakes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As long as you are testing functions that do not interact too much with the
    outside world, things are pretty easy. The problems start when the units you are
    testing interface with third-party components such as databases, HTTP connections,
    and specific files.
  prefs: []
  type: TYPE_NORMAL
- en: On one hand, you want to see how your code behaves due to various circumstances.
    On the other hand, you don't want to wait for the database to boot, and you definitely
    don't want to have several databases containing different versions of data so
    that you can check all the necessary conditions.
  prefs: []
  type: TYPE_NORMAL
- en: How can we deal with such cases? The idea is not to execute the actual code
    that triggers all those side effects but instead use test doubles. Test doubles
    are constructions in code that mimic the actual API, except they don't perform
    actions of the mimicked functions or objects.
  prefs: []
  type: TYPE_NORMAL
- en: The most common test doubles are mocks, fakes, and stubs. Many people tend to
    mistake one for another as they are similar, though not the same.
  prefs: []
  type: TYPE_NORMAL
- en: Different test doubles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mocks are test doubles that register all the received calls but do nothing more
    than that. They do not return any value and they do not change state in any way.
    They are useful when we have a third-party framework that is supposed to call
    our code. By using mocks, we can observe all the calls and are thus able to verify
    that the framework behaves as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Stubs are a bit more complicated when it comes to their implementation. They
    return values, but those values are predefined. It may seem surprising that the
    `StubRandom.randomInteger()` method always returns the same value (for example,
    `3`), but it may be a sufficient stub implementation when we are testing the type
    of the returned value or the fact that it does return a value at all. The exact
    value may not be that important.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, fakes are objects that have a working implementation and behave mostly
    like the actual production implementation. The main difference is that fakes may
    take various shortcuts, such as avoiding calling the production database or filesystem.
  prefs: []
  type: TYPE_NORMAL
- en: When implementing the **Command Query Separation** (**CQS**) design pattern,
    you will usually want to double queries with stubs and commands with mocks.
  prefs: []
  type: TYPE_NORMAL
- en: Other uses for test doubles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fakes can also be used, to a limited extent, outside of testing. In-memory processing
    data without resorting to database access can also be great for prototyping or
    when you're hitting performance bottlenecks.
  prefs: []
  type: TYPE_NORMAL
- en: Writing test doubles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To write test doubles, we typically use an external library, just as we do
    with unit tests. Some of the most popular solutions are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'GoogleMock (also known as gMock), which is now a part of the GoogleTest library:
    [https://github.com/google/googletest](https://github.com/google/googletest).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Trompeloeil, which focuses on C++14, integrates well with many testing libraries,
    such as Catch2, doctest, and GTest: [https://github.com/rollbear/trompeloeil](https://github.com/rollbear/trompeloeil).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code in the following sections will show you how to use both GoogleMock
    and Trompeloeil.
  prefs: []
  type: TYPE_NORMAL
- en: GoogleMock example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since GoogleMock is part of GoogleTest, we will present them together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: GTest is the most popular C++ testing framework at the time of writing this
    book. Its integration with GMock means that GMock is probably already available
    for you in your project. This combination is intuitive to use and fully-featured,
    so there's no reason to look for alternatives if you're already invested in GTest.
  prefs: []
  type: TYPE_NORMAL
- en: Trompeloeil example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To contrast this example with the previous one, this time, we are using Trompeloeil
    for test doubles and Catch2 as a testing framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: One of the great features of Catch2 is that it makes it easy to write behavior-driven
    development-style tests, such as the one shown here. If you prefer this style,
    then Catch2 with Trompeloeil would be a good choice as they integrate very well.
  prefs: []
  type: TYPE_NORMAL
- en: Test-driven class design
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It's not enough to distinguish between different types of tests and learn a
    particular testing framework (or several). When you start testing your actual
    code, you will soon notice that not all classes can be tested easily. Sometimes,
    you may feel the need to access private attributes or methods. Resist this urge
    if you want to maintain the principles of good architecture! Instead, consider
    either testing the business requirements that are available through the type's
    public API or refactoring the type so that there's another unit of code you can
    test.
  prefs: []
  type: TYPE_NORMAL
- en: When tests and class design clash
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The problem you may be facing is not that the testing frameworks are inadequate.
    Usually, what you encounter is inappropriately designed classes. Even though your
    classes may behave correctly and may look correct unless they allow for testing,
    they are not designed correctly.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is good news. It means that you can repair the problem before
    it's inconvenient to do so. The class design will probably haunt you later on
    when you start building a class hierarchy based on it. Fixing the design during
    test implementation will simply reduce the possible technological debt.
  prefs: []
  type: TYPE_NORMAL
- en: Defensive programming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike its name may suggest, defensive programming is not a security feature.
    Its name comes from defending your classes and functions from being used contrary
    to their original intention. It's not directly related to testing, but it's a
    great design pattern to use since it improves your code's quality, making your
    project future-proof.
  prefs: []
  type: TYPE_NORMAL
- en: Defensive programming starts with static typing. If you create a function that
    handles a custom-defined type as a parameter, you must make sure nobody will call
    it with some accidental value. A user will have to consciously check what the
    function expects and prepare the input accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'In C++, we can also leverage type-safety features when we''re writing template
    code. When we''re creating a container for our customers'' reviews, we could accept
    a list of any type and copy from it. To get nicer errors and well-crafted checks,
    we could write the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `explicit` keyword protects us from unwanted implicit casts. By specifying
    that our input parameter satisfies the `range` concept, we ensure that we''re
    only going to compile with a valid container. Thanks to using concepts, we can
    get clearer error messages from our defense against invalid use. Using `static_assert`
    in our code is also a great defensive measure as it allows us to provide a nice
    error message if needed. Our `is_range_of_reviews` check could be implemented
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This way, we ensure that the range we got actually contains reviews of the type
    we desire.
  prefs: []
  type: TYPE_NORMAL
- en: 'Static typing will not prevent invalid runtime values from being passed to
    the function. That''s why the next form of defensive programming is checking preconditions.
    This way, your code will fail as soon as the first sign of a problem arises, which
    is always better than returning an invalid value that propagates to other parts
    of the system. Until we have contracts in C++, we can use the GSL library we mentioned
    in earlier chapters to check the pre- and post-conditions of our code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here, by using the `Expects` macro, we're checking that our incoming review
    actually has the IDs of the merchant and reviewer set. Aside from the cases where
    it doesn't, we are also defending ourselves against cases where adding a review
    to our storage failed when we use the `Ensures` post-condition macro.
  prefs: []
  type: TYPE_NORMAL
- en: 'When it comes to runtime checks, one of the first things that comes to mind
    is checking whether one or more attributes is not a `nullptr`. The best way to
    guard yourself against this problem is to distinguish nullable resources (those
    that can take `nullptr` as value) from non-nullable ones. There''s a great tool
    you can use for this, and is available in the standard library from C++17: `std::optional`.
    If you can, use it in all the APIs that you design.'
  prefs: []
  type: TYPE_NORMAL
- en: The boring refrain – write your tests first
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This has been said many times, yet many people tend to "forget" this rule. When
    you actually write your tests, the first thing you must do is reduce the risk
    of creating classes that are hard to test. You start with API usage and need to
    bend the implementation to best serve the API. This way, you usually end up with
    APIs that are both more pleasant to use and easier to test. When you're implementing
    **test-driven development** (**TDD**) or writing tests before code, you'll also
    end up implementing dependency injection, which means your classes can be more
    loosely coupled.
  prefs: []
  type: TYPE_NORMAL
- en: Doing this the other way around (writing your classes first and only then adding
    unit tests to them) may mean that you up with code that is easier to write but
    harder to test. And when testing gets harder, you may feel the temptation to skip
    it.
  prefs: []
  type: TYPE_NORMAL
- en: Automating tests for continuous integration/continuous deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the next chapter, we will focus on **continuous integration** and **continuous
    deployment** (**CI**/**CD**). For a CI/CD pipeline to work properly, you need
    to have a set of tests that catch the bugs before they enter production. It is
    up to you and your team to make sure all the business requirements are properly
    expressed as tests.
  prefs: []
  type: TYPE_NORMAL
- en: Tests are useful on several levels. With behavior-driven development, which
    we mentioned in the previous section, business requirements form a basis for automated
    tests. But the system you are building doesn't consist solely of business requirements.
    You want to make sure all the third-party integrations are working as expected.
    You want to make sure all your subcomponents (such as microservices) can actually
    interface with each other. Finally, you want to make sure that the functions and
    classes you are building are free of any bugs you could have imagined.
  prefs: []
  type: TYPE_NORMAL
- en: Each test that you can automate is a candidate for a CI/CD pipeline. Each of
    them also has its place somewhere in this pipeline. For example, end-to-end tests
    make the most sense after the deployment as acceptance tests. On the other hand,
    unit tests make the most sense when they're executed directly after compilation.
    After all, our aim is to break the circuit as soon as we find any possible divergence
    from the specification.
  prefs: []
  type: TYPE_NORMAL
- en: You don't have to run all the tests that you have automated each time you run
    a CI/CD pipeline. It's better if the runtime of each pipeline is relatively short.
    Ideally, it should finish within a couple of minutes from the commit. How can
    we make sure everything is properly tested, then, if we want to keep the runtime
    minimal?
  prefs: []
  type: TYPE_NORMAL
- en: One answer is to prepare different suites of tests for different purposes. For
    example, you can have minimal tests for commits to a feature branch. With many
    commits coming to feature branches every day, this means they will only be tested
    briefly and that the answer will be available fast. Merging feature branches to
    the shared development branch then requires a slightly larger set of test cases.
    This way, we make sure we haven't broken anything that other team members will
    be using. Finally, a more extensive set of cases will be run for merges to production
    branches. After all, we want the production branches to be tested thoroughly,
    even if the testing takes quite a long time.
  prefs: []
  type: TYPE_NORMAL
- en: Another answer is to use the trimmed-down set of test cases for CI/CD purposes
    and have an additional continuous testing process. This process runs regularly
    and performs in-depth checks on the current state of a particular environment.
    The tests can go as far as security tests and performance tests and may thus assess
    the eligibility of the environment to be promoted.
  prefs: []
  type: TYPE_NORMAL
- en: Promotion occurs when we select an environment and acknowledge that this environment
    has all the qualities to become a more mature environment. For example, that development
    environment can become the next staging environment, or that staging environment
    can become the next production environment. If this promotion happens automatically,
    it is also a good practice to provide automatic rollback in case the subtle differences
    (such as in terms of domain name or traffic) make the freshly promoted environment
    no longer pass the tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'This also presents another important practice: to always run tests on the production
    environment. Such tests have to be the least intrusive, of course, but they should
    tell you that your system is performing correctly at any given time.'
  prefs: []
  type: TYPE_NORMAL
- en: Testing the infrastructure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you want to incorporate the concepts of configuration management, Infrastructure
    as Code, or immutable deployments into the software architecture of your application,
    you should also consider testing the infrastructure itself. There are several
    tools you can use to do this, including Serverspec, Testinfra, Goss, and Terratest,
    which are among some of the more popular ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'These tools slightly differ in scope, as stated here:'
  prefs: []
  type: TYPE_NORMAL
- en: Serverspec and Testinfra focus more on testing the actual state of the servers
    that are configured via configuration management, such as Salt, Ansible, Puppet,
    and Chef. They're written in Ruby and Python, respectively, and they plug into
    the languages' testing engines. This means RSPec for Serverspec and Pytest for
    Testinfra.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goss is a bit different both in terms of scope and form. Besides testing the
    servers, you can also use Goss to test the containers you use in your project
    with the dgoss wrapper. As for its form, it doesn't use the imperative code you
    would see in Serverspec or Testinfra. Rather, similar to Ansible or Salt, it uses
    a YAML file to describe the desired state we want to check for. If you're already
    using a declarative approach to configuration management (such as the aforementioned
    Ansible or Salt), Goss may be more intuitive and thus a much better fit for testing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, Terratest is a tool that allows you to test the output of Infrastructure
    as Code tools such as Packer and Terraform (hence the name). Just like Serverspec
    and Testinfra use their language testing engines to write tests for servers, Terratest
    leverages Go's testing package to write the appropriate test cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's see how can we use each of these tools to validate that the deployment
    went on according to plan (at least from the infrastructure's point of view).
  prefs: []
  type: TYPE_NORMAL
- en: Testing with Serverspec
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following is an example of a test for Serverspec that checks the availability
    of Git in a specific version and the Let''s Encrypt configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The Ruby DSL syntax should be readable even by those who do not use Ruby daily.
    You may need to get used to writing the code.
  prefs: []
  type: TYPE_NORMAL
- en: Testing with Testinfra
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following is an example of a test for Testinfra that checks the availability
    of Git in a specific version and the Let''s Encrypt configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Testinfra uses plain Python syntax. It should be readable, but just like Serverspec,
    you may need some training to confidently write tests in it.
  prefs: []
  type: TYPE_NORMAL
- en: Testing with Goss
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following is an example of a YAML file for Goss that checks the availability
    of Git in a specific version and the Let''s Encrypt configuration file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: YAML's syntax will probably require the least preparation both to read it and
    write it. However, if your project already uses Ruby or Python, you may want to
    stick to Serverspec or Testinfra when it comes to writing more complicated tests.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter focused both on the architectural and technical aspects of testing
    different parts of the software. We looked at the testing pyramid to understand
    how different kinds of tests contribute to the overall health and stability of
    a software project. Since testing can be both functional and non-functional, we
    saw some examples of both these types.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most important things to remember from this chapter is that tests
    are not the end stage. We want to have them not because they bring immediate value,
    but because we can use them to check for known regressions, when refactoring,
    or when we're changing the behavior of existing parts of the system. Tests can
    also prove useful when we want to perform root cause analysis as they can quickly
    verify different hypotheses.
  prefs: []
  type: TYPE_NORMAL
- en: Having established the theoretical requirements, we showed examples of the different
    testing frameworks and libraries we can use to write test doubles. Even though
    writing tests first and their implementation later requires some practice, it
    has an important benefit. This benefit is a better class design.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to highlight that modern architecture is something more than just software
    code, we also looked at a few tools for testing infrastructure and deployment.
    In the next chapter, we will see how continuous integration and continuous deployment
    bring better service quality and robustness to the applications you will architect.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What is the base layer of the testing pyramid?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What kinds of non-functional tests are there?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the name of the famous method for root cause analysis?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it possible to test the compile-time code in C++?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What should you use when you're writing unit tests for code with external dependencies?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the role of unit tests in continuous integration/continuous deployment?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are some tools that allow you to test infrastructure code?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Is it a good idea to access the class's private attributes and methods in a
    unit test?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Testing C++ Code: [https://www.packtpub.com/application-development/modern-c-programming-cookbook](https://www.packtpub.com/application-development/modern-c-programming-cookbook)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Test Doubles: [https://martinfowler.com/articles/mocksArentStubs.html](https://martinfowler.com/articles/mocksArentStubs.html)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuous Integration/Continuous Deployment: [https://www.packtpub.com/virtualization-and-cloud/hands-continuous-integration-and-delivery](https://www.packtpub.com/virtualization-and-cloud/hands-continuous-integration-and-delivery)
    and [https://www.packtpub.com/virtualization-and-cloud/cloud-native-continuous-integration-and-delivery](https://www.packtpub.com/virtualization-and-cloud/cloud-native-continuous-integration-and-delivery)'
  prefs: []
  type: TYPE_NORMAL
