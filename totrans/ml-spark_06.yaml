- en: Building a Classification Model with Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will learn the basics of classification models, and how
    they can be used in a variety of contexts. Classification generically refers to
    classifying things into distinct categories or classes. In the case of a classification
    model, we typically wish to assign classes based on a set of features. The features
    might represent variables related to an item or object, an event or context, or
    some combination of these.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest form of classification is when we have two classes; this is referred
    to as **binary classification**. One of the classes is usually labeled as the
    **positive class** (assigned a label of 1), while the other is labeled as the
    **negative class** (assigned a label of -1, or, sometimes, 0). A simple example
    with two classes is shown in the following figure. The input features, in this
    case, have two dimensions, and the feature values are represented on the *x* and y-axes
    in the figure. Our task is to train a model that can classify new data points
    in this two-dimensional space as either one class (red) or the other (blue).
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_001.png)'
  prefs: []
  type: TYPE_IMG
- en: A simple binary classification problem
  prefs: []
  type: TYPE_NORMAL
- en: 'If we have more than two classes, we would refer to multiclass classification,
    and classes are typically labeled using integer numbers starting at 0 (for example,
    five different classes would range from label 0 to 4). An example is shown in
    the following figure. Again, the input features are assumed to be two-dimensional
    for ease of illustration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_002.png)'
  prefs: []
  type: TYPE_IMG
- en: A simple multiclass classification problem
  prefs: []
  type: TYPE_NORMAL
- en: 'Classification is a form of supervised learning, where we train a model with
    training examples that include known targets or outcomes of interest (that is,
    the model is supervised with these example outcomes). Classification models can
    be used in many situations, but a few common examples include the ones listed
    next:'
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the probability of Internet users clicking on an online advert; here,
    the classes are binary in nature (that is, click or no click)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting fraud; again, in this case, the classes are commonly binary (fraud
    or no fraud)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting defaults on loans (binary)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifying images, video, or sounds (most often multiclass, with potentially
    very many different classes)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assigning categories or tags to news articles, web pages, or other content (multiclass)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering e-mail and web spam, network intrusions, and other malicious behavior
    (binary or multiclass)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting failure situations, for example, in computer systems or networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ranking customers or users in order of probability that they might purchase
    a product or use a service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting customers or users who might stop using a product, service, or provider
    (called churn)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just a few possible use cases. In fact, it is probably safe to say
    that classification is one of the most widely used machine learning and statistical
    techniques in modern businesses, especially, online businesses.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Discuss the types of classification models available in ML library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Spark to extract appropriate features from raw input data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train a number of classification models using ML library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make predictions with our classification models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply a number of standard evaluation techniques to assess the predictive performance
    of our models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Illustrate how to improve model performance using some of the feature extraction
    approaches from [Chapter 4](6e72c765-ca1d-4959-91f4-6b741ff2f7cb.xhtml), *Obtaining,
    Processing, and Preparing Data with Spark*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explore the impact of parameter tuning on model performance, and learn how to
    use cross-validation to select the most optimal model parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Types of classification models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will explore three common classification models available in Spark: linear
    models, decision trees, and naive Bayes models. Linear models, while less complex,
    are relatively easier to scale to very large datasets. Decision tree is a powerful
    non-linear technique, which can be a little more difficult to scale up (fortunately,
    ML library takes care of this for us!) and more computationally intensive to train,
    but delivers leading performance in many situations. The naive Bayes models are
    more simple, but are easy to train efficiently and parallelize (in fact, they
    require only one pass over the dataset). They can also give reasonable performance
    in many cases where appropriate feature engineering is used. A naive Bayes model
    also provides a good baseline model against which we can measure the performance
    of other models.'
  prefs: []
  type: TYPE_NORMAL
- en: Currently, Spark's ML library supports binary classification for linear models,
    decision trees, and naive Bayes models, and multiclass classification for decision
    trees and naive Bayes models. In this book, for simplicity in illustrating the
    examples, we will focus on the binary case.
  prefs: []
  type: TYPE_NORMAL
- en: Linear models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The core idea of linear models (or generalized linear models) is that we model
    the predicted outcome of interest (often called the **target** or **dependent
    variable**) as a function of a simple linear predictor applied to the input variables
    (also referred to as features or independent variables).
  prefs: []
  type: TYPE_NORMAL
- en: '*y = f(W^Tx)*'
  prefs: []
  type: TYPE_NORMAL
- en: Here, *y* is the target variable, *w* is the vector of parameters (known as
    the **weight vector**), and *x* is the vector of input features.
  prefs: []
  type: TYPE_NORMAL
- en: '*wTx* is the linear predictor (or vector dot product) of the weight vector
    *w* and feature vector *x*. To this linear predictor, we applied a function *f*
    (called the **link function**).'
  prefs: []
  type: TYPE_NORMAL
- en: Linear models can, in fact, be used for both classification and regression,
    simply by changing the link function. Standard linear regression (covered in the
    next chapter) uses an identity link (that is, *y =W^Tx* directly), while binary
    classification uses alternative link functions as discussed here.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at the example of online advertising. In this case, the target
    variable would be 0 (often assigned the class label of -1 in mathematical treatments)
    if no click was observed for a given advert displayed on a web page (called an
    **impression**). The target variable would be 1 if a click occurred. The feature
    vector for each impression would consist of variables related to the impression
    event (such as features relating to the user, web page, advert and advertiser,
    and various other factors relating to the context of the event, such as the type
    of device used, time of the day, and geolocation).
  prefs: []
  type: TYPE_NORMAL
- en: Thus, we would like to find a model that maps a given input feature vector (advert
    impression) to a predicted outcome (click or not). To make a prediction for a
    new data point, we will take the new feature vector (which is unseen, and hence,
    we do not know what the target variable is), and compute the dot product with
    our weight vector. We will then apply the relevant link function, and the result
    is our predicted outcome (after applying a threshold to the prediction, in the
    case of some models).
  prefs: []
  type: TYPE_NORMAL
- en: Given a set of input data in the form of feature vectors and target variables,
    we would like to find the weight vector that is the best fit for the data, in
    the sense that we minimize some error between what our model predicts and the
    actual outcomes observed. This process is called model fitting, training, or optimization.
  prefs: []
  type: TYPE_NORMAL
- en: More formally, we seek to find the weight vector that minimizes the sum, over
    all the training examples, of the loss (or error) computed from some loss function.
    The loss function takes the weight vector, feature vector, and the actual outcome
    for a given training example as input, and outputs the loss. In fact, the loss
    function itself is effectively specified by the link function; hence, for a given
    type of classification or regression (that is, a given link function), there is
    a corresponding loss function.
  prefs: []
  type: TYPE_NORMAL
- en: For further details on linear models and loss functions, see the linear methods
    section related to binary classification in the *Spark Programming Guide* at [http://spark.apache.org/docs/latest/mllib-linear-methods.html#binary-classification](http://spark.apache.org/docs/latest/mllib-linear-methods.html#binary-classification)
    and [http://spark.apache.org/docs/latest/ml-classification-regression.html#linear-methods](http://spark.apache.org/docs/latest/ml-classification-regression.html#linear-methods).
  prefs: []
  type: TYPE_NORMAL
- en: Also, see the Wikipedia entry for generalized linear models at [http://en.wikipedia.org/wiki/Generalized_linear_model](http://en.wikipedia.org/wiki/Generalized_linear_model).
  prefs: []
  type: TYPE_NORMAL
- en: While a detailed treatment of linear models and loss functions is beyond the
    scope of this book, Spark ML provides two loss functions suitable to binary classification
    (you can learn more about them from the Spark documentation). The first one is
    a logistic loss, which equates to a model known as **logistic regression**, while
    the second one is the hinge loss, which is equivalent to a linear **Support Vector
    Machine** (**SVM**). Note that the SVM does not strictly fall into the statistical
    framework of generalized linear models, but can be used in the same way as it
    essentially specifies a loss and link function.
  prefs: []
  type: TYPE_NORMAL
- en: In the following figure, we show the logistic loss and hinge loss relative to
    the actual zero-one loss. The zero-one loss is the true loss for binary classification--it
    is either zero if the model predicts correctly, or one if the model predicts incorrectly.
    The reason it is not actually used is that it is not a differentiable loss function,
    so it is not possible to easily compute a gradient and, thus, very difficult to
    optimize.
  prefs: []
  type: TYPE_NORMAL
- en: 'The other loss functions are approximations to the zero-one loss, which make
    optimization possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_003.png)'
  prefs: []
  type: TYPE_IMG
- en: The logistic, hinge, and zero-one loss functions
  prefs: []
  type: TYPE_NORMAL
- en: The preceding loss diagram is adapted from the scikit-learn example at [http://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_loss_functions.html](http://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_loss_functions.html).
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logistic regression is a probabilistic model that is, its predictions are bounded
    between 0 and 1, and for binary classification, equate to the model's estimate
    of the probability of the data point belonging to the positive class. Logistic
    regression is one of the most widely used linear classification models.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned earlier, the link function used in logistic regression is this
    logit link:'
  prefs: []
  type: TYPE_NORMAL
- en: '*1 / (1 + exp(- W^Tx))   a*'
  prefs: []
  type: TYPE_NORMAL
- en: 'The related loss function for logistic regression is the logistic loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '*log(1 + exp(-y W^Tx)) *'
  prefs: []
  type: TYPE_NORMAL
- en: Here, *y* is the actual target variable (either 1 for the positive class or
    -1 for the negative class).
  prefs: []
  type: TYPE_NORMAL
- en: Multinomial logistic regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multinomial logistic regression generalizes to multiclass problems; it allows
    for more than two categories of the outcome variable. Just like binary logistic
    regression, multinomial logistic regression also uses maximum likelihood estimation
    to evaluate the probability.
  prefs: []
  type: TYPE_NORMAL
- en: Multinomial logistic regression is mainly used when the dependent variable in
    question is nominal. Multinomial logistic regression is a classification problem
    in which a linear combination of the observed features and parameters can be utilized
    to calculate the probability of each particular outcome of the dependent variable.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will use a different dataset from the one we used for our
    recommendation model, as the MovieLens data doesn't have much for us to work with
    in terms of a classification problem. We will use a dataset from a competition
    on Kaggle. The dataset was provided by StumbleUpon, and the problem relates to
    classifying whether a given web page is ephemeral (that is, short-lived, and will
    cease being popular soon), or evergreen (that is, persistently popular) on their
    web content recommendation pages.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset used here can be downloaded from [http://www.kaggle.com/c/stumbleupon/data](http://www.kaggle.com/c/stumbleupon/data).
  prefs: []
  type: TYPE_NORMAL
- en: Download the training data (`train.tsv`)-you will need to accept the terms and
    conditions before downloading the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: You can find more information about the competition at [http://www.kaggle.com/c/stumbleupon](http://www.kaggle.com/c/stumbleupon).
  prefs: []
  type: TYPE_NORMAL
- en: The code listing to get started is available at [https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_06/2.0.0/src/scala/org/sparksamples/classification/stumbleupon](https://github.com/ml-resources/spark-ml/tree/branch-ed2/Chapter_06/2.0.0/src/scala/org/sparksamples/classification/stumbleupon).
  prefs: []
  type: TYPE_NORMAL
- en: 'A glimpse of the StumbleUpon dataset stored as a temporary table using Spark
    SQLContext is given in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_004.png)'
  prefs: []
  type: TYPE_IMG
- en: Visualizing the StumbleUpon dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We ran custom logic to reduce the number of features to two, so that we can
    visualize the dataset in a two-dimensional plane, keeping the lines in the dataset
    constant.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have the data in a two-dimensional format, log scale is applied to
    both *x* and *y* for plotting convenience. In our case, we used D3.js for plotting
    as shown next. This data will be classified into two classes, and we will use
    the same base image to show the classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_005.png)'
  prefs: []
  type: TYPE_IMG
- en: Extracting features from the Kaggle/StumbleUpon evergreen classification dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we begin, we will remove the column name header from the first line
    of the file to make it easier for us to work with the data in Spark. Change to
    the directory in which you downloaded the data (referred to as `PATH` here), run
    the following command to remove the first line, and pipe the result to a new file
    called `train_noheader.tsv`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we are ready to start up our Spark shell (remember to run this command
    from your Spark installation directory):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You can type in the code that follows for the remainder of this chapter directly
    into your Spark shell.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a manner similar to what we did in the earlier chapters, we will load the
    raw training data into an RDD, and inspect it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: You can check the fields that are available by reading through the overview
    on the dataset page as mentioned earlier. The first two columns contain the URL
    and ID of the page. The next column contains some raw textual content. The next
    column contains the category assigned to the page. The next 22 columns contain
    numeric or categorical features of various kinds. The final column contains the
    target--1 is evergreen, while 0 is non-evergreen.
  prefs: []
  type: TYPE_NORMAL
- en: We'll start off with a simple approach of using only the available numeric features
    directly. As each categorical variable is binary, we already have a *1-of-k* encoding
    for these variables, so we don't need to do any further feature extraction.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the way the data is formatted, we will have to do a bit of data cleaning
    during our initial processing by trimming out the extra quotation characters (`"`).
    There are also missing values in the dataset; they are denoted by the `"?"` character.
    In this case, we will simply assign a zero value to these missing values.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we extracted the `label` variable from the last column,
    and an array of `features` for columns 5 to 25 after cleaning and dealing with
    missing values. We converted the `label` variable to an integer value, and the
    `features` variable to an `Array[Double]`. Finally, we wrapped `label` and `features`
    in a `LabeledPoint` instance, converting the features into an MLlib vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will also cache the data and count the number of data points as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You will see that the value of `numData` is `7395`.
  prefs: []
  type: TYPE_NORMAL
- en: We will explore the dataset in more detail a little later, but we will tell
    you now that there are some negative feature values in the numeric data. As we
    saw earlier, the naive Bayes model requires non-negative features, and will throw
    an error if it encounters negative values. So, for now, we will create a version
    of our input feature vectors for the naive Bayes model by setting any negative
    feature values to zero.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: StumbleUponExecutor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The StumbleUponExecutor ([https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/StumbleUponExecutor.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/StumbleUponExecutor.scala))
    object can be used to choose and run the respective classification model; for
    example, to run `LogisiticRegression` and to execute the logistic regression pipeline,
    set program argument as LR. For other commands, refer to the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s train the StumbleUpon dataset by splitting it into 80% training and
    20% testing; use `LogisticRegression` with `TrainValidationSplit` from Spark to
    build the model, and get the evaluation metrics around test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'To create a pipeline object, we will use `ParamGridBuilder`. `ParamGridBuilder`
    is used to build the param grid, which is a list of parameters to choose from
    or search over by the estimator for best model selection. You can find more details
    about it at the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://spark.apache.org/docs/2.0.0/api/java/org/apache/spark/ml/tuning/ParamGridBuilder.html](https://spark.apache.org/docs/2.0.0/api/java/org/apache/spark/ml/tuning/ParamGridBuilder.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We will use `TrainValidationSplit` for hyperparameter tuning. It evaluates each
    combination of parameters once as opposed to*k* times in the case of `CrossValidator`.
    It creates a single training, test dataset pair, and splits between the training
    and testing is done based on the `trainRatio` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: '`Trainvalidationsplit` takes `Estimator`, a set of `ParamMaps` provided in
    the `estimatorParamMaps` parameter, and `Evaluator`. Refer to the following link
    for more information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.tuning.TrainValidationSplit](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.tuning.TrainValidationSplit)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The code listing can be found at this link: [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/LogisticRegressionPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/LogisticRegressionPipeline.scala)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The visualization of predicted and actual data in a two-dimensional scatter
    plot is shown in these two screenshots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_006.png)![](img/image_06_007.png)'
  prefs: []
  type: TYPE_IMG
- en: Linear support vector machines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SVM is a powerful and popular technique for regression and classification. Unlike
    logistic regression, it is not a probabilistic model but predicts classes based
    on whether the model evaluation is positive or negative.
  prefs: []
  type: TYPE_NORMAL
- en: 'The SVM link function is the identity link, so the predicted outcome is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*y = w^Tx*'
  prefs: []
  type: TYPE_NORMAL
- en: Hence, if the evaluation of *wTx* is greater than or equal to a threshold of
    0, the SVM will assign the data point to class 1; otherwise, the SVM will assign
    it to class 0
  prefs: []
  type: TYPE_NORMAL
- en: (this threshold is a model parameter of SVM, and can be adjusted).
  prefs: []
  type: TYPE_NORMAL
- en: 'The loss function for SVM is known as the hinge loss and is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*max(0, 1 - yw^Tx)*'
  prefs: []
  type: TYPE_NORMAL
- en: SVM is a maximum margin classifier--it tries to find a weight vector such that
    the classes are separated as much as possible. It has been shown to perform well
    on many classification tasks, and the linear variant can scale to very large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: SVMs have a large amount of theory behind them, which is beyond the scope of
    this book, but you can visit [http://en.wikipedia.org/wiki/Support_vector_machine](http://en.wikipedia.org/wiki/Support_vector_machine)
    and [http://www.support-vector-machines.org/](http://www.support-vector-machines.org/)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: In the following figure, we have plotted the different decision functions for
    logistic regression (the blue line) and linear SVM (the red line) based on the
    simple binary classification example explained earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see that the SVM effectively focuses on the points that lie closest
    to the decision function (the margin lines are shown with red dashes):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_008.png)'
  prefs: []
  type: TYPE_IMG
- en: Decision functions for logistic regression and linear SVM for binary classification
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s train the StumbleUpon dataset by splitting it into 80% training and
    20% testing, use SVM from Spark to build the model, and get evaluation metrics
    around the test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The code listing is available at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/SVMPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/SVMPipeline.scala).
  prefs: []
  type: TYPE_NORMAL
- en: The naive Bayes model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Naive Bayes is a probabilistic model, which makes predictions by computing the
    probability of a data point that belongs to a given class. A naive Bayes model
    assumes that each feature makes an independent contribution to the probability
    assigned to a class (it assumes conditional independence between features).
  prefs: []
  type: TYPE_NORMAL
- en: Due to this assumption, the probability of each class becomes a function of
    the product of the probability of a feature occurring, given the class, as well
    as the probability of this class. This makes training the model tractable and
    relatively straightforward. The class prior probabilities and feature conditional
    probabilities are all estimated from the frequencies present in the dataset. Classification
    is performed by selecting the most probable class, given the features and class
    probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: An assumption is also made about the feature distributions (the parameters of
    which are estimated from the data). Spark ML implements multinomial naive Bayes,
    which assumes that the feature distribution is a multinomial distribution that
    represents non-negative frequency counts of the features.
  prefs: []
  type: TYPE_NORMAL
- en: It is suitable for binary features (for example, 1-of-k encoded categorical
    features), and is commonly used for text and document classification (where, as
    we have seen in [Chapter 4](6e72c765-ca1d-4959-91f4-6b741ff2f7cb.xhtml), *Obtaining,
    Processing, and Preparing Data with Spark*, the bag-of-words vector is a typical
    feature representation).
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at the *ML - Naive Bayes* section in the Spark documentation at
    [http://spark.apache.org/docs/latest/ml-classification-regression.html#naive-bayes](http://spark.apache.org/docs/latest/ml-classification-regression.html#naive-bayes)
    for more information.
  prefs: []
  type: TYPE_NORMAL
- en: The Wikipedia page at [http://en.wikipedia.org/wiki/Naive_Bayes_classifier](http://en.wikipedia.org/wiki/Naive_Bayes_classifier)
    has a more detailed explanation of the mathematical formulation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following figure, we have shown the decision function of naive Bayes
    on our simple binary classification example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_009.png)'
  prefs: []
  type: TYPE_IMG
- en: Decision function of naive Bayes for binary classification
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s train the StumbleUpon dataset by splitting it into 80% training and
    20% testing, use naive Bayes from Spark to build the model, and get evaluation
    metrics around the test data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The complete code listing is available at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/NaiveBayesPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/NaiveBayesPipeline.scala).
  prefs: []
  type: TYPE_NORMAL
- en: 'The visualization of predicted and actual data in a two-dimensional scatter
    plot is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_010.png)![](img/image_06_011.png)'
  prefs: []
  type: TYPE_IMG
- en: Decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Decision tree model is a powerful, non-probabilistic technique, which can
    capture more complex non-linear patterns and feature interactions. They have been
    shown to perform well on many tasks, are relatively easy to understand and interpret,
    can handle categorical and numerical features, and do not require input data to
    be scaled or standardized. They are well-suited to be included in ensemble methods
    (for example, ensembles of decision tree models, which are called decision forests).
  prefs: []
  type: TYPE_NORMAL
- en: The decision tree model constructs a tree, where the leaves represent a class
    assignment to class 0 or 1, and the branches are a set of features. In the following
    figure, we show a simple decision tree where the binary outcome is **Stay at home**
    or **Go to beach!**. The features are the weather outside.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_012.png)'
  prefs: []
  type: TYPE_IMG
- en: A simple decision tree
  prefs: []
  type: TYPE_NORMAL
- en: The decision tree algorithm is a top-down approach, which begins with a root
    node (or feature), and then selects a feature at each step that gives the best
    split of the dataset as measured by the information gain of this split. The information
    gain is computed from the node impurity (which is the extent to which the labels
    at the node are similar, or homogenous) minus the weighted sum of the impurities
    for the two child nodes that would be created by the split. For classification
    tasks, there are two measures that can be used to select the best split. These
    are Gini impurity and entropy.
  prefs: []
  type: TYPE_NORMAL
- en: See the *ML Library - Decision Tree* section in the *Spark Programming Guide*
    at [http://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier](http://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier)
    for further details on the decision tree algorithm and impurity measures for classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we have plotted the decision boundary for the
    decision tree model, as we did for the other models earlier. We can see that the
    decision tree is able to fit complex, non-linear models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_013.png)'
  prefs: []
  type: TYPE_IMG
- en: Decision function for a decision tree for binary classification
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s train the StumbleUpon dataset by splitting it into 80% training and
    20% testing, use decision trees from Spark to build the model, and get evaluation
    metrics around the test data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The code listing is available at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/DecisionTreePipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/DecisionTreePipeline.scala).
  prefs: []
  type: TYPE_NORMAL
- en: 'The visualization of predicted and actual data in a two-dimensional scatter
    plot is shown in the following figures:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_014.png)![](img/image_06_015.png)'
  prefs: []
  type: TYPE_IMG
- en: Ensembles of trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The ensemble method is a machine learning algorithm that creates a model composed
    of a set of other base models. Spark machine learning supports two major ensemble
    algorithms: RandomForest and GradientBoostedTrees.'
  prefs: []
  type: TYPE_NORMAL
- en: Random Forests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Random Forests are known as ensembles of decision trees, formed by combining
    many decision trees. Like decision trees, random forests can handle categorical
    features, support multiclass classification, and don't require feature scaling.
  prefs: []
  type: TYPE_NORMAL
- en: Spark ML supports random forests for both binary and multiclass classification
    and regression using both continuous and categorical features.
  prefs: []
  type: TYPE_NORMAL
- en: Let's train the sample lib SVM data by splitting it into 80% training and 20%
    testing, use Random Forest Classifier from Spark to build the model, and get evaluation
    metrics around the test data. The model can be persisted and loaded for later
    use.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s train the StumbleUpon dataset by splitting it into 80% training and
    20% testing, use Random Forest Trees from Spark to build the model, and get evaluation
    metrics around the test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The complete code listing is available at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/RandomForestPipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/RandomForestPipeline.scala).
  prefs: []
  type: TYPE_NORMAL
- en: 'The visualization of predicted and actual data in a two-dimensional scatter
    plot is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_016.png)![](img/image_06_017.png)'
  prefs: []
  type: TYPE_IMG
- en: Gradient-Boosted Trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Gradient-Boosted Trees are ensembles of decision trees. Gradient-Boosted Trees
    iteratively train decision trees to minimize loss function. Gradient-Boosted Trees
    handle categorical features, support multiclass classification, and don't require
    feature scaling.
  prefs: []
  type: TYPE_NORMAL
- en: Spark ML implements Gradient-Boosted Trees using the existing decision tree
    implementation. It supports both classification and regression.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s train the StumbleUpon dataset by splitting it into 80% training and
    20% testing, use Gradient-Boosted Trees from Spark to build the model, and get
    evaluation metrics around the test data as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The code listing can be found at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/GradientBoostedTreePipeline.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/GradientBoostedTreePipeline.scala).
  prefs: []
  type: TYPE_NORMAL
- en: 'The visualization of predictions in a two-dimensional scatter plot is shown
    in the following figures:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_018.png)![](img/image_06_019.png)'
  prefs: []
  type: TYPE_IMG
- en: Multilayer perceptron classifier
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The neural network is a complex adaptive system, which changes its internal
    structure based on the information flowing through it using weights. Optimizing
    the weights of a multilayered neural network is called **backpropagation**. Backpropagation
    is a bit beyond the scope of this book, and involves an activation function and
    basic calculus.
  prefs: []
  type: TYPE_NORMAL
- en: The multilayer perceptron classifier is based on a feed-forward artificial neural
    network. It consists of multiple layers. Each neural layer is completely connected
    to the next neural layer in the network, and nodes in the input layer denote the
    input data. All other nodes map inputs to the outputs by performing a linear combination
    of the inputs with the nodes' weights and bias, and by applying an activation
    or link function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s train the sample `libsvm` data by splitting it into 80% training and
    20% testing, use Multi Layer Perceptron classifier from Spark to build the model,
    and get evaluation metrics around the test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The code listing is available at [https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/MultilayerPerceptronClassifierExample.scala](https://github.com/ml-resources/spark-ml/blob/branch-ed2/Chapter_06/2.0.0/scala-spark-app/src/main/scala/org/sparksamples/classification/stumbleupon/MultilayerPerceptronClassifierExample.scala).
  prefs: []
  type: TYPE_NORMAL
- en: Before we proceed further, please note that the following examples for Feature
    Extraction and Classification use the MLLib package from Spark v1.6\. Kindly follow
    the code listing mentioned earlier to use Spark v2.0 Dataframe-based APIs. As
    of Spark 2.0, RDD-based APIs have entered maintenance mode.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting the right features from your data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might recall from [Chapter 4](6e72c765-ca1d-4959-91f4-6b741ff2f7cb.xhtml),
    *Obtaining, Processing, and Preparing Data with Spark*, that the majority of machine
    learning models operate on numerical data in the form of feature vectors. In addition,
    for supervised learning methods such as classification and regression, we need
    to provide the target variable (or variables in the case of multiclass situations)
    together with the feature vector.
  prefs: []
  type: TYPE_NORMAL
- en: Classification models in MLlib operate on instances of `LabeledPoint`, which
    is a wrapper around the target variable (called `label`) and the `feature` vector.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: While in most examples of using classification, you will come across existing
    datasets that are already in the vector format, in practice, you will usually
    start with raw data that needs to be transformed into features. As we have already
    seen, this can involve preprocessing and transformation such as binning numerical
    features, scaling and normalizing features, and using 1-of-k encodings for categorical
    features.
  prefs: []
  type: TYPE_NORMAL
- en: Training classification models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have extracted some basic features from our dataset and created
    our input RDD, we are ready to train a number of models. To compare the performance
    and use of different models, we will train a model using logistic regression,
    SVM, naive Bayes, and a decision tree. You will notice that training each model
    looks nearly identical, although each has its own specific model parameters, which
    can be set. Spark ML sets sensible defaults in most cases, but in practice, the
    best parameter setting should be selected using evaluation techniques, which we
    will cover later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Training a classification model on the Kaggle/StumbleUpon evergreen classification
    dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can now apply the models from Spark ML to our input data. First, we need
    to import the required classes, and set up some minimal input parameters for each
    model. For logistic regression and SVM, this is the number of iterations while,
    for the decision tree model, it is the maximum tree depth.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, train each model in turn. First, we will train logistic regression as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up, we will train an SVM model like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'You will now see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we will train the naive Bayes model; remember to use your special non-negative
    feature dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we will train our decision tree.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we set the mode or Algo of the decision tree to `Classification`,
    and we used the `Entropy` impurity measure.
  prefs: []
  type: TYPE_NORMAL
- en: Using classification models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We now have four models trained on our input labels and features. We will now
    see how to use these models to make predictions on our dataset. For now, we will
    use the same training data to illustrate the predict method of each model.
  prefs: []
  type: TYPE_NORMAL
- en: Generating predictions for the Kaggle/StumbleUpon evergreen classification dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will use our logistic regression model as an example (the other models are
    used in the same way):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: We saw that, for the first data point in our training dataset, the model predicted
    a label of 1 (that is, evergreen). Let's examine the true label for this data
    point.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: So, in this case, our model got it wrong!
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also make predictions in bulk by passing in an `RDD[Vector]` as input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Evaluating the performance of classification models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we make predictions using our model, as we did earlier, how do we know
    whether the predictions are good or not? We need to be able to evaluate how well
    our model performs. Evaluation metrics commonly used in binary classification
    include prediction accuracy and error, precision and recall, the area under the
    precision-recall curve, the receiver operating characteristic (ROC) curve, the
    area under ROC curve (AUC), and the F-measure.
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy and prediction error
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The prediction error for binary classification is possibly the simplest measure
    available. It is the number of training examples that are misclassified, divided
    by the total number of examples. Similarly, accuracy is the number of correctly
    classified examples divided by the total examples.
  prefs: []
  type: TYPE_NORMAL
- en: We can calculate the accuracy of our models in our training data by making predictions
    on each input feature and comparing them to the true label. We will sum up the
    number of correctly classified instances, and divide this by the total number
    of data points to get the average classification accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This gives us 51.5 percent accuracy, which doesn't look particularly impressive!
    Our model got only half of the training examples correct, which seems to be about
    as good as a random chance.
  prefs: []
  type: TYPE_NORMAL
- en: The predictions made by the model are not naturally exactly 1 or 0\. The output
    is usually a real number that must be turned into a class prediction. This is
    done through the use of a threshold in the classifier's decision or scoring function.
  prefs: []
  type: TYPE_NORMAL
- en: For example, binary logistic regression is a probabilistic model, which returns
    the estimated probability of class 1 in its scoring function. Thus, a decision
    threshold of 0.5 is typical. That is, if the estimated probability of being in
    class 1 is higher than 50 percent, the model decides to classify the point as
    class 1; otherwise, it will be classified as class 0.
  prefs: []
  type: TYPE_NORMAL
- en: The threshold itself is effectively a model parameter that can be tuned in some
    models. It also plays a role in evaluation measures, as we will see now.
  prefs: []
  type: TYPE_NORMAL
- en: 'What about the other models? Let''s compute the accuracy for the other three:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the decision tree prediction threshold needs to be specified explicitly,
    as highlighted here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now inspect the accuracy for the other three models. First, the SVM
    model, which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output for the SVM model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: Next, is our naive Bayes model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we compute the accuracy for the decision tree:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: We can see that both SVM and naive Bayes also performed quite poorly. The decision
    tree model is better with 65% accuracy, but this is still not particularly high.
  prefs: []
  type: TYPE_NORMAL
- en: Precision and recall
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In information retrieval, precision is a commonly used measure of the quality
    of the results, while recall is a measure of the completeness of the results.
  prefs: []
  type: TYPE_NORMAL
- en: In the binary classification context, precision is defined as the number of
    true positives (that is, the number of examples correctly predicted as class 1)
    divided by the sum of true positives and false positives (that is, the number
    of examples that were incorrectly predicted as class 1). Thus, we can see that
    a precision of 1.0 (or 100%) is achieved if every example predicted by the classifier
    to be class 1 is, in fact, in class 1 (that is, there are no false positives).
  prefs: []
  type: TYPE_NORMAL
- en: Recall is defined as the number of true positives divided by the sum of true
    positives and false negatives (that is, the number of examples that were in class
    1, but were predicted as class 0 by the model). We can see that a recall of 1.0
    (or 100%) is achieved if the model doesn't miss any examples that were in class
    1 (that is, there are no false negatives).
  prefs: []
  type: TYPE_NORMAL
- en: Generally, precision and recall are inversely related; often, higher precision
    is related to lower recall and vice versa. To illustrate this, assume that we
    built a model that always predicted class 1\. In this case, the model predictions
    would have no false negatives, because the model always predicts 1; it will not
    miss any of class 1\. Thus, the recall will be 1.0 for this model. On the other
    hand, the false positive rate could be very high, meaning precision would be low
    (this depends on the exact distribution of the classes in the dataset).
  prefs: []
  type: TYPE_NORMAL
- en: Precision and recall are not particularly useful as standalone metrics, but
    are typically used together to form an aggregate or averaged metric. Precision
    and recall are also dependent on the threshold selected for the model.
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, the following are some threshold levels where a model will always
    predict class 1\. Hence, it will have a recall of 1, but most likely, it will
    have low precision. At a high enough threshold, the model will always predict
    class 0\. The model will then have a recall of 0, since it cannot achieve any
    true positives, and will likely have many false negatives. Furthermore, its precision
    score will be undefined, as it will achieve zero true positives and zero false
    positives.
  prefs: []
  type: TYPE_NORMAL
- en: '**The precision-recall** (**PR**) curve shown in the following figure plots
    precision against the recall outcomes for a given model, as the decision threshold
    of the classifier is changed. The area under this PR curve is referred to as the
    average precision. Intuitively, an area under the PR curve of 1.0 will equate
    to a perfect classifier that will achieve 100 percent in both precision and recall.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_020.png)'
  prefs: []
  type: TYPE_IMG
- en: Precision-recall curve
  prefs: []
  type: TYPE_NORMAL
- en: See [http://en.wikipedia.org/wiki/Precision_and_recall](http://en.wikipedia.org/wiki/Precision_and_recall)
    and [http://en.wikipedia.org/wiki/Average_precision#Average_precision](http://en.wikipedia.org/wiki/Average_precision)
    for more details on precision, recall, and area under the PR curve.
  prefs: []
  type: TYPE_NORMAL
- en: ROC curve and AUC
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ROC curve is a concept similar to the PR curve. It is a graphical illustration
    of the true positive rate against the false positive rate for a classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '**The true positive rate** (**TPR**) is the number of true positives divided
    by the sum of true positives and false negatives. In other words, it is the ratio
    of true positives to all positive examples. This is the same as the recall we
    saw earlier, and is also commonly referred to as sensitivity.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The false positive rate** (**FPR**) is the number of false positives divided
    by the sum of false positives and true negatives (that is, the number of examples
    correctly predicted as class 0). In other words, it is the ratio of false positives
    to all negative examples.'
  prefs: []
  type: TYPE_NORMAL
- en: In a manner similar to precision and recall, the ROC curve (plotted in the following
    figure) represents the classifier's performance trade-off of TPR against FPR,
    for different decision thresholds. Each point on the curve represents a different
    threshold in the decision function for the classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/image_06_021.png)'
  prefs: []
  type: TYPE_IMG
- en: The ROC curve
  prefs: []
  type: TYPE_NORMAL
- en: The area under the ROC curve (commonly referred to as AUC) represents an average
    value. Again, an AUC of 1.0 will represent a perfect classifier. An area of 0.5
    is referred to as the random score. Thus, a model that achieves an AUC of 0.5
    is no better than guessing randomly.
  prefs: []
  type: TYPE_NORMAL
- en: As both, the area under the PR curve and the area under the ROC curve, are effectively
    normalized (with a minimum of 0 and maximum of 1), we can use these measures to
    compare models with differing parameter settings, and even compare completely
    different models. Thus, these metrics are popular for model evaluation and selection
    purposes.
  prefs: []
  type: TYPE_NORMAL
- en: 'MLlib comes with a set of built-in routines to compute the area under the PR
    and ROC curves for binary classification. Here, we will compute these metrics
    for each of our models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: As we did previously to train the naive Bayes model and computing accuracy,
    we need to use the special `nbData` version of the dataset that we created to
    compute the classification metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that because the `DecisionTreeModel` model does not implement the `ClassificationModel`
    interface that is implemented by the other three models, we need to compute the
    results separately for this model in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Your output will look similar to the one here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: We can see that all models achieve broadly similar results for the average precision
    metric.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression and SVM achieve results of around 0.5 for AUC. This indicates
    that they do no better than random chance! Our naive Bayes and decision tree models
    fare a little better, achieving an AUC of 0.58 and 0.65, respectively. Still,
    this is not a very good result in terms of binary classification performance.
  prefs: []
  type: TYPE_NORMAL
- en: While we don't cover multiclass classification here, MLlib provides a similar
    evaluation class called `MulticlassMetrics`, which provides averaged versions
    of many common metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Improving model performance and tuning parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, what went wrong? Why have our sophisticated models achieved nothing better
    than random chance? Is there a problem with our models?
  prefs: []
  type: TYPE_NORMAL
- en: Recall that we started out by just throwing the data at our model. In fact,
    we didn't even throw all our data at the model, just the numeric columns that
    were easy to use. Furthermore, we didn't do a lot of analysis on these numeric
    features.
  prefs: []
  type: TYPE_NORMAL
- en: Feature standardization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many models that we employ make inherent assumptions about the distribution
    or scale of input data. One of the most common forms of assumption is about normally-distributed
    features. Let's take a deeper look at the distribution of our features.
  prefs: []
  type: TYPE_NORMAL
- en: To do this, we can represent the feature vectors as a distributed matrix in
    MLlib, using the `RowMatrix` class. `RowMatrix` is an RDD made up of vectors,
    where each vector is a row of our matrix.
  prefs: []
  type: TYPE_NORMAL
- en: The `RowMatrix` class comes with some useful methods to operate on the matrix,
    one of which is a utility to compute statistics on the columns of the matrix.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code statement will print the mean of the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code statement will print the minimum value of the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code statement will print the maximum value of the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code statement will print the variance of the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the variance is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code statement will print the non-zero number of the matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The `computeColumnSummaryStatistics` method computes a number of statistics
    over each column of features including the mean and variance, storing each of
    these in a vector with one entry per column (that is, one entry per feature in
    our case).
  prefs: []
  type: TYPE_NORMAL
- en: 'Looking at the preceding output for mean and variance, we can see quite clearly
    that the second feature has a much higher mean and variance than some of the other
    features (you will find a few other features that are similar, and a few others
    that are more extreme). So, our data definitely does not conform to a standard
    Gaussian distribution in its raw form. To get the data in a more suitable form
    for our models, we can standardize each feature such that it has zero mean and
    unit standard deviation. We can do this by subtracting the column mean from each
    feature value, and then scaling it by dividing it by the column standard deviation
    for the feature as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*(x - μ) / sqrt(variance)*'
  prefs: []
  type: TYPE_NORMAL
- en: Practically, for each feature vector in our input dataset, we can simply perform
    an element-wise subtraction of the preceding mean vector from the feature vector,
    and then perform an element-wise division of the feature vector by the vector
    of feature standard deviations. The standard deviation vector itself can be obtained
    by performing an element-wise square root operation on the variance vector.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned in [Chapter 4](6e72c765-ca1d-4959-91f4-6b741ff2f7cb.xhtml),
    *Obtaining, Processing, and Preparing Data with Spark*, we fortunately have access
    to a convenience method from Spark's `StandardScaler` to accomplish this.
  prefs: []
  type: TYPE_NORMAL
- en: '`StandardScaler` works in much the same way as the Normalizer feature we used
    in that chapter. We will instantiate it by passing in two arguments that tell
    it whether to subtract the mean from the data, and whether to apply standard deviation
    scaling. We will then fit `StandardScaler` on our input vectors. Finally, we will
    pass in an input vector to the transform function, which will then return a normalized
    vector. We will do this within the following `map` function to preserve the `label`
    from our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Our data should now be standardized. Let's inspect the first row of the original
    and standardized features.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the preceding line of code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code will be the first row of the standardized features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the first feature has been transformed by applying the standardization
    formula. We can check this by subtracting the mean (which we computed earlier)
    from the first feature, and dividing the result by the square root of the variance
    (which we computed earlier).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'The result should be equal to the first element of our scaled vector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: We can now retrain our model using the standardized data. We will use only the
    logistic regression model to illustrate the impact of feature standardization
    (since the decision tree and naive Bayes are not impacted by this).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The result should look similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Simply through standardizing our features, we have improved the logistic regression
    performance for accuracy and AUC from 50%, no better than random, to 62%.
  prefs: []
  type: TYPE_NORMAL
- en: Additional features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have seen that we need to be careful about standardizing and potentially
    normalizing our features, and the impact on model performance can be serious.
    In this case, we used only a portion of the features available. For example, we
    completely ignored the category variable and the textual content in the boilerplate
    variable column.
  prefs: []
  type: TYPE_NORMAL
- en: This was done for ease of illustration, but let's assess the impact of adding
    an additional feature such as the category feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will inspect the categories, and form a mapping of index to category,
    which you might recognize as the basis for a 1-of-k encoding of this categorical
    feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the different categories is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code will print the number of categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we will need to create a vector of length 14 to represent this feature,
    and assign a value of 1 for the index of the relevant category for each data point.
    We can then prepend this new feature vector to the vector of other numerical features,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: You should see output similar to what is shown here. You can see that the first
    part of our feature vector is now a vector of length 14 with one nonzero entry
    at the relevant category index.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, since our raw features are not standardized, we should perform this
    transformation using the same `StandardScaler` approach that we used earlier before
    training a new model on this expanded dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: We can inspect the features before and after scaling as we did earlier.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code will print the features after scaling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'You will see the following on the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: While the original raw features were sparse (that is, there are many entries
    that are zero), if we subtract the mean from each entry, we would end up with
    a non-sparse (dense) representation, as can be seen in the preceding example.
    This is not a problem in this case as the data size is small, but often large-scale
    real-world problems have extremely sparse input data with many features (online
    advertising and text classification are good examples). In this case, it is not
    advisable to lose this sparsity, as the memory and processing requirements for
    the equivalent dense representation can quickly explode with many millions of
    features. We can use `StandardScaler` and set `withMean` to `false` to avoid this.
  prefs: []
  type: TYPE_NORMAL
- en: We're now ready to train a new logistic regression model with our expanded feature
    set, and then we will evaluate the performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see output similar to this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: By applying a feature standardization transformation to our data, we improved
    both the accuracy and AUC measures from 50% to 62%, and then, we achieved a further
    boost to 66% by adding the category feature into our model (remember to apply
    the standardization to our new feature set).
  prefs: []
  type: TYPE_NORMAL
- en: The best model performance in the competition was an AUC of 0.88906 (see [http://www.kaggle.com/c/stumbleupon/leaderboard/private](http://www.kaggle.com/c/stumbleupon/leaderboard/private)).
  prefs: []
  type: TYPE_NORMAL
- en: One approach to achieving performance almost as high is outlined at [http://www.kaggle.com/c/stumbleupon/forums/t/5680/beating-the-benchmark-leaderboard-auc-0-878](http://www.kaggle.com/c/stumbleupon/forums/t/5680/beating-the-benchmark-leaderboard-auc-0-878).
  prefs: []
  type: TYPE_NORMAL
- en: Notice that there are still features that we have not yet used; most notably,
    the text features in the boilerplate variable. The leading competition submissions
    predominantly use the boilerplate features and features based on the raw textual
    content to achieve their performance. As we saw earlier, while adding category-improved
    performance, it appears that most of the variables are not very useful as predictors,
    while the textual content turned out to be highly predictive.
  prefs: []
  type: TYPE_NORMAL
- en: Going through some of the best performing approaches for these competitions
    can give you a good idea as to how feature extraction and engineering play a critical
    role in model performance.
  prefs: []
  type: TYPE_NORMAL
- en: Using the correct form of data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another critical aspect of model performance is using the correct form of data
    for each model. Previously, we saw that applying a naive Bayes model to our numerical
    features resulted in very poor performance. Is this because the model itself is
    deficient?
  prefs: []
  type: TYPE_NORMAL
- en: In this case, recall that MLlib implements a multinomial model. This model works
    on input in the form of non-zero count data. This can include a binary representation
    of categorical features (such as the 1-of-k encoding covered previously) or frequency
    data (such as the frequency of occurrences of words in a document). The numerical
    features we used initially do not conform to this assumed input distribution,
    so it is probably unsurprising that the model did so poorly.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate this, we''ll use only the category feature, which, when 1-of-k
    encoded, is of the correct form for the model. We will create a new dataset as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will train a new naive Bayes model and evaluate its performance.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: So, by ensuring that we use the correct form of input, we have improved the
    performance of the naive Bayes model slightly from 58% to 60%.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning model parameters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous section showed the impact of feature extraction and selection on
    model performance as well as the form of input data and a model's assumptions
    around data distributions. So far, we have discussed model parameters only in
    passing, but they also play a significant role in model performance.
  prefs: []
  type: TYPE_NORMAL
- en: MLlib's default train methods use default values for the parameters of each
    model. Let's take a deeper look at them.
  prefs: []
  type: TYPE_NORMAL
- en: Linear models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Both logistic regression and SVM share the same parameters, because they use
    the same underlying optimization technique of **stochastic gradient descent**
    (**SGD**). They differ only in the loss function applied. If we take a look at
    the class definition for logistic regression in MLlib, we will see the following
    definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the arguments that can be passed to the constructor are `stepSize`,
    `numIterations`, `regParam`, and `miniBatchFraction`. Of these, all except `regParam`
    are related to the underlying optimization technique.
  prefs: []
  type: TYPE_NORMAL
- en: The instantiation code for logistic regression initializes the `gradient`, `updater`,
    and `optimizer`, and sets the relevant arguments for `optimizer` (`GradientDescent`
    in this case).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: '`LogisticGradient` sets up the logistic loss function that defines our logistic
    regression model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'While a detailed treatment of optimization techniques is beyond the scope of
    this book, MLlib provides two optimizers for linear models: SGD and L-BFGS. L-BFGS
    is often more accurate, and has fewer parameters to tune.'
  prefs: []
  type: TYPE_NORMAL
- en: SGD is the default, while L-BGFS can currently only be used directly for logistic
    regression via `LogisticRegressionWithLBFGS`. Try it out yourself, and compare
    the results to those found with SGD.
  prefs: []
  type: TYPE_NORMAL
- en: See [http://spark.apache.org/docs/latest/mllib-optimization.html](http://spark.apache.org/docs/latest/mllib-optimization.html)
    for further details.
  prefs: []
  type: TYPE_NORMAL
- en: 'To investigate the impact of the remaining parameter settings, we will create
    a helper function, which will train a logistic regression model given a set of
    parameter inputs. First, we will import the required classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will define our helper function to train a model given a set of inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will create a second helper function to take the input data and
    a classification model, and generate the relevant AUC metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: We will also cache our scaled dataset, including categories, to speed up the
  prefs: []
  type: TYPE_NORMAL
- en: 'multiple model training runs that we will be using to explore these different
    parameter settings, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: Iterations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Many machine learning methods are iterative in nature, converging to a solution
    (the optimal weight vector that minimizes the chosen loss function) over a number
    of iteration steps. SGD typically requires relatively few iterations to converge
    to a reasonable solution, but can be run for more iterations to improve the solution.
    We can see this by trying a few different settings for the `numIterations` parameter,
    and comparing the AUC results like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'Your output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: So, we can see that the number of iterations has a minor impact on the results
    once a certain number of iterations have been completed.
  prefs: []
  type: TYPE_NORMAL
- en: Step size
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In SGD, the step size parameter controls how far in the direction of the steepest
    gradient the algorithm takes a step when updating the model weight vector after
    each training example. A larger step size might speed up convergence, but a step
    size that is too large might cause problems with convergence, as good solutions
    are overshot. The learning rate determines the size of the steps we take to reach
    a (local or global) minimum. In other words, we follow the direction of the slope
    of the surface created by the objective function downhill until we reach a valley.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see the impact of changing the step size here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give us the following results, which show that increasing the step
    size too much can begin to negatively impact performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: Regularization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We briefly touched on the `Updater` class in the preceding logistic regression
    code. An `Updater` class in MLlib implements regularization. Regularization can
    help avoid over-fitting of a model to training data by effectively penalizing
    model complexity. This can be done by adding a term to the loss function, which
    acts to increase the loss as a function of the model weight vector.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization is almost always required in real use cases, but is of particular
    importance when the feature dimension is very high (that is, the effective number
    of variable weights that can be learned is high) relative to the number of training
    examples.
  prefs: []
  type: TYPE_NORMAL
- en: When regularization is absent or low, models can tend to overfit. Without regularization,
    most models will overfit on a training dataset. This is a key reason behind the
    use of cross-validation techniques for model fitting (which we will cover now).
  prefs: []
  type: TYPE_NORMAL
- en: Before we proceed further, let's define what it means to overfit and underfit
    data. Overfitting occurs when a model learns details and the noise in training
    data to an extent that negatively impacts the performance of the model on new
    data. The model should not follow the training dataset very rigorously, and in
    underfitting, a model can neither model the training data nor generalize to new
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, since applying regularization encourages simpler models, model performance
    can suffer when regularization is high through underfitting the data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The forms of regularization available in MLlib are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`SimpleUpdater`: This equates to no regularization, and is the default for
    logistic regression'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SquaredL2Updater`: This implements a regularizer based on the squared L2-norm
    of the weight vector; this is the default for SVM models'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`L1Updater`: This applies a regularizer based on the L1-norm of the weight
    vector; this can lead to sparse solutions in the weight vector (as less important
    weights are pulled towards zero)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Regularization and its relation to optimization is a broad and heavily researched
    area. Some more information is available from the following links:'
  prefs: []
  type: TYPE_NORMAL
- en: 'General regularization overview: [http://en.wikipedia.org/wiki/Regularization_(mathematics)](http://en.wikipedia.org/wiki/Regularization_(mathematics))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'L2 regularization: [http://en.wikipedia.org/wiki/Tikhonov_regularization](http://en.wikipedia.org/wiki/Tikhonov_regularization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Overfitting and underfitting: [http://en.wikipedia.org/wiki/Overfitting](http://en.wikipedia.org/wiki/Overfitting)
    Detailed overview of overfitting and L1 versus L2 regularization: [http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.9860&rep=rep1&type=pdf](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.92.9860&rep=rep1&type=pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s explore the impact of a range of regularization parameters using `SquaredL2Updater`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'Your output should look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, at low levels of regularization, there is not much impact in
    model performance. However, as we increase regularization, we can see the impact
    of under-fitting on our model evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: You will find similar results when using the L1 regularization. Give it a try
    by performing the same evaluation of regularization parameter against the AUC
    measure for `L1Updater`.
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The decision trees, which controls the maximum depth of the tree and, thus,
    the complexity of the model. Deeper trees result in more complex models that will
    be able to fit the data better.
  prefs: []
  type: TYPE_NORMAL
- en: 'For classification problems, we can also select between two measures of impurity:
    `Gini` and `Entropy`.'
  prefs: []
  type: TYPE_NORMAL
- en: Tuning tree depth and impurity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will illustrate the impact of tree depth in a similar manner as we did for
    our logistic regression model.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will need to create another helper function in the Spark shell as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: Now, we're ready to compute our AUC metric for different settings of tree depth.
    We will simply use our original dataset in this example, since we do not need
    the data to be standardized.
  prefs: []
  type: TYPE_NORMAL
- en: Note that decision tree models generally do not require features to be standardized
    or normalized, nor do they require categorical features to be binary-encoded.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, train the model using the `Entropy` impurity measure and varying tree
    depths like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'This preceding code should output the results shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will perform the same computation using the `Gini` impurity measure
    (we omitted the code as it is very similar, but it can be found in the code bundle).
    Your results should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from the preceding results, increasing the tree depth parameter
    results in a more accurate model (as expected, since the model is allowed to get
    more complex with greater tree depth). It is very likely that at higher tree depths,
    the model will overfit the dataset significantly. As the tree depth increases,
    the generalization capability reduces, where generalization is how the concepts
    learned by a machine learning model apply to an example which has not ever been
    seen by the model.
  prefs: []
  type: TYPE_NORMAL
- en: There is very little difference in performance between the two impurity measures.
  prefs: []
  type: TYPE_NORMAL
- en: The naive Bayes model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, let's see the impact of changing the `lambda` parameter for naive Bayes.
    This parameter controls additive smoothing, which handles the case when a `class`
    and `feature` value do not occur together in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: See [http://en.wikipedia.org/wiki/Additive_smoothing](http://en.wikipedia.org/wiki/Additive_smoothing)
    for more details on additive smoothing.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will take the same approach as we did earlier, first creating a convenience
    training function and training the model with varying levels of `lambda` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'The results of the training are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: We can see that `lambda` has no impact in this case, since it will not be a
    problem if the combination of feature and class label do not occur together in
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-validation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this book, we have only briefly mentioned the idea of cross-validation
    and out-of-sample testing. Cross-validation is a critical part of real-world machine
    learning, and is central to many model selection and parameter tuning pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: The general idea behind cross-validation is that we want to know how our model
    will perform on unseen data. Evaluating this on real, live data (for example,
    in a production system) is risky, because we don't really know whether the trained
    model is the best in the sense of being able to make accurate predictions on new
    data. As we saw previously with regard to regularization, our model might have
    overfit the training data, and be poor at making predictions on data it has not
    been trained on.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-validation provides a mechanism where we use part of our available dataset
    to train our model, and another part to evaluate the performance of this model.
    As the model is tested on data that it has not seen during the training phase,
    its performance, when evaluated on this part of the dataset, gives us an estimate
    as to how well our model generalizes for the new data points.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will implement a simple cross-validation evaluation approach using
    a train-test split. We will divide our dataset into two non-overlapping parts.
    The first dataset is used to train our model, and is called the **training set**.
    The second dataset, called the **test set** or **hold-out set**, is used to evaluate
    the performance of our model using our chosen evaluation measure. Common splits
    used in practice include 50/50, 60/40, and 80/20 splits, but you can use any split
    as long as the training set is not too small for the model to learn (generally,
    at least 50% is a practical minimum).
  prefs: []
  type: TYPE_NORMAL
- en: 'In many cases, three sets are created: a training set, an evaluation set (which
    is used like the aforementioned test set to tune the model parameters such as
    lambda and step size), and a test set (which is never used to train a model or
    tune any parameters, but is only used to generate an estimated true performance
    on completely unseen data).'
  prefs: []
  type: TYPE_NORMAL
- en: Here, we will explore a simple train-test split approach. There are many cross-validation
    techniques that are more exhaustive and complex.
  prefs: []
  type: TYPE_NORMAL
- en: One popular example is the **K-fold cross-validation**, where the dataset is
    split into *K* non-overlapping folds. The model is trained on *K-1* folds of data,
    and tested on the remaining, held-out fold. This is repeated *K* times, and the
    results are averaged to give the cross-validation score. The train-test split
    is effectively like a two-fold cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: Other approaches include leave-one-out cross-validation and random sampling.
    See the article at [http://en.wikipedia.org/wiki/Cross-validation_(statistics)](http://en.wikipedia.org/wiki/Cross-validation_(statistics))
    for further details.
  prefs: []
  type: TYPE_NORMAL
- en: First, we will split our dataset into a 60% training set and a 40% test set
    (we will use a constant random seed of 123 here to ensure that we get the same
    results for ease of illustration).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will compute the evaluation metric of interest (again, we will use
    AUC) for a range of regularization parameter settings. Note that here we will
    use a finer-grained step size between the evaluated regularization parameters
    to better illustrate the differences in AUC, which are very small in this case.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'This preceding code will compute the results of training on the training set,
    and the results of evaluating on the test set, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's compare this to the results of training and testing on the training
    set
  prefs: []
  type: TYPE_NORMAL
- en: '(this is what we were doing previously by training and testing on all data).
    Again, we will omit the code, as it is very similar (but it is available in the
    code bundle):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: So, we can see that when we train and evaluate our model on the same dataset,
    we generally achieve the highest performance when regularization is lower. This
    is because our model has seen all the data points, and with low levels of regularization,
    it can overfit the data set and achieve higher performance.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, when we train on one dataset and test on another, we see that,
    generally, a slightly higher level of regularization results in better test set
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: In cross-validation, we would typically find the parameter settings (including
    regularization as well as the various other parameters, such as step size and
    so on) that result in the best test set performance. We would then use these parameter
    settings to retrain the model on all of our data in order to use it to make predictions
    on new data.
  prefs: []
  type: TYPE_NORMAL
- en: Recall from [Chapter 5](d3bf76a8-26be-4db7-8310-b936d220407e.xhtml), *Building
    a Recommendation Engine with Spark* that we did not cover cross-validation. You
    can apply the same techniques we used earlier to split the ratings dataset from
    that chapter into a training and test dataset. You can then try out different
    parameter settings on the training set while evaluating the MSE and MAP performance
    metrics on the test set in a manner similar to what we did earlier. Give it a
    try!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the various classification models available in Spark
    MLlib, and we saw how to train models on input data, and how to evaluate their
    performance using standard metrics and measures. We also explored how to apply
    some of the techniques previously introduced to transform our features. Finally,
    we investigated the impact of using the correct input data format or distribution
    on model performance, and we also saw the impact of adding more data to our model,
    tuning model parameters and implementing cross-validation.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a similar approach to delve into MLlib's regression
    models.
  prefs: []
  type: TYPE_NORMAL
