- en: Chapter 8. Processing Massive Datasets with Parallel Streams – The Map and Collect
    Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章。使用并行流处理大型数据集-映射和收集模型
- en: 'In [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model*, we introduced the concept of stream, the new Java 8 feature. A stream
    is a sequence of elements that can be processed in a parallel or sequential way.
    In this chapter, you will learn how to work with streams with the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba "第7章。使用并行流处理大型数据集-映射和减少模型")中，*使用并行流处理大型数据集-映射和减少模型*，我们介绍了流的概念，这是Java
    8的新功能。流是可以以并行或顺序方式处理的元素序列。在本章中，您将学习如何处理流，内容包括以下主题：
- en: The `collect()` method
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: collect()方法
- en: The first example – searching data without indexing
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个例子-没有索引的搜索数据
- en: The second example – a recommendation system
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个例子-推荐系统
- en: The third example – common contacts in a social network
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个例子-社交网络中的常见联系人
- en: Using streams to collect data
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用流来收集数据
- en: 'In [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model*, we made an introduction to streams. Let''s remember their most important
    characteristics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba "第7章。使用并行流处理大型数据集-映射和减少模型")中，*使用并行流处理大型数据集-映射和减少模型*，我们对流进行了介绍。让我们记住它们最重要的特点：
- en: Streams' elements are not stored in the memory
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流的元素不存储在内存中
- en: Streams can't be reusable
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流不能重复使用
- en: Streams make a lazy processing of data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流对数据进行延迟处理
- en: The stream operation cannot modify the stream source
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流操作不能修改流源
- en: Streams allow you to chain operations so the output of one operation is the
    input of the next one
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流允许您链接操作，因此一个操作的输出是下一个操作的输入
- en: 'A stream is formed by the following three main elements:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 流由以下三个主要元素组成：
- en: A source that generates stream elements
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成流元素的源
- en: Zero or more intermediate operations that generate output as another stream
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零个或多个生成另一个流作为输出的中间操作
- en: One terminal operation that generates a result that could be either a simple
    object, array, collection, map, or anything else
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成结果的一个终端操作，可以是简单对象、数组、集合、映射或其他任何东西
- en: The `Stream` API provides different terminal operations, but there are two more
    significant operations for their flexibility and power. In [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model*, you learned how to use the `reduce()` method, and in this chapter, you
    will learn how to use the `collect()` method. Let's make an introduction to this
    method.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Stream API提供了不同的终端操作，但有两个更重要的操作，因为它们具有灵活性和强大性。在[第7章](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "第7章。使用并行流处理大型数据集-映射和减少模型")中，*使用并行流处理大型数据集-映射和减少模型*，您学习了如何使用reduce()方法，在本章中，您将学习如何使用collect()方法。让我们介绍一下这个方法。
- en: The collect() method
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: collect()方法
- en: 'The `collect()` method allows you to transform and group the elements of the
    stream generating a new data structure with the final results of the stream. You
    can use up to three different data types: an input data type, the data type of
    the input elements that come from the stream, an intermediate data type used to
    store the elements while the `collect()` method is running, and an output data
    type returned by the `collect()` method.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: collect()方法允许您转换和分组流的元素，生成一个新的数据结构，其中包含流的最终结果。您可以使用最多三种不同的数据类型：输入数据类型，来自流的输入元素的数据类型，用于在collect()方法运行时存储元素的中间数据类型，以及collect()方法返回的输出数据类型。
- en: 'There are two different versions of the `collect()` method. The first version
    accepts the following three functional parameters:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: collect()方法有两个不同的版本。第一个版本接受以下三个函数参数：
- en: '**Supplier**: This is a function that creates an object of the intermediate
    data type. If you use a sequential stream, this method will be called once. If
    you use a parallel stream, this method may be called many times and must produce
    a fresh object every time.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 供应商：这是一个创建中间数据类型对象的函数。如果您使用顺序流，此方法将被调用一次。如果您使用并行流，此方法可能会被多次调用，并且必须每次产生一个新的对象。
- en: '**Accumulator**: This function is called to process an input element and store
    it in the intermediate data structure.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**累加器**：此函数用于处理输入元素并将其存储在中间数据结构中。'
- en: '**Combiner**: This function is called to merge two intermediate data structures
    into one. This function will be only called with parallel streams.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组合器**：此函数用于将两个中间数据结构合并为一个。此函数仅在并行流中调用。'
- en: 'This version of the `collect()` method works with two different data types:
    the input data type of the elements that comes from the stream and the intermediate
    data type that will be used to store the intermediate elements and to return the
    final result.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个版本的collect()方法使用两种不同的数据类型：来自流的元素的输入数据类型和将用于存储中间元素并返回最终结果的中间数据类型。
- en: 'The second version of the `collect()` method accepts an object that implements
    the `Collector` interface. You can implement this interface by yourself, but it''s
    easier to use the `Collector.of()` static method. The arguments of this method
    are as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: collect()方法的第二个版本接受实现Collector接口的对象。您可以自己实现这个接口，但使用Collector.of()静态方法会更容易。此方法的参数如下：
- en: '**Supplier**: This function creates an object of the intermediate data type,
    and it works as seen earlier'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**供应商**：此函数创建中间数据类型的对象，并且它的工作方式如前所述'
- en: '**Accumulator**: This function is called to process an input element, transform
    it if necessary, and store it in the intermediate data structure'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Combiner**: This function is called to merge two intermediate data structures
    into one, and it works as seen earlier'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Finisher**: This function is called to transform the intermediate data structure
    into a final data structure if you need to make a final transformation or computation'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Characteristics**: You can use this final variable argument to indicate some
    characteristics of the collector you are creating'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Actually, there's slight difference between the two versions. The three-param
    collect accepts a combiner, that is `BiConsumer`, and it must merge the second
    intermediate result into the first one. Unlike it, this combiner is `BinaryOperator`
    and should return the combiner. Therefore, it has the freedom to merge either
    the second inside the first or the first inside the second, or create a new intermediate
    result. There is another version of the `of()` method, which accepts the same
    arguments except the finisher; in this case, the finishing transformation is not
    performed.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 'Java provides you with some predefined collectors in the `Collectors` factory
    class. You can get those collectors using one of its static methods. Some of those
    methods are:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '`averagingDouble()`, `averagingInt()`, and `averagingLong()`: This returns
    a collector that allows you to calculate the arithmetic mean of a `double`, `int`,
    or `long` function.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`groupingBy()`: This returns a collector that allows you to group the elements
    of a stream by an attribute of its objects generating a map where the keys are
    the values of the selected attribute and the values are a list of the objects
    that have a determined value.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`groupingByConcurrent()`: This is similar to the previous one except for two
    important differences. The first one is that it may work faster in the parallel
    but slower in the sequential mode than the `groupingBy()` method. The second and
    most important difference is that `groupingByConcurrent()` function is an unordered
    collector. The items in the lists are not guaranteed to be in the same order as
    in the stream. The `groupingBy()` collector on the other hand guarantees the ordering.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`joining()`: This returns a `Collector` factory class that concatenates the
    input elements into a string.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`partitioningBy()`: This returns a `Collector` factory class that makes a partition
    of the input elements based on the results of a predicate.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`summarizingDouble()`, `summarizingInt()`, and `summarizingLong()`: These return
    a `Collector` factory class that calculates summary statistics of the input elements.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`toMap()`: This returns a `Collector` factory class that allows you to transform
    input elements into a map based on two mapping functions.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`toConcurrentMap()`: This is similar to the previous one, but in a concurrent
    way. Without custom merger, `toConcurrentMap()` is just faster for parallel streams.
    As occurs with `groupingByConcurrent()`, this is an unordered collector too, whereas
    `toMap()` uses the encounter order to make the conversion.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`toList()`:This returns a `Collector` factory class that stores the input elements
    into a list.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`toCollection()`: This method allows you to accumulate the input elements into
    a new `Collection` factory class (`TreeSet`, `LinkedHashSet`, and so on) in the
    encounter order. The method receives an implementation of the `Supplier` interface
    that creates the collection as a parameter.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maxBy()` and `minBy()`: This returns a `Collector` factory class that produces
    the maximal and minimal element according to the comparator passed as a parameter.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`toSet()`: This returns a `Collector` that stores the input elements into a
    set.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first example – searching data without an index
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model*, you learned how to implement a search tool to look for the documents similar
    to an input query using an inverted index. This data structure makes the search
    operation easier and faster, but there will be situations where you will have
    to make a search operation over a big set of data and you won't have an inverted
    index to help you. In these cases, you have to process all the elements of the
    dataset to get the correct results. In this example, you will see one of these
    situations and how the `reduce()` method of the `Stream` API can help you.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba "第7章。使用并行流处理大规模数据集
    - 映射和归约模型")中，*使用并行流处理大规模数据集 - 映射和归约模型*，您学习了如何实现搜索工具，以查找与输入查询类似的文档，使用倒排索引。这种数据结构使搜索操作更容易和更快，但会有情况，您将不得不对大量数据进行搜索操作，并且没有倒排索引来帮助您。在这些情况下，您必须处理数据集的所有元素才能获得正确的结果。在本例中，您将看到其中一种情况以及`Stream`
    API的`reduce()`方法如何帮助您。
- en: To implement this example, you will use a subset of the **Amazon product co-purchasing
    network metadata** that includes information about 548,552 products sold by Amazon,
    which includes title, salesrank, and the lists of similar products, categories,
    and reviews. You can download this dataset from [https://snap.stanford.edu/data/amazon-meta.html](https://snap.stanford.edu/data/amazon-meta.html).
    We have taken the first 20,000 products and stored each product record in a separate
    file. We have changed the format of some of the fields to ease the data processing.
    All the fields have the `property:value` format.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这个例子，您将使用**亚马逊产品共购买网络元数据**的子集，其中包括亚马逊销售的548,552个产品的信息，包括标题、销售排名以及相似产品、分类和评论列表。您可以从[https://snap.stanford.edu/data/amazon-meta.html](https://snap.stanford.edu/data/amazon-meta.html)下载这个数据集。我们已经取出了前20,000个产品，并将每个产品记录存储在单独的文件中。我们已更改了一些字段的格式，以便简化数据处理。所有字段都具有`property:value`格式。
- en: Basic classes
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基本类
- en: We have some classes that are shared between the concurrent and serial versions.
    Let's see the details of each one.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一些在并发和串行版本之间共享的类。让我们看看每个类的细节。
- en: The Product class
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Product类
- en: 'The `Product` class stores the information about a product. The following are
    the `Product` classes:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`Product`类存储有关产品的信息。以下是`Product`类：'
- en: '`id`: This is a unique identifier of the product.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id`：这是产品的唯一标识符。'
- en: '`asin`: This is the Amazon standard identification number.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`asin`：这是亚马逊的标准识别号。'
- en: '`title`: This is the title of the product.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`title`：这是产品的标题。'
- en: '`group`: This is the group of the product. This attribute can take the values
    `Baby Product`, `Book`, `CD`, `DVD`, `Music`, `Software`, `Sports`, `Toy`, `Video`,
    or `Video Games`.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`group`：这是产品的组。该属性可以取值`Baby Product`、`Book`、`CD`、`DVD`、`Music`、`Software`、`Sports`、`Toy`、`Video`或`Video
    Games`。'
- en: '`salesrank`: This indicates the Amazon salesrank.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`salesrank`：这表示亚马逊的销售排名。'
- en: '`similar`: This is the number of similar items included in the file.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`similar`：这是文件中包含的相似商品的数量。'
- en: '`categories`: This is a list of `String` objects with the categories assigned
    to the product.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`categories`：这是一个包含产品分类的`String`对象列表。'
- en: '`reviews`: This is a list of `Review` objects with the reviews (user and value)
    assigned to the product.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reviews`：这是一个包含产品评论（用户和值）的`Review`对象列表。'
- en: This class includes only the definition of the attributes and the corresponding
    `getXXX()` and `setXXX()` methods, so its source code is not included.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 该类仅包括属性的定义和相应的`getXXX()`和`setXXX()`方法，因此其源代码未包含在内。
- en: The Review class
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评论类
- en: 'As we mentioned earlier, the `Product` class includes a list of `Review` objects
    with the information of the reviews made by the users to a product. This class
    stores the information of each review in the following two attributes:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，`Product`类包括一个`Review`对象列表，其中包含用户对产品的评论信息。该类将每个评论的信息存储在以下两个属性中：
- en: '`user`: The internal code of the user that made the review'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user`：进行评论的用户的内部代码'
- en: '`value`: The score given by the user to the product'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value`：用户对产品给出的评分'
- en: This class includes only the definition of the attributes and the corresponding
    `getXXX()` and `setXXX()` methods, so its source code is not included.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 该类仅包括属性的定义和相应的`getXXX()`和`setXXX()`方法，因此其源代码未包含在内。
- en: The ProductLoader class
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ProductLoader类
- en: 'The `ProductLoader` class allows you to load the information of a product from
    a file to a `Product` object. It implements the `load()` method that receives
    a `Path` object with the path to the file with the information of the product
    and returns a `Product` object. This is its source code:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`ProductLoader`类允许您从文件加载产品的信息到`Product`对象中。它实现了`load()`方法，该方法接收一个包含产品信息文件路径的`Path`对象，并返回一个`Product`对象。以下是其源代码：'
- en: '[PRE0]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The first approach – basic search
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一种方法 - 基本搜索
- en: The first approach receives a word as the input query and searches all the files
    that store the information of the products whether that word is included in one
    of the fields that define the product, no matter which. It will only show the
    name of the file that includes the word.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法接收一个单词作为输入查询，并搜索存储产品信息的所有文件，无论该单词是否包含在定义产品的字段中的一个中。它只会显示包含该单词的文件的名称。
- en: 'To implement this basic approach, we have implemented the `ConcurrentMainBasicSearch`
    class that implements the `main()` method. First, we initialize the query and
    the base path that stores all the files:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这种基本方法，我们实现了`ConcurrentMainBasicSearch`类，该类实现了`main()`方法。首先，我们初始化查询和存储所有文件的基本路径：
- en: '[PRE1]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We need only one stream to generate a list of strings with the results as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要一个流来生成以下结果的字符串列表：
- en: '[PRE2]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Our stream contains the following elements:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的流包含以下元素：
- en: We start the stream with the `walk()` method of the `Files` class passing the
    base `Path` object of our collection of files as a parameter. This method will
    return all the files as a stream and directories stored under that route.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`Files`类的`walk()`方法启动流，将我们文件集合的基本`Path`对象作为参数传递。该方法将返回所有文件和存储在该路径下的目录作为流。
- en: Then, we convert the stream into a concurrent one using the `parallel()` method.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们使用`parallel()`方法将流转换为并发流。
- en: We are only interested in the files that ends with the `.txt` extension, so
    we filter them using the `filter()` method.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们只对以`.txt`扩展名结尾的文件感兴趣，因此我们使用`filter()`方法对它们进行过滤。
- en: Finally, we use the `collect()` method to convert the stream of `Path` objects
    into `ConcurrentLinkedDeque` of `String` objects with the names of the files.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们使用`collect()`方法将`Path`对象的流转换为`ConcurrentLinkedDeque`对象，其中包含文件名的`String`对象。
- en: 'We use the three parameters version of the `collect()` method using the following
    functional parameters:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`collect()`方法的三个参数版本，使用以下功能参数：
- en: '**Supplier**: We use the `new` method reference of the `ArrayList` class to
    create a new data structure per thread to store the corresponding results.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**供应商**：我们使用`ArrayList`类的`new`方法引用来为每个线程创建一个新的数据结构，以存储相应的结果。'
- en: '**Accumulator**: We have implemented our own accumulator in the `ConcurrentStringAccumulator`
    class. We will describe the details of this class later.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**累加器**：我们在`ConcurrentStringAccumulator`类中实现了自己的累加器。稍后我们将描述这个类的细节。'
- en: '**Combiner**: We use the `addAll()` method of the `ConcurrentLinkedDeque` class
    to join two data structures. In this case, all the elements from the second collection
    will be added to the first one. The first collection will be used for further
    combining or as a final result.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组合器**：我们使用`ConcurrentLinkedDeque`类的`addAll()`方法来连接两个数据结构。在这种情况下，第二个集合中的所有元素将被添加到第一个集合中。第一个集合将用于进一步组合或作为最终结果。'
- en: 'Finally, we write the results obtained with the stream in the console:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在控制台中写入流获得的结果：
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The accumulator functional parameter will be executed each time we want to process
    a path of the stream to evaluate whether we have to include its name into the
    result list. To implement this functionality, we have implemented the `ConcurrentStringAccumulator`
    class. Let's see the details of this class.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们要处理流的路径以评估是否将其名称包含在结果列表中时，累加器功能参数将被执行。为了实现这个功能，我们实现了`ConcurrentStringAccumulator`类。让我们看看这个类的细节。
- en: The ConcurrentStringAccumulator class
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ConcurrentStringAccumulator类
- en: 'The `ConcurrentStringAccumulator` class loads a file with the information of
    a product to determine whether it contains the term of the query. It implements
    the `BiConsumer` interface because we want to use it as a parameter of the `collect()`
    method. We have parameterized that interface with the `List<String>` and `Path`
    classes:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConcurrentStringAccumulator`类加载包含产品信息的文件，以确定是否包含查询的术语。它实现了`BiConsumer`接口，因为我们希望将其用作`collect()`方法的参数。我们已经使用`List<String>`和`Path`类对该接口进行了参数化：'
- en: '[PRE4]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'It defines the query as an internal attribute that is initialized in the constructor
    as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 它将查询定义为内部属性，在构造函数中初始化如下：
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then, we implement the `accept()` method defined in the `BiConsumer` interface.
    This method receives two parameters: one of the `ConcurrentLinkedDeque<String>`
    classes and one of the `Path` classes.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们实现了`BiConsumer`接口中定义的`accept()`方法。该方法接收两个参数：`ConcurrentLinkedDeque<String>`类和`Path`类中的一个。
- en: 'To load the file and determine whether it contains the query, we use the following
    stream:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加载文件并确定它是否包含查询，我们使用以下流：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Our stream contains the following elements:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的流包含以下元素：
- en: We create the stream of `String` objects using the `lines()` method of the `Files`
    class in a try-with-resources sentence. This method receives a `Path` object that
    points to a file as a parameter and returns a stream with all the lines of the
    file.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`Files`类的`lines()`方法创建`String`对象的流，在try-with-resources语句中。该方法接收一个指向文件的`Path`对象作为参数，并返回文件的所有行的流。
- en: Then, we use the `parallel()` method to convert the stream into a concurrent
    one.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们使用`parallel()`方法将流转换为并发流。
- en: Then, we use the `map()` method to get the values of every property. As we mentioned
    in the introduction of this section, every line has the `property:value` format.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们使用`map()`方法获取每个属性的值。正如我们在本节的介绍中提到的，每行都具有`property:value`格式。
- en: Finally, we use the `anyMatch()` method to know whether there is any property
    whose value contains the query term.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们使用`anyMatch()`方法来知道是否有任何属性的值包含查询词。
- en: 'If the counter variable has a value bigger than `0`, the file contains the
    query term, and we include the name of the file in the `ConcurrentLinkedDeque`
    class with the results:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果计数变量的值大于`0`，则文件包含查询词，我们将文件名包含在结果的`ConcurrentLinkedDeque`类中：
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The second approach – advanced search
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二种方法-高级搜索
- en: 'Our basic search has some drawbacks:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的基本搜索有一些缺点：
- en: We look for the query term in all the properties, but maybe we only want to
    look for it in some of them, for example, in the title
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在所有属性中寻找查询词，但也许我们只想在其中一些属性中寻找，例如标题
- en: We only show the name of the file, but it would be more informative if we show
    additional information as the title of the product
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们只显示文件的名称，但如果我们显示额外信息，如产品的标题，将更具信息性
- en: 'To solve these problems, we are going to implement the `ConcurrentMainSearch`
    class that implements the `main()` method. First, we initialize the query and
    the base `Path` object that stores all the files:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题，我们将实现实现`main()`方法的`ConcurrentMainSearch`类。首先，我们初始化查询和存储所有文件的基本`Path`对象：
- en: '[PRE8]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, we generate a `ConcurrentLinkedDeque` class of `Product` objects using
    the following stream:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用以下流生成`Product`对象的`ConcurrentLinkedDeque`类：
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This stream has the same elements as the one we implemented in the basic approach
    with the following two changes:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这个流与我们在基本方法中实现的流具有相同的元素，有以下两个变化：
- en: In the `collect()` method, we use the `ConcurrentObjectAccumulator` class in
    the accumulator parameter
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We parameterize the `ConcurrentLinkedDeque` class with the `Product` one
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we write the results in the console, but in this case, we write the
    title of each product:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You can change this code to write whatever information about the product, as
    the salesrank or the categories.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: The most important change between this implementation and the previous one is
    the `ConcurrentObjectAccumulator` class. Let's see the details of this class.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: The ConcurrentObjectAccumulator class
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ConcurrentObjectAccumulator` class implements the `BiConsumer` interface
    parameterized with the `ConcurrentLinkedDeque<Product>` and `Path` classes because
    we want to use it in the `collect()` method. It defines an internal attribute
    named `word` to store the query term. This attribute is initialized in the constructor
    of the class:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The implementation of the `accept()` method (defined in the `BiConsumer` interface)
    is very simple:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The method receives the `Path` object that points to the file we are going to
    process as a parameter and the `ConcurrentLinkedDeque` class to store the results.
    We load the file in a `Product` object using the `ProductLoader` class and then
    check whether the title of the product contains the query term. If it contains
    the query, we add the `Product` object to the `ConcurrentLinkedDeque` class.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: A serial implementation of the example
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with the rest of the examples in this book, we have implemented a serial
    version of both versions of the search operations to verify that the concurrent
    stream allows us to get an improvement of the performance.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: You can implement the serial equivalent of the four classes described earlier
    by deleting the `parallel()` calls in the `Stream` objects to make the streams
    concurrent.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: With the source code of the book, we have included the `SerialMainBasicSearch`,
    `SerialMainSearch`, `SerialStringAccumulator`, and `SerialObjectAccumulator` classes
    that are the serial equivalent ones with the changes commented earlier.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Comparing the implementations
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have tested our implementations (the two approaches: serial and concurrent
    versions) to compare their execution times. To test them, we have used three different
    queries:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Patterns
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tree
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For every query, we have executed the two search operations (basic and object)
    for the serial and parallel stream. We have executed them using the JMH framework
    ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/))
    that allows you to implement micro benchmarks in Java. Using a framework for benchmarking
    is a better solution that simply measures time using the methods such as `currentTimeMillis()`
    or `nanoTime()`. We have executed them 10 times in a computer with a four-core
    processor and calculated the medium execution time of those 10 times. These are
    the results in milliseconds:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '|   | String search | Object search |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
- en: '|   | **Java** | **Patterns** | **Tree** | **Java** | **Patterns** | **Tree**
    |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
- en: '| **Serial** | 4318.551 | 4372.565 | 4364.674 | 4573.985 | 4588.957 | 4591.100
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
- en: '| **Concurrent** | 32402.969 | 2428.729 | 2412.747 | 2190.053 | 2173.511 |
    2173.936 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
- en: 'We can draw the following conclusions:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: The results obtained with different queries are very similar
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With serial streams, the execution time of the string search is better than
    the execution time of the object search
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With concurrent streams, the execution time of the object search is better than
    the execution time of the string search
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concurrent streams get better performance than serial ones in all cases
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we compare the concurrent and serial versions, for example, for the object
    search with the query patterns using the speed-up, we obtain the following result:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparing the implementations](img/00023.jpeg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
- en: The second example – a recommendation system
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **recommendation system** recommends a product or a service to a customer
    based on the products/services he has bought/used and on the products/services
    bought/used by the users that have bought/used the same services as him.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**推荐系统**根据客户购买/使用的产品/服务以及购买/使用与他相同服务的用户购买/使用的产品/服务向客户推荐产品或服务。'
- en: We have used the example explained in the previous section to implement a recommendation
    system. Each description of a product includes the reviews of a number of customers
    to a product. This review includes the score the customer gives to the product.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用了前一节中解释的示例来实现推荐系统。每个产品的描述都包括一些客户对产品的评论。这个评论包括客户对产品的评分。
- en: In this example, you will use these reviews to get a list of the products that
    may be interesting to a customer. We will obtain the list of the products purchased
    by a customer. In order to get that list, a list of the users who have purchased
    those products and the list of products purchased by those users are sorted using
    the average score given in the reviews. That will be the suggested products for
    the user.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，您将使用这些评论来获取对客户可能感兴趣的产品的列表。我们将获取客户购买的产品列表。为了获取该列表，我们对购买这些产品的用户列表以及这些用户购买的产品列表进行排序，使用评论中给出的平均分数。这将是用户的建议产品。
- en: Common classes
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通用类
- en: 'We have added two new classes to the ones used in the previous section. These
    classes are:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经添加了两个新的类到前一节中使用的类中。这些类是：
- en: '`ProductReview`: This class extends the product class with two new attributes'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProductReview`：这个类通过添加两个新属性扩展了产品类'
- en: '`ProductRecommendation`: This class stores the information of the recommendation
    of a product'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ProductRecommendation`：这个类存储了对产品的推荐的信息'
- en: Let's see the details of both classes.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这两个类的细节。
- en: The ProductReview class
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ProductReview类
- en: 'The `ProductReview` class extends the `Product` class adding two new attributes:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`ProductReview`类通过添加两个新属性扩展了`Product`类：'
- en: '`buyer`: This attribute stores the name of a customer of the product'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`buyer`：这个属性存储产品的客户的姓名'
- en: '`value`: This attribute stores the value given by this customer to the product
    in his review'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value`：这个属性存储客户在评论中给产品的评分'
- en: 'The class includes the definition of the attributes: the corresponding `getXXX()`
    and `setXXX()` methods, a constructor to create a `ProductReview` object from
    a `Product` object, and the values for the new attributes. It''s very simple,
    so its source code is not included.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 该类包括属性的定义：相应的`getXXX()`和`setXXX()`方法，一个从`Product`对象创建`ProductReview`对象的构造函数，以及新属性的值。它非常简单，所以它的源代码没有包含在内。
- en: The ProductRecommendation class
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ProductRecommendation类
- en: 'The `ProductRecommendation` class stores the necessary information for a product
    recommendation that includes the following:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`ProductRecommendation`类存储了产品推荐所需的信息，包括以下内容：'
- en: '`title`: The title of the product we are recommending'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`title`：我们正在推荐的产品的标题'
- en: '`value`: The score of that recommendation, which is calculated as the average
    score of all the reviews for that product'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value`：该推荐的分数，计算为该产品所有评论的平均分数'
- en: This class includes the definition of the attributes, the corresponding `getXXX()`
    and `setXXX()` methods, and the implementation of the `compareTo()` methods (the
    class implements the `Comparable` interface) that will allow us to sort the recommendations
    in descending order by its value. It's very simple, so its source code is not
    included.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类包括属性的定义，相应的`getXXX()`和`setXXX()`方法，以及`compareTo()`方法的实现（该类实现了`Comparable`接口），这将允许我们按照其值的降序对推荐进行排序。它非常简单，所以它的源代码没有包含在内。
- en: The recommendation system – the main class
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐系统 - 主类
- en: 'We have implemented our algorithm in the `ConcurrentMainRecommendation` class
    to obtain the list of recommended products to a customer. This class implements
    the `main()` method that receives as a parameter the ID of the customer whose
    recommended products we want to obtain. We have the following code:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在`ConcurrentMainRecommendation`类中实现了我们的算法，以获取推荐给客户的产品列表。这个类实现了`main()`方法，该方法接收客户的ID作为参数，我们想要获取推荐的产品。我们有以下代码：
- en: '[PRE13]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We have used different stream to transform the data in the final solution.
    The first one loads the whole list of the `Product` objects from its files:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用不同的流来转换最终解决方案中的数据。第一个加载整个`Product`对象列表的流来自其文件：
- en: '[PRE14]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This stream has the following elements:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这个流有以下元素：
- en: We start the stream with the `walk()` method of the `Files` class. This method
    will create a stream to process all the files and directories under the data directory.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`Files`类的`walk()`方法开始流。这个方法将创建一个流来处理数据目录下的所有文件和目录。
- en: Then, we use the `parallel()` method to convert the stream into a concurrent
    one.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们使用`parallel()`方法将流转换为并发流。
- en: Then, we get the files with the extension `.txt` only.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们只获取扩展名为`.txt`的文件。
- en: Finally, we use the `collect()` method to obtain a `ConcurrentLinkedDeque` class
    of the `Product` objects. It's very similar to the one used in the previous section
    with the difference that we use another accumulator object. In this case, we use
    the `ConcurrentLoaderAccumulator` class that we will describe later.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们使用`collect()`方法来获取`ConcurrentLinkedDeque`类的`Product`对象。它与前一节中使用的方法非常相似，不同之处在于我们使用了另一个累加器对象。在这种情况下，我们使用`ConcurrentLoaderAccumulator`类，稍后我们将对其进行描述。
- en: 'Once we have the list of products, we are going to organize those products
    in a map using the identifier of the customer as the key for that map. We use
    the `ProductReview` class to store the information of the customers of the products.
    We will create as many `ProductReview` objects as reviews have a `Product`. We
    use the following stream to make the transformation:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了产品列表，我们将使用客户的标识符作为地图的键来组织这些产品。我们使用`ProductReview`类来存储产品的客户信息。我们将创建与`Product`有关的评论数量相同的`ProductReview`对象。我们使用以下流进行转换：
- en: '[PRE15]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This stream has the following elements:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这个流有以下元素：
- en: We start stream with the `parallelStream()` method of the `productList` object,
    so we create a concurrent stream.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we use the `flatMap()` method to convert the stream of `Product` objects
    we have into a unique stream of `ProductReview` objects.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use the `collect()` method to generate the final map. In this case,
    we have used the predefined collector generated by the `groupingByConcurrent()`
    method of the `Collectors` class. The returned collector will generate a map where
    the keys will be the different values of the buyer attributes and the values of
    a list of `ProductReview` objects with the information of the products purchased
    by that user. This transformation will be done, as the method name indicates,
    in a concurrent way.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The next stream is the most important stream of this example. We take the products
    purchased by a customer and generate the recommendations to that customer. It''s
    a two-phase process made by one stream. In the first phase, we obtain the users
    that purchased the products purchased by the original customer. In the second
    phase, we generate a map with the products purchased by those customers with all
    the reviews of the products made by those customers. This is the code for that
    stream:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We have the following elements in that stream:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: First, we get the list of products purchased by the user and generate a concurrent
    stream using the `parallelStream()` method.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we get all the reviews for that products using the `map()` method.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this moment, we have a stream of `List<Review>`. We convert that stream into
    a stream of `Review` objects. Now we have a stream with all the reviews of the
    products purchased by the user.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we transform that stream into a stream of `String` objects with the names
    of the users who made the reviews.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we get the unique names of the users with the `distinct()` method. Now
    we have a stream of `String` objects with the names of the users who purchased
    the same products as the original user.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we use the `map()` method to transform each customer into its list of
    purchased products.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this moment, we have a stream of `List<ProductReview>` objects. We convert
    that stream into a stream of `ProductReview` objects using the `flatMap()` method.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we generate a map of products using the `collect()` method and the
    `groupingByConcurrent()` collector. The keys of the map will be the title of the
    product and the values of the list of `ProductReview` objects with the reviews
    made by the customers obtained earlier.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To finish our recommendation algorithm, we need one last step. For every product,
    we want to calculate its average score in the reviews and sort the list in descending
    order to show in the first place the top-rated products. To make that transformation,
    we use an additional stream:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We process the map obtained in the previous step. For each product, we process
    its list of reviews generating a `ProductRecommendation` object. The value of
    this object is calculated as the average value of each review using a stream using
    the `mapToInt()` method to transform the stream of `ProductReview` objects into
    a stream of integers and the `average()` method to get the average value of all
    the numbers in the string.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in the recommendations `ConcurrentLinkedDeque` class, we have a list
    of `ProductRecommendation` objects. We sort that list using an other stream with
    the `sorted()` method. We use that stream to write the final list in the console.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: The ConcurrentLoaderAccumulator class
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To implement this example, we have used the `ConcurrentLoaderAccumulator` class
    used as the accumulator function in the `collect()` method that transforms the
    stream of `Path` objects with the routes of all the files to process into the
    `ConcurrentLinkedDeque` class of `Product` objects. This is the source code of
    this class:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: It implements the `BiConsumer` interface. The `accept()` method uses the `ProducLoader`
    class (explained earlier in this chapter) to load the product information from
    the file and add the resultant `Product` object in the `ConcurrentLinkedDeque`
    class received as parameters.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 它实现了`BiConsumer`接口。`accept()`方法使用`ProducLoader`类（在本章前面已经解释过）从文件中加载产品信息，并将生成的`Product`对象添加到作为参数接收的`ConcurrentLinkedDeque`类中。
- en: The serial version
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 串行版本
- en: 'As with other examples in the book, we have implemented a serial version of
    this example to check that parallel streams improve the performance of the application.
    To implement this serial version, we have to follow these steps:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书中的其他示例一样，我们实现了此示例的串行版本，以检查并行流是否提高了应用程序的性能。要实现此串行版本，我们必须按照以下步骤进行：
- en: Replace the `ConcurrentLinkedDeque` data structure by the `List` or `ArrayList`
    data structures
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`ConcurrentLinkedDeque`数据结构替换为`List`或`ArrayList`数据结构
- en: Change the `parallelStrem()` method by the `stream()` method
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`parallelStrem()`方法替换为`stream()`方法
- en: Change the `gropingByConcurrent()` method by the `groupingBy()` method
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`gropingByConcurrent()`方法替换为`groupingBy()`方法
- en: You can see the serial version of this example in the source code of the book.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在本书的源代码中看到此示例的串行版本。
- en: Comparing the two versions
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较两个版本
- en: 'To compare the serial and concurrent versions of our recommendation system,
    we have obtained the recommended products for three users:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较我们的推荐系统的串行和并行版本，我们已经为三个用户获取了推荐的产品：
- en: '`A2JOYUS36FLG4Z`'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`A2JOYUS36FLG4Z`'
- en: '`A2JW67OY8U6HHK`'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`A2JW67OY8U6HHK`'
- en: '`A2VE83MZF98ITY`'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`A2VE83MZF98ITY`'
- en: 'For these three users, we have executed both versions using the JMH framework
    ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/))
    that allows you to implement micro benchmarks in Java. Using a framework for benchmarking
    is a better solution that simply measures time using the methods such as `currentTimeMillis()`
    or `nanoTime()`. We have executed them 10 times in a computer with a four-core
    processor and calculated the medium execution time of those 10 times. These are
    the results in milliseconds:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这三个用户，我们使用JMH框架（[http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/)）执行了两个版本，该框架允许您在Java中实现微基准测试。使用基准测试框架比简单地使用`currentTimeMillis()`或`nanoTime()`等方法来测量时间更好。我们在一个四核处理器的计算机上执行了10次，并计算了这10次的中位执行时间。以下是以毫秒为单位的结果：
- en: '|   | A2JOYUS36FLG4Z | A2JW67OY8U6HHK | A2VE83MZF98ITY |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|   | A2JOYUS36FLG4Z | A2JW67OY8U6HHK | A2VE83MZF98ITY |'
- en: '| --- | --- | --- | --- |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **Serial** | 4848.672 | 4830.051 | 4817.216 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| **串行** | 4848.672 | 4830.051 | 4817.216 |'
- en: '| **Concurrent** | 2454.003 | 2458.003 | 2527.194 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| **并行** | 2454.003 | 2458.003 | 2527.194 |'
- en: 'We can draw the following conclusions:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出以下结论：
- en: The results obtained are very similar for the three users
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所得结果对于这三个用户来说非常相似
- en: The execution time of concurrent streams is always better than the execution
    time of the sequential ones
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行流的执行时间始终优于顺序流的执行时间
- en: 'If we compare the concurrent and serial versions, for example, the second user
    using the speed-up, we obtain the following result:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们比较并行和串行版本，例如使用加速比的第二个用户，我们得到以下结果：
- en: '![Comparing the two versions](img/00024.jpeg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![比较两个版本](img/00024.jpeg)'
- en: The third example – common contacts in a social network
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三个例子 - 社交网络中的共同联系人
- en: Social networks are transforming our society and the way people relate to each
    other. Fackebook, Linkedin, Twitter, or Instagram have millions of users who use
    these networks to share life moments with their friends, make new professional
    contacts, promote their professional brand, meet new people, or simply know the
    latest trends in the world.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 社交网络正在改变我们的社会以及人们之间的关系方式。Facebook、Linkedin、Twitter或Instagram拥有数百万用户，他们使用这些网络与朋友分享生活时刻，建立新的职业联系，推广自己的专业品牌，结识新朋友，或者了解世界上的最新趋势。
- en: We can see a social network as a graph where users are the nodes of the graph
    and relations between users are the arcs of the graph. As occurs with graphs,
    there are social networks such as Facebook, where relations between users are
    undirected or bidirectional. If user *A* is connected with user *B*, user *B*
    is connected with *A* too. On the contrary, there are social networks such as
    Twitter where relations between users are directed. We say in this case that user
    *A* follows user *B*, but the contrary is not necessarily true.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将社交网络视为一个图，其中用户是图的节点，用户之间的关系是图的弧。与图一样，有些社交网络（如Facebook）中用户之间的关系是无向的或双向的。如果用户*A*与用户*B*连接，用户*B*也与*A*连接。相反，有些社交网络（如Twitter）中用户之间的关系是有向的。在这种情况下，我们说用户*A*关注用户*B*，但反之则不一定成立。
- en: In this section, we are going to implement an algorithm to calculate the common
    contacts for every pair of users in a social network with bidirectional relations
    between users. We are going to implement the algorithm described in [http://stevekrenzel.com/finding-friends-with-mapreduce](http://stevekrenzel.com/finding-friends-with-mapreduce).
    The main steps of that algorithm are as follows.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将实现一个算法来计算社交网络中每对用户的共同联系人，这些用户之间存在双向关系。我们将实现[http://stevekrenzel.com/finding-friends-with-mapreduce](http://stevekrenzel.com/finding-friends-with-mapreduce)中描述的算法。该算法的主要步骤如下。
- en: 'Our data source will be a file where we store every user with their contacts:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据源将是一个文件，其中我们存储了每个用户及其联系人：
- en: '[PRE19]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This means that user *A* has users *B*, *C*, and *D* as contacts. Take into
    account that the relations are bidirectional, so if *B* is a contact for *A*,
    *A* will be a contact for *B* too and both relations have to be represented in
    the file. So, we have elements with the following two parts:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着用户*A*的联系人是*B*、*C*和*D*。请注意，关系是双向的，因此如果*A*是*B*的联系人，*A*也将是*B*的联系人，并且这两种关系都必须在文件中表示。因此，我们有以下两个部分的元素：
- en: A user identifier
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户标识符
- en: The list of contacts for that user
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该用户的联系人列表
- en: 'In the next step, we generate a set of elements with three parts per every
    element. The three parts are:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: A user identifier
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user identifier of a friend
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list of contacts for that user
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thus, for user *A*, we will generate the following elements:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We follow the same process for all the elements. We are going to store the
    two user identifiers alphabetically sorted. Thus, for user *B*, we generate the
    following elements:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Once we have generated all the new elements, we group them for the two user
    identifiers. For example, for the tuple *A*-*B* we will generate the following
    group:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Finally, we calculate the intersection between the two lists. The resultant
    lists are the common contacts between the two users. For example, users *A* and
    *B* have in common the contacts *C* and *D*.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'To test our algorithm, we have used two datasets:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: The test sample presented earlier.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The social circles: the Facebook dataset that you can download from [https://snap.stanford.edu/data/egonets-Facebook.html](https://snap.stanford.edu/data/egonets-Facebook.html)
    contains the contact information of 4,039 users from Facebook. We have transformed
    the original data into the data format used by our example.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Base classes
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with other examples in the book, we have implemented the serial and concurrent
    versions of this example to verify that parallel streams improve the performance
    of our application. Both versions share some classes.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The Person class
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `Person` class stores the information about every person in the social
    network that includes the following:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: It's user ID, stored in the ID attribute
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list of contacts of that user, stored as a list of `String` objects in the
    contacts attribute
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The class declares both attributes and the corresponding `getXXX()` and `setXXX()`
    methods. We also need a constructor to create the list and a method named `addContact()`
    to add a single contact to the list of contacts. The source code of this class
    is very simple, so it won't be included here.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: The PersonPair class
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `PersonPair` class extends the `Person` class adding the attribute to store
    the second user identifier. We called this attribute `otherId`. This class declares
    the attribute and implements the corresponding `getXXX()` and `setXXX()` methods.
    We need an additional method named `getFullId()` that returns a string with the
    two user identifiers separated by a `,` character. The source code of this class
    is very simple, so it won't be included here.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: The DataLoader class
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `DataLoader` class loads the file with the information of the users and
    their contacts and converts it into a list of `Person` objects. It implements
    only a static method named `load()` that receives the path of the file as a `String`
    object as a parameter and returns the list of `Person` objects.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned earlier, the file has the following format:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Here, `User` is the identifier of the user, and `C1, C2, C3….CN` are the identifiers
    of the contacts of that user.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: The source code of this class is very simple, so it won't be included here.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: The concurrent version
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let's analyze the concurrent version of this algorithm.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: The CommonPersonMapper class
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `CommonPersonMapper` class is an auxiliary class that will be used later.
    It will generate all the `PersonPair` objects you can generate from a `Person`
    object. This class implements the `Function` interface parameterized with the
    `Person` and `List<PersonPair>` classes.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: 'It implements the `apply()` method defined in the `Function` interface. First,
    we initialize the `List<PersonPair>` object that we''re going to return and obtain
    and sort the list of contacts for the person:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then, we process the whole list of contacts creating the `PersonPair` object
    per contact. As we mentioned earlier, we store the two contacts sorted in alphabetical
    order. The lesser one in the ID field and the other in the `otherId` field:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Finally, we add the list of contacts to the new object and the object to the
    list of results. Once we have processed all the contacts, we return the list of
    results:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The ConcurrentSocialNetwork class
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `ConcurrentSocialNetwork` is the main class of this example. It implements
    only a static method named `bidirectionalCommonContacts()`. This method receives
    the list of persons of the social network with their contacts and returns a list
    of `PersonPair` objects with the common contacts between every pair of users who
    are contacts.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'Internally, we use two different streams to implement our algorithm. We use
    the first one to transform the input list of `Person` objects into a map. The
    keys of this map will be the two identifiers of every pair of users, and the value
    will be a list of `PersonPair` objects with the contacts of both users. So, these
    lists will always have two elements. We have the following code:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This stream has the following components:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: We create the stream using the `parallelStream()` method of the input list.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we use the `map()` method and the `CommonPersonMapper` class explained
    earlier to transform every `Person` object in a list of `PersonPair` objects with
    all the possibilities for that object.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this moment, we have a stream of `List<PersonPair>` objects. We use the `flatMap()`
    method to convert that stream into a stream of `PersonPair` objects.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use the `collect()` method to generate the map using the collector
    returned by the `groupingByConcurrent()` method using the value returned by the
    `getFullId()` method as the keys for the map.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we create a new collector using the `of()` method of the `Collectors`
    class. This collector will receive a `Collection` of string as input, use an `AtomicReference<Collection<String>>`
    as intermediate data structure, and return a `Collection` of string as the return
    type.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The first parameter of the `of()` method is the supplier function. This supplier
    is called always when we need to create an intermediate structure of data. In
    serial streams, this method is called only once, but in concurrent streams, this
    method will be called once per thread.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In our case, we simply create a new `AtomicReference` to store the `Collection<String>`
    object.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'The second parameter of the `of()` method is the accumulator function. This
    function receives an intermediate data structure and an input value as parameters:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In our case, the `acc` parameter is an `AtomicReference` and the `list` parameter
    is a `ConcurrentLinkedDeque`. We use the `updateAndGet()` method of the `AtomicReference`.
    This method updates the current value and returns the new value. If the `AtomicReference`
    is `null`, we create a new `ConcurrentLinkedDeque` with the elements of the list.
    If the `AtomicReference` is not null, it will store a `ConcurrentLinkedDeque`.
    We use the `retainAll()` method to add all the elements of the list.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: The third parameter of the `of()` method is the combiner function. This function
    is only called in parallel streams, and it receives two intermediate data structures
    as a parameter to generate only one.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: In our case, if one of the parameters is null, we return the other. Otherwise,
    we use the `retainAll()` method in the `acc1` parameter and returns the result.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: The fourth parameter of the `of()` method is the finisher function. This function
    converts the final intermediate data structure in the data structure we want to
    return. In our case, the intermediate and final data structures are the same,
    so no conversion is needed.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Finally, we use the last parameter to indicate to the collector that the collector
    is concurrent, that is to say, the accumulator function can be called concurrently
    with the same result container from multiple threads, and unordered, that is to
    say, this operation will not preserve the original order of the elements.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have defined the collector now, we have to convert the map generated
    with the first stream into a list of `PersonPair` objects with the common contacts
    of each pair of users. We use the following code:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We use the `entySet()` method to process all the elements of the map. We create
    a `parallelStream()` method to process all the `Entry` objects and then use the
    `map()` method to convert every list of `PersonPair` objects into a unique `PersonPair`
    object with the common contacts.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: For each entry, the key is the identifier of a pair of users concatenated with,
    as separator and the value is a list of two `PersonPair` objects. The first one
    contains the contacts of one user, and the other contains the contacts of the
    other user.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a stream for that list to generate the common contacts of both users
    with the following elements:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: We create the stream using the `parallelStream()` method of the list
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use the `map()` method to replace each `PersonPair()` object for the list
    of contacts stored in it
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use our collector to generate `ConcurrentLinkedDeque` with the common
    contacts
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we create a new `PersonPair` object with the identifier of both users
    and the list of common contacts. We add that object to the list of results. When
    all the elements of the map have been processed, we can return the list of results.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: The ConcurrentMain class
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ConcurrentMain` class implements the `main()` method to test our algorithm.
    As we mentioned earlier, we have tested it with the following two datasets:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: A very simple dataset to test the correctness of the algorithm
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dataset based on real data from Facebook
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is the source code of this class:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The serial version
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As with other examples in this book, we have implemented a serial version of
    this example. This version is equal to the concurrent one making the following
    changes:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: Replace the `parallelStream()` method by the `stream()` method
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace the `ConcurrentLinkedDeque` data structure by the `ArrayList` data structure
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace the `groupingByConcurrent()` method by the `groupingBy()` method
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don't use the final parameter in the `of()` method
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparing the two versions
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have executed both versions with both datasets using the JMH framework ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/))
    that allows you to implement micro benchmarks in Java. Using a framework for benchmarking
    is a better solution that simply measures time using methods such as `currentTimeMillis()`
    or `nanoTime()`. We have executed them 10 times in a computer with a four-core
    processor and calculated the medium execution time of those 10 times. These are
    the results in milliseconds:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '|   | **Example** | **Facebook** |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
- en: '| **Serial** | 0.861 | 7002.485 |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
- en: '| **Concurrent** | 1.352 | 5303.990 |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
- en: 'We can draw the following conclusions:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: For the example dataset, the serial version obtains a better execution time.
    The reason for this result is that the example dataset has few elements.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the Facebook dataset, the concurrent version obtains a better execution
    time.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we compare the concurrent and serial versions for the Facebook dataset,
    we obtain the following results:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparing the two versions](img/00025.jpeg)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
- en: Summary
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we used the different versions of the `collect()` method provided
    by the `Stream` framework to transform and group the elements of a `Stream`. This
    and [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model*, teach you how to work with the whole stream API.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Basically, the `collect()` method needs a collector that processes the data
    of the stream and generates a data structure returned by the set of aggregate
    operations that forms the stream. A collector works with three different data
    structures—the class of the input elements, an intermediate data structure used
    while processing the input elements, and a final data structure that is returned.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: We used the different versions of the `collect()` method to implement a search
    tool that must look for a query in a set of files without an inverted index, a
    recommendation system, and a tool to calculate the common contacts between two
    users in a social network.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a deep look at the concurrent data structures
    and synchronization mechanisms provided by the Java concurrent API.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
