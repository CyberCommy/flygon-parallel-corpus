- en: Chapter 8. Processing Massive Datasets with Parallel Streams – The Map and Collect
    Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model*, we introduced the concept of stream, the new Java 8 feature. A stream
    is a sequence of elements that can be processed in a parallel or sequential way.
    In this chapter, you will learn how to work with streams with the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The `collect()` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first example – searching data without indexing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second example – a recommendation system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The third example – common contacts in a social network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using streams to collect data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model*, we made an introduction to streams. Let''s remember their most important
    characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: Streams' elements are not stored in the memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streams can't be reusable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streams make a lazy processing of data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The stream operation cannot modify the stream source
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Streams allow you to chain operations so the output of one operation is the
    input of the next one
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A stream is formed by the following three main elements:'
  prefs: []
  type: TYPE_NORMAL
- en: A source that generates stream elements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero or more intermediate operations that generate output as another stream
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One terminal operation that generates a result that could be either a simple
    object, array, collection, map, or anything else
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `Stream` API provides different terminal operations, but there are two more
    significant operations for their flexibility and power. In [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model*, you learned how to use the `reduce()` method, and in this chapter, you
    will learn how to use the `collect()` method. Let's make an introduction to this
    method.
  prefs: []
  type: TYPE_NORMAL
- en: The collect() method
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `collect()` method allows you to transform and group the elements of the
    stream generating a new data structure with the final results of the stream. You
    can use up to three different data types: an input data type, the data type of
    the input elements that come from the stream, an intermediate data type used to
    store the elements while the `collect()` method is running, and an output data
    type returned by the `collect()` method.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two different versions of the `collect()` method. The first version
    accepts the following three functional parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Supplier**: This is a function that creates an object of the intermediate
    data type. If you use a sequential stream, this method will be called once. If
    you use a parallel stream, this method may be called many times and must produce
    a fresh object every time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accumulator**: This function is called to process an input element and store
    it in the intermediate data structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Combiner**: This function is called to merge two intermediate data structures
    into one. This function will be only called with parallel streams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This version of the `collect()` method works with two different data types:
    the input data type of the elements that comes from the stream and the intermediate
    data type that will be used to store the intermediate elements and to return the
    final result.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second version of the `collect()` method accepts an object that implements
    the `Collector` interface. You can implement this interface by yourself, but it''s
    easier to use the `Collector.of()` static method. The arguments of this method
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Supplier**: This function creates an object of the intermediate data type,
    and it works as seen earlier'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accumulator**: This function is called to process an input element, transform
    it if necessary, and store it in the intermediate data structure'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Combiner**: This function is called to merge two intermediate data structures
    into one, and it works as seen earlier'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Finisher**: This function is called to transform the intermediate data structure
    into a final data structure if you need to make a final transformation or computation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Characteristics**: You can use this final variable argument to indicate some
    characteristics of the collector you are creating'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Actually, there's slight difference between the two versions. The three-param
    collect accepts a combiner, that is `BiConsumer`, and it must merge the second
    intermediate result into the first one. Unlike it, this combiner is `BinaryOperator`
    and should return the combiner. Therefore, it has the freedom to merge either
    the second inside the first or the first inside the second, or create a new intermediate
    result. There is another version of the `of()` method, which accepts the same
    arguments except the finisher; in this case, the finishing transformation is not
    performed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Java provides you with some predefined collectors in the `Collectors` factory
    class. You can get those collectors using one of its static methods. Some of those
    methods are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`averagingDouble()`, `averagingInt()`, and `averagingLong()`: This returns
    a collector that allows you to calculate the arithmetic mean of a `double`, `int`,
    or `long` function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`groupingBy()`: This returns a collector that allows you to group the elements
    of a stream by an attribute of its objects generating a map where the keys are
    the values of the selected attribute and the values are a list of the objects
    that have a determined value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`groupingByConcurrent()`: This is similar to the previous one except for two
    important differences. The first one is that it may work faster in the parallel
    but slower in the sequential mode than the `groupingBy()` method. The second and
    most important difference is that `groupingByConcurrent()` function is an unordered
    collector. The items in the lists are not guaranteed to be in the same order as
    in the stream. The `groupingBy()` collector on the other hand guarantees the ordering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`joining()`: This returns a `Collector` factory class that concatenates the
    input elements into a string.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`partitioningBy()`: This returns a `Collector` factory class that makes a partition
    of the input elements based on the results of a predicate.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`summarizingDouble()`, `summarizingInt()`, and `summarizingLong()`: These return
    a `Collector` factory class that calculates summary statistics of the input elements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`toMap()`: This returns a `Collector` factory class that allows you to transform
    input elements into a map based on two mapping functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`toConcurrentMap()`: This is similar to the previous one, but in a concurrent
    way. Without custom merger, `toConcurrentMap()` is just faster for parallel streams.
    As occurs with `groupingByConcurrent()`, this is an unordered collector too, whereas
    `toMap()` uses the encounter order to make the conversion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`toList()`:This returns a `Collector` factory class that stores the input elements
    into a list.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`toCollection()`: This method allows you to accumulate the input elements into
    a new `Collection` factory class (`TreeSet`, `LinkedHashSet`, and so on) in the
    encounter order. The method receives an implementation of the `Supplier` interface
    that creates the collection as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maxBy()` and `minBy()`: This returns a `Collector` factory class that produces
    the maximal and minimal element according to the comparator passed as a parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`toSet()`: This returns a `Collector` that stores the input elements into a
    set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first example – searching data without an index
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model*, you learned how to implement a search tool to look for the documents similar
    to an input query using an inverted index. This data structure makes the search
    operation easier and faster, but there will be situations where you will have
    to make a search operation over a big set of data and you won't have an inverted
    index to help you. In these cases, you have to process all the elements of the
    dataset to get the correct results. In this example, you will see one of these
    situations and how the `reduce()` method of the `Stream` API can help you.
  prefs: []
  type: TYPE_NORMAL
- en: To implement this example, you will use a subset of the **Amazon product co-purchasing
    network metadata** that includes information about 548,552 products sold by Amazon,
    which includes title, salesrank, and the lists of similar products, categories,
    and reviews. You can download this dataset from [https://snap.stanford.edu/data/amazon-meta.html](https://snap.stanford.edu/data/amazon-meta.html).
    We have taken the first 20,000 products and stored each product record in a separate
    file. We have changed the format of some of the fields to ease the data processing.
    All the fields have the `property:value` format.
  prefs: []
  type: TYPE_NORMAL
- en: Basic classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have some classes that are shared between the concurrent and serial versions.
    Let's see the details of each one.
  prefs: []
  type: TYPE_NORMAL
- en: The Product class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `Product` class stores the information about a product. The following are
    the `Product` classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`id`: This is a unique identifier of the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`asin`: This is the Amazon standard identification number.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`title`: This is the title of the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`group`: This is the group of the product. This attribute can take the values
    `Baby Product`, `Book`, `CD`, `DVD`, `Music`, `Software`, `Sports`, `Toy`, `Video`,
    or `Video Games`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`salesrank`: This indicates the Amazon salesrank.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`similar`: This is the number of similar items included in the file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`categories`: This is a list of `String` objects with the categories assigned
    to the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`reviews`: This is a list of `Review` objects with the reviews (user and value)
    assigned to the product.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This class includes only the definition of the attributes and the corresponding
    `getXXX()` and `setXXX()` methods, so its source code is not included.
  prefs: []
  type: TYPE_NORMAL
- en: The Review class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we mentioned earlier, the `Product` class includes a list of `Review` objects
    with the information of the reviews made by the users to a product. This class
    stores the information of each review in the following two attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`user`: The internal code of the user that made the review'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`value`: The score given by the user to the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This class includes only the definition of the attributes and the corresponding
    `getXXX()` and `setXXX()` methods, so its source code is not included.
  prefs: []
  type: TYPE_NORMAL
- en: The ProductLoader class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ProductLoader` class allows you to load the information of a product from
    a file to a `Product` object. It implements the `load()` method that receives
    a `Path` object with the path to the file with the information of the product
    and returns a `Product` object. This is its source code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The first approach – basic search
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first approach receives a word as the input query and searches all the files
    that store the information of the products whether that word is included in one
    of the fields that define the product, no matter which. It will only show the
    name of the file that includes the word.
  prefs: []
  type: TYPE_NORMAL
- en: 'To implement this basic approach, we have implemented the `ConcurrentMainBasicSearch`
    class that implements the `main()` method. First, we initialize the query and
    the base path that stores all the files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We need only one stream to generate a list of strings with the results as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Our stream contains the following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: We start the stream with the `walk()` method of the `Files` class passing the
    base `Path` object of our collection of files as a parameter. This method will
    return all the files as a stream and directories stored under that route.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we convert the stream into a concurrent one using the `parallel()` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are only interested in the files that ends with the `.txt` extension, so
    we filter them using the `filter()` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use the `collect()` method to convert the stream of `Path` objects
    into `ConcurrentLinkedDeque` of `String` objects with the names of the files.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We use the three parameters version of the `collect()` method using the following
    functional parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Supplier**: We use the `new` method reference of the `ArrayList` class to
    create a new data structure per thread to store the corresponding results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accumulator**: We have implemented our own accumulator in the `ConcurrentStringAccumulator`
    class. We will describe the details of this class later.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Combiner**: We use the `addAll()` method of the `ConcurrentLinkedDeque` class
    to join two data structures. In this case, all the elements from the second collection
    will be added to the first one. The first collection will be used for further
    combining or as a final result.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we write the results obtained with the stream in the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The accumulator functional parameter will be executed each time we want to process
    a path of the stream to evaluate whether we have to include its name into the
    result list. To implement this functionality, we have implemented the `ConcurrentStringAccumulator`
    class. Let's see the details of this class.
  prefs: []
  type: TYPE_NORMAL
- en: The ConcurrentStringAccumulator class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ConcurrentStringAccumulator` class loads a file with the information of
    a product to determine whether it contains the term of the query. It implements
    the `BiConsumer` interface because we want to use it as a parameter of the `collect()`
    method. We have parameterized that interface with the `List<String>` and `Path`
    classes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'It defines the query as an internal attribute that is initialized in the constructor
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we implement the `accept()` method defined in the `BiConsumer` interface.
    This method receives two parameters: one of the `ConcurrentLinkedDeque<String>`
    classes and one of the `Path` classes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To load the file and determine whether it contains the query, we use the following
    stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Our stream contains the following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: We create the stream of `String` objects using the `lines()` method of the `Files`
    class in a try-with-resources sentence. This method receives a `Path` object that
    points to a file as a parameter and returns a stream with all the lines of the
    file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we use the `parallel()` method to convert the stream into a concurrent
    one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we use the `map()` method to get the values of every property. As we mentioned
    in the introduction of this section, every line has the `property:value` format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use the `anyMatch()` method to know whether there is any property
    whose value contains the query term.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If the counter variable has a value bigger than `0`, the file contains the
    query term, and we include the name of the file in the `ConcurrentLinkedDeque`
    class with the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The second approach – advanced search
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our basic search has some drawbacks:'
  prefs: []
  type: TYPE_NORMAL
- en: We look for the query term in all the properties, but maybe we only want to
    look for it in some of them, for example, in the title
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We only show the name of the file, but it would be more informative if we show
    additional information as the title of the product
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To solve these problems, we are going to implement the `ConcurrentMainSearch`
    class that implements the `main()` method. First, we initialize the query and
    the base `Path` object that stores all the files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we generate a `ConcurrentLinkedDeque` class of `Product` objects using
    the following stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This stream has the same elements as the one we implemented in the basic approach
    with the following two changes:'
  prefs: []
  type: TYPE_NORMAL
- en: In the `collect()` method, we use the `ConcurrentObjectAccumulator` class in
    the accumulator parameter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We parameterize the `ConcurrentLinkedDeque` class with the `Product` one
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we write the results in the console, but in this case, we write the
    title of each product:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: You can change this code to write whatever information about the product, as
    the salesrank or the categories.
  prefs: []
  type: TYPE_NORMAL
- en: The most important change between this implementation and the previous one is
    the `ConcurrentObjectAccumulator` class. Let's see the details of this class.
  prefs: []
  type: TYPE_NORMAL
- en: The ConcurrentObjectAccumulator class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ConcurrentObjectAccumulator` class implements the `BiConsumer` interface
    parameterized with the `ConcurrentLinkedDeque<Product>` and `Path` classes because
    we want to use it in the `collect()` method. It defines an internal attribute
    named `word` to store the query term. This attribute is initialized in the constructor
    of the class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The implementation of the `accept()` method (defined in the `BiConsumer` interface)
    is very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The method receives the `Path` object that points to the file we are going to
    process as a parameter and the `ConcurrentLinkedDeque` class to store the results.
    We load the file in a `Product` object using the `ProductLoader` class and then
    check whether the title of the product contains the query term. If it contains
    the query, we add the `Product` object to the `ConcurrentLinkedDeque` class.
  prefs: []
  type: TYPE_NORMAL
- en: A serial implementation of the example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with the rest of the examples in this book, we have implemented a serial
    version of both versions of the search operations to verify that the concurrent
    stream allows us to get an improvement of the performance.
  prefs: []
  type: TYPE_NORMAL
- en: You can implement the serial equivalent of the four classes described earlier
    by deleting the `parallel()` calls in the `Stream` objects to make the streams
    concurrent.
  prefs: []
  type: TYPE_NORMAL
- en: With the source code of the book, we have included the `SerialMainBasicSearch`,
    `SerialMainSearch`, `SerialStringAccumulator`, and `SerialObjectAccumulator` classes
    that are the serial equivalent ones with the changes commented earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing the implementations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have tested our implementations (the two approaches: serial and concurrent
    versions) to compare their execution times. To test them, we have used three different
    queries:'
  prefs: []
  type: TYPE_NORMAL
- en: Patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Java
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For every query, we have executed the two search operations (basic and object)
    for the serial and parallel stream. We have executed them using the JMH framework
    ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/))
    that allows you to implement micro benchmarks in Java. Using a framework for benchmarking
    is a better solution that simply measures time using the methods such as `currentTimeMillis()`
    or `nanoTime()`. We have executed them 10 times in a computer with a four-core
    processor and calculated the medium execution time of those 10 times. These are
    the results in milliseconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '|   | String search | Object search |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|   | **Java** | **Patterns** | **Tree** | **Java** | **Patterns** | **Tree**
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Serial** | 4318.551 | 4372.565 | 4364.674 | 4573.985 | 4588.957 | 4591.100
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Concurrent** | 32402.969 | 2428.729 | 2412.747 | 2190.053 | 2173.511 |
    2173.936 |'
  prefs: []
  type: TYPE_TB
- en: 'We can draw the following conclusions:'
  prefs: []
  type: TYPE_NORMAL
- en: The results obtained with different queries are very similar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With serial streams, the execution time of the string search is better than
    the execution time of the object search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With concurrent streams, the execution time of the object search is better than
    the execution time of the string search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concurrent streams get better performance than serial ones in all cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we compare the concurrent and serial versions, for example, for the object
    search with the query patterns using the speed-up, we obtain the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparing the implementations](img/00023.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The second example – a recommendation system
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A **recommendation system** recommends a product or a service to a customer
    based on the products/services he has bought/used and on the products/services
    bought/used by the users that have bought/used the same services as him.
  prefs: []
  type: TYPE_NORMAL
- en: We have used the example explained in the previous section to implement a recommendation
    system. Each description of a product includes the reviews of a number of customers
    to a product. This review includes the score the customer gives to the product.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, you will use these reviews to get a list of the products that
    may be interesting to a customer. We will obtain the list of the products purchased
    by a customer. In order to get that list, a list of the users who have purchased
    those products and the list of products purchased by those users are sorted using
    the average score given in the reviews. That will be the suggested products for
    the user.
  prefs: []
  type: TYPE_NORMAL
- en: Common classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have added two new classes to the ones used in the previous section. These
    classes are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ProductReview`: This class extends the product class with two new attributes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ProductRecommendation`: This class stores the information of the recommendation
    of a product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's see the details of both classes.
  prefs: []
  type: TYPE_NORMAL
- en: The ProductReview class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ProductReview` class extends the `Product` class adding two new attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '`buyer`: This attribute stores the name of a customer of the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`value`: This attribute stores the value given by this customer to the product
    in his review'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The class includes the definition of the attributes: the corresponding `getXXX()`
    and `setXXX()` methods, a constructor to create a `ProductReview` object from
    a `Product` object, and the values for the new attributes. It''s very simple,
    so its source code is not included.'
  prefs: []
  type: TYPE_NORMAL
- en: The ProductRecommendation class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ProductRecommendation` class stores the necessary information for a product
    recommendation that includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`title`: The title of the product we are recommending'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`value`: The score of that recommendation, which is calculated as the average
    score of all the reviews for that product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This class includes the definition of the attributes, the corresponding `getXXX()`
    and `setXXX()` methods, and the implementation of the `compareTo()` methods (the
    class implements the `Comparable` interface) that will allow us to sort the recommendations
    in descending order by its value. It's very simple, so its source code is not
    included.
  prefs: []
  type: TYPE_NORMAL
- en: The recommendation system – the main class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have implemented our algorithm in the `ConcurrentMainRecommendation` class
    to obtain the list of recommended products to a customer. This class implements
    the `main()` method that receives as a parameter the ID of the customer whose
    recommended products we want to obtain. We have the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We have used different stream to transform the data in the final solution.
    The first one loads the whole list of the `Product` objects from its files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This stream has the following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: We start the stream with the `walk()` method of the `Files` class. This method
    will create a stream to process all the files and directories under the data directory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we use the `parallel()` method to convert the stream into a concurrent
    one.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we get the files with the extension `.txt` only.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use the `collect()` method to obtain a `ConcurrentLinkedDeque` class
    of the `Product` objects. It's very similar to the one used in the previous section
    with the difference that we use another accumulator object. In this case, we use
    the `ConcurrentLoaderAccumulator` class that we will describe later.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once we have the list of products, we are going to organize those products
    in a map using the identifier of the customer as the key for that map. We use
    the `ProductReview` class to store the information of the customers of the products.
    We will create as many `ProductReview` objects as reviews have a `Product`. We
    use the following stream to make the transformation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This stream has the following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: We start stream with the `parallelStream()` method of the `productList` object,
    so we create a concurrent stream.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we use the `flatMap()` method to convert the stream of `Product` objects
    we have into a unique stream of `ProductReview` objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use the `collect()` method to generate the final map. In this case,
    we have used the predefined collector generated by the `groupingByConcurrent()`
    method of the `Collectors` class. The returned collector will generate a map where
    the keys will be the different values of the buyer attributes and the values of
    a list of `ProductReview` objects with the information of the products purchased
    by that user. This transformation will be done, as the method name indicates,
    in a concurrent way.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The next stream is the most important stream of this example. We take the products
    purchased by a customer and generate the recommendations to that customer. It''s
    a two-phase process made by one stream. In the first phase, we obtain the users
    that purchased the products purchased by the original customer. In the second
    phase, we generate a map with the products purchased by those customers with all
    the reviews of the products made by those customers. This is the code for that
    stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We have the following elements in that stream:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we get the list of products purchased by the user and generate a concurrent
    stream using the `parallelStream()` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we get all the reviews for that products using the `map()` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this moment, we have a stream of `List<Review>`. We convert that stream into
    a stream of `Review` objects. Now we have a stream with all the reviews of the
    products purchased by the user.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we transform that stream into a stream of `String` objects with the names
    of the users who made the reviews.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we get the unique names of the users with the `distinct()` method. Now
    we have a stream of `String` objects with the names of the users who purchased
    the same products as the original user.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we use the `map()` method to transform each customer into its list of
    purchased products.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this moment, we have a stream of `List<ProductReview>` objects. We convert
    that stream into a stream of `ProductReview` objects using the `flatMap()` method.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we generate a map of products using the `collect()` method and the
    `groupingByConcurrent()` collector. The keys of the map will be the title of the
    product and the values of the list of `ProductReview` objects with the reviews
    made by the customers obtained earlier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To finish our recommendation algorithm, we need one last step. For every product,
    we want to calculate its average score in the reviews and sort the list in descending
    order to show in the first place the top-rated products. To make that transformation,
    we use an additional stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We process the map obtained in the previous step. For each product, we process
    its list of reviews generating a `ProductRecommendation` object. The value of
    this object is calculated as the average value of each review using a stream using
    the `mapToInt()` method to transform the stream of `ProductReview` objects into
    a stream of integers and the `average()` method to get the average value of all
    the numbers in the string.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in the recommendations `ConcurrentLinkedDeque` class, we have a list
    of `ProductRecommendation` objects. We sort that list using an other stream with
    the `sorted()` method. We use that stream to write the final list in the console.
  prefs: []
  type: TYPE_NORMAL
- en: The ConcurrentLoaderAccumulator class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To implement this example, we have used the `ConcurrentLoaderAccumulator` class
    used as the accumulator function in the `collect()` method that transforms the
    stream of `Path` objects with the routes of all the files to process into the
    `ConcurrentLinkedDeque` class of `Product` objects. This is the source code of
    this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: It implements the `BiConsumer` interface. The `accept()` method uses the `ProducLoader`
    class (explained earlier in this chapter) to load the product information from
    the file and add the resultant `Product` object in the `ConcurrentLinkedDeque`
    class received as parameters.
  prefs: []
  type: TYPE_NORMAL
- en: The serial version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As with other examples in the book, we have implemented a serial version of
    this example to check that parallel streams improve the performance of the application.
    To implement this serial version, we have to follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Replace the `ConcurrentLinkedDeque` data structure by the `List` or `ArrayList`
    data structures
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the `parallelStrem()` method by the `stream()` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the `gropingByConcurrent()` method by the `groupingBy()` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can see the serial version of this example in the source code of the book.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing the two versions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To compare the serial and concurrent versions of our recommendation system,
    we have obtained the recommended products for three users:'
  prefs: []
  type: TYPE_NORMAL
- en: '`A2JOYUS36FLG4Z`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`A2JW67OY8U6HHK`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`A2VE83MZF98ITY`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For these three users, we have executed both versions using the JMH framework
    ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/))
    that allows you to implement micro benchmarks in Java. Using a framework for benchmarking
    is a better solution that simply measures time using the methods such as `currentTimeMillis()`
    or `nanoTime()`. We have executed them 10 times in a computer with a four-core
    processor and calculated the medium execution time of those 10 times. These are
    the results in milliseconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '|   | A2JOYUS36FLG4Z | A2JW67OY8U6HHK | A2VE83MZF98ITY |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Serial** | 4848.672 | 4830.051 | 4817.216 |'
  prefs: []
  type: TYPE_TB
- en: '| **Concurrent** | 2454.003 | 2458.003 | 2527.194 |'
  prefs: []
  type: TYPE_TB
- en: 'We can draw the following conclusions:'
  prefs: []
  type: TYPE_NORMAL
- en: The results obtained are very similar for the three users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The execution time of concurrent streams is always better than the execution
    time of the sequential ones
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we compare the concurrent and serial versions, for example, the second user
    using the speed-up, we obtain the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparing the two versions](img/00024.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: The third example – common contacts in a social network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Social networks are transforming our society and the way people relate to each
    other. Fackebook, Linkedin, Twitter, or Instagram have millions of users who use
    these networks to share life moments with their friends, make new professional
    contacts, promote their professional brand, meet new people, or simply know the
    latest trends in the world.
  prefs: []
  type: TYPE_NORMAL
- en: We can see a social network as a graph where users are the nodes of the graph
    and relations between users are the arcs of the graph. As occurs with graphs,
    there are social networks such as Facebook, where relations between users are
    undirected or bidirectional. If user *A* is connected with user *B*, user *B*
    is connected with *A* too. On the contrary, there are social networks such as
    Twitter where relations between users are directed. We say in this case that user
    *A* follows user *B*, but the contrary is not necessarily true.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we are going to implement an algorithm to calculate the common
    contacts for every pair of users in a social network with bidirectional relations
    between users. We are going to implement the algorithm described in [http://stevekrenzel.com/finding-friends-with-mapreduce](http://stevekrenzel.com/finding-friends-with-mapreduce).
    The main steps of that algorithm are as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our data source will be a file where we store every user with their contacts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'This means that user *A* has users *B*, *C*, and *D* as contacts. Take into
    account that the relations are bidirectional, so if *B* is a contact for *A*,
    *A* will be a contact for *B* too and both relations have to be represented in
    the file. So, we have elements with the following two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: A user identifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list of contacts for that user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the next step, we generate a set of elements with three parts per every
    element. The three parts are:'
  prefs: []
  type: TYPE_NORMAL
- en: A user identifier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user identifier of a friend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list of contacts for that user
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thus, for user *A*, we will generate the following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We follow the same process for all the elements. We are going to store the
    two user identifiers alphabetically sorted. Thus, for user *B*, we generate the
    following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we have generated all the new elements, we group them for the two user
    identifiers. For example, for the tuple *A*-*B* we will generate the following
    group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we calculate the intersection between the two lists. The resultant
    lists are the common contacts between the two users. For example, users *A* and
    *B* have in common the contacts *C* and *D*.
  prefs: []
  type: TYPE_NORMAL
- en: 'To test our algorithm, we have used two datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: The test sample presented earlier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The social circles: the Facebook dataset that you can download from [https://snap.stanford.edu/data/egonets-Facebook.html](https://snap.stanford.edu/data/egonets-Facebook.html)
    contains the contact information of 4,039 users from Facebook. We have transformed
    the original data into the data format used by our example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Base classes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As with other examples in the book, we have implemented the serial and concurrent
    versions of this example to verify that parallel streams improve the performance
    of our application. Both versions share some classes.
  prefs: []
  type: TYPE_NORMAL
- en: The Person class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `Person` class stores the information about every person in the social
    network that includes the following:'
  prefs: []
  type: TYPE_NORMAL
- en: It's user ID, stored in the ID attribute
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list of contacts of that user, stored as a list of `String` objects in the
    contacts attribute
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The class declares both attributes and the corresponding `getXXX()` and `setXXX()`
    methods. We also need a constructor to create the list and a method named `addContact()`
    to add a single contact to the list of contacts. The source code of this class
    is very simple, so it won't be included here.
  prefs: []
  type: TYPE_NORMAL
- en: The PersonPair class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `PersonPair` class extends the `Person` class adding the attribute to store
    the second user identifier. We called this attribute `otherId`. This class declares
    the attribute and implements the corresponding `getXXX()` and `setXXX()` methods.
    We need an additional method named `getFullId()` that returns a string with the
    two user identifiers separated by a `,` character. The source code of this class
    is very simple, so it won't be included here.
  prefs: []
  type: TYPE_NORMAL
- en: The DataLoader class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `DataLoader` class loads the file with the information of the users and
    their contacts and converts it into a list of `Person` objects. It implements
    only a static method named `load()` that receives the path of the file as a `String`
    object as a parameter and returns the list of `Person` objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned earlier, the file has the following format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Here, `User` is the identifier of the user, and `C1, C2, C3….CN` are the identifiers
    of the contacts of that user.
  prefs: []
  type: TYPE_NORMAL
- en: The source code of this class is very simple, so it won't be included here.
  prefs: []
  type: TYPE_NORMAL
- en: The concurrent version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, let's analyze the concurrent version of this algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The CommonPersonMapper class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `CommonPersonMapper` class is an auxiliary class that will be used later.
    It will generate all the `PersonPair` objects you can generate from a `Person`
    object. This class implements the `Function` interface parameterized with the
    `Person` and `List<PersonPair>` classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'It implements the `apply()` method defined in the `Function` interface. First,
    we initialize the `List<PersonPair>` object that we''re going to return and obtain
    and sort the list of contacts for the person:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we process the whole list of contacts creating the `PersonPair` object
    per contact. As we mentioned earlier, we store the two contacts sorted in alphabetical
    order. The lesser one in the ID field and the other in the `otherId` field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we add the list of contacts to the new object and the object to the
    list of results. Once we have processed all the contacts, we return the list of
    results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The ConcurrentSocialNetwork class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `ConcurrentSocialNetwork` is the main class of this example. It implements
    only a static method named `bidirectionalCommonContacts()`. This method receives
    the list of persons of the social network with their contacts and returns a list
    of `PersonPair` objects with the common contacts between every pair of users who
    are contacts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Internally, we use two different streams to implement our algorithm. We use
    the first one to transform the input list of `Person` objects into a map. The
    keys of this map will be the two identifiers of every pair of users, and the value
    will be a list of `PersonPair` objects with the contacts of both users. So, these
    lists will always have two elements. We have the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This stream has the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: We create the stream using the `parallelStream()` method of the input list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we use the `map()` method and the `CommonPersonMapper` class explained
    earlier to transform every `Person` object in a list of `PersonPair` objects with
    all the possibilities for that object.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this moment, we have a stream of `List<PersonPair>` objects. We use the `flatMap()`
    method to convert that stream into a stream of `PersonPair` objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use the `collect()` method to generate the map using the collector
    returned by the `groupingByConcurrent()` method using the value returned by the
    `getFullId()` method as the keys for the map.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, we create a new collector using the `of()` method of the `Collectors`
    class. This collector will receive a `Collection` of string as input, use an `AtomicReference<Collection<String>>`
    as intermediate data structure, and return a `Collection` of string as the return
    type.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The first parameter of the `of()` method is the supplier function. This supplier
    is called always when we need to create an intermediate structure of data. In
    serial streams, this method is called only once, but in concurrent streams, this
    method will be called once per thread.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: In our case, we simply create a new `AtomicReference` to store the `Collection<String>`
    object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second parameter of the `of()` method is the accumulator function. This
    function receives an intermediate data structure and an input value as parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: In our case, the `acc` parameter is an `AtomicReference` and the `list` parameter
    is a `ConcurrentLinkedDeque`. We use the `updateAndGet()` method of the `AtomicReference`.
    This method updates the current value and returns the new value. If the `AtomicReference`
    is `null`, we create a new `ConcurrentLinkedDeque` with the elements of the list.
    If the `AtomicReference` is not null, it will store a `ConcurrentLinkedDeque`.
    We use the `retainAll()` method to add all the elements of the list.
  prefs: []
  type: TYPE_NORMAL
- en: The third parameter of the `of()` method is the combiner function. This function
    is only called in parallel streams, and it receives two intermediate data structures
    as a parameter to generate only one.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: In our case, if one of the parameters is null, we return the other. Otherwise,
    we use the `retainAll()` method in the `acc1` parameter and returns the result.
  prefs: []
  type: TYPE_NORMAL
- en: The fourth parameter of the `of()` method is the finisher function. This function
    converts the final intermediate data structure in the data structure we want to
    return. In our case, the intermediate and final data structures are the same,
    so no conversion is needed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we use the last parameter to indicate to the collector that the collector
    is concurrent, that is to say, the accumulator function can be called concurrently
    with the same result container from multiple threads, and unordered, that is to
    say, this operation will not preserve the original order of the elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have defined the collector now, we have to convert the map generated
    with the first stream into a list of `PersonPair` objects with the common contacts
    of each pair of users. We use the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: We use the `entySet()` method to process all the elements of the map. We create
    a `parallelStream()` method to process all the `Entry` objects and then use the
    `map()` method to convert every list of `PersonPair` objects into a unique `PersonPair`
    object with the common contacts.
  prefs: []
  type: TYPE_NORMAL
- en: For each entry, the key is the identifier of a pair of users concatenated with,
    as separator and the value is a list of two `PersonPair` objects. The first one
    contains the contacts of one user, and the other contains the contacts of the
    other user.
  prefs: []
  type: TYPE_NORMAL
- en: 'We create a stream for that list to generate the common contacts of both users
    with the following elements:'
  prefs: []
  type: TYPE_NORMAL
- en: We create the stream using the `parallelStream()` method of the list
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use the `map()` method to replace each `PersonPair()` object for the list
    of contacts stored in it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use our collector to generate `ConcurrentLinkedDeque` with the common
    contacts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we create a new `PersonPair` object with the identifier of both users
    and the list of common contacts. We add that object to the list of results. When
    all the elements of the map have been processed, we can return the list of results.
  prefs: []
  type: TYPE_NORMAL
- en: The ConcurrentMain class
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ConcurrentMain` class implements the `main()` method to test our algorithm.
    As we mentioned earlier, we have tested it with the following two datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: A very simple dataset to test the correctness of the algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A dataset based on real data from Facebook
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is the source code of this class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The serial version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As with other examples in this book, we have implemented a serial version of
    this example. This version is equal to the concurrent one making the following
    changes:'
  prefs: []
  type: TYPE_NORMAL
- en: Replace the `parallelStream()` method by the `stream()` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace the `ConcurrentLinkedDeque` data structure by the `ArrayList` data structure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace the `groupingByConcurrent()` method by the `groupingBy()` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don't use the final parameter in the `of()` method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparing the two versions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have executed both versions with both datasets using the JMH framework ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/))
    that allows you to implement micro benchmarks in Java. Using a framework for benchmarking
    is a better solution that simply measures time using methods such as `currentTimeMillis()`
    or `nanoTime()`. We have executed them 10 times in a computer with a four-core
    processor and calculated the medium execution time of those 10 times. These are
    the results in milliseconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '|   | **Example** | **Facebook** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Serial** | 0.861 | 7002.485 |'
  prefs: []
  type: TYPE_TB
- en: '| **Concurrent** | 1.352 | 5303.990 |'
  prefs: []
  type: TYPE_TB
- en: 'We can draw the following conclusions:'
  prefs: []
  type: TYPE_NORMAL
- en: For the example dataset, the serial version obtains a better execution time.
    The reason for this result is that the example dataset has few elements.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the Facebook dataset, the concurrent version obtains a better execution
    time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we compare the concurrent and serial versions for the Facebook dataset,
    we obtain the following results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparing the two versions](img/00025.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we used the different versions of the `collect()` method provided
    by the `Stream` framework to transform and group the elements of a `Stream`. This
    and [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model*, teach you how to work with the whole stream API.
  prefs: []
  type: TYPE_NORMAL
- en: Basically, the `collect()` method needs a collector that processes the data
    of the stream and generates a data structure returned by the set of aggregate
    operations that forms the stream. A collector works with three different data
    structures—the class of the input elements, an intermediate data structure used
    while processing the input elements, and a final data structure that is returned.
  prefs: []
  type: TYPE_NORMAL
- en: We used the different versions of the `collect()` method to implement a search
    tool that must look for a query in a set of files without an inverted index, a
    recommendation system, and a tool to calculate the common contacts between two
    users in a social network.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a deep look at the concurrent data structures
    and synchronization mechanisms provided by the Java concurrent API.
  prefs: []
  type: TYPE_NORMAL
